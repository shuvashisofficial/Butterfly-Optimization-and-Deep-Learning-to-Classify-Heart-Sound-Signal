{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T16:59:58.496135Z",
     "iopub.status.busy": "2024-03-23T16:59:58.495786Z",
     "iopub.status.idle": "2024-03-23T16:59:58.504929Z",
     "shell.execute_reply": "2024-03-23T16:59:58.503845Z",
     "shell.execute_reply.started": "2024-03-23T16:59:58.496110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import pydot\n",
    "import kymatio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from kymatio import Scattering1D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:00.547182Z",
     "iopub.status.busy": "2024-03-23T17:00:00.546814Z",
     "iopub.status.idle": "2024-03-23T17:00:00.555528Z",
     "shell.execute_reply": "2024-03-23T17:00:00.554326Z",
     "shell.execute_reply.started": "2024-03-23T17:00:00.547153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Activation, Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "#import tensorflow_io as tfio\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:02.803234Z",
     "iopub.status.busy": "2024-03-23T17:00:02.802425Z",
     "iopub.status.idle": "2024-03-23T17:00:02.811682Z",
     "shell.execute_reply": "2024-03-23T17:00:02.810664Z",
     "shell.execute_reply.started": "2024-03-23T17:00:02.803189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "model_file_path = \"best_model_file.hdf5\"\n",
    "checkpoint = ModelCheckpoint(model_file_path, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=5,  # <-- Corrected value\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=5,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('Model.log')\n",
    "\n",
    "# Define a learning rate schedule\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    end_learning_rate=0.000001,\n",
    "    power=0.5,\n",
    "    cycle=False\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [earlystop, csv_logger, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:08.205447Z",
     "iopub.status.busy": "2024-03-23T17:00:08.205082Z",
     "iopub.status.idle": "2024-03-23T17:00:08.211942Z",
     "shell.execute_reply": "2024-03-23T17:00:08.211048Z",
     "shell.execute_reply.started": "2024-03-23T17:00:08.205419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.listdir(r'D:\\MIET_HeartSound\\Dataset\\Dataset2\\heart_sound')\n",
    "data = os.path.join(r'D:\\MIET_HeartSound\\Dataset\\Dataset2\\heart_sound')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:12.706675Z",
     "iopub.status.busy": "2024-03-23T17:00:12.705841Z",
     "iopub.status.idle": "2024-03-23T17:00:12.711017Z",
     "shell.execute_reply": "2024-03-23T17:00:12.709894Z",
     "shell.execute_reply.started": "2024-03-23T17:00:12.706637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir_path = os.path.join(data, 'train')\n",
    "valid_dir_path = os.path.join(data, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:14.420325Z",
     "iopub.status.busy": "2024-03-23T17:00:14.419624Z",
     "iopub.status.idle": "2024-03-23T17:00:14.424562Z",
     "shell.execute_reply": "2024-03-23T17:00:14.423681Z",
     "shell.execute_reply.started": "2024-03-23T17:00:14.420293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "healthy = os.path.join(train_dir_path, 'healthy', 'a0007.wav')\n",
    "unhealthy = os.path.join(train_dir_path, 'unhealthy', 'a0002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:16.172760Z",
     "iopub.status.busy": "2024-03-23T17:00:16.172401Z",
     "iopub.status.idle": "2024-03-23T17:00:16.179007Z",
     "shell.execute_reply": "2024-03-23T17:00:16.178023Z",
     "shell.execute_reply.started": "2024-03-23T17:00:16.172731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    print(wav, sample_rate)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    print(wav, sample_rate)\n",
    "    \n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:17.939601Z",
     "iopub.status.busy": "2024-03-23T17:00:17.939245Z",
     "iopub.status.idle": "2024-03-23T17:00:18.196019Z",
     "shell.execute_reply": "2024-03-23T17:00:18.195041Z",
     "shell.execute_reply.started": "2024-03-23T17:00:17.939574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wave = load_wav_16k_mono(healthy)\n",
    "nwave = load_wav_16k_mono(unhealthy)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(nwave, color='black')\n",
    "plt.plot(wave, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:20.822612Z",
     "iopub.status.busy": "2024-03-23T17:00:20.822236Z",
     "iopub.status.idle": "2024-03-23T17:00:21.680243Z",
     "shell.execute_reply": "2024-03-23T17:00:21.679071Z",
     "shell.execute_reply.started": "2024-03-23T17:00:20.822582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "healthy_heart_train = tf.data.Dataset.list_files(train_dir_path+'/healthy'+'/*.wav')\n",
    "unhealthy_heart_train = tf.data.Dataset.list_files(train_dir_path+'/unhealthy'+'/*.wav')\n",
    "#healthy_heart_valid = tf.data.Dataset.list_files(valid_dir_path+'/healthy'+'/*.wav')\n",
    "#unhealthy_heart_valid = tf.data.Dataset.list_files(valid_dir_path+'/unhealthy'+'/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:23.472903Z",
     "iopub.status.busy": "2024-03-23T17:00:23.471931Z",
     "iopub.status.idle": "2024-03-23T17:00:23.489818Z",
     "shell.execute_reply": "2024-03-23T17:00:23.488665Z",
     "shell.execute_reply.started": "2024-03-23T17:00:23.472859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hhl_train = tf.data.Dataset.zip((healthy_heart_train, tf.data.Dataset.from_tensor_slices(tf.ones(len(healthy_heart_train)))))\n",
    "uhl_train = tf.data.Dataset.zip((unhealthy_heart_train, tf.data.Dataset.from_tensor_slices(tf.zeros(len(unhealthy_heart_train)))))\n",
    "train_data = hhl_train.concatenate(uhl_train)\n",
    "\n",
    "#hhl_valid = tf.data.Dataset.zip((healthy_heart_valid, tf.data.Dataset.from_tensor_slices(tf.ones(len(healthy_heart_valid)))))\n",
    "#uhl_valid = tf.data.Dataset.zip((unhealthy_heart_valid, tf.data.Dataset.from_tensor_slices(tf.zeros(len(unhealthy_heart_valid)))))\n",
    "#valid_data = hhl_valid.concatenate(uhl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:25.500184Z",
     "iopub.status.busy": "2024-03-23T17:00:25.499462Z",
     "iopub.status.idle": "2024-03-23T17:00:31.887874Z",
     "shell.execute_reply": "2024-03-23T17:00:31.887050Z",
     "shell.execute_reply.started": "2024-03-23T17:00:25.500135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#train_data = train_data.concatenate(valid_data)\n",
    "lengths = []\n",
    "for f in os.listdir(os.path.join(train_dir_path, 'healthy')):\n",
    "    tensor_wave = load_wav_16k_mono(os.path.join(train_dir_path, 'healthy', f))\n",
    "    lengths.append(len(tensor_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the lengths\n",
    "train_length = tf.data.experimental.cardinality(train_data).numpy()\n",
    "#valid_length = tf.data.experimental.cardinality(valid_data).numpy()\n",
    "\n",
    "# Print the lengths\n",
    "print(\"Length of train_data:\", train_length)\n",
    "#print(\"Length of valid_data:\", valid_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "J = 6\n",
    "Q = 1\n",
    "T = 30000\n",
    "scatt = Scattering1D(J, T, Q)\n",
    "def extract(file_path, label, wav_length=30000):\n",
    "    def mfccs(wav):\n",
    "        # Ensure wav is a numpy array\n",
    "        wav = wav.numpy()\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(y=wav, sr=2000, n_mfcc=7)\n",
    "        return mfcc\n",
    "\n",
    "    \n",
    "    \n",
    "    def scattering_transform(wav):\n",
    "        # Ensure wav is a numpy array\n",
    "        wav = wav.numpy()\n",
    "        \n",
    "        meta = scatt.meta()\n",
    "        order0 = np.where(meta['order'] == 0)\n",
    "        order1 = np.where(meta['order'] == 1)\n",
    "        order2 = np.where(meta['order'] == 2)\n",
    "\n",
    "        Sx = scatt(wav) \n",
    "        return Sx[order1]\n",
    "    \n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = tf.cast(wav, dtype=tf.float32)  # Ensure wav is float32\n",
    "    wav = wav / tf.reduce_max(tf.abs(wav))\n",
    "    wav = wav[:wav_length] if tf.shape(wav)[0] > wav_length else tf.pad(wav, [(0, wav_length - tf.shape(wav)[0])], \"CONSTANT\")\n",
    "    \n",
    "    # Using tf.py_function to wrap the scattering transform\n",
    "    mfcc = tf.py_function(mfccs, [wav], tf.float32)\n",
    "    mfcc = tf.abs(mfcc)\n",
    "\n",
    "    # Using tf.py_function to wrap the scattering transform\n",
    "    scattering_transform = tf.py_function(scattering_transform, [wav], tf.float32)\n",
    "    scattering_transform = tf.abs(scattering_transform)\n",
    "    # You might need to set the shape of the output manually if required\n",
    "    scattering_transform.set_shape((7, 469)) \n",
    "    \n",
    "    concatenated_feature = tf.concat([scattering_transform, mfcc] , axis = 1)\n",
    "    concatenated_feature = tf.expand_dims(concatenated_feature, axis = 2)\n",
    "    \n",
    "    return concatenated_feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:37.389949Z",
     "iopub.status.busy": "2024-03-23T17:00:37.389564Z",
     "iopub.status.idle": "2024-03-23T17:00:37.409052Z",
     "shell.execute_reply": "2024-03-23T17:00:37.408118Z",
     "shell.execute_reply.started": "2024-03-23T17:00:37.389918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "iterator = hhl_train.shuffle(buffer_size=10000).as_numpy_iterator()\n",
    "iterator.next()\n",
    "filepath, label = next(iterator)\n",
    "print(filepath, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:40.307339Z",
     "iopub.status.busy": "2024-03-23T17:00:40.306396Z",
     "iopub.status.idle": "2024-03-23T17:00:40.327641Z",
     "shell.execute_reply": "2024-03-23T17:00:40.326773Z",
     "shell.execute_reply.started": "2024-03-23T17:00:40.307294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature, label = extract(filepath, label)\n",
    "print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:43.503373Z",
     "iopub.status.busy": "2024-03-23T17:00:43.502676Z",
     "iopub.status.idle": "2024-03-23T17:00:43.652508Z",
     "shell.execute_reply": "2024-03-23T17:00:43.651723Z",
     "shell.execute_reply.started": "2024-03-23T17:00:43.503340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.map(extract)\n",
    "train_data = train_data.cache()\n",
    "train_data = train_data.shuffle(buffer_size=1000)\n",
    "train_data = train_data.batch(4)\n",
    "train_data = train_data.prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:45.895416Z",
     "iopub.status.busy": "2024-03-23T17:00:45.894979Z",
     "iopub.status.idle": "2024-03-23T17:00:45.901683Z",
     "shell.execute_reply": "2024-03-23T17:00:45.900608Z",
     "shell.execute_reply.started": "2024-03-23T17:00:45.895366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_samples = tf.data.experimental.cardinality(train_data).numpy()\n",
    "print(f\"Number of samples in train_data: {num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:48.265552Z",
     "iopub.status.busy": "2024-03-23T17:00:48.265187Z",
     "iopub.status.idle": "2024-03-23T17:00:49.977083Z",
     "shell.execute_reply": "2024-03-23T17:00:49.976092Z",
     "shell.execute_reply.started": "2024-03-23T17:00:48.265524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train_data.take(567)\n",
    "test = train_data.skip(567).take(243)\n",
    "samples, labels = train.as_numpy_iterator().next()\n",
    "print(samples.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the lengths\n",
    "train_length = tf.data.experimental.cardinality(train).numpy()\n",
    "test_length = tf.data.experimental.cardinality(test).numpy()\n",
    "\n",
    "# Print the lengths\n",
    "print(\"Length of train:\", train_length)\n",
    "print(\"Length of test:\", test_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:52.926719Z",
     "iopub.status.busy": "2024-03-23T17:00:52.926348Z",
     "iopub.status.idle": "2024-03-23T17:00:52.932647Z",
     "shell.execute_reply": "2024-03-23T17:00:52.931707Z",
     "shell.execute_reply.started": "2024-03-23T17:00:52.926688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (2,2), activation='relu', input_shape=(7, 528, 1)))\n",
    "    model.add(Conv2D(32, (2,2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:00:56.002446Z",
     "iopub.status.busy": "2024-03-23T17:00:56.002110Z",
     "iopub.status.idle": "2024-03-23T17:00:56.078876Z",
     "shell.execute_reply": "2024-03-23T17:00:56.077938Z",
     "shell.execute_reply.started": "2024-03-23T17:00:56.002421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an optimizer with the learning rate schedule\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model0 = cnn()\n",
    "model0.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T17:01:02.291482Z",
     "iopub.status.busy": "2024-03-23T17:01:02.290658Z",
     "iopub.status.idle": "2024-03-23T17:07:13.791505Z",
     "shell.execute_reply": "2024-03-23T17:07:13.790529Z",
     "shell.execute_reply.started": "2024-03-23T17:01:02.291450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "history0 = model0.fit(train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=200,\n",
    "                    validation_data=test,\n",
    "                    verbose=1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def butterfly_optimization(n, fitness, dimension, lb, ub, max_iter):\n",
    "    # Initialize population\n",
    "    population = np.random.rand(n, dimension) * (ub - lb) + lb\n",
    "    fitness_population = np.array([fitness(ind) for ind in population])\n",
    "    \n",
    "    # BOA parameters\n",
    "    sensory_modality = 0.01  # Sensory modality (perception)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        # Update butterflies\n",
    "        for i in range(n):\n",
    "            if np.random.rand() < sensory_modality:\n",
    "                # Global search\n",
    "                j = np.random.randint(0, n)  # Random butterfly index\n",
    "                step_size = np.random.rand() * (population[j] - population[i])\n",
    "            else:\n",
    "                # Local search\n",
    "                step_size = np.random.normal(0, 1, dimension)\n",
    "            \n",
    "            # Move butterfly\n",
    "            population[i] += step_size\n",
    "            population[i] = np.clip(population[i], lb, ub)  # Keep within bounds\n",
    "            print(\"Calculating\")\n",
    "            # Evaluate new solution\n",
    "            new_fitness = fitness(population[i])\n",
    "            if new_fitness < fitness_population[i]:\n",
    "                fitness_population[i] = new_fitness\n",
    "                print('Found new fitness: ', new_fitness)\n",
    "    \n",
    "    # Return the best solution\n",
    "    best_idx = np.argmin(fitness_population)\n",
    "    return population[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fitness(hyperparams):\n",
    "    learning_rate, batch_size = hyperparams\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model = cnn()  # Your CNN model function\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Assuming `train` and `test` are predefined datasets\n",
    "    history = model.fit(train, batch_size=int(batch_size), epochs=10, validation_data=test, verbose=0)\n",
    "    val_accuracy = np.max(history.history['val_accuracy'])  # Max validation accuracy\n",
    "    \n",
    "    return -val_accuracy  # Negative because BOA minimizes the fitness function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams = butterfly_optimization(\n",
    "    n=10, \n",
    "    fitness=model_fitness, \n",
    "    dimension=2, \n",
    "    lb=np.array([1e-5, 8]),  # Lower bounds for learning rate and batch size\n",
    "    ub=np.array([1e-2, 64]),  # Upper bounds\n",
    "    max_iter=20\n",
    ")\n",
    "\n",
    "print(f\"Best Hyperparameters: Learning Rate = {best_hyperparams[0]}, Batch Size = {int(best_hyperparams[1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define Objective Function\n",
    "def objective_function(learning_rate, stride, dense_layer, num_filters, batch_size, epochs):\n",
    "    model = build_model(learning_rate, stride, num_filters, dense_layer)\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=test,\n",
    "                    verbose=1,\n",
    "                    )\n",
    "    \n",
    "    # Return validation accuracy as score\n",
    "    return history.history['val_accuracy'][-1]\n",
    "\n",
    "# Define Model Builder\n",
    "def build_model(learning_rate, stride, num_filters, dense_layer):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(num_filters[0], (stride[0],stride[0]), activation='relu', input_shape=(7, 528, 1)),\n",
    "        layers.Conv2D(num_filters[1], (stride[1],stride[1]), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(dense_layer, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Butterfly Optimization Function\n",
    "def butterfly_optimization(objective_function, initial_hyperparameters, num_butterflies=10, max_iterations=50):\n",
    "    global_best_hyperparameters = initial_hyperparameters.copy()\n",
    "    global_best_score = objective_function(**initial_hyperparameters)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        for butterfly in range(num_butterflies):\n",
    "            updated_hyperparameters = {}\n",
    "            for param, value in initial_hyperparameters.items():\n",
    "                if isinstance(value, float):\n",
    "                    updated_value = value + np.random.normal(0, 0.1)\n",
    "                    updated_hyperparameters[param] = np.clip(updated_value, 0.001, None)  # Ensure non-negative values\n",
    "                elif isinstance(value, list):\n",
    "                    updated_value = [int(np.round(v + np.random.normal(0, 0.1))) for v in value]\n",
    "                    updated_hyperparameters[param] = [np.clip(v, 1, None) for v in updated_value]  # Ensure positive integers\n",
    "                else:\n",
    "                    updated_hyperparameters[param] = value\n",
    "                \n",
    "            score = objective_function(**updated_hyperparameters)\n",
    "            print('Score:', score, '\\nParameters: ', updated_hyperparameters)\n",
    "            if score > global_best_score:\n",
    "                print('Global: ', updated_hyperparameters)\n",
    "                global_best_score = score\n",
    "                global_best_hyperparameters = updated_hyperparameters.copy()\n",
    "        \n",
    "        # Implement exploration and exploitation adjustments if needed\n",
    "        \n",
    "    return global_best_hyperparameters\n",
    "\n",
    "\n",
    "# Define initial hyperparameters\n",
    "initial_hyperparameters = {\n",
    "    'learning_rate': 1e-5,\n",
    "    'num_filters': [32, 32],\n",
    "    'stride': [3, 3],\n",
    "    'epochs': 50,\n",
    "    'dense_layer':256,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "# Run Butterfly Optimization\n",
    "best_hyperparameters = butterfly_optimization(objective_function, initial_hyperparameters)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 4: Make predictions and evaluate on the test set\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for samples, labels in test.as_numpy_iterator():\n",
    "    predictions = model0.predict(samples)\n",
    "    predicted_classes = (predictions > 0.5).astype(int)  # Adjust threshold as needed for binary classification\n",
    "    true_labels.extend(labels)\n",
    "    predicted_labels.extend(predicted_classes)\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Step 5: Classification report and confusion matrix\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "print(confusion_matrix(true_labels, predicted_labels))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 768212,
     "sourceId": 1324391,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
