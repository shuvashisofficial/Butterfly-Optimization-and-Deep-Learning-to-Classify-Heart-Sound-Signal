{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Librares"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T16:59:58.496135Z","iopub.status.busy":"2024-03-23T16:59:58.495786Z","iopub.status.idle":"2024-03-23T16:59:58.504929Z","shell.execute_reply":"2024-03-23T16:59:58.503845Z","shell.execute_reply.started":"2024-03-23T16:59:58.496110Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Shuvashis\\anaconda3\\envs\\Tempura\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning:\n","\n","IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import pydot\n","import kymatio\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","from termcolor import colored\n","import matplotlib.pyplot as plt \n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n","from kymatio import Scattering1D\n","import warnings\n","warnings.filterwarnings('ignore')\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:00.547182Z","iopub.status.busy":"2024-03-23T17:00:00.546814Z","iopub.status.idle":"2024-03-23T17:00:00.555528Z","shell.execute_reply":"2024-03-23T17:00:00.554326Z","shell.execute_reply.started":"2024-03-23T17:00:00.547153Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  1\n"]}],"source":["from sklearn.model_selection import GridSearchCV\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Activation, Input, Conv2D, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import tensorflow as tf\n","#import tensorflow_io as tfio\n","\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n","sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n","tf.compat.v1.keras.backend.set_session(sess)"]},{"cell_type":"markdown","metadata":{},"source":["# CallBacks"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:02.803234Z","iopub.status.busy":"2024-03-23T17:00:02.802425Z","iopub.status.idle":"2024-03-23T17:00:02.811682Z","shell.execute_reply":"2024-03-23T17:00:02.810664Z","shell.execute_reply.started":"2024-03-23T17:00:02.803189Z"},"trusted":true},"outputs":[],"source":["epochs = 20\n","\n","model_file_path = \"best_model_file.hdf5\"\n","checkpoint = ModelCheckpoint(model_file_path, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n","\n","earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                          min_delta=0,\n","                          patience=5,  # <-- Corrected value\n","                          verbose=1,\n","                          restore_best_weights=True\n","                          )\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n","                              factor=0.2,\n","                              patience=5,\n","                              verbose=1,\n","                              min_delta=0.0001)\n","\n","csv_logger = tf.keras.callbacks.CSVLogger('Model.log')\n","\n","# Define a learning rate schedule\n","initial_learning_rate = 0.001\n","lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n","    initial_learning_rate,\n","    decay_steps=10000,\n","    end_learning_rate=0.000001,\n","    power=0.5,\n","    cycle=False\n",")\n","\n","\n","callbacks = [earlystop, csv_logger, reduce_lr, checkpoint]"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:08.205447Z","iopub.status.busy":"2024-03-23T17:00:08.205082Z","iopub.status.idle":"2024-03-23T17:00:08.211942Z","shell.execute_reply":"2024-03-23T17:00:08.211048Z","shell.execute_reply.started":"2024-03-23T17:00:08.205419Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'D:\\\\MIET_HeartSound\\\\Dataset\\\\Dataset2\\\\heart_sound'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["os.listdir(r'D:\\MIET_HeartSound\\Dataset\\Dataset2\\heart_sound')\n","data = os.path.join(r'D:\\MIET_HeartSound\\Dataset\\Dataset2\\heart_sound')\n","data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:12.706675Z","iopub.status.busy":"2024-03-23T17:00:12.705841Z","iopub.status.idle":"2024-03-23T17:00:12.711017Z","shell.execute_reply":"2024-03-23T17:00:12.709894Z","shell.execute_reply.started":"2024-03-23T17:00:12.706637Z"},"trusted":true},"outputs":[],"source":["train_dir_path = os.path.join(data, 'train')\n","valid_dir_path = os.path.join(data, 'val')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:14.420325Z","iopub.status.busy":"2024-03-23T17:00:14.419624Z","iopub.status.idle":"2024-03-23T17:00:14.424562Z","shell.execute_reply":"2024-03-23T17:00:14.423681Z","shell.execute_reply.started":"2024-03-23T17:00:14.420293Z"},"trusted":true},"outputs":[],"source":["healthy = os.path.join(train_dir_path, 'healthy', 'a0007.wav')\n","unhealthy = os.path.join(train_dir_path, 'unhealthy', 'a0002.wav')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:16.172760Z","iopub.status.busy":"2024-03-23T17:00:16.172401Z","iopub.status.idle":"2024-03-23T17:00:16.179007Z","shell.execute_reply":"2024-03-23T17:00:16.178023Z","shell.execute_reply.started":"2024-03-23T17:00:16.172731Z"},"trusted":true},"outputs":[],"source":["def load_wav_16k_mono(filename):\n","    # Load encoded wav file\n","    file_contents = tf.io.read_file(filename)\n","    # Decode wav (tensors by channels)\n","    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n","    print(wav, sample_rate)\n","    # Removes trailing axis\n","    wav = tf.squeeze(wav, axis=-1)\n","    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n","    print(wav, sample_rate)\n","    \n","    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n","#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n","    return wav"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:17.939601Z","iopub.status.busy":"2024-03-23T17:00:17.939245Z","iopub.status.idle":"2024-03-23T17:00:18.196019Z","shell.execute_reply":"2024-03-23T17:00:18.195041Z","shell.execute_reply.started":"2024-03-23T17:00:17.939574Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[0.04437256]\n"," [0.09277344]\n"," [0.08206177]\n"," ...\n"," [0.01379395]\n"," [0.01266479]\n"," [0.01278687]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04437256 0.09277344 0.08206177 ... 0.01379395 0.01266479 0.01278687], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00906372]\n"," [ 0.0222168 ]\n"," [ 0.02377319]\n"," ...\n"," [-0.0027771 ]\n"," [-0.00247192]\n"," [-0.00201416]], shape=(41657, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00906372  0.0222168   0.02377319 ... -0.0027771  -0.00247192\n"," -0.00201416], shape=(41657,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABIkAAAFlCAYAAABvDLgGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAC4KklEQVR4nO2dd7jcxNXGX917XcCAbcBgsAFTjMGUUAyY3nsPzfQkEEIJnRBKCAECfJAQQu+dAKGHFkILEMAU04spBgwYUwzYxjau1/r+mJ27Wq3KSBppRtr39zz32bu72pmj0dQz55xxXNcFIYQQQgghhBBCCGlt2kwLQAghhBBCCCGEEELMQyURIYQQQgghhBBCCKGSiBBCCCGEEEIIIYRQSUQIIYQQQgghhBBCQCURIYQQQgghhBBCCAGVRIQQQgghhBBCCCEEQIdpAaJYeOGF3UGDBpkWgxBCCCGEEEIIIaQyvPrqq9+5rtvP/7nVSqJBgwZh1KhRpsUghBBCCCGEEEIIqQyO43wW9DndzQghhBBCCCGEEEIIlUSEEEIIIYQQQgghhEoiQgghhBBCCCGEEAIqiQghhBBCCCGEEEIIqCQihBBCCCGEEEIIIaCSiBBCCCGEEEIIIYSASiJCCCGEEEIIIYQQAiqJCCGEEEIIIYQQQgioJCKEEEIIIYQQQgghoJKIEEIIIYQQQgghhIBKIkIIIYQQQgghhBACKokIIYQQYguuC4webVoKQgghhJCWhUoiQgghhNjBLbcAQ4cCjz5qWhJCCCGEkJaESiJCCCGE2MHrr4vX994zKwchhBBCSItCJREhhBBC7MBxTEtACCGEENLSUElECCGEEDtwXdMSEEIIIYS0NFQSEUIIIYQQQgghhBAqiQghhBBiCXQ3I4QQQggxCpVEhBBCCCGEEEIIIYRKIkIIIYRYBmMTEUIIIYQYgUoiQgghhNiBdDejkqiRk0+mKx4hhBBCCoFKIkIIIYTYBRUijfzf/5mWgBBCCCEtApVEhBBCCLEDWhARQgghhBiFSiJCCCGE2IFUEtGSiBBCCCHECFQSEUIIIcQuqCQihBBCCDEClUSEEEIIIYQQQgghhEoiQgghhFgCYxIRQgghhBiFSiJCCCGE2AXdzQghhBBCjEAlESGEEELsgJZEhBBCCCFGoZKIEFJeZs4E5swxLQUhRDe0JCKEkHB++kn0k3/+s2lJCCEVhEoiQkh56dkT2Gwz01IQQgghhBTHxIni9YorzMpBCKkkVBIRQsrN//5nWgJCiC7obkYIIYQQYhQtSiLHcbZxHOcDx3HGOI5zUsR1azmO0+k4zu468iWEEEJIBaG7GSGEhEOFOiEkRzIriRzHaQdwGYBtAQwFsLfjOENDrjsPwH+y5kmIFh57TCxEpMkuIYQQs3DhEw3LhxBCCCE5o8OSaG0AY1zX/cR13VkA7gCwc8B1RwK4B8C3GvIkJDtnny1e33rLrByEEEIaoSVRMFQSEVPMmgWcdRYwY4ZpSQghhOSMDiXRAABfeN6Pq33WheM4AwDsCuBKDfkRQgghhLQeJpREP/0EzJ5dfL7ELi67DPjjH4ELLjAtCfFChTohJAd0KImCeif/LObvAH7vum5nbGKOc4jjOKMcxxk1YcIEDeIRQgghpBTQUiYaE+XTqxew9dbF50vs4qefGl+JHbDPJITkQIeGNMYBWMLzfiCA8b5rhgG4wxHa7oUBbOc4zhzXde/3J+a67tUArgaAYcOGsecjhBBCWg3ujgdjakH43/+ayZfYB5UShBBSeXRYEr0CYLDjOEs7jtMdwAgAD3gvcF13add1B7muOwjA3QAOD1IQEVIonOgQQohdsF+OhuVDTEHFrZ3wubQud94JfPaZaSlIRclsSeS67hzHcX4LcWpZO4DrXdd913GcQ2vfMw4RIYQQQuKRShAufAghhJBw9toLWGQR4JtvTEtCKogOdzO4rvsIgEd8nwUqh1zX/YWOPEnFcV3g0kuBAw8EFlggnzy4CCGEEFImaElECCFE8i0PDSf5oMPdjLQCEyYAb7xRXH5PPgkcdRRw5JH55cHJNiGEkDLBcYsQArAvIITkihZLItICrL468OWXxQ1K06eL1++/zy+P//0vv7QJIYSkh5aewXBhSAghhJCcoSURUePLL4vNTy4QOCEmhJSNadOAmTNNS1FO2OdHw/IhpmEdJISQykMlEbGTIneRuWNNCNHJfPMBq6xSfL4//AAMGlSsa7BuGLg6Gi7QiSnYJgkhpGWgkojYDSfEhJAy8tFHxef55JPiONyzzy4+b1IMHBMJISRffvoJGD3atBSEGIVKImIndDcjhJB0sN+sLny26Tn2WODf/zYtBSHVx3WBZ54pb3+1117A0KF0GyctDZVExE5o1kwIIcmoQr9Jd7NoyrrosoG//x3YbjvTUtjJhx/yKO2yYmNfeccdwCabADfcYFqSdDz1lHidPdusHIQYhKebEbvhhJgQQpJRhX7TxoUPIVVlyBCgRw9gxgzTkpAq8Mkn4nXMGLNypIXjDyG0JCKEEEIqAd10CSFpUXWt0dm/jBsn+q2bbtKXZqthY39fFSWLjWUrsVk2UgmoJCKEEEKqQNET8xdeAM46q9g8CSFmyKN/kcGBb7lFf9pVpwyuuWVVZHDDhRC6mxFLYQdNCCHpKKrfXH998XraafrSZJ8fDcuHmEZnHeRcLzs2KolslCkJZZefEA3QkojYCTtoQghJRhUWXGXYHSeEENOUoZ8vg4xRlF1+QjJAJVHV+eorYO5c01Kkhx00IYS0HlQSEWInbJt2YePzsFGmJJRhw8Vm2UgloJKoynz2GbD44sCf/2xakuSUfYAhhBBCdMOFATFNHu5mpJqUvb9i/Swf//qXeG5jx5qWpPRQSVRlxo0Tr48+alaONJR9YCGEkKIpw+4nIXEsvzyw5ZampSB+8lwws89Kju4ycxzgV7/SlxZQ3udaVrkJcPPN4nXUKLNyVAAqiYjdFKHF504BIaQKVKEv4+ScfPQR8MQTpqUgRVB2ZYJJ8ojfdsMNetKpwlhkO2wzwbBP0QaVRMRuimjk7EgIIVWizH0aA1cTYjdZ+5f33hPt++GH2c51YHMZlnUssrlMSTR8dtqgkqjKUJtKiua554C33jItBSGtSZUmR1W6F51wPCdlZ+RI8XrvvfXPWK+rRdn7b9bH8sNnmJkO0wIQEknZB5pWY8MNxSs7Z0LMwfZHCMkLnfMyzvHSU4Z+vgwylhWWbTA0kNAGLYkIIYSQKlCFyVGZZSekFdDVRtnW9WCjos1GmUhrUIV5kCVQSVRl2EmrwXIihBC7YL9MiF3oapNB6XBBl5wylFkZZCTVgnMHbVBJRAghhBA74KIiGpYPMY3OOshd//TYHOS/7M+1rHKTOnyGmaGSiBBCCKkCNi4W0lKleyGkCuTZJqvc3r/8sn6aW6tR9udqs6LBZtlMUnYFpUVQSdQKlLGhlFFmHYwcCeywAzBnjmlJCCFlo1X7TUJI/uTRv5jss775Bpg2Lf98Ro0Sr1deqTddm/t7m2VToezKrVaGz04bVBJVGWpT1bCpfEaMELtN48aZloQQQorHpv7YRlg+6WC52YfpZ9K/P7Deevnnk9ei1WZ3s7Jjum6S7PAZZoZKImInRQ56Ng2wbbUmyc6NEJIUU31ZHv2VTf0yKT8cU7OTR+Bq0+38rbeKyyuvezVdhkUzYwZw+uniNW9s7jdsls0ksj1MmGBWjgpAJRGxk1bt/Gj9RQhJi6l+Q2e+tvZ948YBM2ealoKQamFrey8DZSi7PBRYF14InHkmcMkl+tMm5UfWuWOPNStHBaCSqMpUYXehiHuwqZyoJCKEtDI2ulDMng0ssQRw4IGmJSFp4ZiqD5ZlMvIqr1Z9DtOni9effjIrByEVh0oiQmyCSiJCSFqq5G5mE7Nni9d//Sv6mvffz1+Wqpc1aS1sUgbnDd3N9JLnfbOfLS9tVG3ogiVJiE0DLJVEhJC0VMHdzEZUxohjjwVWXFEcd03so+p1tEh0zpn4XNLTCm6+QRQpq83lYrNsJrFpTVdyqCRqBdiRRGNTh6JTSTR2LPDOO9nTIaQIPv9c1P9nnzUtCbEBHf3yAw8ATz+dPR0py9y54dc884x4/eGH7PkR/XAepA9dZelNx6Z5WFmw0TVXUvb2ZmOZEjX47LTRYVoAkiNsKOVDp5Jo6aX1pUVI3shF9jXXABttZFaWslKFPl9nf7XzznrSlL+PUhIRUnXyON2sFSjDHCwvGcv6rMvwzAjJGVoSETspWwftusAppwAffpgtHZUda0JIOA89BHzyiWkpzFC2fjMIm3fHVcj7GVThGZuA5WYffCbZaFV3M0kRY4TN5WKzbCYp69zBQqgkagXYkeTPF18A554LbLtttnQYk4i0Olnr/o47AkOG6JGFqFH1/krl/jgxJa1C1dt7WdCpUOfGZDG8/TbbT95wLNYGlURVJo+GUlTnVmQj15GXLJc5c/TIwkGknEyfDlx5pb7n99VXwK236kmrlcjaDgkh1YJjqn20ymIuL+tInel+/332NLywvTXz3HPAqqsCF19sWhJClKCSiNhJWQeYrHJTSVRuTj0VOOww4P779aS39dbA/vsDkybpSY+0BmVefJXV3Yx9tt3Y/nzefhsYOdK0FMVi+zOxHZ195VdfZU+jSuRRN8eMEa+vvaY/bUJygEoiYjdlWyhkhUqicjNhgnidOlVPevI47c7O8Gsuugh45RU9+Zmk1dp6nhTdf+SRX9b68NFHeuQA7OqPbZKlavzzn8Duu5vJe9VVgfXWM5O3KnkErmZ9To90EdPxXNq4HAzE5vpps2ykEvB0s1agzB1JmWUnrUseRwSHccwxevMkxCS66vHkyXrSUYVKTrtRqVcjRuQvB2ldbHY369UrexpBlDXsBftzQmhJZDWvv67PIkEXXIgGo3tA4QBVTvJ6bqwPJAmsL9wZJyQvdG6CsK9Kj3wOOvq6eebJnkaV4FqHECqJrGX6dGCNNcyZPttCqx1xaZMsJD18jsQkrH96lURJyjPvsuezTQfLLTtltQrJwq9/Ddx7b7Y08rpHne5mJBib66fNspFKQCWRrcjTeZ57Ln0aHDgIKZa8zMkJsRmd9VSXCwUtiYgX9qXZ0V2G3jZu63z12muB3XbTk5bN7mZlbB+21pk4yio3aTk4izLBtGli4InqlOUEV+4UpKHITv+NN4Bx44rLz1Z0nW5GyklebY71giShCvXFJiVRknZdhbInpAjKqJiwCZstifhsCSk9VBKZ4PjjhQnr44+HXyM7/SxKojwI6/hXXx1YYoliZbEJXYN01QfWSy4BOjqqf5+6aMVyasV71g3L0M6FEzEH20R28jjdjKSn1S2JioDlUj7Yv2iDSiITfPONeJ02zawcxF6q2skddVT0ce5lh4Gr09MK91hVbJxIm6pPjElEysyECcXl1Sp1Oa/71KkkkpRhHC5rvdEtd1nLgZQGKolagTJ0+n6K7PzyOvqTVI/LLwc++ST+Og7eyWGZ6aOMfb5E58lJulBJq8xl3goU3b+4rrCc/fHHYvPNyowZ8dewr7YDne5mdJUnhPigksgkUZ1yEYPwxInAyy/nn4+tdO8uXjmIFU8ZJ5k//QQccQSw4Ybh1zBwNbGBMtebPHbHCSm6TTz1lLCc/e1vi803K1HlpLtNso1nw+a+ssxjEFB++U0yZ459oVJIKqgkMoEtHfqWWwLrrJPsN0V1nEWUkS3PwUvVByYbyzwpEyfGX0Oz4uRUoW4QfUTVh2nTip2EtkL7I8lYcUXgkEPCv58+Xbx+/30x8pQR122NtpWXMqfVYxIVMWfIo1yqHsO0Wzdgl11MS0E0QCWRCVQadhGN/9VX888jLUXcv60dLFDdBbPNZR6HyWDyZS43UjxF9x9F1s+ZM4H55gOOO664PCU29MvsC9Khu9zefx+45prw72VdKZuSqFU36MqIrNM6T3LksyE6ePBB0xIQDVBJROwmbMDq7ARuvdU+k0Yb42nYSFH39+OPwHvv6UkryeSp6jtFxG7KXG/iZP/pJ/F64425i9KEDeX68cemJSAqSOXQSy+ZlSMpRddxKiXSU3TctTTw+RJSWqgkMoFKpxnXYY8dCzz3nBZxEmEi+GMQl10G7L8/cO21+tMm+VH0hGHrrYGVVtKbpglLwFaqq610ryScsL5Cfl5kPbGpTkbFRCPhFP0MZ80qNr8i0bkZZlPbyhubFSa6XeJUnuvrr0db49lAGRRxhOREh2kBSAhxncnSS8dfV+UO6ZtvxGuRx7UWic2TiTLx4ov60lJZnOb13KrcliWs8/oos7tZXFomlERJsFWuVofPJTt59ivs/5NT9jq9xhri9de/NitH0dDSnJQEWhIRuzuaH36I/l6H7DrSiOv0v/4a6NEDeOWV/GUpA2W+zyItiaZM0ZNOEO+9B5x5Zn7pJ6XMdYLoJ86SKA66zRCTsD6QvLE5cDXrf7l4913g9ttNS0Esg0oiW5Ed9syZ2dMaNSp7GqZ4+eXgz23dTQ6T5/HHhfn5xRcXKw/Rh0pdK5Ml0frrA6efLk6KKgtjxwJTp5qWgtiAbe5mto1FpJEqPJ9HHgG++MK0FNlpNQVCmepeGaxcynqwjc31YOWVgX32MS2FHlqtf8kRKonKgMqR20VRVCen6nJQNmweJIqkzOVQFRdPqYC2pS2pyLH00sDGG+cvCzFHXBuSJ/mUqa2R1iOPfnX77YE119Sfru3MnQtcfz0we7ZpSbKhu04wXk7+2FwuNstGKgGVRLbibfxz5hSXVytR5H0nnRzYsnDXTRXuq1Xbiy289pppCYifPNpEnLtZkSdbmrQiJHrwPsPDDgM+/DDf/PKqD1WKw6jab/zjH8BBBwHnnZevPGVDd7BpUi7eftu0BKTiUElkEtUBkovS6hD3LPms7aVq7maE2IjN4yIXY+XFW1+uvBLYc89881t55XzTz4siXCuTtiMZm/Lbb7Pla4q8+6qo8vz3v4Fnn41PIy8ZGey8GR1hRADgySf1pENICFQSmUClY7Mt3oKtZJE97rfjx6sHDuaOTjKqXufKcH9lkJG0Hqp96YwZevI791xgxRXVrm31NtPZaVoCfeQ9VnfvLl5XWSXffIrEVLwazquCUSnH7bZL5qJdhphERZLHfdx2m/40CckBKolMYKLz1JWnLR1/EZOGAQOA1VZL9psvv8yWZ5GToaOO4uQrDVFtoEzlaUtb9mOrXKSanHIK8P770dewTgrK7Orpf4ZFPdMyjQmqmGoPbIf5wbIlhPigkshW2GGroaOcotL45BM9cth4bPMllxSXV6uh+zmW/aSQJFRxUVV1bKtDqiSN79LqdbOsz9kkLLNm0sZoLGtZ5mVpXnR5fPst8PzzxeYZRNnrASElgUoiEyQdKNJ2LN7fVeVEJklZJw2q8lZ9MVL0c8tbmVhmqnpfpNyE9YE66+vw4WrXsY2UH/8zzDvwedoxvAzWWjpdkti20qNT+aTyHIYPBzbYIFm6ZZ3LlqFelrVsSWnQoiRyHGcbx3E+cBxnjOM4JwV8v6/jOG/V/l5wHOdnOvKtNGXooEgdXZZEcelNmwY89FCytEwwdappCcxShsG7in2Myj3NmSOCeZrm5puBceOKz/fdd4Grry4+X1WKrJeqlqJJqFq7Ut1ssp0kSiKTmwqvvpo97yyYClxdhjHTVnSWXVRan36qnk6Z+wovNt+HzbKRSpBZSeQ4TjuAywBsC2AogL0dxxnqu+xTABu7rrsqgLMAWDxDtZC0HYG3s9dlSVRUp1REPmWMDXXoocCOOwLvvKNHnrzQdXqDLspouaSTp54C7rsv+DvbZM2bM88UwTwff9ycDNOmAQceCGy6afF5r7wy8Jvf6E1TZx3StTueR72uSjwyQtKQZx1XaVtlH6tsdjcrY9m2ep+rcv+OA2y5Zf6ykErSoSGNtQGMcV33EwBwHOcOADsDeE9e4LruC57rXwQwUEO+1YbuMdHYNjgUFRh8zBjxqnrqmq2UsW6qyJxXvcxaXptvHp5OGZ9FGCr3ItuQyeOUpRXD11+bk4GoU6U20qokCVztutn7ctvmKKrYKLeNMtlAHv2SrrLmM7OHJ54wLQEpKTrczQYA+MLzflztszAOAhBq6+84ziGO44xyHGfUhKRBJUk4ZZvk2hjouUji7sv2+w6Tz9TEodUtiYKYNUu8lkHWqmFTmY8dW64g9ibLLqr/sumZ6qQq7mZJMHmfpsu4CHezoHSoVEhPUTGJTKZniqrcByEp0KEkCuqdAluV4zibQiiJfh+WmOu6V7uuO8x13WH9+vXTIF5JKbJjKqO7mW2Doi55466rykSqqgNvVZ6PCWg9aYbNNweOOgr44QfTkghsfoZRsk2fLl6l8rWK2Pxs4vDLzr46PaasrMpa//KSu6zlkZWy3ndZ5S4b7Nu1oUNJNA7AEp73AwGM91/kOM6qAK4FsLPrut9ryLf8qHYY7FjyxSaFXFWetW2ddNnLNU/5y142JBuTJonXLKc92ViHio7X8eGH4vXyy/Xlm5RZs4DZs83lXxSTJwNnnAF0dqr/xtRm2NtvJ1PA2jZ22gBjEuWfbtnL1s8LL4hYjISQ1OhQEr0CYLDjOEs7jtMdwAgAD3gvcBxnSQD3Atjfdd0PNeRZblQ69CJNP8s8ONgiu6olkS3y5o1t90krlXB0lU3WdHQsblVkuP128WqDxYfNgUxNYfM9qDwvk/WqRw9g2WX1pmnj8zj+eOBPfwoPxq9Ckff117+qX2tjefspKgajhIqzYGyOSZRXel4++CD8u/XXr8dizILOMuZ4T0pGZiWR67pzAPwWwH8AjAZwp+u67zqOc6jjOIfWLvsjgIUAXO44zhuO44zKmm+psaVhl3ngLbPsKlTd4qjs8pNGhg4F2jIOJ8cfL15Hj84ujwo//VRMPiQdrhts3WTCArdM/dUXX8Rfo5vvvxfKqbffLiY/2XaTnKJp0q2+TPXH5hP8ylSOXsrgblbGOn/TTfnnoZO4MunsBPr0AW64QU96hGREhyURXNd9xHXd5V3XXdZ13bNrn13puu6Vtf8Pdl23r+u6q9X+hunIt9LY2mHb1illkcfmATYM05M0VcLkZOBqO9LTzfvvZ09DumR8n8Eb2cb4arajw8oxj7I8/HCgvV1/uiQ9Yc/50UeBTz4Bzj23GDnyHkfYN0RTdPmUZd5jCpaPfkz0ATNmCFfa3/62+LyLRIflOSkELUoikpCkHXrejamMjdW2QVFX4GpVC6Is8UNMUsa6JlGR3bZ6qUKZnwkJpoz1UCLr4zff6EmnaLJa1NmGyulmRbtTp8nPf61NsQhtooi+w5tHmcrGNsq40UniqfqzOPFEMU6WdR3TQlRsNlMhWs0SIS1lu6+s8o4cKV6vuiq7LHlStLtcnJtD2S2JWomiLFqq/IyqfG8mSFKeZVbQpUUqxoqqdzJ+2dSp6r8pum9QrQfvvw+MG5c9P10UuRnizctErM6ikHJH3ePHHwPXXKM/3aSUISZRVRW8rRK79O9/F69z5hgVg8RDJVGV4elpahQR1Fi39dj4pgMEy0FeC6gHHoj+vux1vOzyFwWVROr4Fxh5lce0aUBHB3DvvXrS47hWLEmUBkXtDN95p3g955xi8stKVBmuuCKwxBLh39tI1rYVNA9QiYVU5Ta93nrAIYeYWzhXuWxtIW7+a4OXyUMP6U/TTyu054pAJZGtFGFJlGbBzkZNVCh6N531Mj22lV1RdcekxUfeZV70rnxUWp99JgJynnqqvvyKRt6fbW2laGxxN5NMn65+bRJ3M90bR2WqN1F9h6nTmVrBOk/G4uNGR3l4+WVgwgT168vgIVLEwSFUEpUGKonKQCs2JN2WOXlT5meUh+xFu5vFUYS1GGBfvbSFzz8H7r47WxoysHUUZZtg51VfVO7N1uCzZT9koRX7AFOT/rwsl2zoG1qNVmg3Kgq4NHVPR9mVQYFhgqj7WGcd8VdknnkzZ44IoJ0nVBKVBiqJbKXIDrvMDbVsstumPDGVZ9XhhKuR4cOBPfbIlsakSVpEITXyiGehkl/S62yq+62wkPVjY+BqSRIlkV+2Ip+lTXVYB7ruxwb3GluwxbK/DDGJbOLTT/WllbQfzaNsTzkFmGce/el6ybtOVL3OFQiVRCZRVdzkNTDaMigFoeq7a8ukoeiYRLbcdxhx91u0EqXoemv78ymar75Svzas7sw7b/3/H38MvqZslkS6WGaZRiWcTe6eWWVJqzQqyp2OFB+4WpJFSaTr2jzTqDp0N6uT5cQ+Gy2J8k43b0zI3WpK07LL3wJQSWSSadPyTd+WhXMabJYtC3GncJmgSHczU5M9upuFY1tbCytD7+e//W0xspSBBx8Uu5led7407mZ51YO33sonXR20t5uWoBoUHbhakqXOFtnvtaryOoy042SVy8ZUG5IUbVlKmklav8vaHriZWhqoJDKBPInpxBPDr/E2nrx3CdhQsxNXhvKo3g8+yF+WpPD5kzLgracyyGfUNUnSKzOPPJLud0UsCr79FhgxItlvdCmvVH7ntU7TRdUWWVV1N9N1bSthOnB1WZ9Lkg2mMtTTJPmWvT9kCAj9lL09txBUEplg9mzxOnGi2vV5TZLL3Hnr7GSK6KhMuEjYTBkDV5uk7PJLqmqNlRR5KlOY21xWij7dLIwpU7KnYUPdt0EGmzE16S+LiwzrDwH0B6622d2MdT49co1YRrzP/YUXxEaRn59+Eq864zmRXKCSyCRRHbvuDjbKta0MOxd+bNNEFx2TSCe2lGEWbHOtLFOZ2iZrFgWHbfcSxnXX5Zt+mnLIw3VHR9y7PGMS5aGQLEsdVKWqlkR5y5o2rmQZlOSM96UfW+a0JjYYWsXNSje2l8P66wNrrx3+vcnwGz//ObDQQubyLwlUEpkk78mAtwNZZBHgiy+KzT9PbJNdV2dt4r5sH2hsgVYw2dFVhqbiNugi7zb30EPqMhRVZ22MQ6K6kK/aIl83pgJX57XBZXJMtHk81lW3k6aThwLFtnJOE5OoyuVhC2WfaxSNvx599pkZOeK47z7ghx9MS2E9VBLZimqHPXiweppVNO0ry8CmOikqy/1kxebFhI35magXnZ3A+PF608yiJFJZ0NvWfnRa2JQR733mGVtIx+9sqztlwlTQ3bIs4KpQt6ZMAY44Qm+ajElUJ8s92nSapR9bXJ/T8pvfFJeXzeXw0UfiWT75ZPR1ZVHGEyWoJDKJjo59zJjw71TNq21sqGWLp2RjGaqSh+xxJ1QVpUQpenJZxslsmKynnAIMGAB8/XWx8hQ1qSziGf3zn/nnYaOFThaKdB3VocSKSrMK2FpPgPzczWy+Z1MExRZJS9XaiA5MB66m9VwjUqYnnjArRxRFltuzz4rXf/wj+jpa3VYKKolsJa0/e9a8dF5bFsaMAT780LQUjZQ9JlEVYwSZrPsTJhSfpzw1S2feusqwLArvL78M/twGOXXGaCnKJSzP3+lSGtjwbIvG1GQ/r7LWPV6UqU7EbfAUnW9e2PpM0vQ1OsuuDDGJiGDJJYvLK48NUCqJrIdKolbC37htbqBFumeNGAEMGZItjaKVIk8/DcyapTfNIii6ztlcx5MwbJi5vIverZwyJT6gYVmURLbJE0SebURH4Oq00N2seIouwyyWRFUZG3Sj8gzzeM6TJoV/V0YLXS9S7rlzgXHjgq/Jco9vvQVsvHF0GcZhUvFT1ueaFN33ucgi4nX4cL3pBpHHmiyvPph9uzaoJLKVIi0fbOygVd3NbJQ9C0nu55tvis9TlTffLDZPWyyXyjg4Femqp5LWN98Aq66a7rdEHVvLU6eFU5Z8k7LCCuJ1iy2yy2ITecdTKQqTi1aby8UWRo0K/64qpxDecQewxBLBsf6yuJt9841wB3rhhewyJslXhTwsk6rantKWQxHzztmzxevdd0dfZ8OzsUGGikAlUStTholdGLbJbkKOOXP0pJOH7OefH/y5qRhBWXbY0mBLvawqOiyJ+Iz0YaN7rPe68ePjrU6yuptJJdH888dfS8xjY51Nem0eFOlu1qrKAV1x/vzlMWOGvrSimG++9Pm0MnnV3yKURDIm2dSp+tIs46Zqi0Elka3kYUmkw9y6KoO07aiUc2dn/nKkpUjrFBWWWSZ7Gkl21EkwZVosVR1TFjtJ0SHXgAHAWWc1f55H4OoqY0ssufZ2fWllvTbPNGyi6Lg3eeVtA1FzN9Ox4VTKWneog6q1lTC893neednL0UZFtw3Psmr9hUGoJDKJLY3OhkZddpKU4S236MlTl5Ioj+cf10lXfRJus2x+bHM3k0RZfjAmkT5si0nkJ20Z+n8nA7GnyacMzzEvbHQ3y3sRYNLdrJUWOCbblcm8g+Zu8rnffLN6OqbG5iSExWDSlXdZ++aTTgIuuSRbGkW6m+lcr/boIV5XXDG9PKQQqCSylSIsiXTmVTS2uZt56dcPeO65xs+8nfiNN+rJx2Z3szCqHrja5npZNvxKIsYJ0UvR959H4Mskx3KXJbZRGSm632tLMXXNy3Lu5ZfDTzHMi88+KzY/3aQdl8vatvxyRymJjj++/M/Xy/XXx19jo5Ioj3T9aep03bIFlXJbdtn85SBaoJLIJKZ3jMrsbmbbYtwrx3ffAaef3vi9t6yj/MarsuMYdx9l3HG2pa4VhbzfJCcIqaapQhqT/CTpM3ZMI7ZM1OMW8973W22VPp2465Nic3+cBRvdbPOeuyS5dp114hc9uvPedFP19HRh0jXTtFWrbuKswFXdkHQqPstq1aVzfpI3cSE/dMfoyuuZPv54tt9XdaysIFQSmaRo8/YqWhLZgr8M/YP8EkvU/585Mz69Igc+E5ZEui3lbI7PVFbkMfRXXhl9XV6Lr7yeqTw5baWV8km/aLLuytvubhbFRx/pSyvreFzGcbSseOuVyniaN0EypK0Pd90Vf81336VLOwsm51y2zfeyoquvMBEqQJU8+0Nv2mXqd+OURGnTK7p9PPFE+Hdleh4kFiqJqkxcY7XNGicNtsruV/L06lX/P8qSSC6M11wzPg+bJxpF5ymP5/RThh1u08Q9i6++Uv+944iAjDpIU0dUfiNPZimi3tvaPwVhq6y6YhIFkdQ6ooztWydF71w//3ywS4bX3UzV5TCJ1YVJ19annhLHmbcKtvY7eRJ0z6b7FloShaM7ULduij55MCrURV6bhsQIVBKZJKph56EpD9Nil7Ghmh5Q/SSZgEYNap9/rkceWylznUtC1e/Pi/9ezz5b/dok6ZZ19zBvdClRspTpzTcDJ5yQ/vdpyeqeq1qnylbfdC5qTCrPNtwQGDGi+fM0MYmSYDr+2eTJevNPQpFzK93uNWnTevFFfemqEDQH1OFCGVU+EyeqpWlibm27m5wMtJwV3QqtPJX2aZVEpFJQSVRl8ug8Z88Ot9rQSdkm5X7KtOAo0rUxrxhBtliF2Ka81EHcPfknPlOmhF+b5DnlfbqZyWdlUx+gQ3F7wgnABRfokSdJTKIk6ei+3o9NbX+11YrNL0/l/yuvhOeXJE/drh5VpYixO2laeT+r447LN30/uhb3SdrbMsvoS0s3WfIuc6gBv7I77ZhFS6JG2Ldrg0oik6gqEvL2EU7SUAcNanSdMo0ti62iTNl32klPOl6q4G4WRl6DxTvvRH9vS71UIauseU0KfvrJHll0Y3LBJSni/r2yjR4NTJsW/xudFk5xmAzGmyejR5uWQB9BCxIdp5tFcdVVydOPyk9H3Sqqfu6zT/zpWqbaSl6WRHmjEqA474XtpEl609NpxVKlvjeKvBTVr7wCDB4M/PijnvSAfJVEedf1VqlPBUAlkUnyOBI46nf+nfk0u38//VSMJVFc2djutpSXXAstlPw3cQuzIUPSyRJF3G6kaXP+rBS982gzeZW9/4RAXXCXSVCkMkZyxRX55yHRaUnUygse0/cedVx4FqJkPe207OmXlRdeAE48sflzGwJXl7Vtxc3FdaVbZFpJ7iEuuLyN7mZFWNjrClw9fTowZgzw0kvR+aVJW6K6oVLWNkoCoZLIJKoNbdAg0QlkxT/Zsnmx5Lek8lsV2DZpKMqSyIvq8zvggOjvVQN/6qRMO6um8isL/nJZckn1a6P4/vvw3+qwiiwC2+QJosi+NE0sg6ImpCppzZoF7LhjvKVFVSnCFclP0KaU15IorWtOkW2zDP2Al7wUc4B4nuPGif9Vy8XmuWoadFrh6CaPzWsd6xcdcpgmLyWRROcGflS52qjk9FK1/sIgVBKZZNaswEDFkydPxpZbbtn44SefZM8vzHe3DJ3s/febliAZ/k5Ut+l5El59tdj8okizID3sMOCgg7Llp5uiLaXyxFZ3s7xiDdjwbGySIc86q+Jm4SeveB260n3oIeDkk8O/r9oENYn7QB51KM7dzIa2pBvT95TniVG/+Q1w1FHpfvvCC/rkMDkn0+VuplPxmaclkc1KsSLJW0mks92mVRK1yrNsEagkypvvvgPuvDP8+1VXbfro2Wefxed+5ZGOHVgd7mamiDo23gaKsiQqewyNNIPilVcC119fXH4qGNhRf//997HAAgvgs6KtGMaMif4+r4mKbqsTE7z/frH5FblISBP3Jo18up6pzrKJ2rG1rQ4WSR4WonnFJMr7OWVRQrz9tnraOshzsennwQfD89166+iDDz77zP65oApxSiLV8jfZ1yTJO+5+yu5u9sMPatf554dpNlGiKEppqEtJpDOGEskFKonyZvfdgb32Ar78Mvj7yZObGlVb0ARIx656mU8B8JurFqng+tvfkv+m1X12i945+stfgIsu0ptmFAZ2xq655hpMmTIFd911l/a0Ixk9GrjllvDv/RMGhQnE2LFjMXDgQDzxxBPh10b1VyrlO348MHVq8+dFWnrceCPwv//lm0fWwNVp+9KhQ4M///xzsTmSlryUQnELs6z5Vs2CKIjNNw9exOd573HHhae1LCuSpHn/4Q/RaeR9L7rKPIioE50ee6xRiRSUdx6uLkXXjTyVJmlJmmeS66PmD2ny1vVbXey1l9p1/fo1vi+TJVHv3vrz2WQTPemQ3KCSKG+++EK8epUc/uDD//pXw9u2tjY0dR15WBKFXWcjYZ1rEbIff3z8NSbjHcRhkyySPHacjzmm+RqdixeVSWWOiyWnlrab9y5yEFEui77fz5g+Hffcc0/kteuttx6+/PLLZrdaL34lUVD5v/hiY+wi7zUDBgAbbBCeflF89FH090GKrCR479lb/5ZYInvaaVhqKWDRRYO/i6prM2cCAwcCzzyj/pskZFHs+k8Gcl0hr+oOsm5MBgB/663i8g4jjSWRH39/csMN6X6bx/Vx5K2QzNOSKE72uLmujfOZpMSVrwlLIv+mgc68jz0WeOMNPWnp/K2udFXDgZTZ3Wz11dXySeKeTKyHSqK8aW8Xr94Fz6GHNl7j25lzHKdZSaSj8Xd2Csslaa5rs7uZX6b+/Rvf297JFGFJZONzk8QpUWyWXQUD8uemJFLLPPw7nzyTJ07E7rvvHnxtra/76quv4vNUuc911wU23DD8+zffjE8jb+Lu4//+L5+8xo2LdlvJU7GdZkPi88+DLW6j5JwxI/xo56T3F/X9sGHNn22/ffBpk2nKceZMYOGFgXvvbf7ukkuardHOOit5HrqIsvB7+mlRLllQKT/dgav/9z/gV79SS0c1T5OWKknxy1ek1XnSdqpLNpPPR5dVYx59uOrcOqk1VFHHs5eJqLKeNSt5elGxUJNShLsZsR4qifJGTma8jSrGDzXQ3SyNkihIy9ynD7D22sFy2EzY7lJRHVLSATHqfSt3olQSpeaEWlwm25VEkYPKUkup56m6GPDGxrGxXgXJ5P2saDfgsLgIeVj3JVnExFmHfPNNsELoj39UEk2ri6jrAk8+qX59HOPHC4u4445r/u6oo4CNNmr8LE9LjzjiTr565JH8ZfDmF9Q3Ja3LUXFwVBk7VsjiswwvJXm6Zsa187zdQm0grg2ZaN8mreNstCTKQ4YkY9CxxyZPj4GriWaoJMobaUmUoFHlakkENO8ul6FR+5VERSu44hZyRbmbZZwsvfzyy+jXrx9+MOUmkZf7ly35pblWkUVrz8yIkiiKJEqigOtDieszTS6Us+KVPavrTNyCOYw8+qwszyRMdilX//7BbmwzZ0b/Lux93PVpr03T5yRV1OXRB9xxh4jtFpdXUByxosfjKEuizk5gscWAc85p/DyqPiStt0Hl/8or4jUo/oru5zV1qh7LjKeeAoKsOotyN4tToAf9Jg/Zih5T42I+VS1wddz1ZVcSffqp2nVJZH322eTpRdWbK69UzzsobdV8bMDbll5+2ZwcFYBKorwJsiTyo9LgdDTKMp9uFmZJdPnlxcifNI+8NO0ZLZLOPvtsfPfdd/hf3sF0A/jwww/rb4qqc6ZON8vx/ubqHqCTunf48ckTO6ioyh93XVCf4L+XIHegoolb9HR05JeXSv3XWWf9zyRoYe66wW5wKrIGmeDr3MW95x5g1Ci19HSStJ/Ko3/Ze2/gxBPjr/MrX3STVPl/7bWN382cKazOTj1VPd2k1nxRyg0dlk0qea6zTvY0N99cWJYntUh46qnseUuSKnOrELg6rr6pKh38FKlsscWSSKdFp02k2TyKcje79NJkaZXZksgrwzrrAPffH35t2pOTWwQqifJGNnTvoOCfRPganOu6eiyJgnbYykpUMMPnn88//6S70Dp2TU45RU86Adflbo3yww8NJvx33nknhgwZgllykffFF8ARR0QfJZ0XTz8N/PnP2dKIUxLliHYlkQq63M0A9b4sLnC1Sn+W1+5lElxXuMQNGwZMnCg+69Wr/r20Nk3KnDnxgamjJpr+RW0eSqKgPC++GFh11eY4O3GWRGHvo/JK8jvXFaeRrrWWOJUuKm5W1AKziIWaDRNxk3jr9WuvNX6nOs/JYkkUhExDypb3M3r/fT3pjBvX/FlceagG6o3DFkuiLJbVt96qZvXhJa6O7rabWjpp+56PPgJ+97v4sk6Sd9z3CeYQidhzz3BrUtvQbb2bx7pD5fqyBa6OOl3voIOKk6OEUEmUNynczQIX8HfckV2WMp9uNmJE43tvJ5Pm5Lcgslp7edHRWZ97LjBhQuNnGd3NnKI65zffBBZYoOvt66+/DgCYIydHm2wirMCijkCPI+j+v/km/pSaTTcFTjstfb5heSf5PgNGlERR+O41toYVaUkk09EZNDMprgv86U/ihLh//1t85rUCSGtJNGIEMP/80dcEKaDy7AOiFHvyfa0vwMcfFydXkCx+vPXtl78EdtxRLV35uyzyJ1UsJOlf/vY39SOa0+Zl0t3MT9gCPG93s6h6YPscK6klUZ4UNbZ60wkKmK/K/vsDG2+c7DedncAf/iDiWEnStKG0z22XXYC//rXx5E2TlkTLL5/t997To20mSZk5jlCARymDg57/2LF1pZnuPi5tWmnzSYu/LelaI7YgVBLlTQp3s0BLoquuSp53nCVRmdzN/INAyp2lLbfcEv/85z+Dv8yiJIrT6Js0bXZd4Oabm3dbDAQud/15ypP2dLHbbuKUms8+E+91Bry0pJ0YcTdLoPQsxN0szJIoqN2tvTbQu3eyieSFF8YfXa+Kt90FLW5TmJVfeumlwjXKT5I6+u236X8bhspkLMi6Noq0coUtoCZNqlswevsH/yl5X3+tlo+8jyzll2dMouOPB+68M7lMSTAZa06HgkPHAkp+ltYyMAsffAC89Za+9ILKI6/xL87i5N13gYceqr+vQkyid94Bzj5bWC7qJKmVbthzvvfe5HPeOKKuz7qJU2YvCS/eMnIcYM01gRVXVP/9jBnA0ksDBxwQnXZSWfzodDcrou29+27+eVQUKonyRkVJVNQAFRaTSJfpcJGknJQ+8cQTGOG3SpJ0dmLixIlwHAe3+M0Tbez4VPMYNw448EBhzdD102InRaEWTLonfHJhpxC7JFPwboMKo9hnN3QosOSSyum9P3Ik8N130RfZ4G7mR0Uh4brCggdQN0mfMkWcMrXLLmrXx3H00dHjQIq6dOSRR9bfRD2bqDJcffXG3+ehJNphh8b3rhsub1GWrn37Avvt1/x5kjggGXZoJ0+ejAkTJog0/vGPRpdbm9zNXFfIlsRtpCiSWhL99791V0+JvL+XXtJTnn53M39eebLCCsDPfpbsN0VZCmRlhx0a3UXykG3WLH3ueyrIe/jpp/pnRVoSBY1HMq3vvxebbZdckizvOOJke+mlZOl5KYulSBL3sDfeSJ6e3HR9+OHma5O2mwMOUHcBV/1Ox/VpiDtVt4xr4IKgkihvZGc8eTIwZozyzxINF888o+bbHbZg2GyzJLlFk8Vs15vM+PHqF+vqZObOxae1hcKFF17Y9F0iGXQpBXUqF6NibHh48MEH4TgOPtJlSRGF7h0g/4I3Ysf5pJNOSp9PWNnnvIDaAgpKotGjRcwnRVYYMQLo1y/6oiIsiTbfPDpPlf4siUuJ/9r77hOKJLlo//zzYDnTEKWIydPCLar/8E+szz232a35yy+Ba65Rl8X/TN55p/F9hKzf+V1rw0irSPG+V7GsUc1H3rNi2x8wYAAWWWQREUxzv/1EfLSg+vH662Z3yE89FejevVm5esghZuTxEne6mZepU8UcZ6edGj93XRGoe/jw5DvNUe5mecUkeuSR5s+SWBkAQikhF+NBCoKw93kSl5fXJQvIJ3A1IOpBUci8o2KVJklHotpfyLyiyjJu/EvqFhinyElS/mnvOwtJ2kTYtbrblT89OXdJ2gcFrdu81ntAY/2MKm8blUQ77xz9fdJ+tIWgkihvpOnxVlsBgweL//2Dga+RJLby2GST+DgsQLi7meT994Hbb1fLM0zGQYPCf/PEE8EWHgH89ogj1OTQSWdnl8VLk0tP1DOZMAF47jn16xM833vCXOMSphNIyKTkztoCauTIkdnSD6BJ4iwTvqD7j1IS+fKaEeXq9tNPIs6Ad/GQxGUwp4FvKCwMXJ30dLOwCYZfURXXhpJODKNihjz7LPDznwO//319Mhu0cHroIeU+LBKd7qdRacUdtex9f+utwN574+OPP0anLNsddhBKgW++UZNFJXB1iKwj9twz/jdZmDu3Ma1Zs6ID1s6dC5x3XrOiyy9Twno4bdo08Y90f/zww+Z+68MPgTXWAMIU2f4y+eEH/YcAXHGFeI0Ljg4U527mOMC++0a7m/ufh2yvQe6m8iS7OEtKFRllvkksiYLqlsR/IIdfyQU0W7/85z/Rc7hDDhGL8S+/jB57VRTwafE+u1mzgLvuCv8+iLzGv8mT9abX2QmstFKwW3Be95A03Si3zSR9uQq6FDlz5jRaYMnPHAc4/HDxPo8TKlXXBK+9JvqAPE5d+/77hgNhmpAK/aA25DjCqnrppYXLtZeBA+PzzmA9G0kR89m4PkXHnK6iUEmUNyr+6QFKosRTLhWrj5hOeu5aawH77KOWn6dhNyy2wwaWV14BttxS7YhdFbyNXjGmR6zybe7cLiVR07URHdncDTcUi8vGzKIEqb927x5p1nvCMcc0fpAlxo7jNN5fSMfZrVs3AMBsjYuOLnczf566d4CidlB8n82KGhieeUYoDk44QTlr13Xx7ujR4o10cfLx2B13YNzTTyun6acdEUqiE05oCBZeGL5yTR24OslutnQVSZJGVOwYOWn65JN6un45n3xSBDPO+wjwpET0TXvtvjvm+PvkMCVRjeWWWw6nyuPDZdwiX1m/H+aaobKw8OY3fryIpwLgcxlHTBe+59zZ2dnY30glSBizZgklzdprR1+XZEPBiww6PmVK0zP47M03xT9hfYU/j4UWUh+7VQmzflNRPMZx773Abbelk+u225rHwTFj6nVP9Xm4bn1zR4eSS+YbNOcLk2GVVcLT22CD5DJss010PZBB4ydO1HtQRxK8ZfHYY8BNNzV+H/cs0iirVl+9eSGctwXD9OnAe+8Fx4cJ24hISlqLGpV8ZR144IHg2JFxaeQVPHi33ZpjtMq0r7hCyLXWWuG/33JLETRc4lc4haFatnJzNU3MwLjvF164cY7nv14qnYNiPDkOcNZZwjLvv/+NzieOsrmblcUd0UKoJMobFQWGSiOJcwlTiXURs+hvq+0Yzpo+XcSxiTL/r3WYnZ2dmGeeeSLTHf2f/9Qn2rUFQRyJug3FCV6skshjSZRESdQWdE8qC945c8QzOeqo0LS7RaWbtHNVVKa11a7TabHSVa7+L3RPRhPEfmm4v08+EQtWP48+GpzP22837T7cd999eEia6N51V6CP/dJ7742Bm24aKn4c3RDxXC64IHqXKQsJJgWxanFdp5upKDFVd7+85vdhSiKpMAnrww4+WBzvHsTLLzfmEyZjFK4LHHFEfRIqiZi8fv3VV7jJvwhT4L9yEhlgkffll19ixTDz7CRKX9cFBgwQ8VQQMRlJM4m8+GJg660bPvr+u+8an2lMIPPZfoufMD78ULwmVTTUlPENE9jave4urarC8p48uR5DSZbP3Xcnyz+OsADjQc846b3vthuw777JNiK+/75ZNkDMVQYPrm/UpFkoqwYpD/qtJComkS14x8codzObTzdTke3884Ubp+SNNxpdaq65RhxmkJWgunbeeeJEQXkfQbHwvHOH8eP1bTy8/LJoi1EWal6iNh07O8VYs/POwZu7SUMw6FqoP/BA82fetOPyeeIJETQcEErTXr2C0/Sj2iZ69hSvKoq1tAoSKYv/917XzO+/b4hDiokTAblWmzZNWG7fdJO64kp1gzrpPRXR11QlsLkBLB7NKkJKJVHTlMvbkOQxymHfh+G3nAiZ2HVOmwYssQSwyCLig6Ad19rOu8ok78JttomXzUfslNMru3fHM6IziFV6XHIJfqode9ykJOrsFIOPqll6VEcplREKJo5NSiLVPIKIsSCofxyiKMuDLJ13UnezKCXRssuKBasqU6cChx3W8NHEiRMblWBen/4ZM4Cjj8bgeubqeXnoQIHuZt7duASxsVK7m/mfpwzALSc+UUrvSZMw6cUXsaQ/YHeUW5D3O68FWtwkM2xBfN11Ikh1EN6Fgus2LuhV29mMGcDllzdbGEQs9toBHHzwwWrpBxHQjn6MOolGZSEQUn7KkxF/O37oIczyx8k566zg33nrQNzYrBrovHv3RrlGjVJ7ptLixCtT7XddkkWNr8ss0/z7CH6aNg2DBw/GrbfeGnmdO3eu6GPkc/I/U40T7uOOOy5AgJCy81oPeJ+ddBn829/Ea1Q7D+Pee+OviUszKiZR2rH06afFgi6pLHHXOk5jv+GPl+nv73/9a3HUu5dPPwWkxVsS4hSKcdb3KuPf738PnHZa+PdB9S4NQXO4k04SJwrKehjUXuTvXFccKnLqqULZmRT/s5ex1h58MPw3nZ11y9moutPZWVfMfvxxfN5xTJ0K/Pa30S6+afH21f7+6v77w38nN/L88XeC8D7Hb74Jv3+p/FdRgM+dK9xK41wdZ8wADjooWBYvMqTJUksBRx4pFJaSb7+tt61p08Ra5rDD4vtz1dM7J09WrxPePsD7vE46CfjXv9TSUE0fEPfw7LPA9ddnTxsoxvrJEqgkypmm5qdQuQIX596GHLQQUXCvUVUSuf7rpJ+vl9pxwSqKhIYhPW4CMH58sFbfbz4a5G52wglAR0eoIid2cX366Vi3FvC36dpFFxWBdfv1U188PPWU2K2aPBnv+gNjfvqp0iDSHWgcQLz3PXy42g6IRO54I+C0MU/9SqwkuuMOUT5p3NNinslDUYO3P6AlUC+flVdu/s63szM36WLHXx4vvODLOmLye+21DVYmzz/7bLK8a7QD9XgxccyeLcrj9NNT5YXll6//H1YXOjvrVjKqhMW38edxxx0iAPfSSwdf661vffuiz7rrRqcp26D3OdVOPJoo25jXkggQFgbSHD3LxKBHj/r/Dz7Y6GL6xz+qtR3pGhMVg8XXd8cO8BFup13fe18BnH/++eHXxyiJpnrj2xx6aMN3aS2J2r76Ct39wbUD4ug4fiVRzFgUqaD34n92558v/uLwWur4yrlLMpV6odgfnHbSSRgzZgz29y/2fRx39NFob2+v1wu/DBqV1M+q9oNffRVuSeSvv8st1/heRSm90ELB14wcqa4Uk8/866+bA2G7rvgLcUMOZdNNgV/8IvqasOex997hddxxGu9/pZWa03ztNXHdLbeI8cvvorLMMsBqq4n/d9pJWIepENeP/uIX0deE3e+PPzbHNwojjXuhd9yaMEH8RW30BSh/u5BzSNcNtjhRxZ+ufN5R/cbJJ9cPMfnii/oz9qf18MPBm21hecdx663AZZcBp5yi/pu11gKuvDL+Oq/Fpb+97rpr+O/keNVNobeX9e6ee4D+/YH//a/x+1tvFRs4QRaigFDa/PrXjZ9Nnix+ExaPT3L33Y0KjjDFjTcmUVRsMq8lUtxmtYpb/5dfAn36AH/9a/J64XX9O++8+qmyo0eLmGv9+qkd+rTvvqLPC5Kvs1PEGPUq2tIyaZK416h4sRWCSqKc+dJvxjx3brNbi69CB8YkmjsXePxxsWAJ6rDTWBJ58exWXXPZZfFp1RQOKgvWJsl++9vw40Y33xzYeWd0+D+PGNS/k5NHuZN4882B1zUoPWJO+gpUkMgJ7YwZwmrAH6y6MQHgjDPExOX113HIb37T+P3//R+w2GKRMgDAuoDokIL8mwExMKmy9tpYcvLkYHegjg5RL2fPxjZvvokeSKAkOvJIsUvhP2I4gKn+XdGg+uP5bMeaZVcgQS6YUZO/jTZqeOtG5a0yiZQWBDXa/JYJEVYs3zz0UKqTADsA/E3Wc38efuRu4QUXJM4H06eL47njOPfc0MVBaP2RR683/0BROIgYZwH9WeRTkxaNMp///AdYcEE8ecop2HvffevfeSd3iy0GbLwx1lxzTTwf1d7j8CoEgk5SittJnD1bKJOC8Pb9cpIksw263lu3/aeZAWiIaiXLqrNTmOi//TZuvPHGcDljYh1cevHF6JTy+sas0GeXxB1PErbw8ubZ0TTKpCNoEu1TIAci5Z0zJ9waT8UyS1FpMznMCva44xpiH1126aXinySWRClj+iiPMYMH18d3f35xeasoibbbrvn7v/8dWG894bbkf8ZBckv3v3/9q3mT4tVXhVJ02DBximIS3n47+vuwOnLHHaJueOegUm6/u5mfuXOBNdcU/wfF1PHz4IPx1lg33aR+ku5554n+OYiwOnPIIWKxreJqpVpfvXkde2z9/0UWEX/eMejZZxvn9lHl61US6Qz6LseZKCWRV5Em5+HXXdd8XXt7tKttUmWALKskQYJHjWqy2A7EG1coqs/09wWynFTGAvlbuQ547bXG7/ffX1gFybT8z0D2q15kWTz2WDIXrjB3M2+9ikKWkePU+624a6OQ8QTvuSd6Q/Gii5o32Z96qvna774TluQrryz+D5inNHHbbeHXJXV1nDULGDGiYWO9i7ffFuu6oOdZQagkypnv/O4Pc+eKXRkvris6F3/EeS8ffSROSPv1r4MHlaCJkH8y4u+0vOn8/e9d/56fwD9axfWl4YqPPxa7CVJb7Kc2aPVszig0/SOOPFL8I3e15GtTEp40zjwzNL0OxExeOztF/JGaNVUgrtu1qzMtyD3j6quVdpC6bCMefzzw+0lhyq6gOvLNN7jov//Fn1CzevFf89ZbwHXX4ecvv4zfI8EEXu5eqdSFuNgHr74qBtmQ+20gyCIlyqXON9kO7Pw6O4Ff/UoEKE6Rv/fu7ve2P999//yCC4RJ8LvvCiWg4nHriZa1228vXtPE6PDvyPqf2zffCMWGDIQaQKgCee5cDAHwczWpBL/4RbN1iIpFX1Qdrp0eNO0//6k/N7+FEgCMGoXXXnsNV8gdzVmz4l1AfMytTQZnTZ8ervCVHHqo2BV79VXhXvbQQ0IhGXZiS8TzbVIIf/hh4/198EFTmzkdHqs4GYfp178WO35B1lpevPHVAizM5rouXghSoFxxBSIjJ6n0Rd76sMQSzV/PmNFYViq7xyrI8oyL2fDcc0BnJ7qh1o6lLF4l0dSpGL/++ugKsasyuVVs38c8/TTuDPriwguFxUoN2S+6YUoi7ymBYQcSAKKP8Fr/SDxlEzjGBH3mb2+qSqKZM4NjzfkJWlRLpcDdd4v2592ZD5Jxr70a33st5d5/X4z5gHJcxsi8vMQ9/913b06rszPfwNWdnc3KgF/8Qj1g7sknC6V+0ALWK9v339f7KOmuFTWPloS5mrquWPwFuUTdGdB6vPe48caNVmxRlkTe3yVVEn3/fV0+f7ryvr74oq7M8OKZlwKo94EzZjSnteSS9YM7XnklOK0owuZ6qnXLW34zZkRvqnkVNlF9pv87vyXRlCmi7IKYMUNswsj2G3Yfck7u7VPCXLS913jjWPmJmzdL5BiYJJ5jXOBuea1sZ0HyyDr80kuBYy8AcQL3MceIDXIv77zT3IdJmVRd3fxkPSBn5EhhKeR3Y/embTJuW4FQSZQzXwwd2vhBUGWdMUOYHO68M4AQSyLZaG67LXiSEdSI/MqoKHczT6eRZOrc2dmJuHCZDU0p6vQpD/P6P/jpJ+GvKheKHtnHycGjT5/INBsmpBHxKOZHjPJLZSfEk9ctt94abeGgMkkIGfhGSusGac4eRa2T3zjs++nTu+pZHwSUwZw5YgDwm1nKsgza8Zk9GzjjDHSrlVmThLI9vP222I2QExsVH/Gg+/WW5RdfRFo3BZb6d9+JwSyovIMUJRHc4d3VCPKL7+wEbrxRKFsUT/rpADBixAila7smdqqTUO89+60OpK+7pH9/YNCgyDoXpWR8H0CTqiSq/t50U7PFkuwTPbuA8/t/FzQBkuVRmyy3zZ3bVS9Hjx6N/4UsZLpK8Z57gPnmC5ddBsX0MLVWD5/4z3+AddZpTtw7Llx1lagPw4aJQNVSYSk3HGQsmqDf+ujq5V56SUyAhwxpvOCTT5p2y7oDWLCzs3FS/thj4lXV1RYIvE8HwFdBiu3DD8caYen43cTC6ol31zsgsPac2bMb08lqSST7vaDx4MEHhUXJHnuIMnvuObGpcO65mAXgHaA+yfTKNH06Fn/hBXTVoCzuZr6Fycpff409/NcElGVXnam1k1kq1p9Bz6R/f3Eajx/P77f74YdGV4Jp08IPC2gQMsTdzD9m7bVX+ElHXpmjyllapkglwXvv1U+m8+IfF996Kzg9xxEWNSGbWZFyBhG3AKopwxuYMyc/JdE774i21aOH6F+WWSZdvB0gePy+/fa65eXCCwtXdyDRZlVo23/tNWEZHeTiFxVbSBLl9uQljSXR44+LPnzhhevukWF146abhNLKv9lz7bWNv3n44bqsQRaucrzo37/5u6QLd7+SKOpgHKCxbHffXZxOFxcHCIgud38791sS/eIX9XHWz0svCUsVaeEWsQnWkPbYseFB0r3yRG0e+ecUc+eK+W2YJREg5md+/Ir/oM1iP/LaIGVzEuR4FKTEvfzyxvdJ4so9+6zok6PwbkypyC7bsf/ayy+vuwy3SFwiKonyxu8THlSx5EImYlc+NsimgqZ0RtQOi+f3ykqiKVPgjByJUE/0++8HHn4YDc5fUcfEeujh/+C994QJ8p//LBRFno6tU7GxNig9In4TeYIUEH/aTZdgoky/ilEmRMki7/L7r78GXnyxSfHXVYrnnCPqSJRstYG0G4Dl7767ecCcObNLFhcBi/wffxSTPb/rnHyWQYqQm28G/vQnbBbmqiPLedVVgwc1L34f8CC87STqeGGIGCUvv/wyvvE+n6QuRa4r3LnGj4fruuGn8j3zTPDncnKjuPgeD6BnzyY7u2hUJ6HePsT3m6uCAv5NmhQ5If/LX/6CxRdfXH3BEdeOP/qo4e2N0i3WM+FXPNNFUKu3jkcp/+UXX+AkuXvqoU9cWt625PWxr+HUynauX1EhUbEY6dVLvPoCrL8bETy2HbW+dPjwrk2IBm65JfA3f33nneYjo4HMJzc5CFAUx3HHHWpWP6NGCffAb78NrPNtAF70ThazWBI5Tle9O//ss/Fl0C73LrsIK5SXX67vTtcUDkOAYEuiGl0tPIuSSCVgeUD6fiXRGX43R5X2/MQTSnmeN358o/vpEUeEWxlLllwyvB76yyIqCKq3zFU2fuQ4pyP46X//qx70Oa5fDDqZzX8Coj8tnZZEfssLrxXuNdcIayDvCYtJdvWD5olnnilii/jGg8iTTf34XMW7kP1wVOBnL6oxifwWUfJ3UbL++GP9+6++Ep4E++xT/37o0PiyPPnkxvdPPtlYn+QhOKNGCSsPL64L/Lxm7ztsWHPa3nReey2+nvpdpOTBOF6mTKlvUHnLViqzvC6nXlTdzbzfbbll3cpQziGky2TQc/Fb/oc9O5mHLNsglyWJ9x6jnqU/jddfF/2gN7YhoK58lDKGzUe8JD1FNuz7KOtP/xopyr33ww8blccbb9wcU82PdzxS6R/khrc/7ukRR9TbSYucmEYlUd74B7kgs015TGHt2kBLItUOOIJ/ecxlJ/tjYEhTaCRQEg0ahD7SpcVDl3Jh112BHXZo/FI2LDmgP/GE2LGeOVPs4NQIXQafd57YxfNYOuwuMm3seD77TAyono69QekRUZ67+6/1o6okqj2TLEaJ8o4ee/jhwPhDXQ1YLpgV4gINBzA0KN6M576WA9Bj6tTGQJuyTPwdeJS5ai2YZ7ewgSbMRzxoAeeLKRSItw7ExHlpA7DOOutgNe+O7pNPxufh5ZhjhEm239VAlRtuEK+KA47i2XqNeBdUt9widneDiIhB9Lrf/14S0k4WAnDrqacKqxG/RaOHLkeQeeeNjWnhdwB4Ui4A01qE1CYOjut2ufE5qLv0ee9sBcTEO4pxHW2r9QVtQe5sgJqSSF7juvBOiT4YPTo8X3gU7oquHu0Ahkbcz9FQUJqF0BfAlClTkv3IMzZF8ePBB4sF86KLhsYz2dWrKMtqSVQbr59/5hkMDFKoea+Tz9y7OK3ViYkTJza1o67eL65efP11eN9x112NLgJBKCiJXpMnAElUJtlbbtn43nXrY7b/nrxupCquWI7T2Kd5FexJJu5JlURffRW/Y500Xx14Y+VI4k6Q+uCD4IMfvN+rsv769f+vvLLx/qRi2ztHiNs08xK2mXjPPY0HKwCNcd/SpuvtE+66q+GwiUBUlUT+8Abyd599Fr6Y7927fkKbvN6rWBw9OjhAuhd/W/vnP5PFeJO/f/TR5hiaMp2nnxbxq+ICUnsVlGGstJIIVAwEb5wFbOAAEF4Gkqg+09vfPfFEfd7sn28GPVe/u3vYffj71KjA295rk7gdSgWp//l7lURRsYa8SqK4wPhxpzp/9FHjyZNBzJoVvW46++zGGD9BSqIBA4Tb+5Ah4dahgJjHBp3ILVHpH2Tf6F1D+Nc5dDcjWvDveAXt5vquXfWyy9C0JIubLF55ZWww5p09Hd9Cffo0DtaeyaSykihkIjJHRZMvB+kttxQ71v/8Z0Mn0WRJ5Mezc3sC0Giq6boiOPbtt9fdJNBoHfRqxCkjgwFsEnA6ThdRR0B7ZUjaiQSUpxzOuwFAgAVJG2rxQ+TkZtas8ElAXB3y7GjvBODXJ5/cuIMUFHsjRO4u5A6IPDHN//3554vdRr+MYbv8jtMQZLWJKGs8Hz3mzsXlADq9O7GKC9IupCtCgHKuq5SidrNl2cn7njBB7BCG7D41TW1VJnzePuiAA4Bllw1WCHktD3zPuE3KqGgG/BaAruVURL/UNe1UULz6I/L0kv/EnZgYg+O6kE4xbagriWZ5JqnzIkZJFKP46FW7vzb/6Wk11lxttcaTv4KQv5swAd593ahBvAMKfamPyNKcNQt/B+ruUAn5DYBlk/aLfouBEBaIievlwHdvmtzNYsfL9vb6oiNASTTz009xgm8zpSvNuF3cxRaLnvRKV5wwAsaErjKq9QFNpeS3Qonrg8aPF4rifv1EfxlwT5/JwKdxLigSb5/m7XvT7u6q7Ja/8IJYxBa9OIgr36AFbdihGDKtX/wieqGVBK8l0WGHNfaF89YCB8TFPQlDdeE8frxarJDf/U60ibC4M9789tyz0bpm9dWF9awnfqeyksiPqtuuVDDIvsrfXuPmK0F1J0o56P+tzG/8+GaLNdcVynjphiRjzdx9t7C4SBOTyPtckgS49hJU7tLlMmwO7B8LgjYLVZUEfrn79g2+zn+t/8TBKMLmCnJzJ+5QFG9/F3aIkOT11+uKO4lU+o8ZI/qRkMOCuujsBE49Vfw/ZkzwfM9jJBD47OU4AojYtmFxS3/1q2hZtt02+nugHs9zxx2FBd+55zaPEbQkIjpw/UqiqIX6Dz8AEydikEex0YXKJObss4XGP2Si5VUxBBh6dtFgiPvII/H5+ohUEslFsb9D9DW4hA41IvaD3Cl33XpMm5137rJQmDt3LobXLl86yKKrxlEAro3a7VKMav9GTRHVptrxr7pq00f71V67AYGLmsUAbArAlUqVn34Kr2MxE5O5HnezwN+FKYniTD1rDAHQFNJu/PjG4HAKR5K6W2yB2SrtIYbh48fjMACxZ3+dcUZ4UEFZFq7b5G52OwD3+OOj3Sfk/Z57rmgD990ndgj/8pfAy3cDsPiNN+LBBx+E4zjYb7/9Aq8LlNFL2O/23hsv3nsvxvsUO8MA8Uz8J5OF1O3F4/L3EjbY+pSi/pzkt26SHbgAtn377a6gyW2oL9C9PfcOAJoOT/Xeu6J1TJvrBk6ApkyahPfirBRknf/gA3hLLGoQPw2+/lwBFdXJ4vGXhLJp/CXRpLTEaIOvrLJYdMyd26WcnBfAZlGWRFOm1BWlHiXR2JpFX38Af/UF1e9SgGoMXO3lnnvuwdchVkhX1mSKVBJ5fzd2bLR1yIABdcuuBx8MPG7+xEGDxIT844/jhf/ss/DT4/JUEkl0BHVOgutGHwEdJI9qANw88N7f8ceL17RKIlV5BwyoL+y32ir8ur/+Ndq6LuxENUAslvv2bbTcippTRT1nVQWIvH+PFWkk/g07xQMxApk7N369ss02zcHp99ijOcYMkDwIcZL4d16CZN5gA/Ea1s79MvmtJ4Hm4PnSCtyPX26ZdxBpFWFB1oNBefuRh6kkOe0rKLaa64og7YMHx5/M6pfroYfiLRWjDlmSbLVVcAiKuPr11FON1o+Sk06qjytr1CIkLrecUEadcgrwxhuN17eIJZGmM2BJGHfdey92SfID/9GpEpVGfdVVwnxylVXCgybWCAgn2UXD8jzAnSyOB+6+G3uF/U52KG1tkR1krJIoqoH6B+ff/x5YcEH03XRTjARwBIAFI5KehoAAuF56xO/Nz549u8sS4YX//S/aCkESof3fGQjsKFcE8BRErBMHEAsSr2WOlziXmCOPxIyllmou++nTxT3LjnvqVLEokLvUUTslNYa/8gpi9isEsp5H7PK7nZ047Ne/RrgTkxpyKFkg7kLpDrrnnuHXzJ2L/h980ORa6IT50Acxdmx9h3zOnMABf6fan7PTTugJ4Lbbb0ezE6IPlUFccscdGH7HHbgegHc/puv/t99uHIRjBkoXwOTXXkNI2EZB2LPu1q3RXdT3tVxuT5k0Kf4ZKuJ1N/NanQROyTo767IrKokmfP114MSmA0DbxIlqcQR88kRZ/vwMyZVEQ+MvKe3uUkNZpV2EAEBnJ+a2taENwEUA+o4bF36Kltf1yqMk+n7CBAwKSb7rKpWJaEKlgwNg9913x0orrYR3ApTRe6HWBmr9xn2+72fPmIFu3vmIP5B6FBcEq+T/CagdVhBHlKW2H68LhcoJaBJ/gOqkBJ06FcUnnzQfHBCHv04stRSw007R8VF0ETTepFUSZd2tP+OM4BP2wohzmfITtciPmrN7fxdl0SjvP2yDLk9eeim6PcmFtGSVVRrbht8ax2tJpPJc0ypQwixPDz20rrT045cnSD6/BXuYO5df7gg3/tT3GEbcmCYVXVmVRFHW/EH4w47E4VcShckbpARVqVtBmwznnSf+vF4g3rmuP04ZLYmIDt72x4uIcylIMlnxIxuSfyEXgLIlUQp+POAAfFOLRROK40R2aLFqmKj78zfeMWOEoqhGdDhjoSSKxGtNEXIU9qSJE7uUbe0AfhmXpgIPy0B4AbRJM91LLxWmvkEoLIp6SrN/L488Isrb23H37y8mgyedFB4kMw2emETfhOxOtwHY3RsIMwmeU1Ym1iazIYb5zQSZt0p5XRfbnX8+FELFNuJdBDpOPeaF4wS6F0rOADAd6WPDxBFpsHvjjfX/FepU7yh3uyh8E6gwJVGi/mrNNSODk3uVRLGDo3fi8uKLStm/+frrgWNAB4BucScAedqfd3oe52y3lJJkdVScUHZKmKYNNLmbHXdc+sTmzMEPtf6jS0UeZt3ixaMkWiiiP0+EymlgHqTN08cffwxst13gNbsBcEIUn92efDLencGP3DlOsmBPQ9LFi0TFgkkSFCg6Cbp3oIPK1D+Of/65sgV0EzGnxiqhGsfRT9aF2J/+1BzcVyf+Rb50rwPUlURRQd5//FEoN2TfHxNSQjuqAbwBMRf2nrz68suN33td6uPmDXPmNJaRDNjtPWErjDCFxFVXNcbYDJJNMnx48zVRVmZepOJCHjARFedSBuSWMmS19FPd+EiiJIo6dU0VlbHRi38+FbYxH3QgjI7+VZaPt5z8GxzvvJN8HCwhtCTKGWO6xoBjmL2E2JoAEC4KWdgQwKLnnRd9UVtbo2WLr3OMUxL98O9/h1sD/fWvzZ95/G7nbf62gV4x33vNlT97//3ARdiMmTMbLBJivGQbYieFMV3lNJSIheaYd97BcjE/n4IAK6p99xWdob9D1DF59FNzlZwzbRpuPvhgBBy8CgDYRiWtBRdsNr/2LAw/rfnmr60qW5Cvs9wVThqMN4gffwQuvLD+fwTyvKGw8skVbzlocPsLxTfh8U+fZB+R6IyqsADcNbxKolimTq0r8hRPnGsH8MNSS2FB3yKuAwoB7kMmdlHKrIsBqIWrLhEhivk42gDs6P0g6rTPGGZMm4Y5KSb0n33xRdd4MSiiP58AoF/otz78p03GcAnEvOS2DLvYM264IZlLuIzdRjKfENiE3w0CiHZPS8qqqya3fvKT1movbrPRNP42pHrKVpK2d9VV4YdN5E2SDcA4GaWF2TPPxPfh06Y11hkZd3DBKB8ABcIUCJ2djYqMpCfIernrLvH65ZfiBDJVRo3KXt9VlYhPPZUtn7zxBygPM64I85rIwqRJ9XltnOXl5pvHx3QqO66MpWHh35prrumWnSFC/VH434xFFzWSr/LfWmu57uefh35/s+78evXq+v8njemeuM8+gZ9/BrjjNN/DPQrXTFtqqdDvxij8fkrI5z9suKH5OpP0b8EFI78/wLR8/r/99jMvQ4n+zkt4/dx+/fTKsO++Xf38lL//Xek3fwDcj3v2bPp8LcD9eP/9I387vXt342Ve5r+vNab1FPT37/xrkb/ttzcvQ9F/m25qXoY8/u65J/y7K68M/26RRczLbvPfcsu57rPP1t/vsot43X33bOmedpra83j0UfNlwL/632GHFZfXM8+47m9/q3ZtR4c55YJmAIxy3WY9DN3NcsZUaKtuSY4Z9fFy/CWZmd3ZiS8idrsy6PGD8Zgtz6Mx2XG33Rb63QCN+QDAzxWumTfIXayGSpmGua58FRQgznZcN/LrgNB1Zrk1NroQ8ZD01K7Xk8RmUsC9/XbggQeAH3/Eyd5TcCJoB+AExAbbH8Ayt9wS+du5uuMXtBgx53wlogMGrYQLQm9rIV14XUxaBXmoSNXYbbfw7w49NPw79uXRjBkDbLRR/b201L777mzpnnVW8Of+YOZBVqarxAWq0EDv3vnnUUZUTpTWxcYbN7vrhpHEba+kUEmUM6YmklmGoOTnmSWn22uv4brNNgv9fojuDGOCNqclIiSddagoicIUaCrBbG2jM6YDz3zKUo6kjODQUiSNnaZbyeLMnSsCe/burRzXqh3BbezIgM/80DfcHtphbgOoKMaaFoCQqpLB1bUlSRvTys/ee6td542tJPGdQJkL80cemdO6aN7gi0U1FtdpWYOz2I8WJZHjONs4jvOB4zhjHMc5KeB7x3Gci2vfv+U4zhpB6VQRU0qiLJY4sfFzNPGniO+aD4MvF3HBZE2Q1PKi7PwUEyco4XkxhaLT2q2qJK3PcbHIsrBj/CUARLy3tM8264ECRB9KMaRKTtQJqIQQUhi6LEluv11POnkRd3hFq1K0kkiVIdrNGawjs5LIcZx2AJcB2BbC4GBvx3H8hgfbQqzJBgM4BMAVWfMtC70Vjge3jQSh1kgINiqJ5jMtQMHQ8qLaJFUSLZCLFIIkhuixgfGJ9XQATYHUqwaVRIQQK2Dg+9bGVLiL7jFbc2GnrlUIHZZEawMY47ruJ67rzgJwB4CdfdfsDODmWnykFwH0cRxH+eTpMnPVtdeaFoEYwEYlUavBZ1Bt9k14fcZzUbTwBKi8rAIdECfhVZnqT38JIYSQlFBJpMQAAF943o9Dc8xelWsAAI7jHOI4zijHcUZNqB2HXWaWawFzNNIMFRTmoXsO8ZKnu5kqy5kWgGihA0A300IQQgixn160H7aeoGcUF8eSSiIlgjbU/JbYKteID133atd1h7muO6xfv36ZhTON08F941akHcB400IQQqxikGkBYphoWoCMfBt/iRY6QIswQgghCkybZloCEsdCCyU/wY5KIiXGAVjC834gmtfHKtdUEqe9XDYlVT/WtyjaUU1LlsdMC0CIRQw3LYBm8jkDsjhmFpTP8oDyiXY2Mta0AIQQuzG1dqHVDTFBt25AW0KVyDzVP2JGh5LoFQCDHcdZ2nGc7gBGAHjAd80DAA6onXI2HMBk13W/0pC39ZTNksiEkmgrA3nmTTuKd0d4Kuf0X198cfxs3XUT/+6THGQhxAaO/f3vTYuglbIribjJocZ/TAtgE4tZrO6bbz7AhEV90sVSFEl354kddEsxg9188+z5/vGPwMkn198PHJg9TULiSKMkmteGIAb5knkkcF13DoDfQsw7RgO403Xddx3HOdRxnENrlz0CsVYcA+AaAIdnzbcslE1JlMT6RdcRwEW5COjmh4jI9/MA6F2cKACAz3NOf/U118SiSyzR8NkEJz586xmK6f8rzaSEEIPstf/+mPXvf2tLz11kEW1ppWFpo7lnZ5BpAUpCB8TuHoHdu8F77AEcfHD8dboXK3N1ze4AvP22vrR0sdBC4d8tumhxcthMmrVLz57BnydpYz17ApdfXn8/X+1c3jKHH1lrLdMSkDhoSRSIlu0C13UfcV13edd1l3Vd9+zaZ1e6rntl7X/Xdd0jat+v4rruKB35loGyKYmSoGvXWeN0pFD6WqZFPvCww/LNoL29aXepnxt/EPSZZ5+tlPy23t0jAJPmmQcvqEuXGy9eeKFpEarPHXeYliAdPXqg++KLa0vOxhOzPjUtgGauLzIzucCxjI0ALMDFsMDmOZrjqMW98I2dJIYo67FO2iMCSGdJFLbITqokmjy5/l62z+OOSy6PLay8smkJ9LPmmqYlSMaKK0Z/H6UkClvnUElEslJJJVHtnqan/f1vfgMsvHDX2/++/HJ2mQzgTI8vgVeQwFLqD3/IIg4cTR3Wx2FftLeLSSsA9Fa3k1pq2WWVruteU7r9VPNJf79/f6zvuybTnuRuu+HHQw9t+KgDwH9jftbZs6fSIJ9YlSQnYSlc+MrARgBu2krRmTQsDsEaa2iTB4DyxPf/VNPr3l3bInPOBx9oSUc3NihqdfLHIjPT6bajkcEAfqiNF98ee2zT9/54AWGM1SZRDRMLD5vjRqoqiZbznJuo2ufazmabxV+z+urp0n7nnebP/vxn8araZnfcMV3eZSGNkkgGaPbXWQWL8y569GicD8jfZg0SvM022X6fhSrGWfJukq+4IrDBBnrS/dnP9KTjJ+4ZpLEkCrOcqxB2zmAqhBEl0VFHAVOn5pd+bfDo5VH0JOKEExoWVgsppjMHwEpDhwIBk9pYTj8d/ZP/KkagObGXzAQwOfaqGlkXFIqD6BIAzo/4fqOwLxynrlH/wx+AKVPUlEWq91WbrM+7wALirYKVUiL69sUCI0Y0fNQJYP2NQu8YAOC2tQGDBsUm/2ZSeWQb8Pvx/+c/+bZfANh//9CvpmjK4mMAE9Zeu/HDMHeqsAE8wqUzFSH9sT9ulrICvGfP8F0mH994FnJBe9Udyy+fbDJdELvttFPD+28MyaGLM885pzjXBYsVEHNr/fIivoX2BMfBSYpp9Nddjlnqf23cSEzUHC3tHEeFo46Kv6atTa0P9N5D377pZUrKIYfkl/ajj8YrKjbZJPr7JHNFOZeZNEntepXn8rvfqedvG9KiKskaRlon7rBD4+feOeB660Wn0aMHcPfd9fe6lEQHHhj9/Z57Zks/inHj8ks7T6Lc33v1Ai66SPy/8srxY91556nlqXvOJ4nz/OjWDVhmmWRp5iWrRVBJlDOFn27Wt69ouBFa08zuXbVBo2cCa5Km36col66lmKqZ/EsvAWPGiEXcn/6UaHHzytCh8RfJDjKCWQAWVQ2MmbWuKE6SxwGICrf7nf+Dq64SrwstVDcDnmce4UoRtCPnR3VHSk4kah1ve0BchBe9b3bdVS1dL7W6+ymATWofdQ+YfEzyBEt029qiFYLLLw8AuNzrR6+CfN4dHcAXX9StZubOFe13qaUCf6a6yx9K796RcS6mb799fBoKVm+dADb3KRgweHDwxWH9le44VSET3m3QaEEXq/5dYQVg9GgxiVpuOSWLpwW23rrr/9lhF33j66UuuADYYov6+3vvjc3HzwsAPlfoq8Lo6Vu4p7YgtYQDf/3r6JgkOgno0+OWCzM07To/GfHdgvDMA3zuNU57e7Qruace99Q9Sc6iJApyC5bpRbn9RY27eQam//vf469xnPg+sFevxnsoUtGcZCd9fb9dcAzdugEHHRR9TVjsJKn47NULeP11YNtt4/OT84BZs9Tki1NaHHAAcH7UdpwC1xfqHNvI99+L1yTPeJVVgA8+aG433jr5179Gp9GjR+P18v/u3YFRo4C//CX691ts0WxhtvTSgG+DsIm0SmYVttwy/po/FmrjqsaQIeHfzTNPfbPFceL7HVVLI9lXDxsWfZ1fgd+nT7S1kIol0VVXAf/8Z+Pnsr7de29zHamip5APKolyxlG1ovj5z1PnMdurAfc21BAlzqsqid5yS7j1hJy0hEwQ14lLu6MjVePqUhKp7pStvTbgc3X6LYDtFH7aJk2PozjiiNCFvGSzrbbCAqqDT1ZLoiWXzPZ7AHBdzEJdgYKf/Qz41a+AM88UE55va85zcoKkcvKEf1cpjtogf1+AKfnnXqsfRTe2BvoLe7J/AHhGfhYwuPXx7vy0t0fHKfjrX4EDD8S8v/hFw8drAbgbos5F0t4uylEOelKep4LPq1N2uYuaFEXUtUXCdo+8yllvn9M/2EZvDoD2Hj1CLW3kNNJdcsnwHRndi9CQBZd/WRDbErt3F4oiQLSFV18Vk5QInAEDuv6Pt0GssemmwOOP19+nUCBMAPBTQheUhjhEw4c3fFf2aVF7z57FLaQD2lncsa5zNNX5IPfXgwAMBTARwBuyPvpcvFzUZXSvvLI5Ee/YrSHA8YLeN7qfiyz/qPlG1Hd+RcBJJwHvvZddLkDtXh1Hba7krWdBGxqbbtp8L7/5TXy6cSSpq9ddlzz9OEVMmBWnXJA6DrDaasAjjzR+f/TRzb+RyhC/9WsYcc9vn33U0oliu+2A8ePF///9L3DqqdnT9MdmOf306OtlGIOlFY41cF2xaeYfZ71lte66wFtvhSvqe/QInuP36CH6qjjX/379mpVUUVYkN9wglAMqp/Adf7y4NkyxHKaMVFG07bZb/DU6OOII8brggtHXAcJbIIx5560/VxUlkeqGnxxT5CE5Ycoif5m2twOzQ7ff4i2JOjqA+ecXc1vvmm3TTcXrrrvWrdE23lj0E7QkIllpU13433GHUMykwPFW/iANvA8lo8r99gtv1PLzkO/7xwUI8yuJ+vUDnn8+VqSu6ahvMZ6EywConEXkqJq2xk2SVTpPSdxkUFcnHMbDD3f9+wxqQXTfeEPIddppouOUFlZJJvMqk9wxY+r/L7AA8Npr+CJg0X3WuefW30Q9o6OPBt5/v/EzxxGKpfffb4xLEnMvaw0fHm1JNHAgcOONTUHsRgHYA8CTK6yACRtu2Pw7f77+CW+IskbZCS8sRlVcnQybeHsVDd4JY4iJbiei+79rAGy5xRZwPvsstZJoblJ3l5C6OBONQaO9/095+GEEq+t8xAU89Ux821QnF/7rPJMg1VCYPQC0q1pL1KweGyz2fM+wydIwIQ0tKal5dwyTY1xHAei3TkNE3LmAdjYzJq0eWd0qarwU8Nk7EEfQAsBLSy4pFgEBi6MZAF579VU4QYoEb31IoiR6INgGciLQaB2Q9sjroD5atskoF6IkCqRBg+IDoOqkrU1t/PTWs2nTmq0tLr64+TdBCkA/cTF/kmxspbU8D+Ltt+tW4kHIsS9MvpVWav5MtjvVvjkuJqUOK4O2NtEnu65wrYvZiFDCXzc8mxeByLJU6Zfk8/Dfu/85RClkevZsVNTJ38r8Vdy7/fGi3n03/NrFFhNukypj0VZbiWtPOCH4+7DPVepUUaf7yrq/4YbAZ59FXxs1T/S62qusc1Tbg+yzx44Vr6NCzrnyu/C1t0eGUYjdYPPW0cmTgVVXracrkfe7227CU8XSmIM6qf4dGsZRXUx369Y1AIxCfSKnQkdHR13rGqOx/iMSBJsMW1jIxh7y/c3/+If4Z6+9wtOVabz3njAvjPNTBtB1Z927R5uGvvBC7LGrp8Vlpvrc4ibJrhu/+yM1+nHuZiEd0nfy2XuDV/pRsebZTthYXXbZZfEyBAzUj8XnEMzYsYFWQQsF7TR1dAB/+5uwNgqxYAEgFhp+U1n5TIcM6VK0XHDBBbHPumevXtFKopjB7+GHH0a/IDehGTWnDmnWLeuSd3cmITO9ZRY1mYoa3MLqtPc3XveNkHo7BwH9n+f9bHiUSGF1P2ZypaxskYQ8K796R1516+DB6LXNNthgpm9pH7QrFdMXOB7z6HlVrQv99+cJ5hqnbJD0RMxmhTcm1lVXYQSAAwB8LhcH3np04YVIZBcYsAvYYF2bJu5YRGDLb6MmiZJu3bRbrHwd9oW819df7/oosJZ4rEC7aVhcXj1wYKAyz1vPXdcNdMNy48rG+33c+DdhgligPfhgaKDf559/vu6K5DjAMcdEpxmGQozAQKLKu3fvxoC38t7jXFfiUK1/jhO/EPGnNXVqs2uXN55gEuI2Lv39dtRCN81psGEyL7us+JPuy3vsIV779wcOP7w+Dw4q58MOE5ugfuRvVNvfTz9Ffy/TyRLc1r+w1dFv+ZU9ccqJzz8Xr2GbIG+/XZ9fyv4gypJIEvZsw4JeqyqJXDeZwkVeu8MOYu1w113h18o527nnAvff3/x9WGgJlXlK2DWPPhr8eZR1cFRbk/m4bn3dGEZU39OtW/OcNQrVdiX7cc+YGcheewH33APcdpt4394OXHYZ8NxzwdfH9T9h9+D93KsUaxGoJMoZZSWRuBiACAyaaLrjOIBUzMTEWuhK96234tMNW7jJTjWk0ffu2RP44QfgppuCf++1JEo4sTtdmsZGDQLrrhtrknpNyOfX9u6NLQG0hd2736VLZcDabz/cE3XNAQeI15RKooU/+AD47jux6zd6dHD8hQS7s4cffnj4l1LGgMVBwog8gmnTQl32/hzk8tfRIYJRel1wMnDccccFdvjfeeMddXREL4Z+/DHwY+lmOGDAgOABSlqF+GNTxCiJomrcHG/smbC6OWlS9CAXZqkXVj9D6uVa66yDwWExiCCURF39Y9hkJG6yp0lJNAV166H7LrgAMtf9fvlLtLW1oXv37sBZZ9V/EHTkdIwlkdOtG3DiiWIn0ndfr6y2WvCP/PfnsQ5TPaj5CtTKOUipeuqpTS7K102dihVXWQXdpEuht+4fcwy+VMwX664beEKRGzTpAvBPANPi0nztNeC34Q6cc1QCDeew+9cwinnTl+OQxwKgKSbRoEGNihHVOcPll4txNuBEsM1qir8N0XhIgUqdkU87dO7iHR/iynLhhYX1qVxEvv++aEce9/r11ltPz+Q77UlXUeNuRwfw73/XXUHkfCVN/MCrr67/Lxebr7wS/RuV8vD38zNmND8Xx4kew9ZaK/jzuN13fzlEWZvMP390WkGEjWGy/zz8cDEXOOMM8f7SS8VCMao+XX55sJWtVOZ0doZbulx6KSDj7MVZEsmy8bu6qTJiRPO8wRsvMGzMiMP/jJJaeHjp00dY1sm2J+uYP800SqJbbgFuv72eVhJLoiSKdm8MqnXXBXbfvdnCRiqKZV/rOMHKP/9cdt99xauKa1dbW7AlUtD8eMklo63KouZNck4xd258/xL1vXeN5bUkSjuXA4Trn6xnUTGMHn0UuPlmMY7I04Hb20UdCYt95n1ejwVsafvrVVSdpZKI6CKNkuhnKr6xfuRgEtM5djWDkDxWB7CF1C6HpSU/r5kPN9ns9O4tXCu8g5F3Ie0NXB3nouFjT7lw8XQ436+5ZrNrUQBeM/6wYWbxyZPxBIBJMkCzH2kCKYmbLNYmx6GqsF69gEMPFS53cacrhNWleeapKwdXWAF4+WXg179uvEY1eHYcUgbPhLPzvvtw4a9+lS69CO3+PPPMgxP8g6bq4J/kfgMGNcc7oLS3R1sthUxaRo4ciXPOOUfUu3nnBV5/HbtHyXHiieJVBkH2ySVLPGqK1EvGL4iQC0BTXXpUmtYCwgc76Ldh9S8kn6eefVYoV0KYg5o1A6CkgHKDLEiSDtZed0UA6NULn779NmagHodl1z32wMmyPnt93L3Buv0BuYHQRViXxU9Hhzjh46qrGuvxyJFYS+6affFFoztARH1X6TkdAHei5m7mfxabbiqOffY+vx490KtXL7z11ltYTLoh+Pro1ZMsxgOez9wg820Azx5+eGMspCBi+tuZCqcQhsmVhYb+3Zv2TTeJCalHriYV16ef1n/zy1+qZXjWWcIiom/fwHq33ODBcF0XB15zDZa/776uz5ssiSTedtZ1GyFltOWWIqA6EH36TRBDhoh25A8OutJKogyyxFxZbbXmzZADDhBja1QA4KgxRZbB4ouL1yxKIu9hAbItxgVQ9y6+otxhvM9qq62ClURR48F2IZEavfcZ5C7mLwfHAd58E/g6wLZOZ5uT+ba3C6viFVcUfbVU5gVZOOy+e6Oi349XSRSm7Fp88XrZ+q1L/cg5qopSI0iBFtSXrbCCSM91gaefjk83CP+9RcVx8eKfq2+0ETBxongG/sVzFtcpKd9++zVa7MnNT395+pUorttc12RcmX97gk3IDd+gjQV/+9l+e5Gu1zXPf83KKzcqIq69Vvx99JFaUOwFFwyOvxNWF6P6IBUlkUq9/M5jj+qNm3vrrUJBG+RuFrdujGKtter1LGgz6PrrgYceEocn+OczcX2y9LTo3j04kLjKWlTebwu4mUla504N4TgOLoA4YUbhYgDAwAED0CeJ77Hj1Du6gJ1bL2ussUbwwq0WM+UNAL+UCynZqK+4ovFa+fmyywKPPoq/eTXK/fvXJ1RAfWLkHQQ7OuryBjS2V+WuUBSeTnB6v35i8jlggJgIhPDpp5/i9RgTxrNrr5PDlET+wefuu4Gf/xzfhyV45JEAAhZ0SywBrLOOMJUcMkQEhPZNcBtK3XGCT2956KHmz1ZcsXG3FwCOOy5MwkBWXXVV/O1vfwu/wFMO7bvsgqOuvlo9Vk4C/uL3n/cOfmGTzvvuCw4aqWJOWmPaLrvU37S3i8G+dopZEyEL06FDh+Jkr8XJaqvh5eAUBFttJQYhuXBIM6n2+t6H7RyffnpTu9vSc2JRKO3tQukpT7vzfh52fQQNbSJs0PV+HnSCWJIyct3metHWhgVrSvE9ARwNiHYorwtSBoUR4urUZZnhnSR567E3MPTAgeFxDULSVaGjo0O4/HgXqjLwtk9J1IUse9/kaWmVAKYhXAngbm/f5Mm7b9++8fcUUadiXYi9JKg3gcGbgXrMAvgCn3vT7tu3aUIaEQpU/YQd74l3Eda4Bx98MHbx9GXeJznX2z946maskshxxPHtN90UbnW4+urAs8+GyiWfY9ehyL17i/5qhx3S9XuLLCI2S/wLn4UWEmNrVLmqLF5kvZNlncYlMOi+klgPh/WR/ns+44zgwL9RlkRh9+OVL+g4+SBl1KqrNh5y8Nxz9eDIQW0p6uS5IFZfPbgsvfcQtON/113Rp3JKt+8XXhBzsyB6966XiRwbguacp5wSbp0VRBpXwLQxnrzz/333FfIHKSD9mwFRi+ijjhKKRtm3q7QPVXczWW/DlBtxeV14YT0e2jbb1C33//hH4MUXgxUzQcpPP0GfeQPlH3SQUBott1x8O580qbFueQlSEsW5oUb1oV5LojjkM19qqcb81l+/0ToxrZLIK+dLL4nNAplmkBXjL3/ZaE0H1NvBoYdG38uCCwLnnBPuxuYvD1nPvPVNw0ENZYNKopxxHAcnAFgfEMF/o5ATmQEDsHgSSwjHEY34gw+ad8p97LHnnpgZtAPyxBMYURvsOvzmnV6lD1Bf4DgOsPXWuMTrVuaPA3PVVXXTaklHh1COXHBBoEXTGnHl5JUBwAdy4TNuXKQ/8WKLLYaf1awRwobkObV7DjoWPZC11wbuuSd8V7/WCTbld845YoCKWIQ2WGjNndus+AGaO0xfvl14Oug1FI7rfvPNN3Fs0KTwD38QCxRfvKn29nYMUt3Fz4LK5GOXXZItNAICSLtyAQ2IgbtPn+YF0dZbC4ulBK58iYYYn1yysz5WTqo331zUIS9BE2Uvrgv86U9NaberlOuyywpFwyGHiPfvvCPqcVjw6KBJTNhzUbAkcmJ2J7+IiUMWRu/evTF16lR8CeBiKePmm4uy8pv0H398+AkmV14ZeM8yHlCD/GFKaMl//yt2P72LLclxx2H2736H+RIc2TvvvPOKxds1Hkdb+SzClERe19KRI4VMAH6veix4wLP+LYBvIuIgxC6VQurJFwC6nFP/9Kd42RLgHHKIOM3Ezw03dP3bEMXNe98B7er2u+6CG+aKDagtGL31LCiQckg7845TDcHMPXVTabna0SEWW0GyDhkiNi+CgvV75HMAnKSSl9dV4+STgS8DHB7DXFFkOflO6Au8JspCTrrLyXqQxpIoCBUlUVyMOn+f094uFqaPPVYfm9raoutVlJLoP/8BnnkmXjETJuP669fbpOqJanJMCZL5tdfif5/GLcTbL/3tb835XHaZ6JNlmssuK/IJsso/++zI+I0A6tZ4Ydfk5dLifWa33io2cD/+uFlZd37NUdWvIA2Sr18/cfCJ3PxVsSSKcyWUSKWG/Fy6F0ni5i4rrNB4b964SWHKQBUlkR95P7ffLuZGUen5kQqRoDlTWEyrqDSjFEhyk8dfjkHIDctdd20sg6BYk/KzuFi2/t9JZLByabHkVVw+8ED42rZvX+H6GTcvaW8X44c8fMePXwEkQyV451nS8yHFKbNlhUqinGnYjYszT11/fdFpX3RR9Gk0zZmI1+WXT39CVrduXRPILpnlxMsvt68Tn8+7o+HvnNramjXh7e1i8RMSD0bJRc9zn3MS7ETFpX3p5SKyzlqqx6DWmCfsJKkwggIn+og1fgzzvQWCO/EaI0eOxBtvvBGbfyBLLCFiAARYuv3pzDOTpRVmMZFmMpuCDeUiJmBA7eEdmMPyfPTR+vG0ijQ8UxmQ8Pbbgy8Oqavz9eoldngee6zZTN3bNqN2PYJ2gOM4/vjG9yutJAbdsOcVlqZXARcmj8TbDwZZQHpOs2pLY+Jek72X6qD/17+Gx5jo6AjcwZcK5w5vnZK71mFssgnw1FPBde+CC9Dt/PMx+sMP1WSGsNIJJc6SaO5cscjeZBMAwNphfeM554j4WkEnKcmsgMZ64cnbcRw1SyJfvVodQIMjYtyRzkkJc9Xx1NlLvP2Aty57629tjNh9993hHHCA2CCIczGOkkly3XXN40mEkmjjjTfGsGHD8Mc//jHw+lglkTftQw4RyiLvQvnYY5s3lgK47rrrcH2UG1gQ888fnHbYpo6UdcCAUIvPrmcb1Qdsvrnoc2VMkrTjkN9qQSUodZySKMotUJZL3HwySkm01Vainw3KRx44ERQ/MAsyr4ThCLpIoySSc5pllhFjjV9puN9+jX2BX8bf/lZYHPtd98LG4Z12Em0XCFb0prEuUkG17sr7k+NukmehMr8Iuz9/Xb3uOnH0uPRY8LuHJW2Lsp1HBRRXURKFtd0RI5o3y+Pan/w+KM2gvs110yuJVltNKLGka2/UZtPyy4u4aVJhGCQH0NhPhaE6Pzv1VBFrz9tf77gjcFLElkLPnvH5h7lVSrn87fSGG8SmqFdZdcYZQuEd5KlQUagkypmGU2Wkv3QU++6bXEuZZCAM6zwcpytGQZci5bDDxKv/uFDZKcu0vGmqyKLDnzOjsiBs+F1r7bXhui4WVgmA6iFwkenxp04z3B/sjyuUBc9z6d69e5dFlU4iF6JB+C0ygiwb/GR57t6FkOviWekOETCJ6xa0WNaws9eQwtZbi3sNOyknbKF3zjlCJu8usyTOkigm7Uh07Z4/9xxe8J+gF5a2V07/JOOddxpdYXXJl4Ugpbf8xytfmrhzfhTvd7mwUw+lrN767504yz5NNeDsVlsBRx9dt74KKIumGumpo67rprIk+gi1Y9RRCxKvgo5dek8aC3tj84TtuH71VWOMh3/9qx6bJ+mC0JvufPPFuplLOgH06dMHr7zyCoZ4FzJysYp6YHGlzZr55xduZ3GxdQL41a9+hV8GxWDy56vSVsJcUVTmGqpl703LPw4FuawE8eKLjYuVOPlU5lZR8YZk247LR8VlOCj//v1FHtKdXc4ZsyLzSntiXRolkbzXsEWzf34i38tN1MUXFy5GDz/c+Lswy8mODuBXvxIhC9IGt06DvM8w93mJf7M47bMAkvVv/me2wgrAjTeGKxn8dTcur/POExsJUeuxoM3uODmjiBuro9Ly//agg8TJammVRIBY08lr3nuvof9vwHVF3+Y/EdQ/d1Dd2PePU2HKN39MWx2EySj74+efb/x8/vmbT4Wef35RdzRuVtsOlUQ50zDRWnvt/HYHVIlozE1Koj32EPL6Xd9k5xQUdNYb8yJPsgTGi0LeS8JFRFNDmjKl4fjYZVLE8VgrykQeiJYxwpLICG++CfgtH4LM5IHoHas8OucHH2z6qHuQkkgDR55di3p1443xF4fk63oVkv7n6l0kR8TnakpbWqVFBUcNI2ndWmghTJE70GHyBH3ub/MrrRTsHpUEj+w33HAD3k7pstZFlOuPt+4GuZElRfF+3bgxx6sk8gaSP/JIYeKteiS53+Jh1qymS1IpibzPJGA3cC6APfbYAzNmzEC/MNdHSdoTgeJiUqj0Eb17p1KmAGiOx+XPT+VkFgDzwrdxJdlzz654ZqlmKFGuCFm5//56fJegtI88Erj33sbPDjpIXZYoi0tVawfVMaK9vbEfSGJJ5L3Wq3hwnIb4WA3suKN4jdvAUVmAh7mbOY6wkps6VbhZSUaOVHMNC0Lea9Qx31GkURINGhR+tLk3LX/ahxwigiCHxKQLtJwF6vVgt93CXbaT4q3L338PTJjQfE1bmwgB4XeJ8iOt46Xlnr+dRJWtSkxVf9uSY0/SsoiyCAKa5ezdW1iDRI2fadzNksiQBL8s114rrNzC+o5vv63nJ09li2LAgHCvBO8zD+rjgyyJwvrMjg5hPT/FE5UviXIsK3F9bVqrxYpDJZEJsiw6X3xRdBJesnZgNTeCn9d8QVeJ27kbOVK8yl187/3svXd6OV59FRgzRvwft3udUVkQGhhcppu1TOebr0HG9dZbL3kaWTpJE0qioDzkDvuqq9Z9fLPIFPXcX301WvkSlt/LzeGk5/UqYpIoJGPu6eRTThGD6IEHpk7Lieo/vKfMRe2U+dPebjsRc+YFpRD7jWTYJUxyulnsyY1tbfgg7MswCxPp8gfgF7/4BVb2BuFPwz33NPvGBymJdLRHxf4h1iLE+/y8brPduwsT74gT6nwZiVepDH7llfj79OTd2dnZ7G42fLhwM5AuzQELCHlKnvf0ylDFlkarQDiOiLEyfHh2JUnc7199Nfz6uPQ8fABg77AxulY2XYHWk9xHnkqiPn2iLaUuvrju3uE/fUZlrvX448llSqsk8qOiJAr639tmHSfcle6CC4RLdJySSCVwdZzLTa9eje+HD4+O8xSFzGv33cXJuEnTSRNg3HFEfxd05LhXJmlZL5UnyywjjkxPEJtQSbY0G8qOUz8VasEFg5XSMgRE3Lxm+HDg0kvrc6oklkQqShb//R14oPgsTunjJ05hnoYs7mZBqJZdUD7t7WKe8tJLjeNA0Ph/wQVijJRl4D2AJWm+QHM/4yfIUjEq1lS3bo3xoVTGChkDMythz0vOk6++Wk8+FYNKorKx2mr1XbI0RHTW++67L2bMmNFohh72Gy+6NL5rrFH3cY/DM8CuGraLFsIjjzyCp/3Hh556qghMnMaSQoU0E+ckE0iV7371KzWXx7T48xw3TgRTV71+992F1doRR4T/JmqhvcYaasoXP2ut1TSwtXsnUKZMS3339xBqpyhtsEHoNcr1LOi6TTbRY+GSBhVLojglkePgubAv/QG+JWmUt1H061ffvfcTt+CK4qWXRIyisPQiiDylCqjX/aWXVjfxfuwx4KKLoq8JcHPbcsst8Ytf/KJ+Lz4lUdP0Ui4YvIt/3/3MRoC1VNBJkPPNlyx2StzJdo4jgpXLTRPv50nxyq/iOpZSSTTbdbHHHntEi+L/QOW0vbyPBFZd+PmtPJIor5I8N39fFHf/Yf1M3EI9zJLI28dEyd3R0WwJnoS4PiuvzSdvuvPPn7x+bb65ePWOlbpkOv10cXKfSuDfKPKaV1x8cbRSQtXq0XHEXEzOCRStFZVJYpkURR51MO3pZmGEPY/Ro8Mt17z5bL218ETxWpQGPceEpxhHpgWEK+yCLIniArXHBa4OwnWbT9NNS1heDz8s8tEZ3qNCtI5jXdnwN7SnngJGjQo/DlGVmGt7pPEDzXuCGJPnYgknQdtuu21z4Nif/axxARFUTvfdlyifUFQDq2Yp1yDlQZjfsS6iXJ9Url988fhA0EUpbNJOPNracjNbfd5xsKPrYpY3XlackmjcOBEE0K9ILcKyTIEuBUbamBgeIpeR3pgxkih3vCyEPZMkbiZ+goJF61LOy7EmiRXVlluKWDFHH13/TN7niBHiNKTzzxeBrD089thj4p+AzYBASyL/xNNXts+efjpwxhnxLnVAo5n78OHAW28FX3fTTUKhtMsu0W05jzbkOGJS7D39LGiinsfueW3R1mRJpHKfSeMSpiWpEjyvuUlSS6KwwwniTigMK9cllxR9+8CBjdZ1Sa0w4vDeZ9A95hUHzv+ckz7H7bYT7m86TyHy9uNRJ/epktdcxnGiwyaEKSa9fcgdd9T/l2uCrMd/f/JJowuyv89SjX3nx3+P/vvTsUGroiT63e/C0wsbR1ZYodEdMYkyKuq++vYVp0B67+OBB8ItCsPSCrMi9iuJVCyJTMeMDLtH/+nbpAEqiUzgr6wffRT/m003FX+68w77LAkmGr/u2E4qg4KOiQEQf1RjlAxJvk97bVqKyEOnC56ua3X8ToFDDz8cUwB0RE0u/fV4wIB4ZV2RhLmbRQTU7yLsmm7dgNmzoxUFJhTZEsPuZqFIGVSD24b93s+889aVHGHX+OPaLbccll122WZFn1SOhSiJptZcPOYmXcBcfDFw+OHBMYoOOKD+f1SZpJm8q9Cjh7A8mTBBHCUf5Brtz0PHeFgLwDu7lnYidzOVRYIqUa4pKjvP3uvyavf+e8wSmDbN7774QvTrl11WD676ww/Rcmy7LfDvfwvLML/SPK6dhl2T9FRXVdKcvuknTkH0y1+KE4xU0T22x9WZoPh2WejXT/QpKvGCvIoWWY49emRbUPvjcvr77D/8IX3akiOO0HO6ZVIl0Q8/RLt09u+fXaYkPPywcH33zv2WWio8dllY3Y5zU5Xj52abATffLP5XOak2Ll+dLLss8PHHYmOIJIbuZgWw995742H/iQdewk6fUSXr4jduUheW/skni1fVidjJJwuLHRtI46ajq0MrYsGa1g3JdvIKWO7HpFIhhKUGDcKll14avni79FIRh0AFw/Wh6R7iYhLJ09yCePdd4K67opVEpiYoYTIUqCSKXeynid8hEo5+r/rb6dOBd9/FYYcdhqFDhzZed9ZZ4vWRR4C99mrabV57nXUAAMcee6x63oBY8GQdi8ICrLa1AZMnBweNVeX550Vsp+WXD7aC85e1fxc+Tf2qBY6dVItvk+i0yiRuXWlQPUVH9gFpAhenmRtJ/H3T5583n4yTBscJVuJKq7/DDxdWRYBY0EVZJt1zDzB2LPCXv0RbPXiJGwdlXB7dFDF/8YdViKMoJdGgQcDTTzcqq3Vw9tmir/UeThCGV4HTq5dQvPhDNGTF7/rrjVWTBO9zufRSfUHAw/II+iyubgwcGG8lr0MmyZJLAv4xMcmGxyabiOcjx9+w69deW4xzI0aE97m33VZfK5pgq62EbEljhhEAVBIVwm233Ybtttuu/kFRi5M8rIaAugminKio7mifcw7wxhvZ8wf0l2GSnYO77xYxQpLgTa8Iy6syKInSyFSU1Vra8srzhIS49hwVy6lIvH2dKlmURIMHA7vvHq0ksqH+67YkyqrIlDJIJVFRCligcULZsyfQvTva2trQ2x+kUpbZhhsKFwjHaSi7hfv1g+u62GijjQoSvMa4ceGLEccRi3WvW2gcMsZM2AlJQXl42X13YR0V9r0KQ4YAjz+ONV9+GR988AEWlwqAIjdQwoizOPRfJylK2e/vv5ZYotFiI4sl0V57iXpx/vn1z9Oc+jXPPOFBmVXwl+WXX6pvSmTFVP8dFwMmC2FjnuMAG2+czxw3jTui44jTwPxWl1kVsCqxztKmrTvNrEoiQC02WJJ7USk/b3oBJ4N24a/b3bqJOK1RJ+lK5Di3337i1e+2vv76Yu0Xlm///unmjKrYMPcrMVQSVYG83Wj8v5GnVMmAdnlMxPx5rrEGcOKJ+aWfRKmy227BMUIkxx8fnbcuRUcaV4g8SZpnGhl1xmnSda0XeQqT6rHhpsirfvToUQ8EmISw5yrT6dGjUeZHHmm6dMkll8RyqoHvgeKV9bqVRMrZx+Qlg/WHHYMbnnD0+zQcdVSy66P6gzwVBLpdOJdbTtR1/1H3Yfjvrb1dHAUvSfssttgC3RZYAMsvv3yy3+WtjJFWBnEuRNICIujUxLgyyWJJlFd77tZNKHduvrnRZUVXeUvFcBpFYF5WREDz/Zmy7PXGBst7Y9ImdIdzKIKwvlPHc0vTd+SNtCBUZdKk8O90zN333VfUG78iOiptxwG++krMGfOCSqJMWNxLVRiVSptXJ62jwZx+ulikyRMk8hjs/Pf/6qvAeefpz0eicg+qz0QekeoljTl+XH5RO/9Jn/M++yS7XkeeSfEr5vJUSqW9F7lTp2rOXzXiFvlh5RqmOO3VS+ya33tv428D2lh7ezs23nhjRUENoNvdLCtShnXWEa5NSS3RsliYyKOZTz01eZqq15tahBXxbG2oP17yLuuTTgLOPTf+ZFe5uy6VSSpyXXONeN155/TypXXZD0O6BHlP0Io7jjoNn3wirKJNWosFlZ0/ryI2IuOuKUpJlFdbSpKuylxXZ3lsv32230+d2nzKZBZUNkBsU/JlCdJu41yaWIFltbxFMNlodOTdrZsIglhm0lgSmd5V9JPFdNzLxhsD//iHnrSSkLSckrr4JeWTT4BvvhH/O444vemWW+rf2zjYZXFj0EUShbbvWjcudkhbG/Cf/whFUZoTlJ58Uq8FogphstlqSQQI69CsMiX5fc+eoi6kcZH05mPKkigKG5RERfdVOss6SPZ55hGKojiXyJNPFvVKtrUoq91HHhG72AcfLPr9IOvPLGN+lmdwzTVCpjC3Ml3lPXBgtFW0l7LPW7PmW5SSKK97TZJu0ZZEDz2U/reOIxQkYSdx6UCHu1nevP5682deuaL6wjzHyjhLoryx4dmUGJ5uZgKTppw63M2q2LBVYhIV/dziyuCii9L/ljTjP30j7IjsKPIsd90LERPU5E10cpIkzURms83En0nWWksoq7yBOQtUYISWdZFKobwwMQFVjRuUJ0lj8+SNDXXBy+qri9ew03yAxo2uoODgQHg5+j9ff33g8ccbP8tSJkGWvarK0bwwqbyoopIor35ZB0VbEmUhD4W5yponj7qRJZ04S6IkMRt1limVRKWGlkQmKGqwKSLvvMh7kpun4quoMo46pcJEnbC9bgW5AZYdHZZEugIgq8hT+z4yyLSXMOsh2+ual3vuAV5+uXGnsyD5jz76aNx///2F5GVEiWnCkiguXRsmvv/8Z3F5qV5TJHvvDXz0EbDNNtnSUe2ndtlFWCWFobsu6k7P//w+/FCUX9Q1RWJD/dIpg1+hmFc+RaRre946sKHPjyNOhrXWSv/bJNcX4SpKCoOWRCYom5IojWtW3uRt+us308x6alVaeW+5pZrKDaDZcicpScv0N7/Jll8S8lBy5mXd9vvfx18zzzzh32WQIdTKpXdvsZvula2sk43evZsnaAX1mX//+9/Dv6y6JVFe9cUGV6+4Njd5cv4yeMnb3SwNyy2XPd0k7mbewNJB3+skbyWRPJwk6pq0dO8OzJqV7Dc29DU62WKL8O9sUBJVyZJIR5o29Plp8Mqla1M5iwx+pk7NL1+ihZLOuokSQY1Tx+TChp1S3elHvS/q2HU/riuOlZSm80kog+JO5UjQKJIoJ9ZYw96BXBWT1m5jx+rLW4VevYDLLxdHiUu8fZc8tj0LZa8PgFhs/eEPZvI2tVmgagVnQwDYvJCneNlCmnhhVULeszzdMux73fkVia56f/rpetLJiq0Wcjb0L1VCxzMsyt3My+OPA1dcoX59FktelXAbadJNem0emM6/5LA3MkHZzT5brdFdfz0waBDQp49pSUhaZs40LUE+FNWew2J2+H+va3IRN+HRoSSqAt26NQbEto2ilf1F5H3yydHf22BJpNOSUeV+vIuMMh6fHYY3jpgKn3xSdzvLcxFZ5phEZaofZdhsyyPdVrck8hPU3vJo3950ttgCOPRQPekmybdMaevI/6qripGjpFBJVAWyNsKkx7eabvRe5p8/3e/89/Dee+Hf77UX8Omn6osxG8oniQzPPpufHHmS5B5vuy0/ObzY8OxV0DnBSTLp98UkCnU3W3bZ0N8CyO7+WSXSPj/d7mZZdjLTErVYzivvRReN/r6IPiDOkshfLvfdB9x8c37ymLRyzINhw8Qu/s47q10vZV5wwWC3M93K/LzdzdJeo4JtVnC2URYlkS2Y8mzI25IoKUX2wUnasA1lE8Uhh5iWwGos3oIkuaBjIl+00qhnz/Dv/v1vPXn4B0Xd7mY2d5S6Jm0232PUKTd5UNQky+YyjyBWSXTffc2fea+1eaFRtBuDqTpgw+aBjfXfBpn8Gxq77JJvfjbcs07mnTd6Fz9qvhCE7YGrVdD1jIcMib8mafmSeKqqJIqjCGtrW+tnFsvtKGbP1i9DXpjOv+TQksgEZXM3s2ExEEbawcx/D0mOh0yatgm4YNOP6RgGVVAsqLLggtHfhy00Ulg1lZ5Wi2GR1w7u4MHAmWcmy98UcTKcfXYxcgRhQ/kEUbRcqvV08cWzpV0UuvLcY4/4e7alTytzOReVrmloSaRfhrh51EILqadlQ9mQ1FjSE7cY3kbz9dd60yPpSBq4LSkmJ6hEP3Guh1XaiUtCETtuhx9uzyLCBmy2JDLpbpaUDz8ETjstezpFPI9u3aK/T6N4yIL3nrP2fWUcu3r0iP4+6p7eeQd47LFk+ZXZkshxhDtfFHGbBLrk0HGNbkwdlOLF1rIJwobxL4+YREWSNN+o026zpq0b0/mXHM60TRMX30CFJI0g6NpnnkmWn02mwLricay7rp50W5lWUoRdfLG5vHXA+l0dhg4Vr0kVA7pjEplAVYYNNoj+Xqc7ahHl4j/e3c+KK+rLq0wLRl0kvZ+45xGVXt++wNJLJ8uvzDGJgHBFYt++wIUXAvffry8v24jrp7t3zydf3W201TdqsiqJkgbFjyNqk2bzzZP/Ni02rQ9JZlq8lRtCpdHkZYmgw92s6HggRVhlrLVW/nkAwO9/X0w+tnfMo0ebloDoIkPg6kTYXqclRS+4dtxRWMC89Za+NNNg4vmoLlTiglMutph6nmWoh7oXIHF423MR5fPii/nnoRPdFpZltiSKoq0NOOaY4i3hiiRu7IuzEkyLSet4k274tsYk6t07/LtNN02eXhStatkOlGO8thgGrjaByQaro8FUocPxl0PYpCuN6W+URn/w4OTpVZEVVjAtQTb22Sf486InQzos6bLKnKI/WGedddC9e3ecHHeceJ5UZfLQ3q4WS8dPEZZEeZSxiVgQtiyIWgGV8lt+efMyJElD9yKzSrFyvONH2DysLG44OrBBSVQm68GyxiSK+k2c+6pqeqpy6XzeKm7oRWI6/5JDJVGr0a9f8t/Y3MhssbhSlaPKp17ZXE90E7ULBOTznKPSXGop/flJ7r5bX1q1OrLgggti5syZ+tIlxWPDZNDGPsdGmfLG2zcVMcblbUkT9wyT3mMVTjcrIs9evfLPIwkm2rIN7mbLLKM3vaqjS0kkPzNtaZ0lLbqbVQq6m5lA9yRKtRHedx+w3XbZ8yu6E8hj0qkqs8nOumwWWxwMykOSZ7XbbtHfF11Py9YubKUK7dVEwNAqlFvZKcMzyNOSqOzuZmHuiUU+V1vrkA2WRCoxzWwpP1PuZmWK6Rc3Z7JhwycvqnQvBqCSyASmBvhddtFvFmmavGSTz2ijjfJJX4Us92bzMysrpss0aqA3qTgpyorAdPnrpAr3ojKxtOU+k06Sk/4+SVpZ2X//fNNPQ9ExifLOo+j4LWVQEpFiOPhg0xLE07NncfE14zA1xiQ54SuIIvoYVcskFVnWW0+89u+fXS5SGuhuZoIePYBp00xLUQ3SLkrjOq62NhEIdtCgdOknzY8kp+gyValrecoUlL+OmERZKdrVRBet3iaLjkmkq260+nMj6epA2WNBmk5Pp2IqLL+kn5eRuHq466755KuzDKdPN5e3CYLkzyO+qM3ldPjhwLbbqrkiesnLfVIVm8u0BFBJZALdk5U0wZV1UtVGuMoq+tMsake6qs+kLBQVk8gGpUwSJZGOCYMN95yVKrZPm+8pa52xyR3NxvpftEymLYmSbhgksSRacsns6eVBERsLtvUhtskTxVNPBX++664i1ESZ7kUnebmbZUW3NaDO9UKYVVJSBdEjj6QLwl0Ed95pr2wWQSVRFchbSeTvMGyKQWKDJYWNJLm/uCDMRFClOpPXgiOub+jZM33aZSn/ssiZlVa5Tz+tet9FkdRCrQwkWRAutFDw56aVKVtsoS+tsHs09VyrcOrs8OHBn8t6U7Y2o0pZ76tIt9ykazZdgav79Emfji7C7mWPPYqVo6TQsdkEujuHrBrpzTfXI4cJbNxVNRFM1QbKJm9STMclyeJuduONwL//rVWcLrxyzZ0bfW0WJVFQfiQ9RcZEyDsfm9I02Q/efTfwzjvF5+ttk3kfTw+YP90s6TNOkp6t4+jii+tL65JLxOt889kRuPqDD+KvsZ2wNtGqSqINNoj+XkceeVH0gTlVrRtAte+tAGhJZCtJOomspyHcdVf091VsZEXfk81lyEW3fvIo0ygFTFx+Bx6oV5awvPO0JErKggtGf29zmywDVbL4qIqSKO4kwjSo3I+33W+4oX4Z/EiZTB0XnufOfFjaedarouvs/PMDI0cK17ohQ4rNO4iw+w9z/cvCjTfqTxNoXSVRHLbet00HPfjz1TVPs7XsiTK0JKoCxx8ff01UY+3bN1v+JjsCGzuhKJmyKg+GDcv2+yDOOEN/mrbw/PPAP/6hJy3Ti2Kdgat1ppFESVTEAlKS1H++Vfj1r8Wr7cF0s5JH0Gx/usQMadwoTMZN0m2ZVAWGD2+2TrKtHPII5bD11vrTBMKVRJ2d4jXuXqp2Mun664vXRRfNnpZt9TKIKKVT0md7xRXZ5bGFMjw7i6GSqOxcdJEw2W1V8jrdzAaCZHz88eTpxPkFH3NM8jTTIo/R1IHKM1xvPWCfffTlWRV0TgiTuJsdcED6fJK2WVPHRHvlfOml+GuKJq8TG8vQpxZBK5aD7AP237+Y/NIufpKmryuNVqwTqpg6NbRqzyTsfqRFbZFWvEUSdt9//jPw3nt63F/LELg6CGlpOf/80df5769fv3zkIaWD7mYmueWW7GkUGfyMmCdNILi8dq7S8Mwz9Z0tkgybF0SSMrkuFtGvLbxw/nnYTCsu7myXL0922KGYfPJWEukmSZ0wpdy2gXnnNS1BM088Afz3v6aliCes3lxyCfCzn+kNPG4TYW2rowNYccViZUmCbo+DoPTWXRf4v/8DfvWr5OmlxXSAfT82yFBiqCQyybbbmpagHFThdLOq56dKR4f4S8Inn4i/MpHH4kU1zW7dgNmz9ecfRhJ3s7zx5r/mmtHX5n0qpK3IMrLpCF7TJJHd9H2abmNBFO3OJ6+Js1zMSwbdMYlM1ylbQgbcf78xMULZfPNyH+7Su7daSAoSTlj7mD07vz5IB44D/P73atcVydChwsqLWE8Lb1lYgI6JlQ2WRHnvFts4KY5C1w7BSiull6FsZRbF0kuXZ5JWdEyioO8+/RQYNSo/OaLyLmLCpFq3//CH6O8vuCC7LGVEPqOsddX0wjYJRfaHeZeLjeW+667i9Wc/y55WEvejMlhXkmi8z3CppczJQcqJybba0ZE+eH5VYwKq9Mmnnpq/HBJbyqWkUElkAp2VNs9Ti8IoYsKddx5l6DhWWUVPOmGn3x16KLD66nryIPmjGrh6wIB4Kxqd7evMM/NJ10/SU5biLGUWWiibPGHYHoukSEsik/dftKL8+efFq43PPG/22QeYMcOOk6qycNFF+tIqk3UaISqMGweMHm1aikZs2CjXlaapY+zzKsOwdKu0iV1xqCQqO1EByTjxIACwwALBn19xBfDaa8XKQtITNLDKoJSHH16sLF7WWgu4/HLxf56WRBtsIF5//vP88tCB7ROgnXcWr9L6o2ykGdd0WsOGXStP0cl73LW1fvXooScdk6dILrdcvumr0GrzNluO/SbxDBgArLCCaSmKp+qx9XTKopJWkZvTNpVzCWFMIhPYOskLw7S7Wd6svXb+eeg0j3/1VTvrEDvjOkXFJOrVK3teOk/yybNerrRSsvRZH4P52c/ycXUOKu88JoMbb5z8N0WMYTb2yVXFdNvW/axNKsb8SEUZIWXAdF+QllZwNwuTaehQYNq06p64VyGoJCJ2UqS7mY4jMsPSjvosLWusEX9NKyxYvGU6cqQ5ObyYiklkGlsmKCqssALw/vv5pV+mssibPA5nWHzx5L8p4pnI9tmqlkRlYp11gj9PU7Ybbhj8ue56UNRzP+ec8O8WXhj47jtgu+2KkUXCPrWa/O1vwGefZUujiNMAi65/uk43K+K3aSnqJMNWPi1SA1QSmSBpbA3TcIAmtjN8uGkJGrGp/RaBLUdSq+T/0kvAxIn5y2KatAE1VVGxJLKFIs3pbS6HrCyxhGkJ9HDGGcGfqyr6vP3MKadkl8emOrP77uHfvfMO8NZb6az5wkgyZpx4or58iXmOPTZ7Gja1nSQEyZ1FoWFLOZieA/pp1VNsNUEVW6tgSweiSt6nm5WtPJLiLbNjjjEmBtGIzSf56FQSqVjKZWGBBYo7RSeubPN07Sg6doRtk0MVs/e88suToscub37vvFNs3jpReT5prMHCFnZlcieRae+3X3Q+iy4KbLll/groMMpyyimpFnlYowS1s002EQfKXH+9nvSK+K3tVPneCoBKIpPYNqlOS9kbYZHyF/3MBw4EBg8uNk9iPyr1cP/985cjiMceS/9b208W8+M9GU43WcoxDTaPZ0suGfz5VVeJV50xiarmbubNL+wQhLJRhDXYfvuJ1zffTCZPGfotnSS5X511v9XK2SR59llFuBMVZY3S0SEOlEljsWmjksiGNtarl2kJSg2VRCQef0O3eTGgShG7ckXl16rY6Cdeped8443ArFlq1+q0JMrraPqisKUOyNO28qJM48JGGwV/3q+feOVx5SQtYfVh/fVFm1h1VT3pFWX9SEiZKKI/ziMP3cqtLDLqHLttmwcceaRpCUoNYxKZpKyTzSqZ7heFnODlvXAjRAUVV5y2NvWJTJyS6N57gfnmU5ePlI+yjmckmio+17B7Up136HZlVEmjiP7T9nlXFetiK5BnvSqiThTlbmYqPZtDGWTFlGtsRaCSyCSmB+SxY4FvvsmeTtXM6/Pgd78Txz7uuKNpSUhZWXNN0xLEE9ZWd921WDkAOyYoNsjQqpgaN/jMs5FX+eUVk0g3JuptWepslS0eSDpaWUm04YbA//6XPb3u3YHevYHJk7PLRCoF3c1MYMuAvNRSwNprm5YimCLLqIi82tuBnXYq7r44AaoWX3wBbL+9vvR01w+5W9Otm950y0iruCWWyd0sjKKPGiZ2EGdJlOR0M5vcRqpKK5TJV18Bo0eblqJ8tLKS6Jln9KTnOMDIkdnlAUTgbVIZqCQidhI3eb/lFuCgg4B11ilGnjiKPklHFZtkaSV0L5gHDtSbnm5GjABOOAE477xs6cw7b7bfl6W+77mneC2DdViVscFyJCllVMaVjaJjVDFwNenfv/gTKb3k+Rzy7LMOOSS/tCVFBMdOg439xpZbAquvLv63RSaSmkzuZo7jLAjgnwAGARgLYE/XdSf6rlkCwM0A+gOYC+Bq13UvypIvaTGCBphllgGuvbZ4WcoCFxL5sdlm4d+VcVDUIXO3bsBf/pItjQ8+APr2zS5LGdh1V7ZRm9Bx2hWfp34GDMgn3ax9XlWfdVXvK4hWulcVyloeUfMxXeShJLLNArGsz5/kStZaehKAJ13XHQzgydp7P3MAHO+67ooAhgM4wnGcoRnzLTc33QSssUZ1FkR5LIzL7G621VZ600tD//7CBSirZUcSyqggSYIcRKOsPw4+WLzKU5OIOssvn73c+vSp/29DfbRBhryo8r1FUcTx6URw/fX60koSkygJui2JomTIy6K0LHWWC1ligjxOXC1Lm0sD22llyKok2hnATbX/bwKwi/8C13W/cl33tdr/UwCMBpDT9lBJ2G474NVXgQ7GDQ+lzJ1M796mJQB69ABmzgT23ru4PMv8zJIQNbifdBIwZw6wwALFyZOGqj6rs882LUG1J39Vo6rtoCr07Gkm3yRtuEiLgPffB374QW9+rQrbfiMct4JZZhlgueX0p2vT6WZAPu2Bdar0ZNVSLOq67leAUAY5jrNI1MWO4wwCsDqAlzLmS1TIK04OGz4hwTiOCFJeJqrUnuedV1gTTZpkWpLWo8hF17/+pfckliSBikn5yRq4WiWtJKjO1Xr1En+EAMAnnwglhg7y7OPK3H/mFffU1niEeVhNkdISqyRyHOcJiHhCfk5NkpHjOPMBuAfAMa7r/hhx3SEADgGAJZdcMkkW1aLMnaoOqrRwbRWKfmZF51elNlmlewmDfUh12Wmn+GuKdi8qqk0V3XZNtiNb+/g8n4HJ8jYxLqjcL/vyYJZe2rQEJC0XWRqad9FFs6fRCvPLFiFWSeS67hZh3zmO843jOIvVrIgWA/BtyHXdIBRE/3Bd996Y/K4GcDUADBs2jDUtC3k11EUiDcZaE3aKpEzYelqHDkwvKNgXVI+iLUtsoor1OewZyRAAcacset1PdFsSkWJgmTdStX7Ldrp3Ny1BI3Q3IwFkXSk8AODA2v8HAviX/wLHcRwA1wEY7bru3zLmR0yzzTbAuuualoIQkgXdixybsGnyX7WyjWLBBU1LQKqAaptpawNOO01v3jvsAJx8MnDxxdHXHXFE/ZCCIUP0ykCICXSPm9ttpzc9ki9pXG1J5cmqJPo/AFs6jvMRgC1r7+E4zuKO4zxSu2Z9APsD2MxxnDdqf+w9iiCPxdLmm+tP0zTsFEmr4ThiMVRlTLXrVuxPpk+3I2C/lwMOiL9GZwwaupsVS2cncOaZ6terxP1pbwfOOSde4dnWBlxzjUhTx0mWphXbZXFx01lOPDgmXx56qP6/6fpN1KFlJPGQSUnkuu73rutu7rru4NrrD7XPx7uuu13t/+dc13Vc113Vdd3Van+PRKdMrMXWCaNp2Ck2cuKJ+efBukiIHUSdQvX118DYsYWJ0kWcNQghtpDXISNZ5LCJPMrkkEP0pxnGSScVl1da8jxti3M1wUcfmZYgnOWXB4YNAy6/XF+afO6lp8KBKQgpEFsnV6Yo4uQGU2VelYGvqnXW9PPREfixSiy6KLDUUurXP/+8nnxVThmUbaBMMbpM1+8iyetebStDb1+c12lKtqLyLPIYq+aZR3+aYZx7bnF5paWqwdhtwuvmbxs9egCvvAJsuKFpSYhFlGhmRBJT1UUgsRNOBMrFAguI1/nnNyuHbkz3ewMH1v9nm0jO8ssXl9fcueJVp5Io72duun6XFZsX6t5nesIJ5uQwAetz9SmTEp5kh226MrDlkmSETYBXXx245ZZiZbEJdorVj5VRtWd8/PHA3/4GHHaYaUnywaSCZsAA8Vq1OlM1dCqJ+KztZp996jv5NitvTSyobS4PwH75SDR8fq0Jn3vpYeS2sjJkiIj1EEWRRxq+9pr+vEh54eBgP927A8cea1qK/DC5aGf9LwedneK1TDvdVEalx9ay88plUkZby+fgg4FHHwVWXdW0JCQNHA8JKSUlmhmRBt5/H5g0Kfqaq6+u/6+rk65iZ89o/nqoYt0gJA3sD9JTZD+y+uridccdi8uTmIdjVbnYbTfRp0oLTVIu2N5aC85/KgOVRLaio1Pda6/saRCShqFDTUuQH5zwlAM+JxLHKqsA06YBe+6pL828610r1etWuVcuqkiVufZa0xKQIpGbL717m5WDZIZKIluxddLQKpM2khxZZ1daSfxVja22Eq/bb29WDmI/7CfLw7zz6klHToiHDdOTXhi2zg10UUTbsa19zjef2fxNlkfV6zMBNtnEtASkSK66SpxSmuRUU2IljElEiA440anTp49pCfJhzTX5nMsAnxExwcCBwKhR1VSQk3zp29e0BIQQood55gHWW8+0FEQDtCQiRAf//rdpCcxT9dPNCCEkijXXBHr2zDcPKkGrSf/+piUghBBCuqCSiCSjqIV52SbCG2ygJ5199tGTjkmovCEmYf0rN3x+dlHFUwJtrmM83YwQQogFUElEkmHz5CotNt3TP/5hWoL0cIJJCCGEJMfkPMRk3nfeaS5vUodxg4LhvJa0MFQSkWTYpFAhdiEHU1qbEZPYVC9skoWQMlBEm+E8JhgT/dW22xafJ2mGyrpg2FeQFoZKImInXFyVFw6qpNVhGyAkHXmO/ZxXBFP0Bg+xj169TEtACLEMKolIMqo4iajiPZmg6Ak4J/wkCBvaM+smqQpVrMs29BFhmChvKokIIYT4oJKoVdA1+HMSQeIouo788pfF5kfspoqL2qTsvLNpCbLDsSaYqtdv7/21Uh0wea9UEhFCCPFBJRFJBicRJIyqL15IuWjVQLAAcPvtZvPPgumyI2Zp1ZhEN90ErLMOsOiixefdqkqiYcNMS0AIIdbSYVoAQgKhwqF8tOpEkxDbYBskuqAbcTFssYX4M0mr9RtPPw1MmmRaCmIzrdYmCPFAJRFJBjvMYlhzTdMSJIenmxHSCOtoejjWtCZFuJuxbjXSqv1Ur14M2EyiadW2QQioJCLEvgnjmDHAIouYliI53bqJ16InXbY9P0IkrJvpYdkRUixsc4QQQmpQSdQq6Br8t99eTzpxeLX3SyxRTJ62sOyypiVIx4YbAmeeCRx6aDH5cYeHkGCqsNirwj3kQdX7vVaNSWSSqtcpQtLCvoK0MAxcbSt//KNpCYIxobB54YXi8yTJcRzgtNOAfv2KyY8xkAipHja251ZeRDMmUfXZZBPx+pvfGBWDEGv4v/8zLQFJy7hxpiWoDFQS2cq++5qWwB4GDswn3auuyiddQnSx1lrAMceYloIkhQvd7NioLLKBostl0KBi82PbKZ4llhDlvuGGpiUhxA7yWneQ/BkwwLQElYHuZsROaHJOCPDyy6YlIGWEfVt1KVqJcsghxbkQA41KKQauJoSYgMpqQmhJRCylCJclDgLlZqutxOvBB5uVgxCiHy7k7aDo57DzzsC224r/de/mc8wnpPy8+aZpCQhpCWhJRNQ57rji8nrmmeLM3LkYKSdLLcVJP2nGpjphqm+pQp9m0z3YJEsr8PDDwKRJQN++etP99FO96RFCimfVVfPPg30+IVQSEUWKXngttRRw003ACisUmy8hhBBz2Dg5t0nx2Ao4jn4FkZcJE/JLmxBSftjnE0IlUeVpbwc6O01LkY4DDsg3fQ4ChFQPG5UMRVOFMqjCPRA7mTvXtASEkDKgexzaaCNg4YX1pklITlBJVHXGjQMWW8y0FIQQUgw2KH9Ny0AFCyHhsH0QQkzwzDOmJSBEGSqJqs5885mWwF44USSkurRy+67CvVfhHoidsG6Ropk0iRZshJBSQSVRq8BJUTOmd/sJISQPqtDfV+Ee8oDjVnZYt0jR9O5tWgKShLL0s336ACuvbFoKUlGoJKo6nAzFwzIipHrYMMnj6WaE2AfbByGkCkycaFoCUmHaTAtACCGEEALA7gX8k0+ay/uuu8SrifJZc83i88yDESPEa8+eZuUgxEYuvRQ47zzTUtiBzeMQIQVBSyLSuthgaUAIyQdO8vJnt93EXx7Y+PxskMnEuPXMMyKmStm54gpgnXWAjTc2LQkh9nHEEaYlsAeuDwihkqjy2DCptR2WESFEJ60ywbz7btMSkCLo1Uv8lZ0+fYBjjjEtBSGEEGI9dDcjRNeCbqedgKWX1pMWISQdm20mXrt1MysHyQaV98GwXAghZWHQINMSkFZlwQVNS1B6aElEiC7+9S/TEhBCbrsNGDsWmHde05KQqmGDhZgNMhBCSBwTJuQX/+uii4B1180nbS9UypeT554DllnGtBSlh0qiVoEdXTgsG0KqwzzzACuuaFoKAfsWQgghrcjCC+eX9lFH5Zc2APToIV6r4Gbbiqy/vmkJKgGVRIQQQgixA2kpQwUbIYQQE+y2G3DmmcDRR5uWhBBjUElEWhea7RNCiJ1QSdQIy4MQQoqhvR047TTTUhBiFAauJoSTb0KITvKKw9AK2Ky8NzlW2FwuhBBCCKkUtCQihBBCdPKf/4gA2osvblqS8kF3M0IIIYQQo9CSqAzsuWf633L3MZzhw8XrdtuZlYMQUi2WWw744x+LV3SsvHKx+ZHioNKMEEIIIQVBS6Iy8I9/ZE+DE8xmVl8dmDUL6NbNtCSEEJKdZ58FvvjCtBQkD9rbxWv37mblIIQQQkjloZKoDHTwMeUGFUSEkKrQt6/4KzN0Nwtmhx2AE08Efvc705IQQmzh8885jyWE5AK1D1WnreZRuOSSZuUghBBCVKGSqJGODuC880xLQQixiSWWMC0BIaSiMCZR1ZlnHuDOO4EnnzQtCSGEEBKNjXH0rr4a2GsvYP31TUtCCCGEEJI7VBLZzLBhetLZYw+eskMIIYSkYfBg4I47GA+IEEIIIS0B3c1s5oUXgDlzTEtBCCGEEEIIIYSQFoBKIpvp1o0B6QghhLQODFxNCCGEEGIUupsRQgghxC6oJCKEEEIIMQKVRIQQQgixAxsDVxNCCCGEtBBUEhFCCCHEDqSL9ZAhZuUghBBCCGlRGJOIEEIIIXbQpw/w8MPAOuuYloQQQgghpCWhkogQQggh9rDddqYlIIQQQghpWehuRgghhBBCCCGEEEKoJCKEEEIIIYQQQgghVBIRQgghhBBCCCGEEFBJRAghhBBCCCGEEELAwNWEEEIIIYQQE4wcCcw3n2kpCCGEeKCSiBBCCCGEEFI8w4ebloAQQoiPTO5mjuMs6DjO447jfFR77RtxbbvjOK87jvNQljwJIYQQQgghhBBCiH6yxiQ6CcCTrusOBvBk7X0YRwMYnTE/QgghhBBCCCGEEJIDWZVEOwO4qfb/TQB2CbrIcZyBALYHcG3G/AghhBBC4nn0UeCSS0xLQQghhBBSKrLGJFrUdd2vAMB13a8cx1kk5Lq/AzgRwPxxCTqOcwiAQwBgySWXzCgeIYQQQlqSrbcWf4QQQgghRJlYJZHjOE8A6B/w1akqGTiOswOAb13XfdVxnE3irndd92oAVwPAsGHDXJU8CCGEEEIIIYQQQkg2YpVErutuEfad4zjfOI6zWM2KaDEA3wZctj6AnRzH2Q5ATwALOI5zq+u6+6WWmhBCCCGEEEIIIYRoJWtMogcAHFj7/0AA//Jf4Lruya7rDnRddxCAEQCeooKIEEIIIYQQQgghxC6yKon+D8CWjuN8BGDL2ns4jrO44ziPZBWOEEIIIYQQQgghhBRDpsDVrut+D2DzgM/HA9gu4POnATydJU9CCCGEEEIIIYQQop+slkSEEEIIIYQQQgghpAJQSUQIIYQQQgghhBBCqCQihBBCCCGEEEIIIVQSEUIIIYQQQgghhBBQSUQIIYQQQgghhBBCQCURIYQQQgghhBBCCAGVRIQQQgghhBBCCCEEVBIRQgghhBBCCCGEEACO67qmZQjFcZwJAD4zLYcGFgbwnWkhSClh3SFpYL0haWC9IWlgvSFpYL0haWHdIWlgvQlmKdd1+/k/tFpJVBUcxxnluu4w03KQ8sG6Q9LAekPSwHpD0sB6Q9LAekPSwrpD0sB6kwy6mxFCCCGEEEIIIYQQKokIIYQQQgghhBBCCJVERXG1aQFIaWHdIWlgvSFpYL0haWC9IWlgvSFpYd0haWC9SQBjEhFCCCGEEEIIIYQQWhIRQgghhBBCCCGEECqJcsdxnG0cx/nAcZwxjuOcZFoeUjyO41zvOM63juO84/lsQcdxHncc56Paa1/PdyfX6ssHjuNs7fl8Tcdx3q59d7HjOE7t8x6O4/yz9vlLjuMMKvQGSS44jrOE4zj/dRxntOM47zqOc3Ttc9YdEorjOD0dx3nZcZw3a/XmjNrnrDckFsdx2h3Hed1xnIdq71lvSCSO44ytPe83HMcZVfuM9YZE4jhOH8dx7nYc5/3aPGdd1hsSh+M4Q2p9jfz70XGcY1h39EMlUY44jtMO4DIA2wIYCmBvx3GGmpWKGOBGANv4PjsJwJOu6w4G8GTtPWr1YwSAlWq/ubxWjwDgCgCHABhc+5NpHgRgouu6ywG4EMB5ud0JKZI5AI53XXdFAMMBHFGrH6w7JIqZADZzXfdnAFYDsI3jOMPBekPUOBrAaM971huiwqau667mOV6a9YbEcRGAR13XXQHAzyD6HdYbEonruh/U+prVAKwJ4CcA94F1RztUEuXL2gDGuK77ieu6swDcAWBnwzKRgnFd91kAP/g+3hnATbX/bwKwi+fzO1zXnem67qcAxgBY23GcxQAs4LruSFcEErvZ9xuZ1t0ANpfacFJeXNf9ynXd12r/T4GYQA0A6w6JwBVMrb3tVvtzwXpDYnAcZyCA7QFc6/mY9YakgfWGhOI4zgIANgJwHQC4rjvLdd1JYL0hydgcwMeu634G1h3tUEmULwMAfOF5P672GSGLuq77FSCUAQAWqX0eVmcG1P73f97wG9d15wCYDGCh3CQnhVMzdV0dwEtg3SExOMJl6A0A3wJ43HVd1huiwt8BnAhgrucz1hsShwvgMcdxXnUc55DaZ6w3JIplAEwAcIMj3FuvdRynF1hvSDJGALi99j/rjmaoJMqXIK0jj5MjUYTVmai6xHpWYRzHmQ/APQCOcV33x6hLAz5j3WlBXNftrJliD4TYMVs54nLWGwLHcXYA8K3ruq+q/iTgM9ab1mR913XXgAitcITjOBtFXMt6QwCgA8AaAK5wXXd1ANNQcw8KgfWGNOA4TncAOwG4K+7SgM9YdxSgkihfxgFYwvN+IIDxhmQhdvFNzdQRtddva5+H1Zlxtf/9nzf8xnGcDgC90ezeRkqI4zjdIBRE/3Bd997ax6w7RIma+f7TEH72rDckivUB7OQ4zlgI1/jNHMe5Faw3JAbXdcfXXr+FiA2yNlhvSDTjAIyrWbkCwqVnDbDeEHW2BfCa67rf1N6z7miGSqJ8eQXAYMdxlq5pPEcAeMCwTMQOHgBwYO3/AwH8y/P5iFpk/aUhAqm9XDOdnOI4zvCaX+wBvt/ItHYH8FTNv5aUmNpzvg7AaNd1/+b5inWHhOI4Tj/HcfrU/p8HwBYA3gfrDYnAdd2TXdcd6LruIIi5ylOu6+4H1hsSgeM4vRzHmV/+D2ArAO+A9YZE4Lru1wC+cBxnSO2jzQG8B9Ybos7eqLuaAaw7+nFdl385/gHYDsCHAD4GcKppefhnpA7cDuArALMhtNMHQfi2Pgngo9rrgp7rT63Vlw8AbOv5fBjE5OtjAJcCcGqf94QwtxwD4GUAy5i+Z/5pqTcbQJi3vgXgjdrfdqw7/IupN6sCeL1Wb94B8Mfa56w3/FOtQ5sAeIj1hn8KdWUZAG/W/t6V81zWG/4p1J3VAIyqjVX3A+jLesM/xbozL4DvAfT2fMa6o/lPFgYhhBBCCCGEEEIIaWHobkYIIYQQQgghhBBCqCQihBBCCCGEEEIIIVQSEUIIIYQQQgghhBBQSUQIIYQQQgghhBBCQCURIYQQQgghhBBCCAGVRIQQQgghhBBCCCEEVBIRQgghhBBCCCGEEFBJRAghhBBCCCGEEEIA/D9clCDx3pzTXAAAAABJRU5ErkJggg==","text/plain":["<Figure size 1440x432 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["wave = load_wav_16k_mono(healthy)\n","nwave = load_wav_16k_mono(unhealthy)\n","\n","plt.figure(figsize=(20, 6))\n","plt.plot(nwave, color='black')\n","plt.plot(wave, color='red')\n","plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:20.822612Z","iopub.status.busy":"2024-03-23T17:00:20.822236Z","iopub.status.idle":"2024-03-23T17:00:21.680243Z","shell.execute_reply":"2024-03-23T17:00:21.679071Z","shell.execute_reply.started":"2024-03-23T17:00:20.822582Z"},"trusted":true},"outputs":[],"source":["healthy_heart_train = tf.data.Dataset.list_files(train_dir_path+'/healthy'+'/*.wav')\n","unhealthy_heart_train = tf.data.Dataset.list_files(train_dir_path+'/unhealthy'+'/*.wav')\n","#healthy_heart_valid = tf.data.Dataset.list_files(valid_dir_path+'/healthy'+'/*.wav')\n","#unhealthy_heart_valid = tf.data.Dataset.list_files(valid_dir_path+'/unhealthy'+'/*.wav')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:23.472903Z","iopub.status.busy":"2024-03-23T17:00:23.471931Z","iopub.status.idle":"2024-03-23T17:00:23.489818Z","shell.execute_reply":"2024-03-23T17:00:23.488665Z","shell.execute_reply.started":"2024-03-23T17:00:23.472859Z"},"trusted":true},"outputs":[],"source":["hhl_train = tf.data.Dataset.zip((healthy_heart_train, tf.data.Dataset.from_tensor_slices(tf.ones(len(healthy_heart_train)))))\n","uhl_train = tf.data.Dataset.zip((unhealthy_heart_train, tf.data.Dataset.from_tensor_slices(tf.zeros(len(unhealthy_heart_train)))))\n","train_data = hhl_train.concatenate(uhl_train)\n","\n","#hhl_valid = tf.data.Dataset.zip((healthy_heart_valid, tf.data.Dataset.from_tensor_slices(tf.ones(len(healthy_heart_valid)))))\n","#uhl_valid = tf.data.Dataset.zip((unhealthy_heart_valid, tf.data.Dataset.from_tensor_slices(tf.zeros(len(unhealthy_heart_valid)))))\n","#valid_data = hhl_valid.concatenate(uhl_valid)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:25.500184Z","iopub.status.busy":"2024-03-23T17:00:25.499462Z","iopub.status.idle":"2024-03-23T17:00:31.887874Z","shell.execute_reply":"2024-03-23T17:00:31.887050Z","shell.execute_reply.started":"2024-03-23T17:00:25.500135Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[0.04437256]\n"," [0.09277344]\n"," [0.08206177]\n"," ...\n"," [0.01379395]\n"," [0.01266479]\n"," [0.01278687]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04437256 0.09277344 0.08206177 ... 0.01379395 0.01266479 0.01278687], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00408936]\n"," [-0.00686646]\n"," [-0.00848389]\n"," ...\n"," [ 0.00643921]\n"," [ 0.00888062]\n"," [ 0.00592041]], shape=(71611, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00408936 -0.00686646 -0.00848389 ...  0.00643921  0.00888062\n","  0.00592041], shape=(71611,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-5.7983398e-04]\n"," [-1.3427734e-03]\n"," [-1.2207031e-03]\n"," ...\n"," [ 3.0517578e-05]\n"," [ 5.4931641e-04]\n"," [ 5.4931641e-04]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-5.7983398e-04 -1.3427734e-03 -1.2207031e-03 ...  3.0517578e-05\n","  5.4931641e-04  5.4931641e-04], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0241394 ]\n"," [0.04940796]\n"," [0.03500366]\n"," ...\n"," [0.09484863]\n"," [0.11904907]\n"," [0.14749146]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0241394  0.04940796 0.03500366 ... 0.09484863 0.11904907 0.14749146], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02993774]\n"," [0.06143188]\n"," [0.0723877 ]\n"," ...\n"," [0.04708862]\n"," [0.05239868]\n"," [0.03952026]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02993774 0.06143188 0.0723877  ... 0.04708862 0.05239868 0.03952026], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05075073]\n"," [ 0.13824463]\n"," [ 0.16445923]\n"," ...\n"," [ 0.00305176]\n"," [ 0.00088501]\n"," [-0.00372314]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05075073  0.13824463  0.16445923 ...  0.00305176  0.00088501\n"," -0.00372314], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07861328]\n"," [-0.1730957 ]\n"," [-0.16314697]\n"," ...\n"," [-0.00540161]\n"," [-0.00686646]\n"," [-0.00952148]], shape=(62276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07861328 -0.1730957  -0.16314697 ... -0.00540161 -0.00686646\n"," -0.00952148], shape=(62276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03646851]\n"," [ 0.07345581]\n"," [ 0.06161499]\n"," ...\n"," [-1.        ]\n"," [-0.9596863 ]\n"," [-1.        ]], shape=(62276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03646851  0.07345581  0.06161499 ... -1.         -0.9596863\n"," -1.        ], shape=(62276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02490234]\n"," [-0.04989624]\n"," [-0.04086304]\n"," ...\n"," [ 0.00219727]\n"," [ 0.00308228]\n"," [ 0.00238037]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02490234 -0.04989624 -0.04086304 ...  0.00219727  0.00308228\n","  0.00238037], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01028442]\n"," [ 0.02508545]\n"," [ 0.02468872]\n"," ...\n"," [-0.00354004]\n"," [-0.00338745]\n"," [-0.00378418]], shape=(61440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01028442  0.02508545  0.02468872 ... -0.00354004 -0.00338745\n"," -0.00378418], shape=(61440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00109863]\n"," [-0.00311279]\n"," [-0.00283813]\n"," ...\n"," [-0.04019165]\n"," [-0.04226685]\n"," [-0.04333496]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00109863 -0.00311279 -0.00283813 ... -0.04019165 -0.04226685\n"," -0.04333496], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[2.9907227e-03]\n"," [6.0119629e-03]\n"," [4.5471191e-03]\n"," ...\n"," [1.8310547e-03]\n"," [9.4604492e-04]\n"," [3.0517578e-05]], shape=(57965, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[2.9907227e-03 6.0119629e-03 4.5471191e-03 ... 1.8310547e-03 9.4604492e-04\n"," 3.0517578e-05], shape=(57965,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00869751]\n"," [0.02072144]\n"," [0.0234375 ]\n"," ...\n"," [0.03985596]\n"," [0.04241943]\n"," [0.02264404]], shape=(69260, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00869751 0.02072144 0.0234375  ... 0.03985596 0.04241943 0.02264404], shape=(69260,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 9.1552734e-05]\n"," [-3.0517578e-05]\n"," [ 9.1552734e-04]\n"," ...\n"," [ 2.7770996e-03]\n"," [ 7.0190430e-03]\n"," [ 1.0437012e-02]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 9.1552734e-05 -3.0517578e-05  9.1552734e-04 ...  2.7770996e-03\n","  7.0190430e-03  1.0437012e-02], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00305176]\n"," [0.01040649]\n"," [0.01538086]\n"," ...\n"," [0.07150269]\n"," [0.06887817]\n"," [0.06924438]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00305176 0.01040649 0.01538086 ... 0.07150269 0.06887817 0.06924438], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01123047]\n"," [-0.02304077]\n"," [-0.01977539]\n"," ...\n"," [ 0.01000977]\n"," [ 0.01144409]\n"," [ 0.0133667 ]], shape=(71750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01123047 -0.02304077 -0.01977539 ...  0.01000977  0.01144409\n","  0.0133667 ], shape=(71750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01727295]\n"," [0.04421997]\n"," [0.04855347]\n"," ...\n"," [0.10620117]\n"," [0.10577393]\n"," [0.11654663]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01727295 0.04421997 0.04855347 ... 0.10620117 0.10577393 0.11654663], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03222656]\n"," [-0.05673218]\n"," [-0.03414917]\n"," ...\n"," [ 0.00170898]\n"," [-0.00036621]\n"," [-0.00097656]], shape=(71472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03222656 -0.05673218 -0.03414917 ...  0.00170898 -0.00036621\n"," -0.00097656], shape=(71472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02770996]\n"," [0.05883789]\n"," [0.05938721]\n"," ...\n"," [0.01760864]\n"," [0.02026367]\n"," [0.01473999]], shape=(61998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02770996 0.05883789 0.05938721 ... 0.01760864 0.02026367 0.01473999], shape=(61998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00457764]\n"," [ 0.00024414]\n"," [-0.01168823]\n"," ...\n"," [ 0.00836182]\n"," [ 0.02432251]\n"," [ 0.02734375]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00457764  0.00024414 -0.01168823 ...  0.00836182  0.02432251\n","  0.02734375], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00964355]\n"," [ 0.05389404]\n"," [ 0.09970093]\n"," ...\n"," [ 0.29052734]\n"," [ 0.28094482]\n"," [ 0.28225708]], shape=(59259, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00964355  0.05389404  0.09970093 ...  0.29052734  0.28094482\n","  0.28225708], shape=(59259,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00695801]\n"," [-0.00500488]\n"," [-0.0022583 ]\n"," ...\n"," [ 0.03344727]\n"," [ 0.03469849]\n"," [ 0.02301025]], shape=(61998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00695801 -0.00500488 -0.0022583  ...  0.03344727  0.03469849\n","  0.02301025], shape=(61998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00061035]\n"," [-0.00216675]\n"," [-0.00131226]\n"," ...\n"," [ 0.03778076]\n"," [ 0.05999756]\n"," [ 0.07635498]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00061035 -0.00216675 -0.00131226 ...  0.03778076  0.05999756\n","  0.07635498], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02972412]\n"," [-0.05426025]\n"," [-0.03662109]\n"," ...\n"," [ 0.04156494]\n"," [ 0.0383606 ]\n"," [ 0.03408813]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02972412 -0.05426025 -0.03662109 ...  0.04156494  0.0383606\n","  0.03408813], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02886963]\n"," [-0.04840088]\n"," [-0.03686523]\n"," ...\n"," [ 0.01153564]\n"," [ 0.01251221]\n"," [ 0.00799561]], shape=(72447, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02886963 -0.04840088 -0.03686523 ...  0.01153564  0.01251221\n","  0.00799561], shape=(72447,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01818848]\n"," [ 0.03994751]\n"," [ 0.03759766]\n"," ...\n"," [-0.01599121]\n"," [-0.01742554]\n"," [-0.01220703]], shape=(72029, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01818848  0.03994751  0.03759766 ... -0.01599121 -0.01742554\n"," -0.01220703], shape=(72029,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01242065]\n"," [-0.02832031]\n"," [-0.02865601]\n"," ...\n"," [ 0.00579834]\n"," [ 0.0045166 ]\n"," [ 0.00183105]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01242065 -0.02832031 -0.02865601 ...  0.00579834  0.0045166\n","  0.00183105], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.0517578e-05]\n"," [-2.0446777e-03]\n"," [-1.3427734e-03]\n"," ...\n"," [ 2.8686523e-03]\n"," [ 1.8920898e-03]\n"," [ 1.2207031e-03]], shape=(61440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.0517578e-05 -2.0446777e-03 -1.3427734e-03 ...  2.8686523e-03\n","  1.8920898e-03  1.2207031e-03], shape=(61440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01000977]\n"," [ 0.02139282]\n"," [ 0.01895142]\n"," ...\n"," [-0.00698853]\n"," [-0.00772095]\n"," [-0.00909424]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01000977  0.02139282  0.01895142 ... -0.00698853 -0.00772095\n"," -0.00909424], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01260376]\n"," [0.02191162]\n"," [0.01391602]\n"," ...\n"," [0.00097656]\n"," [0.00482178]\n"," [0.00561523]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01260376 0.02191162 0.01391602 ... 0.00097656 0.00482178 0.00561523], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01211548]\n"," [ 0.00216675]\n"," [ 0.00653076]\n"," ...\n"," [-0.13772583]\n"," [-0.07043457]\n"," [ 0.12005615]], shape=(70485, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01211548  0.00216675  0.00653076 ... -0.13772583 -0.07043457\n","  0.12005615], shape=(70485,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00592041]\n"," [ 0.01126099]\n"," [ 0.00750732]\n"," ...\n"," [-0.03833008]\n"," [-0.04675293]\n"," [-0.05917358]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00592041  0.01126099  0.00750732 ... -0.03833008 -0.04675293\n"," -0.05917358], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00030518]\n"," [-0.00073242]\n"," [-0.00042725]\n"," ...\n"," [ 0.00268555]\n"," [ 0.00314331]\n"," [ 0.003479  ]], shape=(64969, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00030518 -0.00073242 -0.00042725 ...  0.00268555  0.00314331\n","  0.003479  ], shape=(64969,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00186157]\n"," [ 0.00524902]\n"," [ 0.00619507]\n"," ...\n"," [-0.00415039]\n"," [-0.00341797]\n"," [-0.00128174]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00186157  0.00524902  0.00619507 ... -0.00415039 -0.00341797\n"," -0.00128174], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.50808716]\n"," [0.9999695 ]\n"," [0.8876343 ]\n"," ...\n"," [0.01400757]\n"," [0.01113892]\n"," [0.01928711]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.50808716 0.9999695  0.8876343  ... 0.01400757 0.01113892 0.01928711], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00238037]\n"," [ 0.00512695]\n"," [ 0.0057373 ]\n"," ...\n"," [-0.01040649]\n"," [-0.01071167]\n"," [-0.01171875]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00238037  0.00512695  0.0057373  ... -0.01040649 -0.01071167\n"," -0.01171875], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00772095]\n"," [0.019104  ]\n"," [0.01867676]\n"," ...\n"," [0.00366211]\n"," [0.00311279]\n"," [0.00134277]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00772095 0.019104   0.01867676 ... 0.00366211 0.00311279 0.00134277], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00952148]\n"," [-0.02050781]\n"," [-0.02099609]\n"," ...\n"," [ 0.00238037]\n"," [ 0.00241089]\n"," [ 0.00259399]], shape=(72586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00952148 -0.02050781 -0.02099609 ...  0.00238037  0.00241089\n","  0.00259399], shape=(72586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01403809]\n"," [ 0.02874756]\n"," [ 0.0256958 ]\n"," ...\n"," [-0.07830811]\n"," [-0.07449341]\n"," [-0.04885864]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01403809  0.02874756  0.0256958  ... -0.07830811 -0.07449341\n"," -0.04885864], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00170898]\n"," [0.00518799]\n"," [0.00680542]\n"," ...\n"," [0.0012207 ]\n"," [0.00125122]\n"," [0.00463867]], shape=(62276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00170898 0.00518799 0.00680542 ... 0.0012207  0.00125122 0.00463867], shape=(62276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0090332 ]\n"," [-0.02087402]\n"," [-0.02096558]\n"," ...\n"," [ 0.06240845]\n"," [ 0.06259155]\n"," [ 0.05541992]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0090332  -0.02087402 -0.02096558 ...  0.06240845  0.06259155\n","  0.05541992], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01397705]\n"," [0.02963257]\n"," [0.02502441]\n"," ...\n"," [0.00894165]\n"," [0.01043701]\n"," [0.01156616]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01397705 0.02963257 0.02502441 ... 0.00894165 0.01043701 0.01156616], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01751709]\n"," [-0.02059937]\n"," [-0.0045166 ]\n"," ...\n"," [-0.00830078]\n"," [-0.00796509]\n"," [-0.01245117]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01751709 -0.02059937 -0.0045166  ... -0.00830078 -0.00796509\n"," -0.01245117], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00030518]\n"," [-0.003479  ]\n"," [-0.00787354]\n"," ...\n"," [-0.00323486]\n"," [-0.00100708]\n"," [ 0.00064087]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00030518 -0.003479   -0.00787354 ... -0.00323486 -0.00100708\n","  0.00064087], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00460815]\n"," [ 0.01028442]\n"," [ 0.01034546]\n"," ...\n"," [-0.00524902]\n"," [-0.00036621]\n"," [ 0.00054932]], shape=(71472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00460815  0.01028442  0.01034546 ... -0.00524902 -0.00036621\n","  0.00054932], shape=(71472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0451355 ]\n"," [0.07293701]\n"," [0.03811646]\n"," ...\n"," [0.00177002]\n"," [0.00280762]\n"," [0.00216675]], shape=(71750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0451355  0.07293701 0.03811646 ... 0.00177002 0.00280762 0.00216675], shape=(71750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05514526]\n"," [ 0.1166687 ]\n"," [ 0.10421753]\n"," ...\n"," [-0.01083374]\n"," [-0.0123291 ]\n"," [-0.01187134]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05514526  0.1166687   0.10421753 ... -0.01083374 -0.0123291\n"," -0.01187134], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00045776]\n"," [0.02279663]\n"," [0.04455566]\n"," ...\n"," [0.01043701]\n"," [0.00961304]\n"," [0.00643921]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00045776 0.02279663 0.04455566 ... 0.01043701 0.00961304 0.00643921], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00546265]\n"," [-0.01043701]\n"," [-0.00558472]\n"," ...\n"," [ 0.01556396]\n"," [ 0.0145874 ]\n"," [ 0.0173645 ]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00546265 -0.01043701 -0.00558472 ...  0.01556396  0.0145874\n","  0.0173645 ], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0055542 ]\n"," [0.01345825]\n"," [0.01309204]\n"," ...\n"," [0.14926147]\n"," [0.14266968]\n"," [0.14291382]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0055542  0.01345825 0.01309204 ... 0.14926147 0.14266968 0.14291382], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00067139]\n"," [ 0.00134277]\n"," [ 0.00091553]\n"," ...\n"," [-0.01071167]\n"," [-0.01068115]\n"," [-0.00811768]], shape=(71611, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00067139  0.00134277  0.00091553 ... -0.01071167 -0.01068115\n"," -0.00811768], shape=(71611,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00091553]\n"," [-0.00360107]\n"," [-0.00418091]\n"," ...\n"," [-0.00299072]\n"," [-0.00418091]\n"," [-0.00286865]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00091553 -0.00360107 -0.00418091 ... -0.00299072 -0.00418091\n"," -0.00286865], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00640869]\n"," [-0.01370239]\n"," [-0.01208496]\n"," ...\n"," [ 0.00912476]\n"," [ 0.0088501 ]\n"," [ 0.00762939]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00640869 -0.01370239 -0.01208496 ...  0.00912476  0.0088501\n","  0.00762939], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01519775]\n"," [0.03048706]\n"," [0.02758789]\n"," ...\n"," [0.00085449]\n"," [0.00045776]\n"," [0.00097656]], shape=(72029, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01519775 0.03048706 0.02758789 ... 0.00085449 0.00045776 0.00097656], shape=(72029,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00299072]\n"," [-0.00411987]\n"," [ 0.00036621]\n"," ...\n"," [-0.1307373 ]\n"," [-0.06015015]\n"," [ 0.02075195]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00299072 -0.00411987  0.00036621 ... -0.1307373  -0.06015015\n","  0.02075195], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0501709 ]\n"," [-0.11087036]\n"," [-0.10644531]\n"," ...\n"," [-0.08459473]\n"," [-0.09796143]\n"," [-0.11709595]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0501709  -0.11087036 -0.10644531 ... -0.08459473 -0.09796143\n"," -0.11709595], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08197021]\n"," [-0.17852783]\n"," [-0.16586304]\n"," ...\n"," [-0.02896118]\n"," [-0.00018311]\n"," [ 0.03982544]], shape=(61440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08197021 -0.17852783 -0.16586304 ... -0.02896118 -0.00018311\n","  0.03982544], shape=(61440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00271606]\n"," [-0.00662231]\n"," [-0.00854492]\n"," ...\n"," [ 0.00515747]\n"," [ 0.00564575]\n"," [ 0.00595093]], shape=(71750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00271606 -0.00662231 -0.00854492 ...  0.00515747  0.00564575\n","  0.00595093], shape=(71750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01022339]\n"," [-0.01779175]\n"," [-0.01165771]\n"," ...\n"," [ 0.00854492]\n"," [ 0.01196289]\n"," [ 0.0112915 ]], shape=(62137, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01022339 -0.01779175 -0.01165771 ...  0.00854492  0.01196289\n","  0.0112915 ], shape=(62137,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01196289]\n"," [ 0.03741455]\n"," [ 0.05322266]\n"," ...\n"," [-0.24850464]\n"," [-0.42132568]\n"," [-0.4291687 ]], shape=(66461, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01196289  0.03741455  0.05322266 ... -0.24850464 -0.42132568\n"," -0.4291687 ], shape=(66461,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01794434]\n"," [ 0.03527832]\n"," [ 0.0291748 ]\n"," ...\n"," [-0.00415039]\n"," [-0.00567627]\n"," [-0.00415039]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01794434  0.03527832  0.0291748  ... -0.00415039 -0.00567627\n"," -0.00415039], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01327515]\n"," [-0.02310181]\n"," [-0.01599121]\n"," ...\n"," [-0.06845093]\n"," [-0.05041504]\n"," [-0.04333496]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01327515 -0.02310181 -0.01599121 ... -0.06845093 -0.05041504\n"," -0.04333496], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01837158]\n"," [0.0350647 ]\n"," [0.02560425]\n"," ...\n"," [0.01644897]\n"," [0.01745605]\n"," [0.01635742]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01837158 0.0350647  0.02560425 ... 0.01644897 0.01745605 0.01635742], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01257324]\n"," [ 0.02404785]\n"," [ 0.02337646]\n"," ...\n"," [-0.04803467]\n"," [-0.04415894]\n"," [-0.0435791 ]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01257324  0.02404785  0.02337646 ... -0.04803467 -0.04415894\n"," -0.0435791 ], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00042725]\n"," [0.00061035]\n"," [0.00128174]\n"," ...\n"," [0.01675415]\n"," [0.01425171]\n"," [0.00784302]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00042725 0.00061035 0.00128174 ... 0.01675415 0.01425171 0.00784302], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08209229]\n"," [-0.16159058]\n"," [-0.12878418]\n"," ...\n"," [-0.03042603]\n"," [-0.03036499]\n"," [-0.03042603]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08209229 -0.16159058 -0.12878418 ... -0.03042603 -0.03036499\n"," -0.03042603], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.009552  ]\n"," [-0.0206604 ]\n"," [-0.01867676]\n"," ...\n"," [ 0.04141235]\n"," [ 0.04162598]\n"," [ 0.03170776]], shape=(61162, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.009552   -0.0206604  -0.01867676 ...  0.04141235  0.04162598\n","  0.03170776], shape=(61162,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01260376]\n"," [ 0.02575684]\n"," [ 0.02111816]\n"," ...\n"," [-0.02755737]\n"," [-0.03295898]\n"," [-0.03546143]], shape=(18530, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01260376  0.02575684  0.02111816 ... -0.02755737 -0.03295898\n"," -0.03546143], shape=(18530,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03106689]\n"," [ 0.06463623]\n"," [ 0.05456543]\n"," ...\n"," [-0.01577759]\n"," [-0.01690674]\n"," [-0.0145874 ]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03106689  0.06463623  0.05456543 ... -0.01577759 -0.01690674\n"," -0.0145874 ], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00244141]\n"," [-0.02069092]\n"," [-0.037323  ]\n"," ...\n"," [ 0.00674438]\n"," [ 0.00473022]\n"," [ 0.00296021]], shape=(72447, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00244141 -0.02069092 -0.037323   ...  0.00674438  0.00473022\n","  0.00296021], shape=(72447,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0227356 ]\n"," [0.04782104]\n"," [0.04244995]\n"," ...\n"," [0.01702881]\n"," [0.0149231 ]\n"," [0.00704956]], shape=(61998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0227356  0.04782104 0.04244995 ... 0.01702881 0.0149231  0.00704956], shape=(61998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02279663]\n"," [-0.04962158]\n"," [-0.03353882]\n"," ...\n"," [ 0.00411987]\n"," [ 0.00485229]\n"," [ 0.00344849]], shape=(71611, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02279663 -0.04962158 -0.03353882 ...  0.00411987  0.00485229\n","  0.00344849], shape=(71611,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00299072]\n"," [-0.00595093]\n"," [-0.00546265]\n"," ...\n"," [ 0.01821899]\n"," [ 0.01843262]\n"," [ 0.01553345]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00299072 -0.00595093 -0.00546265 ...  0.01821899  0.01843262\n","  0.01553345], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00088501]\n"," [-0.00219727]\n"," [-0.00204468]\n"," ...\n"," [ 0.00527954]\n"," [ 0.00439453]\n"," [ 0.00357056]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00088501 -0.00219727 -0.00204468 ...  0.00527954  0.00439453\n","  0.00357056], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04125977]\n"," [ 0.07546997]\n"," [ 0.05062866]\n"," ...\n"," [-0.02218628]\n"," [-0.02539062]\n"," [-0.02105713]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04125977  0.07546997  0.05062866 ... -0.02218628 -0.02539062\n"," -0.02105713], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00942993]\n"," [ 0.02093506]\n"," [ 0.01934814]\n"," ...\n"," [-0.00653076]\n"," [-0.00924683]\n"," [-0.00604248]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00942993  0.02093506  0.01934814 ... -0.00653076 -0.00924683\n"," -0.00604248], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.12057495]\n"," [ 0.38345337]\n"," [ 0.48086548]\n"," ...\n"," [-0.00823975]\n"," [-0.01052856]\n"," [-0.00735474]], shape=(72447, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.12057495  0.38345337  0.48086548 ... -0.00823975 -0.01052856\n"," -0.00735474], shape=(72447,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01211548]\n"," [-0.02398682]\n"," [-0.01919556]\n"," ...\n"," [-0.00634766]\n"," [-0.00561523]\n"," [-0.00350952]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01211548 -0.02398682 -0.01919556 ... -0.00634766 -0.00561523\n"," -0.00350952], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00274658]\n"," [ 0.00564575]\n"," [ 0.00473022]\n"," ...\n"," [-0.00305176]\n"," [-0.00289917]\n"," [-0.00344849]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00274658  0.00564575  0.00473022 ... -0.00305176 -0.00289917\n"," -0.00344849], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02658081]\n"," [-0.06311035]\n"," [-0.06387329]\n"," ...\n"," [-0.04977417]\n"," [-0.05273438]\n"," [-0.05426025]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02658081 -0.06311035 -0.06387329 ... -0.04977417 -0.05273438\n"," -0.05426025], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00704956]\n"," [0.01269531]\n"," [0.00881958]\n"," ...\n"," [0.00820923]\n"," [0.00674438]\n"," [0.00512695]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00704956 0.01269531 0.00881958 ... 0.00820923 0.00674438 0.00512695], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03463745]\n"," [-0.0586853 ]\n"," [-0.02941895]\n"," ...\n"," [-0.01449585]\n"," [-0.02011108]\n"," [-0.03240967]], shape=(62276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03463745 -0.0586853  -0.02941895 ... -0.01449585 -0.02011108\n"," -0.03240967], shape=(62276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00894165]\n"," [ 0.01675415]\n"," [ 0.01171875]\n"," ...\n"," [-0.02175903]\n"," [-0.0201416 ]\n"," [-0.02246094]], shape=(61440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00894165  0.01675415  0.01171875 ... -0.02175903 -0.0201416\n"," -0.02246094], shape=(61440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04849243]\n"," [-0.09341431]\n"," [-0.07226562]\n"," ...\n"," [ 0.00723267]\n"," [ 0.00708008]\n"," [ 0.00698853]], shape=(71750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04849243 -0.09341431 -0.07226562 ...  0.00723267  0.00708008\n","  0.00698853], shape=(71750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02249146]\n"," [-0.04830933]\n"," [-0.04232788]\n"," ...\n"," [ 0.0256958 ]\n"," [ 0.02523804]\n"," [ 0.01715088]], shape=(61998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02249146 -0.04830933 -0.04232788 ...  0.0256958   0.02523804\n","  0.01715088], shape=(61998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00231934]\n"," [-0.00698853]\n"," [-0.00787354]\n"," ...\n"," [-0.00222778]\n"," [-0.00195312]\n"," [-0.00134277]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00231934 -0.00698853 -0.00787354 ... -0.00222778 -0.00195312\n"," -0.00134277], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [-0.01330566]\n"," [-0.01196289]\n"," ...\n"," [-0.01434326]\n"," [-0.01391602]\n"," [-0.00973511]], shape=(61580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561  -0.01330566 -0.01196289 ... -0.01434326 -0.01391602\n"," -0.00973511], shape=(61580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00143433]\n"," [ 0.00250244]\n"," [ 0.00299072]\n"," ...\n"," [-0.00115967]\n"," [-0.00134277]\n"," [-0.00079346]], shape=(72029, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00143433  0.00250244  0.00299072 ... -0.00115967 -0.00134277\n"," -0.00079346], shape=(72029,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00384521]\n"," [0.0067749 ]\n"," [0.00598145]\n"," ...\n"," [0.00778198]\n"," [0.00772095]\n"," [0.00848389]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00384521 0.0067749  0.00598145 ... 0.00778198 0.00772095 0.00848389], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04525757]\n"," [0.09371948]\n"," [0.08105469]\n"," ...\n"," [0.03390503]\n"," [0.03353882]\n"," [0.03372192]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04525757 0.09371948 0.08105469 ... 0.03390503 0.03353882 0.03372192], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03451538]\n"," [-0.06829834]\n"," [-0.04129028]\n"," ...\n"," [ 0.01074219]\n"," [ 0.00814819]\n"," [ 0.00601196]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03451538 -0.06829834 -0.04129028 ...  0.01074219  0.00814819\n","  0.00601196], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.19091797]\n"," [ 0.37683105]\n"," [ 0.30041504]\n"," ...\n"," [-0.05883789]\n"," [-0.06573486]\n"," [-0.07162476]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.19091797  0.37683105  0.30041504 ... -0.05883789 -0.06573486\n"," -0.07162476], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00680542]\n"," [-0.01159668]\n"," [-0.00613403]\n"," ...\n"," [ 0.03033447]\n"," [ 0.02929688]\n"," [ 0.0289917 ]], shape=(41239, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00680542 -0.01159668 -0.00613403 ...  0.03033447  0.02929688\n","  0.0289917 ], shape=(41239,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00949097]\n"," [0.02093506]\n"," [0.01831055]\n"," ...\n"," [0.00393677]\n"," [0.00167847]\n"," [0.00100708]], shape=(72307, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00949097 0.02093506 0.01831055 ... 0.00393677 0.00167847 0.00100708], shape=(72307,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.16937256]\n"," [0.3534851 ]\n"," [0.30374146]\n"," ...\n"," [0.05029297]\n"," [0.03921509]\n"," [0.03686523]], shape=(61440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.16937256 0.3534851  0.30374146 ... 0.05029297 0.03921509 0.03686523], shape=(61440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00576782]\n"," [0.00952148]\n"," [0.00473022]\n"," ...\n"," [0.07778931]\n"," [0.07720947]\n"," [0.09051514]], shape=(72307, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00576782 0.00952148 0.00473022 ... 0.07778931 0.07720947 0.09051514], shape=(72307,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00039673]\n"," [-0.00198364]\n"," [-0.00244141]\n"," ...\n"," [-0.00326538]\n"," [-0.00341797]\n"," [-0.00360107]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00039673 -0.00198364 -0.00244141 ... -0.00326538 -0.00341797\n"," -0.00360107], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01519775]\n"," [0.03601074]\n"," [0.0375061 ]\n"," ...\n"," [0.00744629]\n"," [0.00549316]\n"," [0.00177002]], shape=(72168, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01519775 0.03601074 0.0375061  ... 0.00744629 0.00549316 0.00177002], shape=(72168,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00326538]\n"," [ 0.00787354]\n"," [ 0.00866699]\n"," ...\n"," [-0.00344849]\n"," [-0.0027771 ]\n"," [-0.00256348]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00326538  0.00787354  0.00866699 ... -0.00344849 -0.0027771\n"," -0.00256348], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00558472]\n"," [ 0.00848389]\n"," [-0.00134277]\n"," ...\n"," [-0.08200073]\n"," [ 0.07836914]\n"," [ 0.23431396]], shape=(61719, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00558472  0.00848389 -0.00134277 ... -0.08200073  0.07836914\n","  0.23431396], shape=(61719,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00091553]\n"," [-0.00326538]\n"," [-0.00604248]\n"," ...\n"," [-0.01229858]\n"," [-0.01376343]\n"," [-0.01107788]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00091553 -0.00326538 -0.00604248 ... -0.01229858 -0.01376343\n"," -0.01107788], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01147461]\n"," [-0.0222168 ]\n"," [-0.01745605]\n"," ...\n"," [-0.13006592]\n"," [-0.12768555]\n"," [-0.14883423]], shape=(62276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01147461 -0.0222168  -0.01745605 ... -0.13006592 -0.12768555\n"," -0.14883423], shape=(62276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00378418]\n"," [ 0.00918579]\n"," [ 0.00927734]\n"," ...\n"," [-0.05270386]\n"," [-0.06390381]\n"," [-0.0819397 ]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00378418  0.00918579  0.00927734 ... -0.05270386 -0.06390381\n"," -0.0819397 ], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01156616]\n"," [-0.02252197]\n"," [-0.01968384]\n"," ...\n"," [-0.0032959 ]\n"," [-0.00302124]\n"," [-0.00308228]], shape=(72586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01156616 -0.02252197 -0.01968384 ... -0.0032959  -0.00302124\n"," -0.00308228], shape=(72586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00128174]\n"," [ 0.0050354 ]\n"," [ 0.01419067]\n"," ...\n"," [-0.00268555]\n"," [-0.00213623]\n"," [-0.00488281]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00128174  0.0050354   0.01419067 ... -0.00268555 -0.00213623\n"," -0.00488281], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.9836426e-03]\n"," [-3.6926270e-03]\n"," [-2.8381348e-03]\n"," ...\n"," [-3.9672852e-04]\n"," [ 6.1035156e-05]\n"," [ 3.6621094e-04]], shape=(72447, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.9836426e-03 -3.6926270e-03 -2.8381348e-03 ... -3.9672852e-04\n","  6.1035156e-05  3.6621094e-04], shape=(72447,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00253296]\n"," [ 0.00653076]\n"," [ 0.00680542]\n"," ...\n"," [ 0.0007019 ]\n"," [ 0.00054932]\n"," [-0.00042725]], shape=(61301, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00253296  0.00653076  0.00680542 ...  0.0007019   0.00054932\n"," -0.00042725], shape=(61301,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10046387]\n"," [-0.20285034]\n"," [-0.16204834]\n"," ...\n"," [-0.00579834]\n"," [-0.00576782]\n"," [-0.00375366]], shape=(61998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10046387 -0.20285034 -0.16204834 ... -0.00579834 -0.00576782\n"," -0.00375366], shape=(61998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00137329]\n"," [ 0.00338745]\n"," [ 0.00408936]\n"," ...\n"," [-0.01498413]\n"," [-0.00442505]\n"," [ 0.00299072]], shape=(41936, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00137329  0.00338745  0.00408936 ... -0.01498413 -0.00442505\n","  0.00299072], shape=(41936,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01824951]\n"," [-0.03546143]\n"," [-0.02676392]\n"," ...\n"," [ 0.02990723]\n"," [ 0.03042603]\n"," [ 0.02035522]], shape=(72029, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01824951 -0.03546143 -0.02676392 ...  0.02990723  0.03042603\n","  0.02035522], shape=(72029,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01693726]\n"," [0.0411377 ]\n"," [0.04333496]\n"," ...\n"," [0.00836182]\n"," [0.00787354]\n"," [0.00643921]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01693726 0.0411377  0.04333496 ... 0.00836182 0.00787354 0.00643921], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01184082]\n"," [-0.02185059]\n"," [-0.01602173]\n"," ...\n"," [ 0.00616455]\n"," [ 0.00527954]\n"," [ 0.00296021]], shape=(72447, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01184082 -0.02185059 -0.01602173 ...  0.00616455  0.00527954\n","  0.00296021], shape=(72447,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01101685]\n"," [-0.02160645]\n"," [-0.01779175]\n"," ...\n"," [ 0.00823975]\n"," [ 0.01190186]\n"," [ 0.01052856]], shape=(25061, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01101685 -0.02160645 -0.01779175 ...  0.00823975  0.01190186\n","  0.01052856], shape=(25061,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01431274]\n"," [-0.03213501]\n"," [-0.02947998]\n"," ...\n"," [-0.00323486]\n"," [-0.00494385]\n"," [-0.00619507]], shape=(71193, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01431274 -0.03213501 -0.02947998 ... -0.00323486 -0.00494385\n"," -0.00619507], shape=(71193,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00363159]\n"," [-0.00622559]\n"," [-0.00247192]\n"," ...\n"," [ 0.02825928]\n"," [ 0.02798462]\n"," [ 0.02935791]], shape=(71332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00363159 -0.00622559 -0.00247192 ...  0.02825928  0.02798462\n","  0.02935791], shape=(71332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00888062]\n"," [-0.01937866]\n"," [-0.01824951]\n"," ...\n"," [-0.01074219]\n"," [-0.0085144 ]\n"," [-0.00448608]], shape=(61162, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00888062 -0.01937866 -0.01824951 ... -0.01074219 -0.0085144\n"," -0.00448608], shape=(61162,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03060913]\n"," [-0.06173706]\n"," [-0.05212402]\n"," ...\n"," [-0.04101562]\n"," [-0.04092407]\n"," [-0.05001831]], shape=(61440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03060913 -0.06173706 -0.05212402 ... -0.04101562 -0.04092407\n"," -0.05001831], shape=(61440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00164795]\n"," [ 0.00848389]\n"," [ 0.01528931]\n"," ...\n"," [-0.1716919 ]\n"," [-0.16220093]\n"," [-0.17730713]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00164795  0.00848389  0.01528931 ... -0.1716919  -0.16220093\n"," -0.17730713], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00460815]\n"," [-0.02127075]\n"," [-0.03692627]\n"," ...\n"," [-0.05718994]\n"," [-0.06295776]\n"," [-0.08270264]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00460815 -0.02127075 -0.03692627 ... -0.05718994 -0.06295776\n"," -0.08270264], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-5.7983398e-04]\n"," [ 9.1552734e-05]\n"," [ 4.2419434e-03]\n"," ...\n"," [ 8.8256836e-02]\n"," [ 8.2122803e-02]\n"," [ 8.7677002e-02]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-5.7983398e-04  9.1552734e-05  4.2419434e-03 ...  8.8256836e-02\n","  8.2122803e-02  8.7677002e-02], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.6621094e-04]\n"," [-1.2817383e-03]\n"," [-1.4038086e-03]\n"," ...\n"," [-5.9158325e-01]\n"," [-5.4003906e-01]\n"," [-5.0057983e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.6621094e-04 -1.2817383e-03 -1.4038086e-03 ... -5.9158325e-01\n"," -5.4003906e-01 -5.0057983e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00146484]\n"," [-0.00387573]\n"," [-0.01278687]\n"," ...\n"," [-0.1642456 ]\n"," [-0.15814209]\n"," [-0.19134521]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00146484 -0.00387573 -0.01278687 ... -0.1642456  -0.15814209\n"," -0.19134521], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.0517578e-05]\n"," [ 8.5449219e-04]\n"," [ 1.1901855e-03]\n"," ...\n"," [-2.5939941e-01]\n"," [-2.4090576e-01]\n"," [-2.5912476e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.0517578e-05  8.5449219e-04  1.1901855e-03 ... -2.5939941e-01\n"," -2.4090576e-01 -2.5912476e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00540161]\n"," [-0.02987671]\n"," [-0.05657959]\n"," ...\n"," [-0.42477417]\n"," [-0.394104  ]\n"," [-0.442688  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00540161 -0.02987671 -0.05657959 ... -0.42477417 -0.394104\n"," -0.442688  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00314331]\n"," [-0.01528931]\n"," [-0.02853394]\n"," ...\n"," [-0.04611206]\n"," [-0.03390503]\n"," [-0.02371216]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00314331 -0.01528931 -0.02853394 ... -0.04611206 -0.03390503\n"," -0.02371216], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-9.1552734e-05]\n"," [ 3.3569336e-04]\n"," [ 1.2512207e-03]\n"," ...\n"," [ 2.8106689e-01]\n"," [ 2.6144409e-01]\n"," [ 2.7978516e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-9.1552734e-05  3.3569336e-04  1.2512207e-03 ...  2.8106689e-01\n","  2.6144409e-01  2.7978516e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00021362]\n"," [-0.00057983]\n"," [-0.00054932]\n"," ...\n"," [-0.04470825]\n"," [-0.07296753]\n"," [-0.09307861]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00021362 -0.00057983 -0.00054932 ... -0.04470825 -0.07296753\n"," -0.09307861], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00100708]\n"," [-0.00274658]\n"," [-0.00521851]\n"," ...\n"," [-0.07983398]\n"," [-0.07305908]\n"," [-0.07879639]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00100708 -0.00274658 -0.00521851 ... -0.07983398 -0.07305908\n"," -0.07879639], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00527954]\n"," [-0.02227783]\n"," [-0.03643799]\n"," ...\n"," [-0.30685425]\n"," [-0.28979492]\n"," [-0.30978394]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00527954 -0.02227783 -0.03643799 ... -0.30685425 -0.28979492\n"," -0.30978394], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00076294]\n"," [ 0.0045166 ]\n"," [ 0.00891113]\n"," ...\n"," [-0.37857056]\n"," [-0.35369873]\n"," [-0.38433838]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00076294  0.0045166   0.00891113 ... -0.37857056 -0.35369873\n"," -0.38433838], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01263428]\n"," [-0.04592896]\n"," [-0.05352783]\n"," ...\n"," [ 0.17297363]\n"," [ 0.17660522]\n"," [ 0.21453857]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01263428 -0.04592896 -0.05352783 ...  0.17297363  0.17660522\n","  0.21453857], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00216675]\n"," [-0.00881958]\n"," [-0.01113892]\n"," ...\n"," [ 0.01330566]\n"," [ 0.01086426]\n"," [ 0.00579834]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00216675 -0.00881958 -0.01113892 ...  0.01330566  0.01086426\n","  0.00579834], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00125122]\n"," [0.00680542]\n"," [0.01464844]\n"," ...\n"," [0.2033081 ]\n"," [0.23422241]\n"," [0.31829834]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00125122 0.00680542 0.01464844 ... 0.2033081  0.23422241 0.31829834], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00079346]\n"," [ 0.00296021]\n"," [ 0.00640869]\n"," ...\n"," [-0.05081177]\n"," [-0.03738403]\n"," [-0.02618408]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00079346  0.00296021  0.00640869 ... -0.05081177 -0.03738403\n"," -0.02618408], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00784302]\n"," [ 0.04196167]\n"," [ 0.02609253]\n"," ...\n"," [-0.04159546]\n"," [-0.03521729]\n"," [-0.0333252 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00784302  0.04196167  0.02609253 ... -0.04159546 -0.03521729\n"," -0.0333252 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00234985]\n"," [-0.01373291]\n"," [-0.02874756]\n"," ...\n"," [-0.5520935 ]\n"," [-0.5119629 ]\n"," [-0.53778076]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00234985 -0.01373291 -0.02874756 ... -0.5520935  -0.5119629\n"," -0.53778076], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00189209]\n"," [-0.00775146]\n"," [-0.01339722]\n"," ...\n"," [-0.00201416]\n"," [ 0.00473022]\n"," [ 0.01693726]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00189209 -0.00775146 -0.01339722 ... -0.00201416  0.00473022\n","  0.01693726], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00177002]\n"," [-0.00698853]\n"," [-0.01028442]\n"," ...\n"," [ 0.06796265]\n"," [ 0.08251953]\n"," [ 0.11453247]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00177002 -0.00698853 -0.01028442 ...  0.06796265  0.08251953\n","  0.11453247], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00057983]\n"," [-0.00216675]\n"," [-0.00442505]\n"," ...\n"," [-0.20159912]\n"," [-0.1904602 ]\n"," [-0.21026611]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00057983 -0.00216675 -0.00442505 ... -0.20159912 -0.1904602\n"," -0.21026611], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00195312]\n"," [-0.00689697]\n"," [-0.00820923]\n"," ...\n"," [-0.22885132]\n"," [-0.21676636]\n"," [-0.24008179]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00195312 -0.00689697 -0.00820923 ... -0.22885132 -0.21676636\n"," -0.24008179], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01364136]\n"," [-0.05654907]\n"," [-0.08685303]\n"," ...\n"," [-0.0395813 ]\n"," [-0.05300903]\n"," [-0.04119873]], shape=(13971, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01364136 -0.05654907 -0.08685303 ... -0.0395813  -0.05300903\n"," -0.04119873], shape=(13971,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00106812]\n"," [ 0.00161743]\n"," [ 0.00140381]\n"," ...\n"," [-0.2508545 ]\n"," [-0.22628784]\n"," [-0.2312622 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00106812  0.00161743  0.00140381 ... -0.2508545  -0.22628784\n"," -0.2312622 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 4.2724609e-04]\n"," [ 1.8615723e-03]\n"," [ 4.3945312e-03]\n"," ...\n"," [-5.1425171e-01]\n"," [-4.8687744e-01]\n"," [-5.3854370e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 4.2724609e-04  1.8615723e-03  4.3945312e-03 ... -5.1425171e-01\n"," -4.8687744e-01 -5.3854370e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00231934]\n"," [-0.01025391]\n"," [-0.01696777]\n"," ...\n"," [-0.07507324]\n"," [-0.07659912]\n"," [-0.09378052]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00231934 -0.01025391 -0.01696777 ... -0.07507324 -0.07659912\n"," -0.09378052], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00183105]\n"," [ 0.00787354]\n"," [ 0.00924683]\n"," ...\n"," [-0.40011597]\n"," [-0.3791809 ]\n"," [-0.4126587 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00183105  0.00787354  0.00924683 ... -0.40011597 -0.3791809\n"," -0.4126587 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00167847]\n"," [ 0.00753784]\n"," [ 0.01065063]\n"," ...\n"," [-0.54177856]\n"," [-0.50479126]\n"," [-0.54867554]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00167847  0.00753784  0.01065063 ... -0.54177856 -0.50479126\n"," -0.54867554], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04541016]\n"," [-0.04748535]\n"," [-0.0289917 ]\n"," ...\n"," [-0.32452393]\n"," [-0.33224487]\n"," [-0.40393066]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04541016 -0.04748535 -0.0289917  ... -0.32452393 -0.33224487\n"," -0.40393066], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00231934]\n"," [-0.01123047]\n"," [-0.02127075]\n"," ...\n"," [-0.45565796]\n"," [-0.43374634]\n"," [-0.4830017 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00231934 -0.01123047 -0.02127075 ... -0.45565796 -0.43374634\n"," -0.4830017 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00177002]\n"," [-0.00869751]\n"," [-0.01419067]\n"," ...\n"," [ 0.09625244]\n"," [ 0.08938599]\n"," [ 0.08062744]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00177002 -0.00869751 -0.01419067 ...  0.09625244  0.08938599\n","  0.08062744], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00076294]\n"," [ 0.00292969]\n"," [ 0.00350952]\n"," ...\n"," [-0.09393311]\n"," [-0.08908081]\n"," [-0.09848022]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00076294  0.00292969  0.00350952 ... -0.09393311 -0.08908081\n"," -0.09848022], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00259399]\n"," [0.01159668]\n"," [0.01260376]\n"," ...\n"," [0.42266846]\n"," [0.3894043 ]\n"," [0.4093628 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00259399 0.01159668 0.01260376 ... 0.42266846 0.3894043  0.4093628 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00152588]\n"," [-0.00576782]\n"," [-0.00909424]\n"," ...\n"," [-0.16314697]\n"," [-0.15386963]\n"," [-0.1685791 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00152588 -0.00576782 -0.00909424 ... -0.16314697 -0.15386963\n"," -0.1685791 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00061035]\n"," [ 0.00247192]\n"," [ 0.00320435]\n"," ...\n"," [-0.02539062]\n"," [-0.02487183]\n"," [-0.02905273]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00061035  0.00247192  0.00320435 ... -0.02539062 -0.02487183\n"," -0.02905273], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00204468]\n"," [-0.00958252]\n"," [-0.01565552]\n"," ...\n"," [-0.27264404]\n"," [-0.24972534]\n"," [-0.26602173]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00204468 -0.00958252 -0.01565552 ... -0.27264404 -0.24972534\n"," -0.26602173], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-2.1362305e-04]\n"," [-2.5329590e-03]\n"," [-5.9509277e-03]\n"," ...\n"," [-3.5562134e-01]\n"," [-3.2434082e-01]\n"," [-3.3947754e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-2.1362305e-04 -2.5329590e-03 -5.9509277e-03 ... -3.5562134e-01\n"," -3.2434082e-01 -3.3947754e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00234985]\n"," [-0.01251221]\n"," [-0.02642822]\n"," ...\n"," [-0.1927185 ]\n"," [-0.17047119]\n"," [-0.1736145 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00234985 -0.01251221 -0.02642822 ... -0.1927185  -0.17047119\n"," -0.1736145 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00064087]\n"," [-0.00311279]\n"," [-0.00143433]\n"," ...\n"," [ 0.22946167]\n"," [ 0.22210693]\n"," [ 0.24508667]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00064087 -0.00311279 -0.00143433 ...  0.22946167  0.22210693\n","  0.24508667], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 1.5258789e-04]\n"," [ 9.4604492e-04]\n"," [ 2.5329590e-03]\n"," ...\n"," [-3.4878540e-01]\n"," [-3.4176636e-01]\n"," [-3.8815308e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 1.5258789e-04  9.4604492e-04  2.5329590e-03 ... -3.4878540e-01\n"," -3.4176636e-01 -3.8815308e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00518799]\n"," [-0.01797485]\n"," [-0.02301025]\n"," ...\n"," [-0.16656494]\n"," [-0.15859985]\n"," [-0.17022705]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00518799 -0.01797485 -0.02301025 ... -0.16656494 -0.15859985\n"," -0.17022705], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00314331]\n"," [-0.01358032]\n"," [-0.02368164]\n"," ...\n"," [ 0.02096558]\n"," [ 0.05047607]\n"," [ 0.11599731]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00314331 -0.01358032 -0.02368164 ...  0.02096558  0.05047607\n","  0.11599731], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-9.1552734e-05]\n"," [-3.8452148e-03]\n"," [-5.1574707e-03]\n"," ...\n"," [-3.5910034e-01]\n"," [-3.4103394e-01]\n"," [-3.7765503e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-9.1552734e-05 -3.8452148e-03 -5.1574707e-03 ... -3.5910034e-01\n"," -3.4103394e-01 -3.7765503e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00317383]\n"," [-0.01419067]\n"," [-0.02404785]\n"," ...\n"," [-0.61779785]\n"," [-0.5713806 ]\n"," [-0.63500977]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00317383 -0.01419067 -0.02404785 ... -0.61779785 -0.5713806\n"," -0.63500977], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.01660156]\n"," [-0.02716064]\n"," ...\n"," [-0.02520752]\n"," [-0.02648926]\n"," [-0.03326416]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.01660156 -0.02716064 ... -0.02520752 -0.02648926\n"," -0.03326416], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0010376 ]\n"," [-0.00619507]\n"," [-0.00827026]\n"," ...\n"," [ 0.00598145]\n"," [ 0.15689087]\n"," [-0.00485229]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0010376  -0.00619507 -0.00827026 ...  0.00598145  0.15689087\n"," -0.00485229], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00036621]\n"," [-0.00344849]\n"," [-0.00820923]\n"," ...\n"," [-0.1387024 ]\n"," [-0.10421753]\n"," [-0.10653687]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00036621 -0.00344849 -0.00820923 ... -0.1387024  -0.10421753\n"," -0.10653687], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00015259]\n"," [-0.00140381]\n"," [-0.00430298]\n"," ...\n"," [-0.04022217]\n"," [-0.03985596]\n"," [-0.04656982]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00015259 -0.00140381 -0.00430298 ... -0.04022217 -0.03985596\n"," -0.04656982], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00085449]\n"," [ 0.00485229]\n"," [ 0.00939941]\n"," ...\n"," [-0.23410034]\n"," [-0.22683716]\n"," [-0.25775146]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00085449  0.00485229  0.00939941 ... -0.23410034 -0.22683716\n"," -0.25775146], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00082397]\n"," [-0.00317383]\n"," [-0.00650024]\n"," ...\n"," [-0.0355835 ]\n"," [-0.02230835]\n"," [-0.01818848]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00082397 -0.00317383 -0.00650024 ... -0.0355835  -0.02230835\n"," -0.01818848], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0078125 ]\n"," [ 0.03723145]\n"," [ 0.06854248]\n"," ...\n"," [-0.17819214]\n"," [-0.18051147]\n"," [-0.20410156]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0078125   0.03723145  0.06854248 ... -0.17819214 -0.18051147\n"," -0.20410156], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00109863]\n"," [0.00543213]\n"," [0.0098877 ]\n"," ...\n"," [0.24572754]\n"," [0.23379517]\n"," [0.2593689 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00109863 0.00543213 0.0098877  ... 0.24572754 0.23379517 0.2593689 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00888062]\n"," [-0.04003906]\n"," [-0.06912231]\n"," ...\n"," [-0.29553223]\n"," [-0.28146362]\n"," [-0.33520508]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00888062 -0.04003906 -0.06912231 ... -0.29553223 -0.28146362\n"," -0.33520508], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.01190186]\n"," [-0.02267456]\n"," ...\n"," [-0.16525269]\n"," [-0.15457153]\n"," [-0.1701355 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.01190186 -0.02267456 ... -0.16525269 -0.15457153\n"," -0.1701355 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00253296]\n"," [-0.01257324]\n"," [-0.02258301]\n"," ...\n"," [-0.09048462]\n"," [-0.08462524]\n"," [-0.0921936 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00253296 -0.01257324 -0.02258301 ... -0.09048462 -0.08462524\n"," -0.0921936 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00192261]\n"," [ 0.00958252]\n"," [ 0.0171814 ]\n"," ...\n"," [-0.05795288]\n"," [-0.05953979]\n"," [-0.05947876]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00192261  0.00958252  0.0171814  ... -0.05795288 -0.05953979\n"," -0.05947876], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00177002]\n"," [ 0.00241089]\n"," [ 0.01190186]\n"," ...\n"," [-0.08746338]\n"," [-0.09298706]\n"," [-0.12161255]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00177002  0.00241089  0.01190186 ... -0.08746338 -0.09298706\n"," -0.12161255], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0005188 ]\n"," [-0.00268555]\n"," [-0.00506592]\n"," ...\n"," [-0.08551025]\n"," [-0.19628906]\n"," [-0.22009277]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0005188  -0.00268555 -0.00506592 ... -0.08551025 -0.19628906\n"," -0.22009277], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01202393]\n"," [ 0.05462646]\n"," [ 0.09268188]\n"," ...\n"," [-0.1857605 ]\n"," [-0.17828369]\n"," [-0.20639038]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01202393  0.05462646  0.09268188 ... -0.1857605  -0.17828369\n"," -0.20639038], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00128174]\n"," [-0.00610352]\n"," [-0.01159668]\n"," ...\n"," [-0.08752441]\n"," [-0.08059692]\n"," [-0.0927124 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00128174 -0.00610352 -0.01159668 ... -0.08752441 -0.08059692\n"," -0.0927124 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00073242]\n"," [0.00311279]\n"," [0.00442505]\n"," ...\n"," [0.12133789]\n"," [0.12588501]\n"," [0.15179443]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00073242 0.00311279 0.00442505 ... 0.12133789 0.12588501 0.15179443], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00296021]\n"," [-0.01248169]\n"," [-0.02178955]\n"," ...\n"," [-0.12826538]\n"," [-0.12380981]\n"," [-0.14077759]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00296021 -0.01248169 -0.02178955 ... -0.12826538 -0.12380981\n"," -0.14077759], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0007019 ]\n"," [ 0.00292969]\n"," [ 0.00439453]\n"," ...\n"," [-0.06900024]\n"," [-0.06436157]\n"," [-0.06817627]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0007019   0.00292969  0.00439453 ... -0.06900024 -0.06436157\n"," -0.06817627], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00222778]\n"," [-0.00827026]\n"," [-0.01199341]\n"," ...\n"," [-0.2692566 ]\n"," [-0.24481201]\n"," [-0.25183105]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00222778 -0.00827026 -0.01199341 ... -0.2692566  -0.24481201\n"," -0.25183105], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0007019 ]\n"," [0.0017395 ]\n"," [0.00039673]\n"," ...\n"," [0.1161499 ]\n"," [0.10668945]\n"," [0.1177063 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0007019  0.0017395  0.00039673 ... 0.1161499  0.10668945 0.1177063 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0005188 ]\n"," [-0.02279663]\n"," [-0.03805542]\n"," ...\n"," [ 0.01553345]\n"," [ 0.01452637]\n"," [ 0.01754761]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0005188  -0.02279663 -0.03805542 ...  0.01553345  0.01452637\n","  0.01754761], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00030518]\n"," [-0.00167847]\n"," [-0.00234985]\n"," ...\n"," [-0.0710144 ]\n"," [-0.07104492]\n"," [-0.08718872]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00030518 -0.00167847 -0.00234985 ... -0.0710144  -0.07104492\n"," -0.08718872], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00064087]\n"," [0.00241089]\n"," [0.00283813]\n"," ...\n"," [0.1204834 ]\n"," [0.10968018]\n"," [0.11465454]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00064087 0.00241089 0.00283813 ... 0.1204834  0.10968018 0.11465454], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[9.1552734e-05]\n"," [7.9345703e-04]\n"," [1.9531250e-03]\n"," ...\n"," [1.9662476e-01]\n"," [1.6516113e-01]\n"," [1.6079712e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[9.1552734e-05 7.9345703e-04 1.9531250e-03 ... 1.9662476e-01 1.6516113e-01\n"," 1.6079712e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01333618]\n"," [-0.06115723]\n"," [-0.10708618]\n"," ...\n"," [-0.51330566]\n"," [-0.500885  ]\n"," [-0.57958984]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01333618 -0.06115723 -0.10708618 ... -0.51330566 -0.500885\n"," -0.57958984], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00106812]\n"," [-0.0050354 ]\n"," [-0.00897217]\n"," ...\n"," [-0.3005066 ]\n"," [-0.28701782]\n"," [-0.31973267]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00106812 -0.0050354  -0.00897217 ... -0.3005066  -0.28701782\n"," -0.31973267], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-2.4414062e-04]\n"," [-1.3427734e-03]\n"," [-2.3498535e-03]\n"," ...\n"," [ 2.7465820e-03]\n"," [-9.1552734e-05]\n"," [-3.1433105e-03]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-2.4414062e-04 -1.3427734e-03 -2.3498535e-03 ...  2.7465820e-03\n"," -9.1552734e-05 -3.1433105e-03], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0012207 ]\n"," [ 0.00518799]\n"," [ 0.0088501 ]\n"," ...\n"," [-0.04174805]\n"," [-0.04031372]\n"," [-0.04559326]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0012207   0.00518799  0.0088501  ... -0.04174805 -0.04031372\n"," -0.04559326], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0067749 ]\n"," [-0.00314331]\n"," [-0.10684204]\n"," ...\n"," [-0.37356567]\n"," [-0.3555603 ]\n"," [-0.3914795 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0067749  -0.00314331 -0.10684204 ... -0.37356567 -0.3555603\n"," -0.3914795 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00268555]\n"," [ 0.01055908]\n"," [ 0.01916504]\n"," ...\n"," [-0.41970825]\n"," [-0.39813232]\n"," [-0.44076538]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00268555  0.01055908  0.01916504 ... -0.41970825 -0.39813232\n"," -0.44076538], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00015259]\n"," [-0.00064087]\n"," [-0.00134277]\n"," ...\n"," [-0.03845215]\n"," [-0.02246094]\n"," [-0.0189209 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00015259 -0.00064087 -0.00134277 ... -0.03845215 -0.02246094\n"," -0.0189209 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00256348]\n"," [-0.01095581]\n"," [-0.01766968]\n"," ...\n"," [ 0.24679565]\n"," [ 0.24102783]\n"," [ 0.26904297]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00256348 -0.01095581 -0.01766968 ...  0.24679565  0.24102783\n","  0.26904297], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0045166 ]\n"," [ 0.01763916]\n"," [ 0.02053833]\n"," ...\n"," [-0.03814697]\n"," [-0.0322876 ]\n"," [-0.0274353 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0045166   0.01763916  0.02053833 ... -0.03814697 -0.0322876\n"," -0.0274353 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00094604]\n"," [-0.00424194]\n"," [-0.00726318]\n"," ...\n"," [-0.07897949]\n"," [-0.06869507]\n"," [-0.07247925]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00094604 -0.00424194 -0.00726318 ... -0.07897949 -0.06869507\n"," -0.07247925], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00161743]\n"," [0.00778198]\n"," [0.01434326]\n"," ...\n"," [0.04595947]\n"," [0.04174805]\n"," [0.04104614]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00161743 0.00778198 0.01434326 ... 0.04595947 0.04174805 0.04104614], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00048828]\n"," [0.00100708]\n"," ...\n"," [0.06222534]\n"," [0.06170654]\n"," [0.07189941]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00048828 0.00100708 ... 0.06222534 0.06170654 0.07189941], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00021362]\n"," [ 0.00109863]\n"," [ 0.00183105]\n"," ...\n"," [-0.06958008]\n"," [-0.06097412]\n"," [-0.0607605 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00021362  0.00109863  0.00183105 ... -0.06958008 -0.06097412\n"," -0.0607605 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00030518]\n"," [-0.00286865]\n"," [-0.01119995]\n"," ...\n"," [-0.06491089]\n"," [-0.0557251 ]\n"," [-0.05847168]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00030518 -0.00286865 -0.01119995 ... -0.06491089 -0.0557251\n"," -0.05847168], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0039978 ]\n"," [-0.02044678]\n"," [-0.03890991]\n"," ...\n"," [ 0.9631653 ]\n"," [ 0.86938477]\n"," [ 0.9999695 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0039978  -0.02044678 -0.03890991 ...  0.9631653   0.86938477\n","  0.9999695 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00094604]\n"," [-0.0050354 ]\n"," [-0.01037598]\n"," ...\n"," [-0.137146  ]\n"," [-0.13250732]\n"," [-0.14971924]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00094604 -0.0050354  -0.01037598 ... -0.137146   -0.13250732\n"," -0.14971924], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00082397]\n"," [ 0.00570679]\n"," [ 0.01123047]\n"," ...\n"," [-0.0949707 ]\n"," [-0.08636475]\n"," [-0.08917236]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00082397  0.00570679  0.01123047 ... -0.0949707  -0.08636475\n"," -0.08917236], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00186157]\n"," [ 0.00845337]\n"," [ 0.01422119]\n"," ...\n"," [-0.05023193]\n"," [-0.0458374 ]\n"," [-0.04788208]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00186157  0.00845337  0.01422119 ... -0.05023193 -0.0458374\n"," -0.04788208], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00149536]\n"," [-0.00811768]\n"," [-0.01620483]\n"," ...\n"," [-0.11175537]\n"," [-0.1104126 ]\n"," [-0.1244812 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00149536 -0.00811768 -0.01620483 ... -0.11175537 -0.1104126\n"," -0.1244812 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00076294]\n"," [ 0.00350952]\n"," [ 0.00592041]\n"," ...\n"," [-0.01797485]\n"," [-0.01806641]\n"," [-0.02120972]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00076294  0.00350952  0.00592041 ... -0.01797485 -0.01806641\n"," -0.02120972], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00460815]\n"," [-0.02166748]\n"," [-0.03747559]\n"," ...\n"," [-0.19232178]\n"," [-0.1736145 ]\n"," [-0.17855835]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00460815 -0.02166748 -0.03747559 ... -0.19232178 -0.1736145\n"," -0.17855835], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0055542 ]\n"," [-0.02603149]\n"," [-0.04797363]\n"," ...\n"," [-0.6040344 ]\n"," [-0.56570435]\n"," [-0.61428833]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0055542  -0.02603149 -0.04797363 ... -0.6040344  -0.56570435\n"," -0.61428833], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 2.1362305e-04]\n"," [ 9.7656250e-04]\n"," [ 1.7700195e-03]\n"," ...\n"," [-2.5354004e-01]\n"," [-2.3669434e-01]\n"," [-2.6324463e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 2.1362305e-04  9.7656250e-04  1.7700195e-03 ... -2.5354004e-01\n"," -2.3669434e-01 -2.6324463e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00064087]\n"," [-0.0050354 ]\n"," [-0.01208496]\n"," ...\n"," [-0.2033081 ]\n"," [-0.20812988]\n"," [-0.24987793]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00064087 -0.0050354  -0.01208496 ... -0.2033081  -0.20812988\n"," -0.24987793], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.003479  ]\n"," [ 0.01174927]\n"," [ 0.02224731]\n"," ...\n"," [-0.5271301 ]\n"," [-0.49771118]\n"," [-0.5482483 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.003479    0.01174927  0.02224731 ... -0.5271301  -0.49771118\n"," -0.5482483 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00112915]\n"," [-0.00863647]\n"," [-0.01361084]\n"," ...\n"," [-0.12030029]\n"," [-0.1402893 ]\n"," [-0.10168457]], shape=(15699, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00112915 -0.00863647 -0.01361084 ... -0.12030029 -0.1402893\n"," -0.10168457], shape=(15699,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00085449]\n"," [ 0.00674438]\n"," [ 0.01116943]\n"," ...\n"," [-0.32199097]\n"," [-0.30734253]\n"," [-0.34036255]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00085449  0.00674438  0.01116943 ... -0.32199097 -0.30734253\n"," -0.34036255], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00119019]\n"," [-0.00494385]\n"," [-0.00830078]\n"," ...\n"," [ 0.39056396]\n"," [ 0.44714355]\n"," [ 0.5956726 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00119019 -0.00494385 -0.00830078 ...  0.39056396  0.44714355\n","  0.5956726 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0015564 ]\n"," [-0.00616455]\n"," [-0.01257324]\n"," ...\n"," [-0.08273315]\n"," [-0.07437134]\n"," [-0.07696533]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0015564  -0.00616455 -0.01257324 ... -0.08273315 -0.07437134\n"," -0.07696533], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00445557]\n"," [-0.02084351]\n"," [-0.03549194]\n"," ...\n"," [-0.26654053]\n"," [-0.25042725]\n"," [-0.27703857]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00445557 -0.02084351 -0.03549194 ... -0.26654053 -0.25042725\n"," -0.27703857], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00488281]\n"," [-0.02191162]\n"," [-0.03555298]\n"," ...\n"," [ 0.10696411]\n"," [ 0.10455322]\n"," [ 0.12765503]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00488281 -0.02191162 -0.03555298 ...  0.10696411  0.10455322\n","  0.12765503], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00076294]\n"," [-0.00354004]\n"," [-0.00643921]\n"," ...\n"," [ 0.00424194]\n"," [-0.00210571]\n"," [-0.00497437]], shape=(15519, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00076294 -0.00354004 -0.00643921 ...  0.00424194 -0.00210571\n"," -0.00497437], shape=(15519,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01882935]\n"," [-0.09518433]\n"," [-0.15359497]\n"," ...\n"," [-0.41537476]\n"," [-0.3932495 ]\n"," [-0.43045044]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01882935 -0.09518433 -0.15359497 ... -0.41537476 -0.3932495\n"," -0.43045044], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01168823]\n"," [-0.04742432]\n"," [-0.06082153]\n"," ...\n"," [ 0.20748901]\n"," [ 0.19433594]\n"," [ 0.21426392]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01168823 -0.04742432 -0.06082153 ...  0.20748901  0.19433594\n","  0.21426392], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0010376 ]\n"," [ 0.00314331]\n"," [ 0.0055542 ]\n"," ...\n"," [-0.11477661]\n"," [-0.10653687]\n"," [-0.11499023]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0010376   0.00314331  0.0055542  ... -0.11477661 -0.10653687\n"," -0.11499023], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00109863]\n"," [-0.00509644]\n"," [-0.0085144 ]\n"," ...\n"," [-0.09762573]\n"," [-0.10635376]\n"," [-0.14404297]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00109863 -0.00509644 -0.0085144  ... -0.09762573 -0.10635376\n"," -0.14404297], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.0517578e-05]\n"," [ 1.5563965e-03]\n"," [ 3.8452148e-03]\n"," ...\n"," [-2.9394531e-01]\n"," [-2.9635620e-01]\n"," [-3.4576416e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.0517578e-05  1.5563965e-03  3.8452148e-03 ... -2.9394531e-01\n"," -2.9635620e-01 -3.4576416e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0020752 ]\n"," [-0.00750732]\n"," [-0.01324463]\n"," ...\n"," [ 0.10418701]\n"," [ 0.09451294]\n"," [ 0.09683228]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0020752  -0.00750732 -0.01324463 ...  0.10418701  0.09451294\n","  0.09683228], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 1.5258789e-04]\n"," [ 8.2397461e-04]\n"," [ 0.0000000e+00]\n"," ...\n"," [-2.4377441e-01]\n"," [-2.2970581e-01]\n"," [-2.5354004e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 1.5258789e-04  8.2397461e-04  0.0000000e+00 ... -2.4377441e-01\n"," -2.2970581e-01 -2.5354004e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00054932]\n"," [ 0.0017395 ]\n"," [ 0.00115967]\n"," ...\n"," [-0.05703735]\n"," [-0.03497314]\n"," [-0.02880859]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00054932  0.0017395   0.00115967 ... -0.05703735 -0.03497314\n"," -0.02880859], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00140381]\n"," [-0.00680542]\n"," [-0.01187134]\n"," ...\n"," [-0.09298706]\n"," [-0.08724976]\n"," [-0.09503174]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00140381 -0.00680542 -0.01187134 ... -0.09298706 -0.08724976\n"," -0.09503174], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00286865]\n"," [0.00698853]\n"," [0.01013184]\n"," ...\n"," [0.02539062]\n"," [0.02093506]\n"," [0.01702881]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00286865 0.00698853 0.01013184 ... 0.02539062 0.02093506 0.01702881], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00057983]\n"," [-0.00338745]\n"," [-0.00662231]\n"," ...\n"," [ 0.0703125 ]\n"," [ 0.06344604]\n"," [ 0.06253052]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00057983 -0.00338745 -0.00662231 ...  0.0703125   0.06344604\n","  0.06253052], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0032959 ]\n"," [0.01486206]\n"," [0.02664185]\n"," ...\n"," [0.01199341]\n"," [0.01382446]\n"," [0.02310181]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0032959  0.01486206 0.02664185 ... 0.01199341 0.01382446 0.02310181], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01275635]\n"," [-0.05657959]\n"," [-0.09500122]\n"," ...\n"," [-0.04858398]\n"," [-0.05303955]\n"," [-0.07940674]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01275635 -0.05657959 -0.09500122 ... -0.04858398 -0.05303955\n"," -0.07940674], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00045776]\n"," [ 0.00796509]\n"," [ 0.00775146]\n"," ...\n"," [-0.00839233]\n"," [-0.01312256]\n"," [-0.02362061]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00045776  0.00796509  0.00775146 ... -0.00839233 -0.01312256\n"," -0.02362061], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00024414]\n"," [-0.00152588]\n"," [-0.00283813]\n"," ...\n"," [ 0.02954102]\n"," [ 0.02706909]\n"," [ 0.02774048]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00024414 -0.00152588 -0.00283813 ...  0.02954102  0.02706909\n","  0.02774048], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00036621]\n"," [-0.00094604]\n"," [ 0.00024414]\n"," ...\n"," [-0.02664185]\n"," [-0.02618408]\n"," [-0.03469849]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00036621 -0.00094604  0.00024414 ... -0.02664185 -0.02618408\n"," -0.03469849], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-9.1552734e-05]\n"," [ 1.5869141e-03]\n"," [ 9.8571777e-03]\n"," ...\n"," [-1.1831665e-01]\n"," [-1.1413574e-01]\n"," [-1.2854004e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-9.1552734e-05  1.5869141e-03  9.8571777e-03 ... -1.1831665e-01\n"," -1.1413574e-01 -1.2854004e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00042725]\n"," [-0.00167847]\n"," [-0.00296021]\n"," ...\n"," [ 0.33468628]\n"," [ 0.31835938]\n"," [ 0.35098267]], shape=(14729, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00042725 -0.00167847 -0.00296021 ...  0.33468628  0.31835938\n","  0.35098267], shape=(14729,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00152588]\n"," [-0.00793457]\n"," [-0.01589966]\n"," ...\n"," [ 0.06173706]\n"," [ 0.0630188 ]\n"," [ 0.07751465]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00152588 -0.00793457 -0.01589966 ...  0.06173706  0.0630188\n","  0.07751465], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0050354 ]\n"," [ 0.01885986]\n"," [ 0.01647949]\n"," ...\n"," [-0.21231079]\n"," [-0.19656372]\n"," [-0.21276855]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0050354   0.01885986  0.01647949 ... -0.21231079 -0.19656372\n"," -0.21276855], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00283813]\n"," [-0.01428223]\n"," [-0.02752686]\n"," ...\n"," [-0.3083496 ]\n"," [-0.28601074]\n"," [-0.30264282]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00283813 -0.01428223 -0.02752686 ... -0.3083496  -0.28601074\n"," -0.30264282], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [-0.02859497]\n"," [-0.0567627 ]\n"," ...\n"," [-0.29840088]\n"," [-0.11132812]\n"," [-0.04830933]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561  -0.02859497 -0.0567627  ... -0.29840088 -0.11132812\n"," -0.04830933], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00177002]\n"," [-0.00723267]\n"," [-0.00939941]\n"," ...\n"," [-0.221344  ]\n"," [-0.21817017]\n"," [-0.2562256 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00177002 -0.00723267 -0.00939941 ... -0.221344   -0.21817017\n"," -0.2562256 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00234985]\n"," [-0.00979614]\n"," [-0.00970459]\n"," ...\n"," [ 0.4026184 ]\n"," [ 0.37799072]\n"," [ 0.38537598]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00234985 -0.00979614 -0.00970459 ...  0.4026184   0.37799072\n","  0.38537598], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00634766]\n"," [-0.03018188]\n"," [-0.05334473]\n"," ...\n"," [-0.36483765]\n"," [-0.36468506]\n"," [-0.4244995 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00634766 -0.03018188 -0.05334473 ... -0.36483765 -0.36468506\n"," -0.4244995 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00802612]\n"," [-0.02410889]\n"," [-0.03408813]\n"," ...\n"," [ 0.15478516]\n"," [ 0.14309692]\n"," [ 0.14993286]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00802612 -0.02410889 -0.03408813 ...  0.15478516  0.14309692\n","  0.14993286], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00180054]\n"," [-0.00802612]\n"," [-0.01324463]\n"," ...\n"," [ 0.03500366]\n"," [ 0.03781128]\n"," [ 0.04837036]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00180054 -0.00802612 -0.01324463 ...  0.03500366  0.03781128\n","  0.04837036], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00521851]\n"," [ 0.01635742]\n"," [ 0.01373291]\n"," ...\n"," [-0.17352295]\n"," [-0.15911865]\n"," [-0.17642212]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00521851  0.01635742  0.01373291 ... -0.17352295 -0.15911865\n"," -0.17642212], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 9.1552734e-05]\n"," [ 1.0070801e-03]\n"," [ 5.5236816e-03]\n"," ...\n"," [-1.7181396e-01]\n"," [-1.6098022e-01]\n"," [-1.7056274e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 9.1552734e-05  1.0070801e-03  5.5236816e-03 ... -1.7181396e-01\n"," -1.6098022e-01 -1.7056274e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0038147 ]\n"," [-0.01431274]\n"," [-0.0249939 ]\n"," ...\n"," [-0.01394653]\n"," [-0.01013184]\n"," [-0.00619507]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0038147  -0.01431274 -0.0249939  ... -0.01394653 -0.01013184\n"," -0.00619507], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00137329]\n"," [-0.00689697]\n"," [-0.01177979]\n"," ...\n"," [-0.3916626 ]\n"," [-0.37368774]\n"," [-0.40426636]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00137329 -0.00689697 -0.01177979 ... -0.3916626  -0.37368774\n"," -0.40426636], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00320435]\n"," [-0.01171875]\n"," [-0.01525879]\n"," ...\n"," [-0.25827026]\n"," [-0.22381592]\n"," [-0.18060303]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00320435 -0.01171875 -0.01525879 ... -0.25827026 -0.22381592\n"," -0.18060303], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00186157]\n"," [-0.00567627]\n"," [-0.00662231]\n"," ...\n"," [-0.07897949]\n"," [-0.09130859]\n"," [-0.13342285]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00186157 -0.00567627 -0.00662231 ... -0.07897949 -0.09130859\n"," -0.13342285], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00100708]\n"," [-0.00460815]\n"," [-0.00695801]\n"," ...\n"," [-0.07284546]\n"," [-0.06906128]\n"," [-0.0763855 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00100708 -0.00460815 -0.00695801 ... -0.07284546 -0.06906128\n"," -0.0763855 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00418091]\n"," [-0.02008057]\n"," [-0.03396606]\n"," ...\n"," [ 0.00558472]\n"," [ 0.01104736]\n"," [ 0.02322388]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00418091 -0.02008057 -0.03396606 ...  0.00558472  0.01104736\n","  0.02322388], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00057983]\n"," [-0.00305176]\n"," [-0.00482178]\n"," ...\n"," [ 0.05377197]\n"," [ 0.04293823]\n"," [ 0.03662109]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00057983 -0.00305176 -0.00482178 ...  0.05377197  0.04293823\n","  0.03662109], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00131226]\n"," [-0.00180054]\n"," [-0.01330566]\n"," ...\n"," [-0.14697266]\n"," [-0.14996338]\n"," [-0.12072754]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00131226 -0.00180054 -0.01330566 ... -0.14697266 -0.14996338\n"," -0.12072754], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00018311]\n"," [ 0.00033569]\n"," [ 0.00045776]\n"," ...\n"," [ 0.03848267]\n"," [ 0.03634644]\n"," [ 0.03848267]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00018311  0.00033569  0.00045776 ...  0.03848267  0.03634644\n","  0.03848267], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00680542]\n"," [-0.02999878]\n"," [-0.04595947]\n"," ...\n"," [-0.22720337]\n"," [-0.21386719]\n"," [-0.24047852]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00680542 -0.02999878 -0.04595947 ... -0.22720337 -0.21386719\n"," -0.24047852], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0010376 ]\n"," [ 0.003479  ]\n"," [ 0.00454712]\n"," ...\n"," [-0.08544922]\n"," [-0.10617065]\n"," [-0.15560913]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0010376   0.003479    0.00454712 ... -0.08544922 -0.10617065\n"," -0.15560913], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00021362]\n"," [-0.00085449]\n"," [-0.00149536]\n"," ...\n"," [-0.11761475]\n"," [-0.10189819]\n"," [-0.10070801]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00021362 -0.00085449 -0.00149536 ... -0.11761475 -0.10189819\n"," -0.10070801], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00131226]\n"," [ 0.00524902]\n"," [ 0.00900269]\n"," ...\n"," [-0.04733276]\n"," [-0.0302124 ]\n"," [-0.0423584 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00131226  0.00524902  0.00900269 ... -0.04733276 -0.0302124\n"," -0.0423584 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00021362]\n"," [ 0.00085449]\n"," [ 0.00125122]\n"," ...\n"," [-0.06008911]\n"," [-0.05786133]\n"," [-0.06472778]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00021362  0.00085449  0.00125122 ... -0.06008911 -0.05786133\n"," -0.06472778], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00024414]\n"," [ 0.00112915]\n"," [ 0.00198364]\n"," ...\n"," [-0.11975098]\n"," [-0.1050415 ]\n"," [-0.10189819]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00024414  0.00112915  0.00198364 ... -0.11975098 -0.1050415\n"," -0.10189819], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00079346]\n"," [ 0.0007019 ]\n"," [ 0.00369263]\n"," ...\n"," [-0.49569702]\n"," [-0.46899414]\n"," [-0.5166931 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00079346  0.0007019   0.00369263 ... -0.49569702 -0.46899414\n"," -0.5166931 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00085449]\n"," [ 0.00268555]\n"," [ 0.00344849]\n"," ...\n"," [-0.20941162]\n"," [-0.19985962]\n"," [-0.215271  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00085449  0.00268555  0.00344849 ... -0.20941162 -0.19985962\n"," -0.215271  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00054932]\n"," [ 0.00238037]\n"," [ 0.00338745]\n"," ...\n"," [-0.09725952]\n"," [-0.09637451]\n"," [-0.12271118]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00054932  0.00238037  0.00338745 ... -0.09725952 -0.09637451\n"," -0.12271118], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00024414]\n"," [ 0.00534058]\n"," [ 0.02157593]\n"," ...\n"," [-0.2225647 ]\n"," [-0.21569824]\n"," [-0.23965454]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00024414  0.00534058  0.02157593 ... -0.2225647  -0.21569824\n"," -0.23965454], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00033569]\n"," [-0.006073  ]\n"," [-0.01147461]\n"," ...\n"," [ 0.01629639]\n"," [ 0.01641846]\n"," [ 0.02035522]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00033569 -0.006073   -0.01147461 ...  0.01629639  0.01641846\n","  0.02035522], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00106812]\n"," [ 0.00479126]\n"," [ 0.00265503]\n"," ...\n"," [-0.25387573]\n"," [-0.24365234]\n"," [-0.27612305]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00106812  0.00479126  0.00265503 ... -0.25387573 -0.24365234\n"," -0.27612305], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00085449]\n"," [-0.00170898]\n"," [-0.00109863]\n"," ...\n"," [-0.09191895]\n"," [-0.08856201]\n"," [-0.09521484]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00085449 -0.00170898 -0.00109863 ... -0.09191895 -0.08856201\n"," -0.09521484], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00021362]\n"," [-0.00289917]\n"," [-0.00720215]\n"," ...\n"," [ 0.00030518]\n"," [-0.00030518]\n"," [-0.00402832]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00021362 -0.00289917 -0.00720215 ...  0.00030518 -0.00030518\n"," -0.00402832], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00338745]\n"," [-0.01394653]\n"," [-0.0229187 ]\n"," ...\n"," [-0.40740967]\n"," [-0.3946228 ]\n"," [-0.44979858]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00338745 -0.01394653 -0.0229187  ... -0.40740967 -0.3946228\n"," -0.44979858], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00018311]\n"," [ 0.00268555]\n"," [ 0.00857544]\n"," ...\n"," [-0.04260254]\n"," [-0.05328369]\n"," [-0.05490112]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00018311  0.00268555  0.00857544 ... -0.04260254 -0.05328369\n"," -0.05490112], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00335693]\n"," [-0.0071106 ]\n"," [-0.00738525]\n"," ...\n"," [-0.11721802]\n"," [-0.1081543 ]\n"," [-0.11669922]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00335693 -0.0071106  -0.00738525 ... -0.11721802 -0.1081543\n"," -0.11669922], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0012207 ]\n"," [-0.006073  ]\n"," [-0.01104736]\n"," ...\n"," [ 0.08209229]\n"," [ 0.0798645 ]\n"," [ 0.09289551]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0012207  -0.006073   -0.01104736 ...  0.08209229  0.0798645\n","  0.09289551], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00021362]\n"," [-0.00112915]\n"," ...\n"," [-0.1343689 ]\n"," [-0.08230591]\n"," [-0.00045776]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00021362 -0.00112915 ... -0.1343689  -0.08230591\n"," -0.00045776], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0007019 ]\n"," [-0.00656128]\n"," [-0.01287842]\n"," ...\n"," [-0.18664551]\n"," [-0.17837524]\n"," [-0.20291138]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0007019  -0.00656128 -0.01287842 ... -0.18664551 -0.17837524\n"," -0.20291138], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00228882]\n"," [-0.01043701]\n"," [-0.01806641]\n"," ...\n"," [ 0.5447998 ]\n"," [ 0.52993774]\n"," [ 0.60284424]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00228882 -0.01043701 -0.01806641 ...  0.5447998   0.52993774\n","  0.60284424], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00097656]\n"," [-0.00543213]\n"," [-0.01083374]\n"," ...\n"," [-0.18914795]\n"," [-0.1789856 ]\n"," [-0.19396973]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00097656 -0.00543213 -0.01083374 ... -0.18914795 -0.1789856\n"," -0.19396973], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-9.1552734e-05]\n"," [-4.2724609e-04]\n"," [-8.5449219e-04]\n"," ...\n"," [-5.1574707e-03]\n"," [-6.4392090e-03]\n"," [-8.0871582e-03]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-9.1552734e-05 -4.2724609e-04 -8.5449219e-04 ... -5.1574707e-03\n"," -6.4392090e-03 -8.0871582e-03], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00262451]\n"," [-0.0118103 ]\n"," [-0.01828003]\n"," ...\n"," [-0.11688232]\n"," [-0.10293579]\n"," [-0.08807373]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00262451 -0.0118103  -0.01828003 ... -0.11688232 -0.10293579\n"," -0.08807373], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00128174]\n"," [-0.00848389]\n"," [-0.01303101]\n"," ...\n"," [-0.15014648]\n"," [-0.14105225]\n"," [-0.15560913]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00128174 -0.00848389 -0.01303101 ... -0.15014648 -0.14105225\n"," -0.15560913], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0005188 ]\n"," [ 0.00366211]\n"," [ 0.00787354]\n"," ...\n"," [-0.105896  ]\n"," [-0.09860229]\n"," [-0.10629272]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0005188   0.00366211  0.00787354 ... -0.105896   -0.09860229\n"," -0.10629272], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0144043 ]\n"," [-0.06460571]\n"," [-0.10626221]\n"," ...\n"," [-0.15655518]\n"," [-0.14416504]\n"," [-0.16195679]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0144043  -0.06460571 -0.10626221 ... -0.15655518 -0.14416504\n"," -0.16195679], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00112915]\n"," [-0.00527954]\n"," [-0.00775146]\n"," ...\n"," [-0.31671143]\n"," [-0.28475952]\n"," [-0.29388428]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00112915 -0.00527954 -0.00775146 ... -0.31671143 -0.28475952\n"," -0.29388428], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00527954]\n"," [-0.02383423]\n"," [-0.03833008]\n"," ...\n"," [-0.2824707 ]\n"," [-0.26309204]\n"," [-0.2849121 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00527954 -0.02383423 -0.03833008 ... -0.2824707  -0.26309204\n"," -0.2849121 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.0517578e-05]\n"," [-3.0517578e-04]\n"," [-1.8310547e-04]\n"," ...\n"," [-2.1417236e-01]\n"," [-2.0571899e-01]\n"," [-2.3245239e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.0517578e-05 -3.0517578e-04 -1.8310547e-04 ... -2.1417236e-01\n"," -2.0571899e-01 -2.3245239e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00039673]\n"," [-0.00140381]\n"," [-0.00097656]\n"," ...\n"," [ 0.14715576]\n"," [ 0.14093018]\n"," [ 0.15707397]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00039673 -0.00140381 -0.00097656 ...  0.14715576  0.14093018\n","  0.15707397], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00115967]\n"," [ 0.00518799]\n"," [ 0.0078125 ]\n"," ...\n"," [-0.08084106]\n"," [-0.07330322]\n"," [-0.07769775]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00115967  0.00518799  0.0078125  ... -0.08084106 -0.07330322\n"," -0.07769775], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03918457]\n"," [-0.19836426]\n"," [-0.2388916 ]\n"," ...\n"," [-0.32867432]\n"," [-0.31607056]\n"," [-0.35498047]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03918457 -0.19836426 -0.2388916  ... -0.32867432 -0.31607056\n"," -0.35498047], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01159668]\n"," [-0.05352783]\n"," [-0.09255981]\n"," ...\n"," [ 0.03948975]\n"," [ 0.03952026]\n"," [ 0.04586792]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01159668 -0.05352783 -0.09255981 ...  0.03948975  0.03952026\n","  0.04586792], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00662231]\n"," [-0.03179932]\n"," [-0.0559082 ]\n"," ...\n"," [-0.18536377]\n"," [-0.18182373]\n"," [-0.20928955]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00662231 -0.03179932 -0.0559082  ... -0.18536377 -0.18182373\n"," -0.20928955], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0072937 ]\n"," [-0.03274536]\n"," [-0.05487061]\n"," ...\n"," [-0.4578247 ]\n"," [-0.42877197]\n"," [-0.47698975]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0072937  -0.03274536 -0.05487061 ... -0.4578247  -0.42877197\n"," -0.47698975], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00808716]\n"," [ 0.03671265]\n"," [ 0.06478882]\n"," ...\n"," [-0.2628479 ]\n"," [-0.2519226 ]\n"," [-0.28405762]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00808716  0.03671265  0.06478882 ... -0.2628479  -0.2519226\n"," -0.28405762], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00463867]\n"," [ 0.01956177]\n"," [ 0.03265381]\n"," ...\n"," [-0.27236938]\n"," [-0.26342773]\n"," [-0.29745483]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00463867  0.01956177  0.03265381 ... -0.27236938 -0.26342773\n"," -0.29745483], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.0517578e-05]\n"," [-1.8310547e-04]\n"," [-2.1362305e-04]\n"," ...\n"," [-2.9602051e-02]\n"," [-2.8015137e-02]\n"," [-3.1005859e-02]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.0517578e-05 -1.8310547e-04 -2.1362305e-04 ... -2.9602051e-02\n"," -2.8015137e-02 -3.1005859e-02], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00115967]\n"," [-0.00494385]\n"," [-0.00787354]\n"," ...\n"," [-0.06195068]\n"," [-0.05502319]\n"," [-0.06814575]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00115967 -0.00494385 -0.00787354 ... -0.06195068 -0.05502319\n"," -0.06814575], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00164795]\n"," [-0.00863647]\n"," [-0.01531982]\n"," ...\n"," [-0.21585083]\n"," [-0.20233154]\n"," [-0.22293091]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00164795 -0.00863647 -0.01531982 ... -0.21585083 -0.20233154\n"," -0.22293091], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00036621]\n"," [ 0.01028442]\n"," [ 0.04425049]\n"," ...\n"," [-0.00799561]\n"," [-0.00540161]\n"," [ 0.00021362]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00036621  0.01028442  0.04425049 ... -0.00799561 -0.00540161\n","  0.00021362], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00042725]\n"," [ 0.00119019]\n"," [ 0.00042725]\n"," ...\n"," [-0.35681152]\n"," [-0.34805298]\n"," [-0.3977661 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00042725  0.00119019  0.00042725 ... -0.35681152 -0.34805298\n"," -0.3977661 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.2207031e-04]\n"," [-3.3569336e-04]\n"," [ 6.1035156e-05]\n"," ...\n"," [-5.2246094e-02]\n"," [-3.1372070e-02]\n"," [-3.8879395e-02]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.2207031e-04 -3.3569336e-04  6.1035156e-05 ... -5.2246094e-02\n"," -3.1372070e-02 -3.8879395e-02], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00100708]\n"," [0.00546265]\n"," [0.00958252]\n"," ...\n"," [0.14678955]\n"," [0.13632202]\n"," [0.14520264]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00100708 0.00546265 0.00958252 ... 0.14678955 0.13632202 0.14520264], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00302124]\n"," [-0.01403809]\n"," [-0.02456665]\n"," ...\n"," [-0.00808716]\n"," [-0.01095581]\n"," [-0.01617432]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00302124 -0.01403809 -0.02456665 ... -0.00808716 -0.01095581\n"," -0.01617432], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00018311]\n"," [-0.00018311]\n"," [ 0.00338745]\n"," ...\n"," [ 0.03643799]\n"," [ 0.0368042 ]\n"," [ 0.04086304]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00018311 -0.00018311  0.00338745 ...  0.03643799  0.0368042\n","  0.04086304], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00387573]\n"," [-0.01901245]\n"," [-0.03125   ]\n"," ...\n"," [-0.22695923]\n"," [-0.37182617]\n"," [-0.49908447]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00387573 -0.01901245 -0.03125    ... -0.22695923 -0.37182617\n"," -0.49908447], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01113892]\n"," [-0.0553894 ]\n"," [-0.0980835 ]\n"," ...\n"," [-0.28607178]\n"," [-0.27993774]\n"," [-0.31079102]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01113892 -0.0553894  -0.0980835  ... -0.28607178 -0.27993774\n"," -0.31079102], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00033569]\n"," [-0.00170898]\n"," [-0.00350952]\n"," ...\n"," [-0.10021973]\n"," [-0.09503174]\n"," [-0.10620117]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00033569 -0.00170898 -0.00350952 ... -0.10021973 -0.09503174\n"," -0.10620117], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00509644]\n"," [-0.02539062]\n"," [-0.04190063]\n"," ...\n"," [-0.60769653]\n"," [-0.5915222 ]\n"," [-0.67510986]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00509644 -0.02539062 -0.04190063 ... -0.60769653 -0.5915222\n"," -0.67510986], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.01690674]\n"," [-0.02841187]\n"," ...\n"," [ 0.64294434]\n"," [ 0.6195679 ]\n"," [ 0.7016907 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.01690674 -0.02841187 ...  0.64294434  0.6195679\n","  0.7016907 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0010376 ]\n"," [0.00537109]\n"," [0.0045166 ]\n"," ...\n"," [0.00546265]\n"," [0.00512695]\n"," [0.0055542 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0010376  0.00537109 0.0045166  ... 0.00546265 0.00512695 0.0055542 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00497437]\n"," [ 0.02383423]\n"," [ 0.04199219]\n"," ...\n"," [-0.11694336]\n"," [-0.10754395]\n"," [-0.04058838]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00497437  0.02383423  0.04199219 ... -0.11694336 -0.10754395\n"," -0.04058838], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00921631]\n"," [-0.0128479 ]\n"," ...\n"," [ 0.21185303]\n"," [ 0.21270752]\n"," [ 0.256073  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00921631 -0.0128479  ...  0.21185303  0.21270752\n","  0.256073  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00457764]\n"," [-0.02252197]\n"," [-0.04107666]\n"," ...\n"," [-0.15396118]\n"," [-0.14416504]\n"," [-0.17272949]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00457764 -0.02252197 -0.04107666 ... -0.15396118 -0.14416504\n"," -0.17272949], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00018311]\n"," [-0.00079346]\n"," [-0.00143433]\n"," ...\n"," [ 0.01333618]\n"," [ 0.00701904]\n"," [ 0.00271606]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00018311 -0.00079346 -0.00143433 ...  0.01333618  0.00701904\n","  0.00271606], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00274658]\n"," [ 0.01126099]\n"," [ 0.01831055]\n"," ...\n"," [-0.02801514]\n"," [-0.00106812]\n"," [ 0.02874756]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00274658  0.01126099  0.01831055 ... -0.02801514 -0.00106812\n","  0.02874756], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00256348]\n"," [0.01031494]\n"," [0.01708984]\n"," ...\n"," [0.2033081 ]\n"," [0.18478394]\n"," [0.19195557]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00256348 0.01031494 0.01708984 ... 0.2033081  0.18478394 0.19195557], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00064087]\n"," [-0.00299072]\n"," [-0.00512695]\n"," ...\n"," [-0.36367798]\n"," [-0.33563232]\n"," [-0.35546875]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00064087 -0.00299072 -0.00512695 ... -0.36367798 -0.33563232\n"," -0.35546875], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0017395 ]\n"," [-0.00860596]\n"," [-0.01547241]\n"," ...\n"," [-0.02059937]\n"," [-0.01800537]\n"," [-0.01950073]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0017395  -0.00860596 -0.01547241 ... -0.02059937 -0.01800537\n"," -0.01950073], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00158691]\n"," [-0.00985718]\n"," [-0.02044678]\n"," ...\n"," [ 0.2609558 ]\n"," [ 0.2397461 ]\n"," [ 0.25390625]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00158691 -0.00985718 -0.02044678 ...  0.2609558   0.2397461\n","  0.25390625], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0012207 ]\n"," [-0.00564575]\n"," [-0.00997925]\n"," ...\n"," [-0.01266479]\n"," [-0.01638794]\n"," [-0.02355957]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0012207  -0.00564575 -0.00997925 ... -0.01266479 -0.01638794\n"," -0.02355957], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00585938]\n"," [-0.0274353 ]\n"," [-0.05084229]\n"," ...\n"," [-0.0642395 ]\n"," [-0.06231689]\n"," [-0.07049561]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00585938 -0.0274353  -0.05084229 ... -0.0642395  -0.06231689\n"," -0.07049561], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00085449]\n"," [-0.00170898]\n"," [-0.0032959 ]\n"," ...\n"," [-0.48345947]\n"," [-0.39508057]\n"," [-0.41244507]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00085449 -0.00170898 -0.0032959  ... -0.48345947 -0.39508057\n"," -0.41244507], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00140381]\n"," [-0.00582886]\n"," [-0.01043701]\n"," ...\n"," [ 0.27261353]\n"," [ 0.25775146]\n"," [ 0.28445435]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00140381 -0.00582886 -0.01043701 ...  0.27261353  0.25775146\n","  0.28445435], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0007019 ]\n"," [-0.00271606]\n"," [-0.00442505]\n"," ...\n"," [ 0.06872559]\n"," [ 0.06472778]\n"," [ 0.07058716]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0007019  -0.00271606 -0.00442505 ...  0.06872559  0.06472778\n","  0.07058716], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00653076]\n"," [-0.03405762]\n"," [-0.06069946]\n"," ...\n"," [-0.12606812]\n"," [-0.12426758]\n"," [-0.13323975]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00653076 -0.03405762 -0.06069946 ... -0.12606812 -0.12426758\n"," -0.13323975], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00244141]\n"," [-0.01318359]\n"," [-0.02624512]\n"," ...\n"," [-0.1543274 ]\n"," [-0.14511108]\n"," [-0.15805054]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00244141 -0.01318359 -0.02624512 ... -0.1543274  -0.14511108\n"," -0.15805054], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00274658]\n"," [-0.02459717]\n"," [-0.0536499 ]\n"," ...\n"," [-0.40618896]\n"," [-0.38256836]\n"," [-0.4081726 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00274658 -0.02459717 -0.0536499  ... -0.40618896 -0.38256836\n"," -0.4081726 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0010376 ]\n"," [0.00439453]\n"," [0.00762939]\n"," ...\n"," [0.07659912]\n"," [0.07022095]\n"," [0.07904053]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0010376  0.00439453 0.00762939 ... 0.07659912 0.07022095 0.07904053], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00167847]\n"," [-0.00848389]\n"," [-0.01513672]\n"," ...\n"," [ 0.05822754]\n"," [ 0.05725098]\n"," [ 0.06707764]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00167847 -0.00848389 -0.01513672 ...  0.05822754  0.05725098\n","  0.06707764], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00088501]\n"," [ 0.00402832]\n"," [ 0.0050354 ]\n"," ...\n"," [-0.4388733 ]\n"," [-0.40270996]\n"," [-0.421875  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00088501  0.00402832  0.0050354  ... -0.4388733  -0.40270996\n"," -0.421875  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 5.4931641e-04]\n"," [-1.2207031e-04]\n"," [-2.3193359e-03]\n"," ...\n"," [-1.7721558e-01]\n"," [-2.0120239e-01]\n"," [-2.2640991e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 5.4931641e-04 -1.2207031e-04 -2.3193359e-03 ... -1.7721558e-01\n"," -2.0120239e-01 -2.2640991e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01394653]\n"," [ 0.0949707 ]\n"," [ 0.09976196]\n"," ...\n"," [-0.4005432 ]\n"," [-0.41516113]\n"," [-0.2732849 ]], shape=(14899, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01394653  0.0949707   0.09976196 ... -0.4005432  -0.41516113\n"," -0.2732849 ], shape=(14899,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-2.1362305e-04]\n"," [-1.4038086e-03]\n"," [-2.6550293e-03]\n"," ...\n"," [-3.5876465e-01]\n"," [-3.2876587e-01]\n"," [-3.4869385e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-2.1362305e-04 -1.4038086e-03 -2.6550293e-03 ... -3.5876465e-01\n"," -3.2876587e-01 -3.4869385e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00015259]\n"," [-0.00036621]\n"," [-0.0012207 ]\n"," ...\n"," [-0.0340271 ]\n"," [-0.03579712]\n"," [-0.03369141]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00015259 -0.00036621 -0.0012207  ... -0.0340271  -0.03579712\n"," -0.03369141], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-9.1552734e-05]\n"," [ 1.7089844e-03]\n"," [-9.9182129e-03]\n"," ...\n"," [-6.1557007e-01]\n"," [-5.6054688e-01]\n"," [-5.7757568e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-9.1552734e-05  1.7089844e-03 -9.9182129e-03 ... -6.1557007e-01\n"," -5.6054688e-01 -5.7757568e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00186157]\n"," [ 0.00769043]\n"," [ 0.01037598]\n"," ...\n"," [-0.05905151]\n"," [-0.05847168]\n"," [-0.07049561]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00186157  0.00769043  0.01037598 ... -0.05905151 -0.05847168\n"," -0.07049561], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00402832]\n"," [-0.0166626 ]\n"," [-0.03189087]\n"," ...\n"," [-0.26324463]\n"," [-0.23825073]\n"," [-0.24908447]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00402832 -0.0166626  -0.03189087 ... -0.26324463 -0.23825073\n"," -0.24908447], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00210571]\n"," [-0.01083374]\n"," [-0.02163696]\n"," ...\n"," [-0.77801514]\n"," [-0.70077515]\n"," [-0.7976074 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00210571 -0.01083374 -0.02163696 ... -0.77801514 -0.70077515\n"," -0.7976074 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0017395 ]\n"," [-0.00790405]\n"," [-0.01098633]\n"," ...\n"," [ 0.0430603 ]\n"," [ 0.05957031]\n"," [ 0.07275391]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0017395  -0.00790405 -0.01098633 ...  0.0430603   0.05957031\n","  0.07275391], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-6.10351562e-05]\n"," [ 4.69970703e-03]\n"," [ 1.07421875e-02]\n"," ...\n"," [-2.43988037e-01]\n"," [-2.45574951e-01]\n"," [-2.82958984e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-6.10351562e-05  4.69970703e-03  1.07421875e-02 ... -2.43988037e-01\n"," -2.45574951e-01 -2.82958984e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00790405]\n"," [ 0.03814697]\n"," [ 0.07028198]\n"," ...\n"," [-0.04882812]\n"," [-0.03869629]\n"," [-0.03302002]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00790405  0.03814697  0.07028198 ... -0.04882812 -0.03869629\n"," -0.03302002], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0007019 ]\n"," [-0.00302124]\n"," [-0.00326538]\n"," ...\n"," [-0.5035095 ]\n"," [-0.48461914]\n"," [-0.542511  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0007019  -0.00302124 -0.00326538 ... -0.5035095  -0.48461914\n"," -0.542511  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0017395 ]\n"," [-0.00805664]\n"," [-0.01385498]\n"," ...\n"," [-0.2290039 ]\n"," [-0.21728516]\n"," [-0.22271729]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0017395  -0.00805664 -0.01385498 ... -0.2290039  -0.21728516\n"," -0.22271729], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00088501]\n"," [ 0.00131226]\n"," [-0.00280762]\n"," ...\n"," [-0.0664978 ]\n"," [-0.06362915]\n"," [-0.07177734]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00088501  0.00131226 -0.00280762 ... -0.0664978  -0.06362915\n"," -0.07177734], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00445557]\n"," [ 0.00393677]\n"," [-0.0007019 ]\n"," ...\n"," [-0.12704468]\n"," [-0.11495972]\n"," [-0.12069702]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00445557  0.00393677 -0.0007019  ... -0.12704468 -0.11495972\n"," -0.12069702], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00531006]\n"," [ 0.00949097]\n"," [ 0.06942749]\n"," ...\n"," [-0.00778198]\n"," [-0.00698853]\n"," [-0.00396729]], shape=(15919, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00531006  0.00949097  0.06942749 ... -0.00778198 -0.00698853\n"," -0.00396729], shape=(15919,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.5258789e-04]\n"," [-6.1035156e-04]\n"," [-7.0190430e-04]\n"," ...\n"," [ 1.5539551e-01]\n"," [ 1.4285278e-01]\n"," [ 1.9671631e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.5258789e-04 -6.1035156e-04 -7.0190430e-04 ...  1.5539551e-01\n","  1.4285278e-01  1.9671631e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00933838]\n"," [-0.0255127 ]\n"," [-0.02642822]\n"," ...\n"," [-0.04150391]\n"," [-0.03762817]\n"," [-0.04031372]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00933838 -0.0255127  -0.02642822 ... -0.04150391 -0.03762817\n"," -0.04031372], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00457764]\n"," [-0.01623535]\n"," [-0.01422119]\n"," ...\n"," [-0.25942993]\n"," [-0.24246216]\n"," [-0.26211548]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00457764 -0.01623535 -0.01422119 ... -0.25942993 -0.24246216\n"," -0.26211548], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00231934]\n"," [ 0.01208496]\n"," [ 0.02005005]\n"," ...\n"," [-0.1043396 ]\n"," [-0.10479736]\n"," [-0.1242981 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00231934  0.01208496  0.02005005 ... -0.1043396  -0.10479736\n"," -0.1242981 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0005188 ]\n"," [0.00354004]\n"," [0.00564575]\n"," ...\n"," [0.1696167 ]\n"," [0.17105103]\n"," [0.19232178]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0005188  0.00354004 0.00564575 ... 0.1696167  0.17105103 0.19232178], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00021362]\n"," [ 0.00134277]\n"," [ 0.00219727]\n"," ...\n"," [-0.1899414 ]\n"," [-0.07772827]\n"," [ 0.08380127]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00021362  0.00134277  0.00219727 ... -0.1899414  -0.07772827\n","  0.08380127], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00418091]\n"," [-0.0201416 ]\n"," [-0.03695679]\n"," ...\n"," [-0.15341187]\n"," [-0.1487732 ]\n"," [-0.16699219]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00418091 -0.0201416  -0.03695679 ... -0.15341187 -0.1487732\n"," -0.16699219], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00259399]\n"," [ 0.01446533]\n"," [ 0.02642822]\n"," ...\n"," [-0.08343506]\n"," [-0.08496094]\n"," [-0.11080933]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00259399  0.01446533  0.02642822 ... -0.08343506 -0.08496094\n"," -0.11080933], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00158691]\n"," [-0.0078125 ]\n"," [-0.01443481]\n"," ...\n"," [ 0.20516968]\n"," [ 0.18377686]\n"," [ 0.1869812 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00158691 -0.0078125  -0.01443481 ...  0.20516968  0.18377686\n","  0.1869812 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00488281]\n"," [-0.02206421]\n"," [-0.04141235]\n"," ...\n"," [ 0.05462646]\n"," [ 0.06704712]\n"," [ 0.0927124 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00488281 -0.02206421 -0.04141235 ...  0.05462646  0.06704712\n","  0.0927124 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00247192]\n"," [-0.01083374]\n"," [-0.01895142]\n"," ...\n"," [-0.22000122]\n"," [-0.21450806]\n"," [-0.25057983]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00247192 -0.01083374 -0.01895142 ... -0.22000122 -0.21450806\n"," -0.25057983], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00427246]\n"," [ 0.0222168 ]\n"," [ 0.04159546]\n"," ...\n"," [-0.00982666]\n"," [-0.01394653]\n"," [-0.02288818]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00427246  0.0222168   0.04159546 ... -0.00982666 -0.01394653\n"," -0.02288818], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00531006]\n"," [-0.02554321]\n"," [-0.04644775]\n"," ...\n"," [ 0.10684204]\n"," [ 0.09713745]\n"," [ 0.10256958]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00531006 -0.02554321 -0.04644775 ...  0.10684204  0.09713745\n","  0.10256958], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00271606]\n"," [-0.00280762]\n"," [-0.02017212]\n"," ...\n"," [-0.1831665 ]\n"," [-0.19570923]\n"," [-0.16116333]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00271606 -0.00280762 -0.02017212 ... -0.1831665  -0.19570923\n"," -0.16116333], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-2.1362305e-04]\n"," [-1.0375977e-03]\n"," [-2.0751953e-03]\n"," ...\n"," [-2.0812988e-01]\n"," [-2.0193481e-01]\n"," [-2.2964478e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-2.1362305e-04 -1.0375977e-03 -2.0751953e-03 ... -2.0812988e-01\n"," -2.0193481e-01 -2.2964478e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00119019]\n"," [-0.00549316]\n"," [-0.00961304]\n"," ...\n"," [ 0.01242065]\n"," [ 0.01037598]\n"," [ 0.0083313 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00119019 -0.00549316 -0.00961304 ...  0.01242065  0.01037598\n","  0.0083313 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-6.1035156e-05]\n"," [ 3.6621094e-04]\n"," [ 0.0000000e+00]\n"," ...\n"," [ 1.2344360e-01]\n"," [ 1.0998535e-01]\n"," [ 1.0763550e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-6.1035156e-05  3.6621094e-04  0.0000000e+00 ...  1.2344360e-01\n","  1.0998535e-01  1.0763550e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01495361]\n"," [-0.05645752]\n"," [-0.04708862]\n"," ...\n"," [-0.2628479 ]\n"," [-0.23446655]\n"," [-0.23666382]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01495361 -0.05645752 -0.04708862 ... -0.2628479  -0.23446655\n"," -0.23666382], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0020752 ]\n"," [-0.01040649]\n"," [-0.01986694]\n"," ...\n"," [-0.5965271 ]\n"," [-0.56463623]\n"," [-0.6242676 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0020752  -0.01040649 -0.01986694 ... -0.5965271  -0.56463623\n"," -0.6242676 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.5258789e-04]\n"," [-1.4648438e-03]\n"," [-2.5329590e-03]\n"," ...\n"," [ 1.6317749e-01]\n"," [ 1.4697266e-01]\n"," [ 1.4550781e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.5258789e-04 -1.4648438e-03 -2.5329590e-03 ...  1.6317749e-01\n","  1.4697266e-01  1.4550781e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00189209]\n"," [-0.00775146]\n"," [-0.01251221]\n"," ...\n"," [ 0.23388672]\n"," [ 0.22940063]\n"," [ 0.26367188]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00189209 -0.00775146 -0.01251221 ...  0.23388672  0.22940063\n","  0.26367188], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00195312]\n"," [-0.00924683]\n"," [-0.0138855 ]\n"," ...\n"," [-0.15319824]\n"," [-0.14578247]\n"," [-0.16448975]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00195312 -0.00924683 -0.0138855  ... -0.15319824 -0.14578247\n"," -0.16448975], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.2207031e-04]\n"," [-6.7138672e-04]\n"," [-4.8217773e-03]\n"," ...\n"," [-9.7137451e-02]\n"," [-1.3381958e-01]\n"," [-2.0416260e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.2207031e-04 -6.7138672e-04 -4.8217773e-03 ... -9.7137451e-02\n"," -1.3381958e-01 -2.0416260e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00021362]\n"," [ 0.00192261]\n"," [ 0.0043335 ]\n"," ...\n"," [-0.08279419]\n"," [-0.06613159]\n"," [-0.05657959]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00021362  0.00192261  0.0043335  ... -0.08279419 -0.06613159\n"," -0.05657959], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00311279]\n"," [-0.01644897]\n"," [-0.02838135]\n"," ...\n"," [ 0.28967285]\n"," [ 0.260437  ]\n"," [ 0.26498413]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00311279 -0.01644897 -0.02838135 ...  0.28967285  0.260437\n","  0.26498413], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0005188 ]\n"," [-0.00311279]\n"," [-0.00671387]\n"," ...\n"," [-0.03591919]\n"," [-0.03244019]\n"," [-0.03335571]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0005188  -0.00311279 -0.00671387 ... -0.03591919 -0.03244019\n"," -0.03335571], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00524902]\n"," [-0.0223999 ]\n"," [-0.040802  ]\n"," ...\n"," [ 0.03393555]\n"," [ 0.0305481 ]\n"," [ 0.02355957]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00524902 -0.0223999  -0.040802   ...  0.03393555  0.0305481\n","  0.02355957], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00128174]\n"," [-0.01727295]\n"," [-0.02258301]\n"," ...\n"," [-0.2871399 ]\n"," [-0.27767944]\n"," [-0.3098755 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00128174 -0.01727295 -0.02258301 ... -0.2871399  -0.27767944\n"," -0.3098755 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00057983]\n"," [-0.00534058]\n"," [-0.00527954]\n"," ...\n"," [-0.1038208 ]\n"," [-0.09780884]\n"," [-0.10635376]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00057983 -0.00534058 -0.00527954 ... -0.1038208  -0.09780884\n"," -0.10635376], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 3.0517578e-05]\n"," [ 5.3405762e-03]\n"," [ 1.2420654e-02]\n"," ...\n"," [-1.9186401e-01]\n"," [-1.8112183e-01]\n"," [-2.0004272e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 3.0517578e-05  5.3405762e-03  1.2420654e-02 ... -1.9186401e-01\n"," -1.8112183e-01 -2.0004272e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00476074]\n"," [ 0.02255249]\n"," [ 0.04037476]\n"," ...\n"," [-0.34725952]\n"," [-0.3298645 ]\n"," [-0.36706543]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00476074  0.02255249  0.04037476 ... -0.34725952 -0.3298645\n"," -0.36706543], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00308228]\n"," [-0.01422119]\n"," [-0.02490234]\n"," ...\n"," [ 0.01138306]\n"," [ 0.01296997]\n"," [ 0.01708984]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00308228 -0.01422119 -0.02490234 ...  0.01138306  0.01296997\n","  0.01708984], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00415039]\n"," [-0.01879883]\n"," [-0.03497314]\n"," ...\n"," [-0.10241699]\n"," [-0.09161377]\n"," [-0.09597778]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00415039 -0.01879883 -0.03497314 ... -0.10241699 -0.09161377\n"," -0.09597778], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 6.1035156e-05]\n"," [-3.0212402e-03]\n"," [-7.6293945e-03]\n"," ...\n"," [-1.4932251e-01]\n"," [-1.4157104e-01]\n"," [-1.5646362e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 6.1035156e-05 -3.0212402e-03 -7.6293945e-03 ... -1.4932251e-01\n"," -1.4157104e-01 -1.5646362e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 6.1035156e-05]\n"," [ 6.4086914e-04]\n"," [ 9.1552734e-04]\n"," ...\n"," [-9.4116211e-02]\n"," [-8.8714600e-02]\n"," [-9.8205566e-02]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 6.1035156e-05  6.4086914e-04  9.1552734e-04 ... -9.4116211e-02\n"," -8.8714600e-02 -9.8205566e-02], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00448608]\n"," [-0.02282715]\n"," [-0.03460693]\n"," ...\n"," [-0.41714478]\n"," [-0.38998413]\n"," [-0.42163086]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00448608 -0.02282715 -0.03460693 ... -0.41714478 -0.38998413\n"," -0.42163086], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00131226]\n"," [-0.00210571]\n"," [-0.00375366]\n"," ...\n"," [ 0.3977661 ]\n"," [ 0.32434082]\n"," [ 0.32626343]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00131226 -0.00210571 -0.00375366 ...  0.3977661   0.32434082\n","  0.32626343], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00082397]\n"," [ 0.00408936]\n"," [ 0.01077271]\n"," ...\n"," [-0.27038574]\n"," [-0.33242798]\n"," [-0.35565186]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00082397  0.00408936  0.01077271 ... -0.27038574 -0.33242798\n"," -0.35565186], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00332642]\n"," [-0.01309204]\n"," [-0.01416016]\n"," ...\n"," [-0.12658691]\n"," [-0.11865234]\n"," [-0.12872314]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00332642 -0.01309204 -0.01416016 ... -0.12658691 -0.11865234\n"," -0.12872314], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00665283]\n"," [ 0.03103638]\n"," [ 0.05532837]\n"," ...\n"," [-0.04983521]\n"," [-0.04983521]\n"," [-0.05355835]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00665283  0.03103638  0.05532837 ... -0.04983521 -0.04983521\n"," -0.05355835], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.2207031e-04]\n"," [ 3.0517578e-04]\n"," [ 2.6855469e-03]\n"," ...\n"," [-2.8906250e-01]\n"," [-2.7554321e-01]\n"," [-3.0642700e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.2207031e-04  3.0517578e-04  2.6855469e-03 ... -2.8906250e-01\n"," -2.7554321e-01 -3.0642700e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.1291504e-03]\n"," [ 3.3569336e-04]\n"," [-1.0986328e-03]\n"," ...\n"," [-3.5995483e-01]\n"," [-3.3905029e-01]\n"," [-3.7164307e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.1291504e-03  3.3569336e-04 -1.0986328e-03 ... -3.5995483e-01\n"," -3.3905029e-01 -3.7164307e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0078125 ]\n"," [ 0.04629517]\n"," [ 0.08291626]\n"," ...\n"," [-0.25454712]\n"," [-0.2514038 ]\n"," [-0.293396  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0078125   0.04629517  0.08291626 ... -0.25454712 -0.2514038\n"," -0.293396  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00106812]\n"," [-0.00402832]\n"," [-0.00570679]\n"," ...\n"," [-0.06234741]\n"," [-0.04666138]\n"," [-0.05950928]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00106812 -0.00402832 -0.00570679 ... -0.06234741 -0.04666138\n"," -0.05950928], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00033569]\n"," [-0.00192261]\n"," [-0.00390625]\n"," ...\n"," [ 0.01010132]\n"," [ 0.01785278]\n"," [ 0.03112793]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00033569 -0.00192261 -0.00390625 ...  0.01010132  0.01785278\n","  0.03112793], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00259399]\n"," [-0.01095581]\n"," [-0.0189209 ]\n"," ...\n"," [-0.14337158]\n"," [-0.09432983]\n"," [-0.11364746]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00259399 -0.01095581 -0.0189209  ... -0.14337158 -0.09432983\n"," -0.11364746], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00137329]\n"," [-0.00726318]\n"," [-0.01382446]\n"," ...\n"," [-0.06295776]\n"," [-0.05825806]\n"," [-0.06027222]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00137329 -0.00726318 -0.01382446 ... -0.06295776 -0.05825806\n"," -0.06027222], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00271606]\n"," [-0.00808716]\n"," [-0.0151062 ]\n"," ...\n"," [-0.36520386]\n"," [-0.34906006]\n"," [-0.38772583]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00271606 -0.00808716 -0.0151062  ... -0.36520386 -0.34906006\n"," -0.38772583], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00283813]\n"," [-0.01086426]\n"," [-0.01651001]\n"," ...\n"," [-0.24172974]\n"," [-0.22982788]\n"," [-0.25289917]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00283813 -0.01086426 -0.01651001 ... -0.24172974 -0.22982788\n"," -0.25289917], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00134277]\n"," [-0.00628662]\n"," [-0.01113892]\n"," ...\n"," [-0.08929443]\n"," [-0.1083374 ]\n"," [-0.14529419]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00134277 -0.00628662 -0.01113892 ... -0.08929443 -0.1083374\n"," -0.14529419], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00125122]\n"," [-0.00756836]\n"," [-0.0151062 ]\n"," ...\n"," [ 0.07879639]\n"," [ 0.07910156]\n"," [ 0.09683228]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00125122 -0.00756836 -0.0151062  ...  0.07879639  0.07910156\n","  0.09683228], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00076294]\n"," [ 0.00662231]\n"," [ 0.01824951]\n"," ...\n"," [-0.0769043 ]\n"," [-0.07550049]\n"," [-0.08734131]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00076294  0.00662231  0.01824951 ... -0.0769043  -0.07550049\n"," -0.08734131], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00143433]\n"," [ 0.00698853]\n"," [ 0.01211548]\n"," ...\n"," [-0.12084961]\n"," [-0.11712646]\n"," [-0.14038086]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00143433  0.00698853  0.01211548 ... -0.12084961 -0.11712646\n"," -0.14038086], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.01226807]\n"," [-0.02209473]\n"," ...\n"," [ 0.08337402]\n"," [ 0.07888794]\n"," [ 0.0852356 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.01226807 -0.02209473 ...  0.08337402  0.07888794\n","  0.0852356 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00079346]\n"," [ 0.00671387]\n"," [ 0.01174927]\n"," ...\n"," [-0.35357666]\n"," [-0.33529663]\n"," [-0.3645935 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00079346  0.00671387  0.01174927 ... -0.35357666 -0.33529663\n"," -0.3645935 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-5.7373047e-03]\n"," [-2.6153564e-02]\n"," [-4.6173096e-02]\n"," ...\n"," [-6.1035156e-05]\n"," [-7.1716309e-03]\n"," [-2.4871826e-02]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-5.7373047e-03 -2.6153564e-02 -4.6173096e-02 ... -6.1035156e-05\n"," -7.1716309e-03 -2.4871826e-02], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00115967]\n"," [-0.00595093]\n"," [-0.01077271]\n"," ...\n"," [-0.19262695]\n"," [-0.18185425]\n"," [-0.19921875]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00115967 -0.00595093 -0.01077271 ... -0.19262695 -0.18185425\n"," -0.19921875], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00784302]\n"," [-0.03485107]\n"," [-0.0579834 ]\n"," ...\n"," [-0.06015015]\n"," [-0.05599976]\n"," [-0.06451416]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00784302 -0.03485107 -0.0579834  ... -0.06015015 -0.05599976\n"," -0.06451416], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00271606]\n"," [-0.01263428]\n"," [-0.02261353]\n"," ...\n"," [ 0.20843506]\n"," [ 0.19680786]\n"," [ 0.21542358]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00271606 -0.01263428 -0.02261353 ...  0.20843506  0.19680786\n","  0.21542358], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 6.1035156e-05]\n"," [-4.5776367e-04]\n"," [-9.1552734e-04]\n"," ...\n"," [ 2.7243042e-01]\n"," [ 2.2821045e-01]\n"," [ 2.1374512e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 6.1035156e-05 -4.5776367e-04 -9.1552734e-04 ...  2.7243042e-01\n","  2.2821045e-01  2.1374512e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00280762]\n"," [-0.01345825]\n"," [-0.02352905]\n"," ...\n"," [-0.47427368]\n"," [-0.4456482 ]\n"," [-0.487854  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00280762 -0.01345825 -0.02352905 ... -0.47427368 -0.4456482\n"," -0.487854  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00027466]\n"," [-0.00112915]\n"," [-0.00283813]\n"," ...\n"," [-0.02938843]\n"," [-0.01992798]\n"," [-0.00970459]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00027466 -0.00112915 -0.00283813 ... -0.02938843 -0.01992798\n"," -0.00970459], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00021362]\n"," [-0.00115967]\n"," [-0.00231934]\n"," ...\n"," [-0.01947021]\n"," [-0.01837158]\n"," [-0.02017212]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00021362 -0.00115967 -0.00231934 ... -0.01947021 -0.01837158\n"," -0.02017212], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01101685]\n"," [-0.04888916]\n"," [-0.07962036]\n"," ...\n"," [-0.14553833]\n"," [-0.13778687]\n"," [-0.15048218]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01101685 -0.04888916 -0.07962036 ... -0.14553833 -0.13778687\n"," -0.15048218], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00341797]\n"," [ 0.01504517]\n"," [ 0.02539062]\n"," ...\n"," [-0.14819336]\n"," [-0.14343262]\n"," [-0.16152954]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00341797  0.01504517  0.02539062 ... -0.14819336 -0.14343262\n"," -0.16152954], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00158691]\n"," [-0.00827026]\n"," [-0.01489258]\n"," ...\n"," [-0.03237915]\n"," [-0.01843262]\n"," [-0.01403809]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00158691 -0.00827026 -0.01489258 ... -0.03237915 -0.01843262\n"," -0.01403809], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00015259]\n"," [ 0.00177002]\n"," [ 0.00012207]\n"," ...\n"," [-0.08563232]\n"," [-0.08132935]\n"," [-0.09094238]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00015259  0.00177002  0.00012207 ... -0.08563232 -0.08132935\n"," -0.09094238], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0012207 ]\n"," [-0.00619507]\n"," [-0.01043701]\n"," ...\n"," [-0.14529419]\n"," [-0.13412476]\n"," [-0.13830566]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0012207  -0.00619507 -0.01043701 ... -0.14529419 -0.13412476\n"," -0.13830566], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00427246]\n"," [-0.01623535]\n"," [-0.02252197]\n"," ...\n"," [-0.37731934]\n"," [-0.35195923]\n"," [-0.3804016 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00427246 -0.01623535 -0.02252197 ... -0.37731934 -0.35195923\n"," -0.3804016 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00366211]\n"," [-0.01654053]\n"," [-0.02746582]\n"," ...\n"," [-0.36105347]\n"," [-0.34197998]\n"," [-0.3808899 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00366211 -0.01654053 -0.02746582 ... -0.36105347 -0.34197998\n"," -0.3808899 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00167847]\n"," [-0.00872803]\n"," [-0.01879883]\n"," ...\n"," [-0.35580444]\n"," [-0.34310913]\n"," [-0.3989563 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00167847 -0.00872803 -0.01879883 ... -0.35580444 -0.34310913\n"," -0.3989563 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00402832]\n"," [-0.01882935]\n"," [-0.03295898]\n"," ...\n"," [ 0.35464478]\n"," [ 0.33935547]\n"," [ 0.37869263]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00402832 -0.01882935 -0.03295898 ...  0.35464478  0.33935547\n","  0.37869263], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00064087]\n"," [-0.00286865]\n"," [-0.00476074]\n"," ...\n"," [-0.00695801]\n"," [-0.00708008]\n"," [-0.0085144 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00064087 -0.00286865 -0.00476074 ... -0.00695801 -0.00708008\n"," -0.0085144 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00506592]\n"," [-0.02246094]\n"," [-0.03701782]\n"," ...\n"," [ 0.01266479]\n"," [ 0.01217651]\n"," [ 0.01531982]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00506592 -0.02246094 -0.03701782 ...  0.01266479  0.01217651\n","  0.01531982], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-2.1362305e-04]\n"," [ 9.1552734e-05]\n"," [ 2.1667480e-03]\n"," ...\n"," [-3.4851074e-02]\n"," [-3.3081055e-02]\n"," [-3.4912109e-02]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-2.1362305e-04  9.1552734e-05  2.1667480e-03 ... -3.4851074e-02\n"," -3.3081055e-02 -3.4912109e-02], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 2.1362305e-04]\n"," [ 2.4414062e-04]\n"," [ 0.0000000e+00]\n"," ...\n"," [-1.8750000e-01]\n"," [-1.8072510e-01]\n"," [-2.1542358e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 2.1362305e-04  2.4414062e-04  0.0000000e+00 ... -1.8750000e-01\n"," -1.8072510e-01 -2.1542358e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00222778]\n"," [-0.01177979]\n"," [-0.0222168 ]\n"," ...\n"," [-0.05419922]\n"," [-0.0637207 ]\n"," [-0.09295654]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00222778 -0.01177979 -0.0222168  ... -0.05419922 -0.0637207\n"," -0.09295654], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00091553]\n"," [ 0.00408936]\n"," [ 0.00698853]\n"," ...\n"," [-0.10125732]\n"," [-0.09536743]\n"," [-0.103302  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00091553  0.00408936  0.00698853 ... -0.10125732 -0.09536743\n"," -0.103302  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00137329]\n"," [ 0.00650024]\n"," [ 0.01092529]\n"," ...\n"," [-0.04922485]\n"," [-0.04852295]\n"," [-0.05593872]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00137329  0.00650024  0.01092529 ... -0.04922485 -0.04852295\n"," -0.05593872], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00094604]\n"," [ 0.00265503]\n"," [ 0.00415039]\n"," ...\n"," [-0.1798706 ]\n"," [-0.1652832 ]\n"," [-0.17547607]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00094604  0.00265503  0.00415039 ... -0.1798706  -0.1652832\n"," -0.17547607], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00131226]\n"," [-0.00872803]\n"," [-0.01705933]\n"," ...\n"," [-0.23272705]\n"," [-0.21939087]\n"," [-0.23712158]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00131226 -0.00872803 -0.01705933 ... -0.23272705 -0.21939087\n"," -0.23712158], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01168823]\n"," [-0.04919434]\n"," [-0.06991577]\n"," ...\n"," [-0.14993286]\n"," [-0.13287354]\n"," [-0.14318848]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01168823 -0.04919434 -0.06991577 ... -0.14993286 -0.13287354\n"," -0.14318848], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03710938]\n"," [ 0.02227783]\n"," [ 0.1251831 ]\n"," ...\n"," [-0.15008545]\n"," [-0.152771  ]\n"," [-0.18157959]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03710938  0.02227783  0.1251831  ... -0.15008545 -0.152771\n"," -0.18157959], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00506592]\n"," [-0.02514648]\n"," [-0.04577637]\n"," ...\n"," [-0.06607056]\n"," [-0.0663147 ]\n"," [-0.07839966]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00506592 -0.02514648 -0.04577637 ... -0.06607056 -0.0663147\n"," -0.07839966], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00216675]\n"," [-0.0105896 ]\n"," [-0.01849365]\n"," ...\n"," [-0.18029785]\n"," [-0.17092896]\n"," [-0.18914795]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00216675 -0.0105896  -0.01849365 ... -0.18029785 -0.17092896\n"," -0.18914795], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00170898]\n"," [-0.00778198]\n"," [-0.01495361]\n"," ...\n"," [-0.19503784]\n"," [-0.16546631]\n"," [-0.1486206 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00170898 -0.00778198 -0.01495361 ... -0.19503784 -0.16546631\n"," -0.1486206 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00137329]\n"," [-0.00250244]\n"," [-0.0027771 ]\n"," ...\n"," [-0.20721436]\n"," [-0.18527222]\n"," [-0.19134521]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00137329 -0.00250244 -0.0027771  ... -0.20721436 -0.18527222\n"," -0.19134521], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00524902]\n"," [-0.02374268]\n"," [-0.03546143]\n"," ...\n"," [-0.20932007]\n"," [-0.19659424]\n"," [-0.22042847]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00524902 -0.02374268 -0.03546143 ... -0.20932007 -0.19659424\n"," -0.22042847], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00195312]\n"," [-0.00930786]\n"," [-0.01602173]\n"," ...\n"," [-0.15820312]\n"," [-0.17547607]\n"," [-0.22418213]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00195312 -0.00930786 -0.01602173 ... -0.15820312 -0.17547607\n"," -0.22418213], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00012207]\n"," [0.00234985]\n"," [0.00509644]\n"," ...\n"," [0.06121826]\n"," [0.05596924]\n"," [0.06167603]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00012207 0.00234985 0.00509644 ... 0.06121826 0.05596924 0.06167603], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00100708]\n"," [ 0.00762939]\n"," [ 0.01733398]\n"," ...\n"," [-0.25027466]\n"," [-0.21560669]\n"," [-0.21078491]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00100708  0.00762939  0.01733398 ... -0.25027466 -0.21560669\n"," -0.21078491], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00125122]\n"," [-0.0055542 ]\n"," [-0.00967407]\n"," ...\n"," [ 0.13833618]\n"," [ 0.12997437]\n"," [ 0.04330444]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00125122 -0.0055542  -0.00967407 ...  0.13833618  0.12997437\n","  0.04330444], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.0517578e-05]\n"," [ 9.7656250e-04]\n"," [ 2.0446777e-03]\n"," ...\n"," [-3.8055420e-01]\n"," [-3.6877441e-01]\n"," [-4.3203735e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.0517578e-05  9.7656250e-04  2.0446777e-03 ... -3.8055420e-01\n"," -3.6877441e-01 -4.3203735e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00311279]\n"," [-0.00692749]\n"," [-0.00418091]\n"," ...\n"," [-0.5496521 ]\n"," [-0.5151062 ]\n"," [-0.5690918 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00311279 -0.00692749 -0.00418091 ... -0.5496521  -0.5151062\n"," -0.5690918 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.2207031e-04]\n"," [-3.3569336e-04]\n"," [-3.9672852e-04]\n"," ...\n"," [ 1.9485474e-01]\n"," [ 1.8283081e-01]\n"," [ 1.9873047e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.2207031e-04 -3.3569336e-04 -3.9672852e-04 ...  1.9485474e-01\n","  1.8283081e-01  1.9873047e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00183105]\n"," [ 0.0100708 ]\n"," [ 0.02120972]\n"," ...\n"," [-0.04779053]\n"," [-0.05029297]\n"," [-0.06414795]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00183105  0.0100708   0.02120972 ... -0.04779053 -0.05029297\n"," -0.06414795], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-9.1552734e-05]\n"," [-3.6621094e-04]\n"," [-7.0190430e-04]\n"," ...\n"," [ 7.5378418e-03]\n"," [ 7.8735352e-03]\n"," [ 1.0070801e-02]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-9.1552734e-05 -3.6621094e-04 -7.0190430e-04 ...  7.5378418e-03\n","  7.8735352e-03  1.0070801e-02], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00119019]\n"," [-0.00708008]\n"," [-0.01461792]\n"," ...\n"," [-0.07006836]\n"," [-0.06277466]\n"," [-0.06567383]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00119019 -0.00708008 -0.01461792 ... -0.07006836 -0.06277466\n"," -0.06567383], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00411987]\n"," [-0.00723267]\n"," [-0.00085449]\n"," ...\n"," [ 0.02587891]\n"," [ 0.04110718]\n"," [-0.01727295]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00411987 -0.00723267 -0.00085449 ...  0.02587891  0.04110718\n"," -0.01727295], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00100708]\n"," [-0.00906372]\n"," [-0.02029419]\n"," ...\n"," [-0.28146362]\n"," [-0.24822998]\n"," [-0.2562256 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00100708 -0.00906372 -0.02029419 ... -0.28146362 -0.24822998\n"," -0.2562256 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00213623]\n"," [-0.01147461]\n"," [-0.01547241]\n"," ...\n"," [-0.09057617]\n"," [-0.08758545]\n"," [-0.1000061 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00213623 -0.01147461 -0.01547241 ... -0.09057617 -0.08758545\n"," -0.1000061 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00534058]\n"," [-0.03366089]\n"," [-0.06973267]\n"," ...\n"," [ 0.15170288]\n"," [ 0.1449585 ]\n"," [ 0.16326904]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00534058 -0.03366089 -0.06973267 ...  0.15170288  0.1449585\n","  0.16326904], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00195312]\n"," [ 0.00967407]\n"," [ 0.01785278]\n"," ...\n"," [-0.14752197]\n"," [-0.13476562]\n"," [-0.14489746]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00195312  0.00967407  0.01785278 ... -0.14752197 -0.13476562\n"," -0.14489746], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0012207 ]\n"," [-0.00537109]\n"," [-0.01068115]\n"," ...\n"," [ 0.19915771]\n"," [ 0.1885376 ]\n"," [ 0.20977783]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0012207  -0.00537109 -0.01068115 ...  0.19915771  0.1885376\n","  0.20977783], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0012207 ]\n"," [-0.00622559]\n"," [-0.01049805]\n"," ...\n"," [-0.06237793]\n"," [-0.05160522]\n"," [-0.06732178]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0012207  -0.00622559 -0.01049805 ... -0.06237793 -0.05160522\n"," -0.06732178], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00030518]\n"," [ 0.00015259]\n"," [-0.00198364]\n"," ...\n"," [-0.11120605]\n"," [-0.10803223]\n"," [-0.12594604]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00030518  0.00015259 -0.00198364 ... -0.11120605 -0.10803223\n"," -0.12594604], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00192261]\n"," [-0.00808716]\n"," [-0.0145874 ]\n"," ...\n"," [-0.25738525]\n"," [-0.22625732]\n"," [-0.22747803]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00192261 -0.00808716 -0.0145874  ... -0.25738525 -0.22625732\n"," -0.22747803], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00222778]\n"," [-0.00985718]\n"," [-0.01541138]\n"," ...\n"," [-0.20153809]\n"," [-0.18270874]\n"," [-0.19421387]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00222778 -0.00985718 -0.01541138 ... -0.20153809 -0.18270874\n"," -0.19421387], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01266479]\n"," [-0.05786133]\n"," [-0.09881592]\n"," ...\n"," [-0.04483032]\n"," [-0.0531311 ]\n"," [-0.07623291]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01266479 -0.05786133 -0.09881592 ... -0.04483032 -0.0531311\n"," -0.07623291], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-3.0517578e-05]\n"," [ 1.1444092e-02]\n"," [ 7.2937012e-03]\n"," ...\n"," [-1.2689209e-01]\n"," [-1.2088013e-01]\n"," [-1.3439941e-01]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-3.0517578e-05  1.1444092e-02  7.2937012e-03 ... -1.2689209e-01\n"," -1.2088013e-01 -1.3439941e-01], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00509644]\n"," [-0.01620483]\n"," [-0.02728271]\n"," ...\n"," [-0.388031  ]\n"," [-0.36184692]\n"," [-0.38342285]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00509644 -0.01620483 -0.02728271 ... -0.388031   -0.36184692\n"," -0.38342285], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00210571]\n"," [-0.00970459]\n"," [-0.0184021 ]\n"," ...\n"," [ 0.03463745]\n"," [ 0.03759766]\n"," [ 0.04901123]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00210571 -0.00970459 -0.0184021  ...  0.03463745  0.03759766\n","  0.04901123], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00460815]\n"," [-0.02355957]\n"," [-0.0456543 ]\n"," ...\n"," [-0.31817627]\n"," [-0.2901001 ]\n"," [-0.31811523]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00460815 -0.02355957 -0.0456543  ... -0.31817627 -0.2901001\n"," -0.31811523], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00012207]\n"," [-0.00076294]\n"," [-0.00234985]\n"," ...\n"," [ 0.04464722]\n"," [ 0.03436279]\n"," [ 0.0255127 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00012207 -0.00076294 -0.00234985 ...  0.04464722  0.03436279\n","  0.0255127 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00061035]\n"," [0.00402832]\n"," [0.01000977]\n"," ...\n"," [0.04022217]\n"," [0.02523804]\n"," [0.03555298]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00061035 0.00402832 0.01000977 ... 0.04022217 0.02523804 0.03555298], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00299072]\n"," [ 0.0135498 ]\n"," [ 0.02340698]\n"," ...\n"," [-0.2503357 ]\n"," [-0.23196411]\n"," [-0.24517822]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00299072  0.0135498   0.02340698 ... -0.2503357  -0.23196411\n"," -0.24517822], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00640869]\n"," [-0.0267334 ]\n"," [-0.04669189]\n"," ...\n"," [-0.5773926 ]\n"," [-0.54037476]\n"," [-0.5941162 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00640869 -0.0267334  -0.04669189 ... -0.5773926  -0.54037476\n"," -0.5941162 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00076294]\n"," [ 0.00387573]\n"," [ 0.00500488]\n"," ...\n"," [ 0.00854492]\n"," [-0.04730225]\n"," [-0.13665771]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00076294  0.00387573  0.00500488 ...  0.00854492 -0.04730225\n"," -0.13665771], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00354004]\n"," [-0.01086426]\n"," [-0.01779175]\n"," ...\n"," [-0.39031982]\n"," [-0.42282104]\n"," [-0.3010559 ]], shape=(15263, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00354004 -0.01086426 -0.01779175 ... -0.39031982 -0.42282104\n"," -0.3010559 ], shape=(15263,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00115967]\n"," [-0.00561523]\n"," [-0.00958252]\n"," ...\n"," [ 0.08105469]\n"," [ 0.07757568]\n"," [ 0.08602905]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00115967 -0.00561523 -0.00958252 ...  0.08105469  0.07757568\n","  0.08602905], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00094604]\n"," [-0.0032959 ]\n"," [-0.00741577]\n"," ...\n"," [-0.28622437]\n"," [-0.42681885]\n"," [-0.22381592]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00094604 -0.0032959  -0.00741577 ... -0.28622437 -0.42681885\n"," -0.22381592], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00558472]\n"," [0.02676392]\n"," [0.04882812]\n"," ...\n"," [0.02810669]\n"," [0.027771  ]\n"," [0.03115845]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00558472 0.02676392 0.04882812 ... 0.02810669 0.027771   0.03115845], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00198364]\n"," [ 0.00958252]\n"," [ 0.01745605]\n"," ...\n"," [-0.00354004]\n"," [-0.0039978 ]\n"," [-0.00640869]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00198364  0.00958252  0.01745605 ... -0.00354004 -0.0039978\n"," -0.00640869], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00115967]\n"," [-0.00527954]\n"," [-0.00137329]\n"," ...\n"," [-0.37249756]\n"," [-0.37347412]\n"," [-0.42538452]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00115967 -0.00527954 -0.00137329 ... -0.37249756 -0.37347412\n"," -0.42538452], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00064087]\n"," [-0.00326538]\n"," [-0.006073  ]\n"," ...\n"," [ 0.0333252 ]\n"," [ 0.02246094]\n"," [ 0.01721191]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00064087 -0.00326538 -0.006073   ...  0.0333252   0.02246094\n","  0.01721191], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00280762]\n"," [0.01351929]\n"," [0.02471924]\n"," ...\n"," [0.16705322]\n"," [0.15335083]\n"," [0.16314697]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00280762 0.01351929 0.02471924 ... 0.16705322 0.15335083 0.16314697], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00289917]\n"," [-0.01348877]\n"," [-0.02334595]\n"," ...\n"," [-0.04672241]\n"," [-0.05001831]\n"," [-0.06637573]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00289917 -0.01348877 -0.02334595 ... -0.04672241 -0.05001831\n"," -0.06637573], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00201416]\n"," [-0.00970459]\n"," [-0.01916504]\n"," ...\n"," [-0.07131958]\n"," [-0.06365967]\n"," [-0.06399536]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00201416 -0.00970459 -0.01916504 ... -0.07131958 -0.06365967\n"," -0.06399536], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00091553]\n"," [-0.00393677]\n"," [-0.00692749]\n"," ...\n"," [ 0.00695801]\n"," [ 0.00631714]\n"," [ 0.00689697]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00091553 -0.00393677 -0.00692749 ...  0.00695801  0.00631714\n","  0.00689697], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00405884]\n"," [-0.01889038]\n"," [-0.03311157]\n"," ...\n"," [ 0.08175659]\n"," [ 0.07827759]\n"," [ 0.08639526]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00405884 -0.01889038 -0.03311157 ...  0.08175659  0.07827759\n","  0.08639526], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00506592]\n"," [-0.02407837]\n"," [-0.0368042 ]\n"," ...\n"," [ 0.00363159]\n"," [ 0.01229858]\n"," [ 0.02624512]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00506592 -0.02407837 -0.0368042  ...  0.00363159  0.01229858\n","  0.02624512], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0010376 ]\n"," [0.00436401]\n"," [0.00674438]\n"," ...\n"," [0.08987427]\n"," [0.0612793 ]\n"," [0.05908203]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0010376  0.00436401 0.00674438 ... 0.08987427 0.0612793  0.05908203], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00061035]\n"," [-0.00302124]\n"," [-0.00527954]\n"," ...\n"," [-0.00518799]\n"," [-0.00814819]\n"," [-0.01132202]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00061035 -0.00302124 -0.00527954 ... -0.00518799 -0.00814819\n"," -0.01132202], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00100708]\n"," [-0.00421143]\n"," [-0.00765991]\n"," ...\n"," [-0.14215088]\n"," [-0.13699341]\n"," [-0.15423584]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00100708 -0.00421143 -0.00765991 ... -0.14215088 -0.13699341\n"," -0.15423584], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00915527]\n"," [ 0.03768921]\n"," [ 0.05502319]\n"," ...\n"," [-0.05471802]\n"," [-0.04772949]\n"," [-0.04879761]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00915527  0.03768921  0.05502319 ... -0.05471802 -0.04772949\n"," -0.04879761], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00164795]\n"," [ 0.00820923]\n"," [ 0.01400757]\n"," ...\n"," [-0.35025024]\n"," [-0.3355713 ]\n"," [-0.37756348]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00164795  0.00820923  0.01400757 ... -0.35025024 -0.3355713\n"," -0.37756348], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00024414]\n"," [ 0.00183105]\n"," [ 0.00430298]\n"," ...\n"," [-0.02313232]\n"," [-0.01876831]\n"," [-0.02175903]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00024414  0.00183105  0.00430298 ... -0.02313232 -0.01876831\n"," -0.02175903], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0007019 ]\n"," [-0.00430298]\n"," [-0.00909424]\n"," ...\n"," [ 0.02813721]\n"," [ 0.0262146 ]\n"," [ 0.02923584]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0007019  -0.00430298 -0.00909424 ...  0.02813721  0.0262146\n","  0.02923584], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00320435]\n"," [-0.00720215]\n"," [-0.01586914]\n"," ...\n"," [-0.35235596]\n"," [-0.3458252 ]\n"," [-0.3972168 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00320435 -0.00720215 -0.01586914 ... -0.35235596 -0.3458252\n"," -0.3972168 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00057983]\n"," [0.00137329]\n"," [0.00039673]\n"," ...\n"," [0.10317993]\n"," [0.0942688 ]\n"," [0.10076904]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00057983 0.00137329 0.00039673 ... 0.10317993 0.0942688  0.10076904], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00683594]\n"," [-0.02896118]\n"," [-0.04638672]\n"," ...\n"," [ 0.32998657]\n"," [ 0.33062744]\n"," [ 0.38128662]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00683594 -0.02896118 -0.04638672 ...  0.32998657  0.33062744\n","  0.38128662], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00476074]\n"," [-0.01977539]\n"," [-0.03201294]\n"," ...\n"," [-0.15823364]\n"," [-0.14849854]\n"," [-0.16491699]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00476074 -0.01977539 -0.03201294 ... -0.15823364 -0.14849854\n"," -0.16491699], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00061035]\n"," [-0.00265503]\n"," [-0.00408936]\n"," ...\n"," [-0.07894897]\n"," [-0.07769775]\n"," [-0.08966064]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00061035 -0.00265503 -0.00408936 ... -0.07894897 -0.07769775\n"," -0.08966064], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00427246]\n"," [-0.02716064]\n"," [-0.05987549]\n"," ...\n"," [ 0.14880371]\n"," [ 0.09457397]\n"," [ 0.04226685]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00427246 -0.02716064 -0.05987549 ...  0.14880371  0.09457397\n","  0.04226685], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00079346]\n"," [-0.00384521]\n"," [-0.00946045]\n"," ...\n"," [-0.16220093]\n"," [-0.16311646]\n"," [-0.1885376 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00079346 -0.00384521 -0.00946045 ... -0.16220093 -0.16311646\n"," -0.1885376 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0015564 ]\n"," [ 0.00430298]\n"," [ 0.00775146]\n"," ...\n"," [-0.36044312]\n"," [-0.3328247 ]\n"," [-0.37954712]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0015564   0.00430298  0.00775146 ... -0.36044312 -0.3328247\n"," -0.37954712], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00344849]\n"," [-0.0168457 ]\n"," [-0.03149414]\n"," ...\n"," [ 0.14587402]\n"," [ 0.16055298]\n"," [ 0.19854736]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00344849 -0.0168457  -0.03149414 ...  0.14587402  0.16055298\n","  0.19854736], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00497437]\n"," [-0.02209473]\n"," [-0.03515625]\n"," ...\n"," [-0.24163818]\n"," [-0.23171997]\n"," [-0.25915527]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00497437 -0.02209473 -0.03515625 ... -0.24163818 -0.23171997\n"," -0.25915527], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00088501]\n"," [-0.00408936]\n"," [-0.00735474]\n"," ...\n"," [-0.11920166]\n"," [-0.10671997]\n"," [-0.112854  ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00088501 -0.00408936 -0.00735474 ... -0.11920166 -0.10671997\n"," -0.112854  ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00198364]\n"," [ 0.0088501 ]\n"," [ 0.01391602]\n"," ...\n"," [-0.04431152]\n"," [-0.03643799]\n"," [-0.03372192]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00198364  0.0088501   0.01391602 ... -0.04431152 -0.03643799\n"," -0.03372192], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00097656]\n"," [-0.00500488]\n"," [-0.00967407]\n"," ...\n"," [-0.4416504 ]\n"," [-0.4182434 ]\n"," [-0.46188354]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00097656 -0.00500488 -0.00967407 ... -0.4416504  -0.4182434\n"," -0.46188354], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00228882]\n"," [-0.01055908]\n"," [-0.01623535]\n"," ...\n"," [ 0.38485718]\n"," [ 0.36691284]\n"," [ 0.4093933 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00228882 -0.01055908 -0.01623535 ...  0.38485718  0.36691284\n","  0.4093933 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00012207]\n"," [-0.00085449]\n"," [-0.00296021]\n"," ...\n"," [-0.08837891]\n"," [-0.0836792 ]\n"," [-0.0925293 ]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00012207 -0.00085449 -0.00296021 ... -0.08837891 -0.0836792\n"," -0.0925293 ], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00045776]\n"," [-0.00299072]\n"," [-0.00509644]\n"," ...\n"," [-0.06741333]\n"," [-0.06692505]\n"," [-0.07717896]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00045776 -0.00299072 -0.00509644 ... -0.06741333 -0.06692505\n"," -0.07717896], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00048828]\n"," [ 0.00836182]\n"," [ 0.02325439]\n"," ...\n"," [-0.08731079]\n"," [-0.08642578]\n"," [-0.09701538]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00048828  0.00836182  0.02325439 ... -0.08731079 -0.08642578\n"," -0.09701538], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00906372]\n"," [-0.0362854 ]\n"," [-0.05389404]\n"," ...\n"," [-0.33221436]\n"," [-0.30126953]\n"," [-0.32122803]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00906372 -0.0362854  -0.05389404 ... -0.33221436 -0.30126953\n"," -0.32122803], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00311279]\n"," [-0.01571655]\n"," [-0.02713013]\n"," ...\n"," [-0.17767334]\n"," [-0.17489624]\n"," [-0.19186401]], shape=(16000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00311279 -0.01571655 -0.02713013 ... -0.17767334 -0.17489624\n"," -0.19186401], shape=(16000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00411987]\n"," [-0.00271606]\n"," [ 0.0067749 ]\n"," ...\n"," [ 0.00601196]\n"," [ 0.00424194]\n"," [ 0.00302124]], shape=(65295, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00411987 -0.00271606  0.0067749  ...  0.00601196  0.00424194\n","  0.00302124], shape=(65295,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03945923]\n"," [ 0.0791626 ]\n"," [ 0.07730103]\n"," ...\n"," [-0.00946045]\n"," [-0.01950073]\n"," [-0.02044678]], shape=(58361, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03945923  0.0791626   0.07730103 ... -0.00946045 -0.01950073\n"," -0.02044678], shape=(58361,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0166626 ]\n"," [-0.01928711]\n"," [-0.01217651]\n"," ...\n"," [ 0.02484131]\n"," [ 0.0289917 ]\n"," [ 0.01217651]], shape=(63310, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0166626  -0.01928711 -0.01217651 ...  0.02484131  0.0289917\n","  0.01217651], shape=(63310,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01266479]\n"," [-0.02999878]\n"," [-0.02438354]\n"," ...\n"," [ 0.03155518]\n"," [ 0.03213501]\n"," [ 0.02102661]], shape=(138073, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01266479 -0.02999878 -0.02438354 ...  0.03155518  0.03213501\n","  0.02102661], shape=(138073,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01715088]\n"," [-0.03704834]\n"," [-0.04650879]\n"," ...\n"," [-0.03076172]\n"," [-0.03677368]\n"," [-0.02688599]], shape=(49589, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01715088 -0.03704834 -0.04650879 ... -0.03076172 -0.03677368\n"," -0.02688599], shape=(49589,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00274658]\n"," [-0.01217651]\n"," [-0.01522827]\n"," ...\n"," [ 0.03421021]\n"," [ 0.03433228]\n"," [ 0.01864624]], shape=(143623, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00274658 -0.01217651 -0.01522827 ...  0.03421021  0.03433228\n","  0.01864624], shape=(143623,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00036621]\n"," [0.00256348]\n"," [0.0085144 ]\n"," ...\n"," [0.01358032]\n"," [0.02011108]\n"," [0.03405762]], shape=(33931, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00036621 0.00256348 0.0085144  ... 0.01358032 0.02011108 0.03405762], shape=(33931,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00411987]\n"," [0.00820923]\n"," [0.00784302]\n"," ...\n"," [0.02380371]\n"," [0.02731323]\n"," [0.02368164]], shape=(13215, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00411987 0.00820923 0.00784302 ... 0.02380371 0.02731323 0.02368164], shape=(13215,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03686523]\n"," [-0.06338501]\n"," [-0.05645752]\n"," ...\n"," [-0.01293945]\n"," [-0.0140686 ]\n"," [-0.01147461]], shape=(18835, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03686523 -0.06338501 -0.05645752 ... -0.01293945 -0.0140686\n"," -0.01147461], shape=(18835,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03070068]\n"," [ 0.05371094]\n"," [ 0.04888916]\n"," ...\n"," [-0.0340271 ]\n"," [-0.03396606]\n"," [-0.03482056]], shape=(13816, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03070068  0.05371094  0.04888916 ... -0.0340271  -0.03396606\n"," -0.03482056], shape=(13816,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00875854]\n"," [-0.01309204]\n"," [-0.00894165]\n"," ...\n"," [-0.00970459]\n"," [-0.00958252]\n"," [-0.01147461]], shape=(25560, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00875854 -0.01309204 -0.00894165 ... -0.00970459 -0.00958252\n"," -0.01147461], shape=(25560,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00128174]\n"," [ 0.00256348]\n"," [ 0.00244141]\n"," ...\n"," [-0.00378418]\n"," [-0.00274658]\n"," [-0.00485229]], shape=(18442, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00128174  0.00256348  0.00244141 ... -0.00378418 -0.00274658\n"," -0.00485229], shape=(18442,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0100708 ]\n"," [-0.01797485]\n"," [-0.01672363]\n"," ...\n"," [-0.00708008]\n"," [-0.00650024]\n"," [-0.00619507]], shape=(15225, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0100708  -0.01797485 -0.01672363 ... -0.00708008 -0.00650024\n"," -0.00619507], shape=(15225,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00765991]\n"," [-0.01385498]\n"," [-0.01293945]\n"," ...\n"," [ 0.00820923]\n"," [ 0.00726318]\n"," [ 0.00671387]], shape=(22095, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00765991 -0.01385498 -0.01293945 ...  0.00820923  0.00726318\n","  0.00671387], shape=(22095,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00094604]\n"," [-0.00128174]\n"," [-0.00036621]\n"," ...\n"," [-0.00234985]\n"," [-0.00204468]\n"," [-0.00192261]], shape=(22177, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00094604 -0.00128174 -0.00036621 ... -0.00234985 -0.00204468\n"," -0.00192261], shape=(22177,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00631714]\n"," [-0.01309204]\n"," [-0.0135498 ]\n"," ...\n"," [-0.01596069]\n"," [-0.01409912]\n"," [-0.01361084]], shape=(32760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00631714 -0.01309204 -0.0135498  ... -0.01596069 -0.01409912\n"," -0.01361084], shape=(32760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04046631]\n"," [-0.06915283]\n"," [-0.06130981]\n"," ...\n"," [ 0.05654907]\n"," [ 0.06228638]\n"," [ 0.03604126]], shape=(15920, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04046631 -0.06915283 -0.06130981 ...  0.05654907  0.06228638\n","  0.03604126], shape=(15920,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01022339]\n"," [0.00906372]\n"," [0.00891113]], shape=(28560, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01022339 0.00906372 0.00891113], shape=(28560,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00866699]\n"," [0.01330566]\n"," [0.00979614]\n"," ...\n"," [0.02084351]\n"," [0.01925659]\n"," [0.02026367]], shape=(24120, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00866699 0.01330566 0.00979614 ... 0.02084351 0.01925659 0.02026367], shape=(24120,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01107788]\n"," [0.02429199]\n"," [0.02807617]\n"," ...\n"," [0.08468628]\n"," [0.08627319]\n"," [0.09082031]], shape=(16361, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01107788 0.02429199 0.02807617 ... 0.08468628 0.08627319 0.09082031], shape=(16361,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-6.1035156e-05]\n"," [ 6.1035156e-05]\n"," [-1.2207031e-04]\n"," ...\n"," [ 7.5073242e-03]\n"," [-8.8500977e-04]\n"," [-7.5378418e-03]], shape=(34627, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-6.1035156e-05  6.1035156e-05 -1.2207031e-04 ...  7.5073242e-03\n"," -8.8500977e-04 -7.5378418e-03], shape=(34627,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-6.5002441e-03]\n"," [-9.6740723e-03]\n"," [-6.5002441e-03]\n"," ...\n"," [ 8.8500977e-04]\n"," [ 6.1035156e-04]\n"," [ 9.1552734e-05]], shape=(40125, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-6.5002441e-03 -9.6740723e-03 -6.5002441e-03 ...  8.8500977e-04\n","  6.1035156e-04  9.1552734e-05], shape=(40125,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02020264]\n"," [-0.03729248]\n"," [-0.03408813]\n"," ...\n"," [ 0.0402832 ]\n"," [ 0.04135132]\n"," [ 0.043396  ]], shape=(25073, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02020264 -0.03729248 -0.03408813 ...  0.0402832   0.04135132\n","  0.043396  ], shape=(25073,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00292969]\n"," [0.006073  ]\n"," [0.00646973]\n"," ...\n"," [0.03823853]\n"," [0.03652954]\n"," [0.04257202]], shape=(58154, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00292969 0.006073   0.00646973 ... 0.03823853 0.03652954 0.04257202], shape=(58154,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00814819]\n"," [-0.0128479 ]\n"," [-0.00942993]\n"," ...\n"," [ 0.07565308]\n"," [ 0.08102417]\n"," [ 0.0670166 ]], shape=(20049, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00814819 -0.0128479  -0.00942993 ...  0.07565308  0.08102417\n","  0.0670166 ], shape=(20049,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01644897]\n"," [ 0.02932739]\n"," [ 0.02828979]\n"," ...\n"," [-0.05752563]\n"," [-0.06124878]\n"," [-0.05047607]], shape=(16155, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01644897  0.02932739  0.02828979 ... -0.05752563 -0.06124878\n"," -0.05047607], shape=(16155,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.2207031e-03]\n"," [-2.4414062e-03]\n"," [-2.4414062e-03]\n"," ...\n"," [-9.1552734e-05]\n"," [-6.1035156e-05]\n"," [-3.0517578e-05]], shape=(13274, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.2207031e-03 -2.4414062e-03 -2.4414062e-03 ... -9.1552734e-05\n"," -6.1035156e-05 -3.0517578e-05], shape=(13274,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0105896 ]\n"," [0.01223755]\n"," [0.00415039]\n"," ...\n"," [0.0055542 ]\n"," [0.00549316]\n"," [0.00653076]], shape=(26160, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0105896  0.01223755 0.00415039 ... 0.0055542  0.00549316 0.00653076], shape=(26160,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02282715]\n"," [-0.03851318]\n"," [-0.03265381]\n"," ...\n"," [ 0.01599121]\n"," [ 0.01547241]\n"," [ 0.01766968]], shape=(30720, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02282715 -0.03851318 -0.03265381 ...  0.01599121  0.01547241\n","  0.01766968], shape=(30720,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01791382]\n"," [0.01681519]\n"," [0.0184021 ]], shape=(24060, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01791382 0.01681519 0.0184021 ], shape=(24060,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00668335]\n"," [0.0144043 ]\n"," [0.01623535]\n"," ...\n"," [0.01870728]\n"," [0.01617432]\n"," [0.00738525]], shape=(21478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00668335 0.0144043  0.01623535 ... 0.01870728 0.01617432 0.00738525], shape=(21478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00363159]\n"," [ 0.00558472]\n"," [ 0.00344849]\n"," ...\n"," [-0.02618408]\n"," [-0.03103638]\n"," [-0.01818848]], shape=(16980, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00363159  0.00558472  0.00344849 ... -0.02618408 -0.03103638\n"," -0.01818848], shape=(16980,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02996826]\n"," [-0.05175781]\n"," [-0.04544067]\n"," ...\n"," [-0.00457764]\n"," [-0.00326538]\n"," [-0.00213623]], shape=(16739, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02996826 -0.05175781 -0.04544067 ... -0.00457764 -0.00326538\n"," -0.00213623], shape=(16739,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00390625]\n"," [0.00747681]\n"," [0.00701904]\n"," ...\n"," [0.0135498 ]\n"," [0.01553345]\n"," [0.00927734]], shape=(23720, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00390625 0.00747681 0.00701904 ... 0.0135498  0.01553345 0.00927734], shape=(23720,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.18692017]\n"," [0.19003296]\n"," [0.19448853]\n"," ...\n"," [0.13928223]\n"," [0.13928223]\n"," [0.13708496]], shape=(41838, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.18692017 0.19003296 0.19448853 ... 0.13928223 0.13928223 0.13708496], shape=(41838,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00430298]\n"," [-0.00430298]\n"," [-0.00518799]\n"," ...\n"," [-0.00863647]\n"," [-0.00949097]\n"," [-0.01251221]], shape=(48354, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00430298 -0.00430298 -0.00518799 ... -0.00863647 -0.00949097\n"," -0.01251221], shape=(48354,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00314331]\n"," [-0.01254272]\n"," [-0.01568604]\n"," ...\n"," [ 0.05328369]\n"," [ 0.056427  ]\n"," [ 0.04074097]], shape=(42346, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00314331 -0.01254272 -0.01568604 ...  0.05328369  0.056427\n","  0.04074097], shape=(42346,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03894043]\n"," [-0.05145264]\n"," [-0.05981445]\n"," ...\n"," [-0.0027771 ]\n"," [-0.00140381]\n"," [ 0.00140381]], shape=(39510, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03894043 -0.05145264 -0.05981445 ... -0.0027771  -0.00140381\n","  0.00140381], shape=(39510,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00576782]\n"," [-0.01156616]\n"," [-0.00576782]\n"," ...\n"," [ 0.01446533]\n"," [ 0.01156616]\n"," [ 0.00576782]], shape=(68218, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00576782 -0.01156616 -0.00576782 ...  0.01446533  0.01156616\n","  0.00576782], shape=(68218,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00134277]\n"," [-0.00134277]\n"," [ 0.        ]\n"," ...\n"," [ 0.01477051]\n"," [ 0.0161438 ]\n"," [ 0.01748657]], shape=(44916, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00134277 -0.00134277  0.         ...  0.01477051  0.0161438\n","  0.01748657], shape=(44916,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02630615]\n"," [-0.02630615]\n"," [-0.01315308]\n"," ...\n"," [ 0.03945923]\n"," [ 0.03945923]\n"," [ 0.03945923]], shape=(54770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02630615 -0.02630615 -0.01315308 ...  0.03945923  0.03945923\n","  0.03945923], shape=(54770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0111084 ]\n"," [-0.0135498 ]\n"," [-0.01971436]\n"," ...\n"," [-0.02713013]\n"," [-0.02960205]\n"," [-0.03207397]], shape=(30500, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0111084  -0.0135498  -0.01971436 ... -0.02713013 -0.02960205\n"," -0.03207397], shape=(30500,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02023315]\n"," [-0.00808716]\n"," [-0.00808716]\n"," ...\n"," [-0.00808716]\n"," [ 0.        ]\n"," [ 0.00808716]], shape=(28824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02023315 -0.00808716 -0.00808716 ... -0.00808716  0.\n","  0.00808716], shape=(28824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0489502 ]\n"," [-0.05532837]\n"," [-0.05743408]\n"," ...\n"," [ 0.05105591]\n"," [ 0.0425415 ]\n"," [ 0.03192139]], shape=(39436, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0489502  -0.05532837 -0.05743408 ...  0.05105591  0.0425415\n","  0.03192139], shape=(39436,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.07894897]\n"," [0.09539795]\n"," [0.10525513]\n"," ...\n"," [0.04934692]\n"," [0.03289795]\n"," [0.01644897]], shape=(38276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.07894897 0.09539795 0.10525513 ... 0.04934692 0.03289795 0.01644897], shape=(38276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07595825]\n"," [-0.12658691]\n"," [-0.13925171]\n"," ...\n"," [ 0.64556885]\n"," [ 0.63290405]\n"," [ 0.64556885]], shape=(32134, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07595825 -0.12658691 -0.13925171 ...  0.64556885  0.63290405\n","  0.64556885], shape=(32134,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07955933]\n"," [-0.06817627]\n"," [-0.06817627]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(41876, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07955933 -0.06817627 -0.06817627 ...  0.          0.\n","  0.        ], shape=(41876,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00683594]\n"," [ 0.01364136]\n"," [ 0.01705933]\n"," ...\n"," [-0.00683594]\n"," [-0.00341797]\n"," [ 0.00341797]], shape=(21128, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00683594  0.01364136  0.01705933 ... -0.00683594 -0.00341797\n","  0.00341797], shape=(21128,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.027771]\n"," [0.027771]\n"," [0.      ]\n"," ...\n"," [0.      ]\n"," [0.      ]\n"," [0.      ]], shape=(59114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.027771 0.027771 0.       ... 0.       0.       0.      ], shape=(59114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00598145]\n"," [ 0.        ]\n"," [-0.00598145]], shape=(54696, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00598145  0.\n"," -0.00598145], shape=(54696,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04544067]\n"," [-0.0227356 ]\n"," [-0.05682373]\n"," ...\n"," [ 0.0227356 ]\n"," [ 0.01135254]\n"," [-0.01135254]], shape=(79534, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04544067 -0.0227356  -0.05682373 ...  0.0227356   0.01135254\n"," -0.01135254], shape=(79534,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01913452]\n"," [-0.02459717]\n"," [-0.02731323]\n"," ...\n"," [ 0.01092529]\n"," [ 0.00546265]\n"," [-0.00274658]], shape=(78904, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01913452 -0.02459717 -0.02731323 ...  0.01092529  0.00546265\n"," -0.00274658], shape=(78904,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0050354 ]\n"," [0.00601196]\n"," [0.00756836]\n"," ...\n"," [0.00585938]\n"," [0.0050354 ]\n"," [0.00494385]], shape=(43398, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0050354  0.00601196 0.00756836 ... 0.00585938 0.0050354  0.00494385], shape=(43398,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00762939]\n"," [ 0.        ]\n"," [-0.00189209]\n"," ...\n"," [ 0.0038147 ]\n"," [ 0.00762939]\n"," [ 0.01333618]], shape=(48874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00762939  0.         -0.00189209 ...  0.0038147   0.00762939\n","  0.01333618], shape=(48874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02124023]\n"," [0.02249146]\n"," [0.02249146]\n"," ...\n"," [0.00375366]\n"," [0.00500488]\n"," [0.00500488]], shape=(32514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02124023 0.02249146 0.02249146 ... 0.00375366 0.00500488 0.00500488], shape=(32514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00860596]\n"," [-0.00860596]\n"," [-0.00430298]\n"," ...\n"," [ 0.00430298]\n"," [-0.00213623]\n"," [ 0.00213623]], shape=(29764, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00860596 -0.00860596 -0.00430298 ...  0.00430298 -0.00213623\n","  0.00213623], shape=(29764,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08053589]\n"," [-0.09060669]\n"," [-0.08053589]\n"," ...\n"," [-0.06710815]\n"," [-0.06710815]\n"," [-0.06710815]], shape=(42386, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08053589 -0.09060669 -0.08053589 ... -0.06710815 -0.06710815\n"," -0.06710815], shape=(42386,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22277832]\n"," [-0.22277832]\n"," [-0.22277832]\n"," ...\n"," [-0.14355469]\n"," [-0.06436157]\n"," [ 0.00494385]], shape=(45214, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22277832 -0.22277832 -0.22277832 ... -0.14355469 -0.06436157\n","  0.00494385], shape=(45214,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.23571777]\n"," [-0.25      ]\n"," [-0.27142334]\n"," ...\n"," [ 0.        ]\n"," [ 0.00714111]\n"," [-0.00714111]], shape=(17178, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.23571777 -0.25       -0.27142334 ...  0.          0.00714111\n"," -0.00714111], shape=(17178,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13296509]\n"," [-0.15542603]\n"," [-0.17041016]\n"," ...\n"," [-0.09552002]\n"," [-0.11984253]\n"," [-0.13482666]], shape=(62976, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13296509 -0.15542603 -0.17041016 ... -0.09552002 -0.11984253\n"," -0.13482666], shape=(62976,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07192993]\n"," [-0.07192993]\n"," [-0.07192993]\n"," ...\n"," [-0.07913208]\n"," [-0.07913208]\n"," [-0.08633423]], shape=(26612, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07192993 -0.07192993 -0.07192993 ... -0.07913208 -0.07913208\n"," -0.08633423], shape=(26612,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08636475]\n"," [0.09283447]\n"," [0.1010437 ]\n"," ...\n"," [0.00216675]\n"," [0.00302124]\n"," [0.00302124]], shape=(63658, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08636475 0.09283447 0.1010437  ... 0.00216675 0.00302124 0.00302124], shape=(63658,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [ 0.        ]\n"," [-0.00598145]\n"," ...\n"," [ 0.        ]\n"," [-0.00598145]\n"," [-0.00598145]], shape=(58886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145  0.         -0.00598145 ...  0.         -0.00598145\n"," -0.00598145], shape=(58886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00772095]\n"," [ 0.01931763]\n"," [ 0.        ]\n"," ...\n"," [-0.00772095]\n"," [-0.00772095]\n"," [-0.02703857]], shape=(101542, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00772095  0.01931763  0.         ... -0.00772095 -0.00772095\n"," -0.02703857], shape=(101542,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.05227661]\n"," [0.16177368]\n"," [0.26135254]\n"," ...\n"," [0.09228516]\n"," [0.08276367]\n"," [0.06399536]], shape=(62334, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.05227661 0.16177368 0.26135254 ... 0.09228516 0.08276367 0.06399536], shape=(62334,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.36834717]\n"," [0.4184265 ]\n"," [0.4555664 ]\n"," ...\n"," [0.00161743]\n"," [0.00323486]\n"," [0.        ]], shape=(18214, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.36834717 0.4184265  0.4555664  ... 0.00161743 0.00323486 0.        ], shape=(18214,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0211792 ]\n"," [-0.0211792 ]\n"," [-0.0211792 ]\n"," ...\n"," [-0.03814697]\n"," [-0.0211792 ]\n"," [-0.0211792 ]], shape=(22180, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0211792  -0.0211792  -0.0211792  ... -0.03814697 -0.0211792\n"," -0.0211792 ], shape=(22180,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01879883]\n"," [0.01879883]\n"," [0.03759766]\n"," ...\n"," [0.03759766]\n"," [0.02630615]\n"," [0.00750732]], shape=(67336, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01879883 0.01879883 0.03759766 ... 0.03759766 0.02630615 0.00750732], shape=(67336,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02999878]\n"," [-0.13208008]\n"," [-0.29599   ]\n"," ...\n"," [ 0.11889648]\n"," [ 0.10598755]\n"," [ 0.07501221]], shape=(28812, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02999878 -0.13208008 -0.29599    ...  0.11889648  0.10598755\n","  0.07501221], shape=(28812,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06750488]\n"," [-0.05249023]\n"," [-0.0375061 ]\n"," ...\n"," [-0.01000977]\n"," [-0.01251221]\n"," [-0.01501465]], shape=(83566, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06750488 -0.05249023 -0.0375061  ... -0.01000977 -0.01251221\n"," -0.01501465], shape=(83566,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00942993]\n"," [ 0.00942993]\n"," [ 0.00473022]\n"," ...\n"," [-0.00473022]\n"," [-0.00473022]\n"," [ 0.        ]], shape=(24918, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00942993  0.00942993  0.00473022 ... -0.00473022 -0.00473022\n","  0.        ], shape=(24918,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.07104492]\n"," [0.07202148]\n"," [0.07104492]\n"," ...\n"," [0.10632324]\n"," [0.10391235]\n"," [0.10391235]], shape=(19334, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.07104492 0.07202148 0.07104492 ... 0.10632324 0.10391235 0.10391235], shape=(19334,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00234985]\n"," [ 0.00119019]\n"," [-0.00119019]\n"," ...\n"," [-0.25057983]\n"," [-0.20822144]\n"," [-0.14822388]], shape=(83394, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00234985  0.00119019 -0.00119019 ... -0.25057983 -0.20822144\n"," -0.14822388], shape=(83394,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05249023]\n"," [-0.04373169]\n"," [-0.02624512]\n"," ...\n"," [-0.04373169]\n"," [-0.04373169]\n"," [-0.04956055]], shape=(45910, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05249023 -0.04373169 -0.02624512 ... -0.04373169 -0.04373169\n"," -0.04956055], shape=(45910,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04998779]\n"," [-0.05712891]\n"," [-0.06430054]\n"," ...\n"," [-0.42855835]\n"," [-0.37142944]\n"," [-0.29284668]], shape=(44976, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04998779 -0.05712891 -0.06430054 ... -0.42855835 -0.37142944\n"," -0.29284668], shape=(44976,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02301025]\n"," [-0.02099609]\n"," [-0.01550293]\n"," ...\n"," [ 0.0329895 ]\n"," [ 0.04098511]\n"," [ 0.04449463]], shape=(57022, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02301025 -0.02099609 -0.01550293 ...  0.0329895   0.04098511\n","  0.04449463], shape=(57022,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.43392944]\n"," [-0.43182373]\n"," [-0.43096924]\n"," ...\n"," [-0.10638428]\n"," [-0.10806274]\n"," [-0.10931396]], shape=(28874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.43392944 -0.43182373 -0.43096924 ... -0.10638428 -0.10806274\n"," -0.10931396], shape=(28874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13726807]\n"," [-0.13070679]\n"," [-0.13070679]\n"," ...\n"," [-0.13070679]\n"," [-0.14379883]\n"," [-0.16992188]], shape=(43514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13726807 -0.13070679 -0.13070679 ... -0.13070679 -0.14379883\n"," -0.16992188], shape=(43514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06988525]\n"," [ 0.07525635]\n"," [ 0.07525635]\n"," ...\n"," [-0.41397095]\n"," [-0.43548584]\n"," [-0.44622803]], shape=(29736, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06988525  0.07525635  0.07525635 ... -0.41397095 -0.43548584\n"," -0.44622803], shape=(29736,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00100708]\n"," [-0.00201416]\n"," [-0.00201416]\n"," ...\n"," [ 0.02249146]\n"," [ 0.01748657]\n"," [ 0.01400757]], shape=(53056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00100708 -0.00201416 -0.00201416 ...  0.02249146  0.01748657\n","  0.01400757], shape=(53056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06970215]\n"," [-0.06317139]\n"," [-0.06317139]\n"," ...\n"," [-0.12854004]\n"," [-0.12854004]\n"," [-0.13290405]], shape=(45486, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06970215 -0.06317139 -0.06317139 ... -0.12854004 -0.12854004\n"," -0.13290405], shape=(45486,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00750732]\n"," [0.00500488]\n"," [0.00500488]\n"," ...\n"," [0.02249146]\n"," [0.01251221]\n"," [0.00750732]], shape=(45888, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00750732 0.00500488 0.00500488 ... 0.02249146 0.01251221 0.00750732], shape=(45888,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01315308]\n"," [0.01138306]\n"," [0.01052856]\n"," ...\n"," [0.05776978]\n"," [0.05526733]\n"," [0.05172729]], shape=(49662, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01315308 0.01138306 0.01052856 ... 0.05776978 0.05526733 0.05172729], shape=(49662,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00820923]\n"," [0.01638794]\n"," [0.01638794]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.        ]], shape=(55002, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00820923 0.01638794 0.01638794 ... 0.         0.         0.        ], shape=(55002,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02920532]\n"," [0.02737427]\n"," [0.02920532]\n"," ...\n"," [0.0072937 ]\n"," [0.00912476]\n"," [0.00912476]], shape=(48846, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02920532 0.02737427 0.02920532 ... 0.0072937  0.00912476 0.00912476], shape=(48846,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0390625]\n"," [0.0390625]\n"," [0.03125  ]\n"," ...\n"," [0.0234375]\n"," [0.0234375]\n"," [0.0234375]], shape=(97360, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0390625 0.0390625 0.03125   ... 0.0234375 0.0234375 0.0234375], shape=(97360,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01376343]\n"," [0.01748657]\n"," [0.01873779]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.        ]], shape=(98908, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01376343 0.01748657 0.01873779 ... 0.         0.         0.        ], shape=(98908,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0072937 ]\n"," [-0.0072937 ]\n"," [ 0.        ]\n"," ...\n"," [-0.01824951]\n"," [-0.0072937 ]\n"," [-0.01824951]], shape=(28816, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0072937  -0.0072937   0.         ... -0.01824951 -0.0072937\n"," -0.01824951], shape=(28816,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.14840698]\n"," [ 0.1703186 ]\n"," [ 0.18005371]\n"," ...\n"," [-0.00485229]\n"," [-0.00485229]\n"," [-0.00244141]], shape=(59876, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.14840698  0.1703186   0.18005371 ... -0.00485229 -0.00485229\n"," -0.00244141], shape=(59876,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01000977]\n"," [-0.00250244]\n"," [ 0.01000977]\n"," ...\n"," [ 0.00500488]\n"," [ 0.00250244]\n"," [ 0.00250244]], shape=(62410, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01000977 -0.00250244  0.01000977 ...  0.00500488  0.00250244\n","  0.00250244], shape=(62410,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.20953369]\n"," [-0.22857666]\n"," [-0.20953369]\n"," ...\n"," [-0.17141724]\n"," [-0.24761963]\n"," [-0.29522705]], shape=(35096, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.20953369 -0.22857666 -0.20953369 ... -0.17141724 -0.24761963\n"," -0.29522705], shape=(35096,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00213623]\n"," [ 0.        ]\n"," [-0.00430298]\n"," ...\n"," [ 0.05160522]\n"," [ 0.05807495]\n"," [ 0.06668091]], shape=(27598, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00213623  0.         -0.00430298 ...  0.05160522  0.05807495\n","  0.06668091], shape=(27598,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10818481]\n"," [-0.10818481]\n"," [-0.10818481]\n"," ...\n"," [-0.08480835]\n"," [-0.08480835]\n"," [-0.08187866]], shape=(26998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10818481 -0.10818481 -0.10818481 ... -0.08480835 -0.08480835\n"," -0.08187866], shape=(26998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08169556]\n"," [0.08361816]\n"," [0.08602905]\n"," ...\n"," [0.07104492]\n"," [0.07104492]\n"," [0.07202148]], shape=(16868, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08169556 0.08361816 0.08602905 ... 0.07104492 0.07104492 0.07202148], shape=(16868,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02297974]\n"," [ 0.01150513]\n"," [-0.0057373 ]\n"," ...\n"," [ 0.01724243]\n"," [ 0.02874756]\n"," [ 0.04598999]], shape=(54354, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02297974  0.01150513 -0.0057373  ...  0.01724243  0.02874756\n","  0.04598999], shape=(54354,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.28100586]\n"," [-0.23880005]\n"," [-0.18865967]\n"," ...\n"," [-0.12268066]\n"," [-0.14379883]\n"," [-0.1583252 ]], shape=(49510, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.28100586 -0.23880005 -0.18865967 ... -0.12268066 -0.14379883\n"," -0.1583252 ], shape=(49510,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.35101318]\n"," [ 0.35150146]\n"," [ 0.3534851 ]\n"," ...\n"," [-0.49499512]\n"," [-0.49398804]\n"," [-0.48849487]], shape=(24010, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.35101318  0.35150146  0.3534851  ... -0.49499512 -0.49398804\n"," -0.48849487], shape=(24010,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02172852]\n"," [-0.03262329]\n"," [-0.03262329]\n"," ...\n"," [ 0.08694458]\n"," [ 0.05435181]\n"," [ 0.03262329]], shape=(47412, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02172852 -0.03262329 -0.03262329 ...  0.08694458  0.05435181\n","  0.03262329], shape=(47412,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.09408569]\n"," [0.10751343]\n"," [0.12365723]\n"," ...\n"," [0.08602905]\n"," [0.0887146 ]\n"," [0.09408569]], shape=(35546, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.09408569 0.10751343 0.12365723 ... 0.08602905 0.0887146  0.09408569], shape=(35546,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03662109]\n"," [-0.0375061 ]\n"," [-0.03573608]\n"," ...\n"," [ 0.06265259]\n"," [ 0.05603027]\n"," [ 0.04190063]], shape=(31830, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03662109 -0.0375061  -0.03573608 ...  0.06265259  0.05603027\n","  0.04190063], shape=(31830,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.05264282]\n"," [0.10964966]\n"," [0.14694214]\n"," ...\n"," [0.03289795]\n"," [0.02194214]\n"," [0.01095581]], shape=(87164, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.05264282 0.10964966 0.14694214 ... 0.03289795 0.02194214 0.01095581], shape=(87164,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04177856]\n"," [-0.04177856]\n"," [-0.04736328]\n"," ...\n"," [ 0.06686401]\n"," [ 0.06686401]\n"," [ 0.07519531]], shape=(23940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04177856 -0.04177856 -0.04736328 ...  0.06686401  0.06686401\n","  0.07519531], shape=(23940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00100708]\n"," [ 0.00048828]\n"," [ 0.00299072]\n"," ...\n"," [-0.00100708]\n"," [-0.00201416]\n"," [-0.00299072]], shape=(61626, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00100708  0.00048828  0.00299072 ... -0.00100708 -0.00201416\n"," -0.00299072], shape=(61626,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0057373 ]\n"," [-0.0057373 ]\n"," [-0.01431274]\n"," ...\n"," [-0.0057373 ]\n"," [-0.01431274]\n"," [-0.0057373 ]], shape=(75306, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0057373  -0.0057373  -0.01431274 ... -0.0057373  -0.01431274\n"," -0.0057373 ], shape=(75306,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06433105]\n"," [-0.06433105]\n"," [-0.06433105]\n"," ...\n"," [ 0.00585938]\n"," [ 0.00585938]\n"," [ 0.01461792]], shape=(34130, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06433105 -0.06433105 -0.06433105 ...  0.00585938  0.00585938\n","  0.01461792], shape=(34130,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00640869]\n"," [0.00640869]\n"," ...\n"," [0.00640869]\n"," [0.00640869]\n"," [0.00640869]], shape=(63438, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00640869 0.00640869 ... 0.00640869 0.00640869 0.00640869], shape=(63438,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04125977]\n"," [-0.03625488]\n"," [-0.03250122]\n"," ...\n"," [ 0.05374146]\n"," [ 0.05499268]\n"," [ 0.0562439 ]], shape=(23204, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04125977 -0.03625488 -0.03250122 ...  0.05374146  0.05499268\n","  0.0562439 ], shape=(23204,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00241089]\n"," [ 0.00241089]\n"," ...\n"," [-0.0105896 ]\n"," [-0.01156616]\n"," [-0.01300049]], shape=(77760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00241089  0.00241089 ... -0.0105896  -0.01156616\n"," -0.01300049], shape=(77760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0062561 ]\n"," [0.0062561 ]\n"," [0.0062561 ]\n"," ...\n"," [0.01873779]\n"," [0.01873779]\n"," [0.02124023]], shape=(46002, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0062561  0.0062561  0.0062561  ... 0.01873779 0.01873779 0.02124023], shape=(46002,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01300049]\n"," [-0.00964355]\n"," [-0.00817871]\n"," ...\n"," [-0.00576782]\n"," [-0.00482178]\n"," [-0.00335693]], shape=(38226, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01300049 -0.00964355 -0.00817871 ... -0.00576782 -0.00482178\n"," -0.00335693], shape=(38226,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01464844]\n"," [-0.03845215]\n"," [-0.072052  ]\n"," ...\n"," [-0.00366211]\n"," [-0.01159668]\n"," [-0.02502441]], shape=(25478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01464844 -0.03845215 -0.072052   ... -0.00366211 -0.01159668\n"," -0.02502441], shape=(25478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06378174]\n"," [ 0.01275635]\n"," [-0.0255127 ]\n"," ...\n"," [-0.02807617]\n"," [-0.04592896]\n"," [-0.04846191]], shape=(33316, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06378174  0.01275635 -0.0255127  ... -0.02807617 -0.04592896\n"," -0.04846191], shape=(33316,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00518799]\n"," [ 0.00518799]\n"," [ 0.00518799]\n"," ...\n"," [-0.00518799]\n"," [ 0.        ]\n"," [ 0.02072144]], shape=(84388, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00518799  0.00518799  0.00518799 ... -0.00518799  0.\n","  0.02072144], shape=(84388,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01647949]\n"," [-0.0211792 ]\n"," [-0.0211792 ]\n"," ...\n"," [ 0.00939941]\n"," [ 0.01647949]\n"," [ 0.01647949]], shape=(36856, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01647949 -0.0211792  -0.0211792  ...  0.00939941  0.01647949\n","  0.01647949], shape=(36856,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15032959]\n"," [-0.17648315]\n"," [-0.17648315]\n"," ...\n"," [-0.2026062 ]\n"," [-0.2026062 ]\n"," [-0.17648315]], shape=(37724, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15032959 -0.17648315 -0.17648315 ... -0.2026062  -0.2026062\n"," -0.17648315], shape=(37724,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.00793457]\n"," ...\n"," [-0.08731079]\n"," [-0.09524536]\n"," [-0.13491821]], shape=(23408, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.00793457 ... -0.08731079 -0.09524536\n"," -0.13491821], shape=(23408,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07522583]\n"," [ 0.04388428]\n"," [ 0.01254272]\n"," ...\n"," [-0.04702759]\n"," [-0.03762817]\n"," [-0.02194214]], shape=(89948, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07522583  0.04388428  0.01254272 ... -0.04702759 -0.03762817\n"," -0.02194214], shape=(89948,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01177979]\n"," [-0.01412964]\n"," [-0.0211792 ]\n"," ...\n"," [ 0.        ]\n"," [-0.00234985]\n"," [-0.00234985]], shape=(50940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01177979 -0.01412964 -0.0211792  ...  0.         -0.00234985\n"," -0.00234985], shape=(50940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00140381]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.02224731]\n"," [-0.02087402]\n"," [-0.02224731]], shape=(77814, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00140381  0.          0.         ... -0.02224731 -0.02087402\n"," -0.02224731], shape=(77814,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.0138855 ]\n"," [0.01434326]\n"," [0.01257324]], shape=(51990, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.0138855  0.01434326 0.01257324], shape=(51990,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00100708]\n"," [0.00100708]\n"," [0.00201416]\n"," ...\n"," [0.02151489]\n"," [0.03100586]\n"," [0.04400635]], shape=(39400, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00100708 0.00100708 0.00201416 ... 0.02151489 0.03100586 0.04400635], shape=(39400,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01074219]\n"," [-0.00860596]\n"," [-0.00860596]\n"," ...\n"," [ 0.00213623]\n"," [ 0.00213623]\n"," [ 0.        ]], shape=(37166, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01074219 -0.00860596 -0.00860596 ...  0.00213623  0.00213623\n","  0.        ], shape=(37166,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01257324]\n"," [-0.01257324]\n"," [-0.00628662]\n"," ...\n"," [-0.01257324]\n"," [-0.00628662]\n"," [-0.00628662]], shape=(24326, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01257324 -0.01257324 -0.00628662 ... -0.01257324 -0.00628662\n"," -0.00628662], shape=(24326,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01873779]\n"," [-0.02749634]\n"," [-0.03500366]\n"," ...\n"," [-0.01126099]\n"," [-0.01000977]\n"," [-0.00750732]], shape=(51860, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01873779 -0.02749634 -0.03500366 ... -0.01126099 -0.01000977\n"," -0.00750732], shape=(51860,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.19509888]\n"," [-0.19073486]\n"," [-0.18856812]\n"," ...\n"," [ 0.7132263 ]\n"," [ 0.7123413 ]\n"," [ 0.71017456]], shape=(47472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.19509888 -0.19073486 -0.18856812 ...  0.7132263   0.7123413\n","  0.71017456], shape=(47472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.11364746]\n"," [ 0.11364746]\n"," [ 0.11364746]\n"," ...\n"," [-0.11364746]\n"," [-0.1022644 ]\n"," [-0.11364746]], shape=(60348, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.11364746  0.11364746  0.11364746 ... -0.11364746 -0.1022644\n"," -0.11364746], shape=(60348,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08630371]\n"," [0.0871582 ]\n"," [0.08843994]\n"," ...\n"," [0.602478  ]\n"," [0.59906006]\n"," [0.5969238 ]], shape=(53732, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08630371 0.0871582  0.08843994 ... 0.602478   0.59906006 0.5969238 ], shape=(53732,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.25558472]\n"," [ 0.26055908]\n"," [ 0.24316406]\n"," ...\n"," [-0.00497437]\n"," [-0.0173645 ]\n"," [-0.03723145]], shape=(41086, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.25558472  0.26055908  0.24316406 ... -0.00497437 -0.0173645\n"," -0.03723145], shape=(41086,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02603149]\n"," [-0.03717041]\n"," [-0.0446167 ]\n"," ...\n"," [ 0.01858521]\n"," [ 0.03344727]\n"," [ 0.0446167 ]], shape=(29228, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02603149 -0.03717041 -0.0446167  ...  0.01858521  0.03344727\n","  0.0446167 ], shape=(29228,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.18530273]\n"," [ 0.17514038]\n"," [ 0.16497803]\n"," ...\n"," [-0.00418091]\n"," [-0.00119019]\n"," [-0.00299072]], shape=(70222, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.18530273  0.17514038  0.16497803 ... -0.00418091 -0.00119019\n"," -0.00299072], shape=(70222,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01470947]\n"," [-0.01470947]\n"," [-0.01470947]\n"," ...\n"," [-0.00421143]\n"," [ 0.00421143]\n"," [ 0.00421143]], shape=(21886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01470947 -0.01470947 -0.01470947 ... -0.00421143  0.00421143\n","  0.00421143], shape=(21886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22857666]\n"," [-0.22857666]\n"," [-0.22857666]\n"," ...\n"," [ 0.        ]\n"," [-0.01428223]\n"," [ 0.        ]], shape=(60186, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22857666 -0.22857666 -0.22857666 ...  0.         -0.01428223\n","  0.        ], shape=(60186,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01885986]\n"," [-0.02359009]\n"," [-0.02359009]\n"," ...\n"," [-0.02359009]\n"," [-0.02359009]\n"," [-0.01885986]], shape=(22444, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01885986 -0.02359009 -0.02359009 ... -0.02359009 -0.02359009\n"," -0.01885986], shape=(22444,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06710815]\n"," [-0.06710815]\n"," [-0.07382202]\n"," ...\n"," [-0.09732056]\n"," [-0.09732056]\n"," [-0.09732056]], shape=(33722, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06710815 -0.06710815 -0.07382202 ... -0.09732056 -0.09732056\n"," -0.09732056], shape=(33722,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00830078]\n"," [ 0.01104736]\n"," [ 0.01104736]\n"," ...\n"," [-0.0027771 ]\n"," [ 0.        ]\n"," [ 0.00830078]], shape=(40450, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00830078  0.01104736  0.01104736 ... -0.0027771   0.\n","  0.00830078], shape=(40450,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.36190796]\n"," [-0.42855835]\n"," [-0.5428467 ]\n"," ...\n"," [-0.2000122 ]\n"," [-0.19049072]\n"," [-0.20953369]], shape=(56842, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.36190796 -0.42855835 -0.5428467  ... -0.2000122  -0.19049072\n"," -0.20953369], shape=(56842,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00601196]\n"," [0.00350952]\n"," [0.00100708]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.00100708]], shape=(39924, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00601196 0.00350952 0.00100708 ... 0.         0.         0.00100708], shape=(39924,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00372314]\n"," [ 0.        ]\n"," ...\n"," [-0.01486206]\n"," [-0.01486206]\n"," [-0.01486206]], shape=(63882, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00372314  0.         ... -0.01486206 -0.01486206\n"," -0.01486206], shape=(63882,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00076294]\n"," [ 0.00311279]\n"," [ 0.00500488]\n"," ...\n"," [-0.05511475]\n"," [-0.056427  ]\n"," [-0.05609131]], shape=(27810, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00076294  0.00311279  0.00500488 ... -0.05511475 -0.056427\n"," -0.05609131], shape=(27810,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04971313]\n"," [0.04385376]\n"," [0.02923584]\n"," ...\n"," [0.00585938]\n"," [0.00585938]\n"," [0.00585938]], shape=(21356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04971313 0.04385376 0.02923584 ... 0.00585938 0.00585938 0.00585938], shape=(21356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00485229]\n"," [0.00244141]\n"," ...\n"," [0.04623413]\n"," [0.08273315]\n"," [0.10949707]], shape=(66312, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00485229 0.00244141 ... 0.04623413 0.08273315 0.10949707], shape=(66312,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01242065]\n"," [0.01242065]\n"," [0.        ]\n"," ...\n"," [0.00497437]\n"," [0.0173645 ]\n"," [0.        ]], shape=(28756, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01242065 0.01242065 0.         ... 0.00497437 0.0173645  0.        ], shape=(28756,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.28570557]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.14285278]\n"," [-0.14285278]\n"," [ 0.14285278]], shape=(64898, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.28570557  0.          0.         ... -0.14285278 -0.14285278\n","  0.14285278], shape=(64898,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00735474]\n"," [-0.01470947]\n"," [-0.01470947]\n"," ...\n"," [ 0.04412842]\n"," [ 0.03308105]\n"," [ 0.02206421]], shape=(52062, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00735474 -0.01470947 -0.01470947 ...  0.04412842  0.03308105\n","  0.02206421], shape=(52062,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00250244]\n"," [-0.00250244]\n"," ...\n"," [ 0.00250244]\n"," [ 0.00250244]\n"," [ 0.0062561 ]], shape=(42874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00250244 -0.00250244 ...  0.00250244  0.00250244\n","  0.0062561 ], shape=(42874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05377197]\n"," [-0.02688599]\n"," [-0.03762817]\n"," ...\n"," [-0.05377197]\n"," [-0.05377197]\n"," [-0.05377197]], shape=(49488, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05377197 -0.02688599 -0.03762817 ... -0.05377197 -0.05377197\n"," -0.05377197], shape=(49488,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08779907]\n"," [-0.0975647 ]\n"," [-0.0975647 ]\n"," ...\n"," [-0.0975647 ]\n"," [-0.08779907]\n"," [-0.0975647 ]], shape=(74918, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08779907 -0.0975647  -0.0975647  ... -0.0975647  -0.08779907\n"," -0.0975647 ], shape=(74918,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04620361]\n"," [-0.04202271]\n"," [-0.03152466]\n"," ...\n"," [-0.07144165]\n"," [-0.07144165]\n"," [-0.07144165]], shape=(20088, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04620361 -0.04202271 -0.03152466 ... -0.07144165 -0.07144165\n"," -0.07144165], shape=(20088,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01931763]\n"," [ 0.00772095]\n"," [ 0.00772095]\n"," ...\n"," [-0.00772095]\n"," [-0.00772095]\n"," [-0.00772095]], shape=(30264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01931763  0.00772095  0.00772095 ... -0.00772095 -0.00772095\n"," -0.00772095], shape=(30264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01525879]\n"," [-0.01089478]\n"," [-0.00436401]\n"," ...\n"," [ 0.01089478]\n"," [ 0.01525879]\n"," [ 0.02178955]], shape=(35990, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01525879 -0.01089478 -0.00436401 ...  0.01089478  0.01525879\n","  0.02178955], shape=(35990,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02124023]\n"," [ 0.0249939 ]\n"," [ 0.02749634]\n"," ...\n"," [-0.01251221]\n"," [-0.00875854]\n"," [-0.0062561 ]], shape=(28878, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02124023  0.0249939   0.02749634 ... -0.01251221 -0.00875854\n"," -0.0062561 ], shape=(28878,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02722168]\n"," [-0.01361084]\n"," [-0.02722168]\n"," ...\n"," [ 0.1496582 ]\n"," [ 0.17687988]\n"," [ 0.16326904]], shape=(28576, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02722168 -0.01361084 -0.02722168 ...  0.1496582   0.17687988\n","  0.16326904], shape=(28576,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.2062378]\n"," [-0.2062378]\n"," [-0.1937561]\n"," ...\n"," [ 0.2062378]\n"," [ 0.2062378]\n"," [ 0.1937561]], shape=(54586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.2062378 -0.2062378 -0.1937561 ...  0.2062378  0.2062378  0.1937561], shape=(54586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07894897]\n"," [-0.0657959 ]\n"," [-0.07894897]\n"," ...\n"," [-0.05264282]\n"," [-0.03945923]\n"," [-0.03945923]], shape=(93880, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07894897 -0.0657959  -0.07894897 ... -0.05264282 -0.03945923\n"," -0.03945923], shape=(93880,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00350952]\n"," [0.00350952]\n"," [0.00299072]\n"," ...\n"," [0.01651001]\n"," [0.01550293]\n"," [0.01400757]], shape=(47102, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00350952 0.00350952 0.00299072 ... 0.01651001 0.01550293 0.01400757], shape=(47102,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01638794]\n"," [0.01638794]\n"," [0.01638794]\n"," ...\n"," [0.13113403]\n"," [0.14099121]\n"," [0.15408325]], shape=(21674, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01638794 0.01638794 0.01638794 ... 0.13113403 0.14099121 0.15408325], shape=(21674,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02532959]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.02532959]\n"," [-0.02532959]\n"," [-0.01266479]], shape=(34962, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02532959  0.          0.         ... -0.02532959 -0.02532959\n"," -0.01266479], shape=(34962,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03170776]\n"," [-0.02880859]\n"," [-0.02880859]\n"," ...\n"," [-0.03457642]\n"," [-0.03747559]\n"," [-0.03457642]], shape=(25412, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03170776 -0.02880859 -0.02880859 ... -0.03457642 -0.03747559\n"," -0.03457642], shape=(25412,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04403687]\n"," [-0.04205322]\n"," [-0.03903198]\n"," ...\n"," [-0.02703857]\n"," [-0.02401733]\n"," [-0.02703857]], shape=(65608, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04403687 -0.04205322 -0.03903198 ... -0.02703857 -0.02401733\n"," -0.02703857], shape=(65608,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03518677]\n"," [0.05014038]\n"," [0.04489136]\n"," ...\n"," [0.02038574]\n"," [0.02124023]\n"," [0.02151489]], shape=(88620, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03518677 0.05014038 0.04489136 ... 0.02038574 0.02124023 0.02151489], shape=(88620,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03314209]\n"," [-0.03866577]\n"," [-0.05523682]\n"," ...\n"," [ 0.01104736]\n"," [ 0.01657104]\n"," [ 0.01657104]], shape=(35274, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03314209 -0.03866577 -0.05523682 ...  0.01104736  0.01657104\n","  0.01657104], shape=(35274,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00500488]\n"," [ 0.00674438]\n"," [ 0.0062561 ]\n"," ...\n"," [-0.02731323]\n"," [-0.02304077]\n"," [-0.01669312]], shape=(26014, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00500488  0.00674438  0.0062561  ... -0.02731323 -0.02304077\n"," -0.01669312], shape=(26014,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07107544]\n"," [-0.08508301]\n"," [-0.04403687]\n"," ...\n"," [-0.05606079]\n"," [-0.05905151]\n"," [-0.05404663]], shape=(68754, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07107544 -0.08508301 -0.04403687 ... -0.05606079 -0.05905151\n"," -0.05404663], shape=(68754,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00253296]\n"," [-0.00616455]\n"," [-0.00924683]\n"," ...\n"," [ 0.02011108]\n"," [ 0.01837158]\n"," [ 0.01358032]], shape=(18644, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00253296 -0.00616455 -0.00924683 ...  0.02011108  0.01837158\n","  0.01358032], shape=(18644,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22763062]\n"," [-0.21139526]\n"," [-0.1869812 ]\n"," ...\n"," [-0.17074585]\n"," [-0.16259766]\n"," [-0.17074585]], shape=(43284, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22763062 -0.21139526 -0.1869812  ... -0.17074585 -0.16259766\n"," -0.17074585], shape=(43284,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02023315]\n"," [-0.02890015]\n"," [-0.02600098]\n"," ...\n"," [-0.03466797]\n"," [-0.03179932]\n"," [-0.03179932]], shape=(28304, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02023315 -0.02890015 -0.02600098 ... -0.03466797 -0.03179932\n"," -0.03179932], shape=(28304,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1111145 ]\n"," [-0.11538696]\n"," [-0.05187988]\n"," ...\n"," [-0.06900024]\n"," [-0.06472778]\n"," [-0.06838989]], shape=(34652, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1111145  -0.11538696 -0.05187988 ... -0.06900024 -0.06472778\n"," -0.06838989], shape=(34652,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.591156  ]\n"," [0.51934814]\n"," [0.44198608]\n"," ...\n"," [0.03314209]\n"," [0.03866577]\n"," [0.03314209]], shape=(60506, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.591156   0.51934814 0.44198608 ... 0.03314209 0.03866577 0.03314209], shape=(60506,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01623535]\n"," [-0.01748657]\n"," [-0.01873779]\n"," ...\n"," [-0.00875854]\n"," [-0.01000977]\n"," [-0.01000977]], shape=(46554, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01623535 -0.01748657 -0.01873779 ... -0.00875854 -0.01000977\n"," -0.01000977], shape=(46554,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1550293 ]\n"," [-0.1550293 ]\n"," [-0.17053223]\n"," ...\n"," [ 0.03875732]\n"," [ 0.01550293]\n"," [-0.01550293]], shape=(24636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1550293  -0.1550293  -0.17053223 ...  0.03875732  0.01550293\n"," -0.01550293], shape=(24636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04092407]\n"," [-0.05847168]\n"," [-0.05847168]\n"," ...\n"," [-0.47369385]\n"," [-0.52630615]\n"," [-0.555542  ]], shape=(45378, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04092407 -0.05847168 -0.05847168 ... -0.47369385 -0.52630615\n"," -0.555542  ], shape=(45378,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02197266]\n"," [0.03540039]\n"," [0.0378418 ]\n"," ...\n"," [0.02563477]\n"," [0.02746582]\n"," [0.03051758]], shape=(40940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02197266 0.03540039 0.0378418  ... 0.02563477 0.02746582 0.03051758], shape=(40940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09951782]\n"," [-0.08340454]\n"," [-0.06445312]\n"," ...\n"," [-0.00473022]\n"," [-0.00189209]\n"," [-0.00189209]], shape=(34618, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09951782 -0.08340454 -0.06445312 ... -0.00473022 -0.00189209\n"," -0.00189209], shape=(34618,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.57525635]\n"," [ 0.5765381 ]\n"," [ 0.5786438 ]\n"," ...\n"," [-0.15689087]\n"," [-0.1590271 ]\n"," [-0.16113281]], shape=(39124, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.57525635  0.5765381   0.5786438  ... -0.15689087 -0.1590271\n"," -0.16113281], shape=(39124,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04354858]\n"," [0.02978516]\n"," [0.02178955]\n"," ...\n"," [0.06045532]\n"," [0.06533813]\n"," [0.06216431]], shape=(55056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04354858 0.02978516 0.02178955 ... 0.06045532 0.06533813 0.06216431], shape=(55056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01361084]\n"," [-0.02722168]\n"," [-0.01361084]\n"," ...\n"," [-0.01361084]\n"," [-0.00680542]\n"," [-0.00680542]], shape=(45146, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01361084 -0.02722168 -0.01361084 ... -0.01361084 -0.00680542\n"," -0.00680542], shape=(45146,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16259766]\n"," [-0.17886353]\n"," [-0.21139526]\n"," ...\n"," [-0.21139526]\n"," [-0.21139526]\n"," [-0.1869812 ]], shape=(21562, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16259766 -0.17886353 -0.21139526 ... -0.21139526 -0.21139526\n"," -0.1869812 ], shape=(21562,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01669312]\n"," [ 0.01669312]\n"," [ 0.01669312]\n"," ...\n"," [-0.00140381]\n"," [-0.00140381]\n"," [-0.00140381]], shape=(50714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01669312  0.01669312  0.01669312 ... -0.00140381 -0.00140381\n"," -0.00140381], shape=(50714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05264282]\n"," [ 0.02630615]\n"," [ 0.05264282]\n"," ...\n"," [-0.01315308]\n"," [ 0.01315308]\n"," [ 0.01315308]], shape=(89968, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05264282  0.02630615  0.05264282 ... -0.01315308  0.01315308\n","  0.01315308], shape=(89968,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02883911]\n"," [0.04226685]\n"," [0.0378418 ]\n"," ...\n"," [0.01205444]\n"," [0.01138306]\n"," [0.00927734]], shape=(55802, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02883911 0.04226685 0.0378418  ... 0.01205444 0.01138306 0.00927734], shape=(55802,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12194824]\n"," [-0.10568237]\n"," [-0.12194824]\n"," ...\n"," [-0.21951294]\n"," [-0.22763062]\n"," [-0.21951294]], shape=(47096, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12194824 -0.10568237 -0.12194824 ... -0.21951294 -0.22763062\n"," -0.21951294], shape=(47096,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01950073]\n"," [-0.02151489]\n"," [-0.02301025]\n"," ...\n"," [ 0.00350952]\n"," [ 0.00549316]\n"," [ 0.00650024]], shape=(32284, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01950073 -0.02151489 -0.02301025 ...  0.00350952  0.00549316\n","  0.00650024], shape=(32284,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00024414]\n"," [-0.00238037]\n"," [-0.00872803]\n"," ...\n"," [-0.01593018]\n"," [-0.01834106]\n"," [-0.01681519]], shape=(29988, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00024414 -0.00238037 -0.00872803 ... -0.01593018 -0.01834106\n"," -0.01681519], shape=(29988,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03341675]\n"," [-0.03341675]\n"," [-0.03341675]\n"," ...\n"," [-0.08078003]\n"," [-0.06686401]\n"," [-0.0612793 ]], shape=(48480, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03341675 -0.03341675 -0.03341675 ... -0.08078003 -0.06686401\n"," -0.0612793 ], shape=(48480,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0489502 ]\n"," [-0.04467773]\n"," [-0.03829956]\n"," ...\n"," [-0.03616333]\n"," [-0.02554321]\n"," [-0.01913452]], shape=(40742, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0489502  -0.04467773 -0.03829956 ... -0.03616333 -0.02554321\n"," -0.01913452], shape=(40742,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01303101]\n"," [-0.01220703]\n"," [-0.01303101]\n"," ...\n"," [-0.00570679]\n"," [-0.00488281]\n"," [-0.00732422]], shape=(94856, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01303101 -0.01220703 -0.01303101 ... -0.00570679 -0.00488281\n"," -0.00732422], shape=(94856,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00057983]\n"," [ 0.00119019]\n"," [ 0.00057983]\n"," ...\n"," [-0.00769043]\n"," [-0.00653076]\n"," [-0.00592041]], shape=(25332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00057983  0.00119019  0.00057983 ... -0.00769043 -0.00653076\n"," -0.00592041], shape=(25332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00805664]\n"," [-0.00805664]\n"," [-0.00939941]\n"," ...\n"," [-0.01208496]\n"," [-0.00805664]\n"," [-0.00268555]], shape=(46248, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00805664 -0.00805664 -0.00939941 ... -0.01208496 -0.00805664\n"," -0.00268555], shape=(46248,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02746582]\n"," [-0.02908325]\n"," [-0.03231812]\n"," ...\n"," [-0.00646973]\n"," [-0.00323486]\n"," [-0.00323486]], shape=(46060, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02746582 -0.02908325 -0.03231812 ... -0.00646973 -0.00323486\n"," -0.00323486], shape=(46060,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00820923]\n"," [0.00820923]\n"," [0.00820923]\n"," ...\n"," [0.01638794]\n"," [0.01638794]\n"," [0.00820923]], shape=(24444, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00820923 0.00820923 0.00820923 ... 0.01638794 0.01638794 0.00820923], shape=(24444,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02630615]\n"," [0.0657959 ]\n"," [0.0657959 ]\n"," ...\n"," [0.02630615]\n"," [0.01315308]\n"," [0.01315308]], shape=(36788, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02630615 0.0657959  0.0657959  ... 0.02630615 0.01315308 0.01315308], shape=(36788,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00250244]\n"," [-0.00628662]\n"," ...\n"," [ 0.00250244]\n"," [ 0.        ]\n"," [ 0.00878906]], shape=(34946, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00250244 -0.00628662 ...  0.00250244  0.\n","  0.00878906], shape=(34946,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02160645]\n"," [-0.01940918]\n"," [-0.02029419]\n"," ...\n"," [-0.00881958]\n"," [-0.01278687]\n"," [-0.01498413]], shape=(50770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02160645 -0.01940918 -0.02029419 ... -0.00881958 -0.01278687\n"," -0.01498413], shape=(50770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02151489]\n"," [ 0.02151489]\n"," [ 0.01998901]\n"," ...\n"," [-0.03649902]\n"," [-0.03399658]\n"," [-0.03250122]], shape=(41636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02151489  0.02151489  0.01998901 ... -0.03649902 -0.03399658\n"," -0.03250122], shape=(41636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04730225]\n"," [-0.04730225]\n"," [-0.04730225]\n"," ...\n"," [-0.06756592]\n"," [-0.0743103 ]\n"," [-0.06756592]], shape=(72620, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04730225 -0.04730225 -0.04730225 ... -0.06756592 -0.0743103\n"," -0.06756592], shape=(72620,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02801514]\n"," [-0.02648926]\n"," [-0.02700806]\n"," ...\n"," [-0.00100708]\n"," [-0.00100708]\n"," [-0.00250244]], shape=(32880, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02801514 -0.02648926 -0.02700806 ... -0.00100708 -0.00100708\n"," -0.00250244], shape=(32880,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0184021 ]\n"," [0.01226807]\n"," [0.00613403]\n"," ...\n"," [0.02453613]\n"," [0.03067017]\n"," [0.0368042 ]], shape=(40338, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0184021  0.01226807 0.00613403 ... 0.02453613 0.03067017 0.0368042 ], shape=(40338,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07858276]\n"," [-0.08673096]\n"," [-0.08673096]\n"," ...\n"," [ 0.        ]\n"," [ 0.01898193]\n"," [ 0.01898193]], shape=(17850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07858276 -0.08673096 -0.08673096 ...  0.          0.01898193\n","  0.01898193], shape=(17850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00222778]\n"," [0.00268555]\n"," [0.00198364]\n"," ...\n"," [0.0177002 ]\n"," [0.01828003]\n"," [0.01852417]], shape=(52420, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00222778 0.00268555 0.00198364 ... 0.0177002  0.01828003 0.01852417], shape=(52420,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0083313 ]\n"," [0.0055542 ]\n"," [0.0027771 ]\n"," ...\n"," [0.02365112]\n"," [0.01806641]\n"," [0.01391602]], shape=(25412, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0083313  0.0055542  0.0027771  ... 0.02365112 0.01806641 0.01391602], shape=(25412,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.2147522 ]\n"," [ 0.2147522 ]\n"," [ 0.19464111]\n"," ...\n"," [-0.19464111]\n"," [-0.19464111]\n"," [-0.19464111]], shape=(40002, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.2147522   0.2147522   0.19464111 ... -0.19464111 -0.19464111\n"," -0.19464111], shape=(40002,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14285278]\n"," [-0.14285278]\n"," [-0.14285278]\n"," ...\n"," [-0.28570557]\n"," [ 0.        ]\n"," [-0.14285278]], shape=(37268, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14285278 -0.14285278 -0.14285278 ... -0.28570557  0.\n"," -0.14285278], shape=(37268,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07745361]\n"," [-0.09155273]\n"," [-0.09155273]\n"," ...\n"," [-0.1126709 ]\n"," [-0.1126709 ]\n"," [-0.10562134]], shape=(41586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07745361 -0.09155273 -0.09155273 ... -0.1126709  -0.1126709\n"," -0.10562134], shape=(41586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01428223]\n"," [0.02856445]\n"," [0.03570557]\n"," ...\n"," [0.04284668]\n"," [0.01428223]\n"," [0.03570557]], shape=(52928, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01428223 0.02856445 0.03570557 ... 0.04284668 0.01428223 0.03570557], shape=(52928,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1184082 ]\n"," [0.07894897]\n"," [0.0657959 ]\n"," ...\n"," [0.05264282]\n"," [0.01315308]\n"," [0.        ]], shape=(61196, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1184082  0.07894897 0.0657959  ... 0.05264282 0.01315308 0.        ], shape=(61196,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03033447]\n"," [ 0.02560425]\n"," [ 0.02560425]\n"," ...\n"," [-0.12512207]\n"," [-0.12039185]\n"," [-0.11090088]], shape=(89892, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03033447  0.02560425  0.02560425 ... -0.12512207 -0.12039185\n"," -0.11090088], shape=(89892,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05932617]\n"," [-0.0647583 ]\n"," [-0.06781006]\n"," ...\n"," [-0.02279663]\n"," [-0.01693726]\n"," [-0.01498413]], shape=(34188, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05932617 -0.0647583  -0.06781006 ... -0.02279663 -0.01693726\n"," -0.01498413], shape=(34188,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01028442]\n"," [0.01617432]\n"," [0.019104  ]\n"," ...\n"," [0.01324463]\n"," [0.00881958]\n"," [0.00588989]], shape=(37194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01028442 0.01617432 0.019104   ... 0.01324463 0.00881958 0.00588989], shape=(37194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03723145]\n"," [-0.02481079]\n"," [-0.03723145]\n"," ...\n"," [ 0.02978516]\n"," [ 0.0173645 ]\n"," [ 0.01242065]], shape=(27812, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03723145 -0.02481079 -0.03723145 ...  0.02978516  0.0173645\n","  0.01242065], shape=(27812,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07806396]\n"," [-0.07073975]\n"," [-0.06341553]\n"," ...\n"," [-0.10488892]\n"," [-0.10733032]\n"," [-0.10974121]], shape=(50872, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07806396 -0.07073975 -0.06341553 ... -0.10488892 -0.10733032\n"," -0.10974121], shape=(50872,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00939941]\n"," [ 0.0015564 ]\n"," [-0.00939941]\n"," ...\n"," [-0.01568604]\n"," [-0.01409912]\n"," [-0.00784302]], shape=(23116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00939941  0.0015564  -0.00939941 ... -0.01568604 -0.01409912\n"," -0.00784302], shape=(23116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [-0.00897217]\n"," [-0.01196289]\n"," ...\n"," [-0.01913452]\n"," [-0.01733398]\n"," [-0.0161438 ]], shape=(52278, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145 -0.00897217 -0.01196289 ... -0.01913452 -0.01733398\n"," -0.0161438 ], shape=(52278,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05172729]\n"," [ 0.0574646 ]\n"," [ 0.0574646 ]\n"," ...\n"," [-0.02874756]\n"," [-0.02297974]\n"," [-0.0057373 ]], shape=(41304, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05172729  0.0574646   0.0574646  ... -0.02874756 -0.02297974\n"," -0.0057373 ], shape=(41304,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07519531]\n"," [-0.06686401]\n"," [-0.0557251 ]\n"," ...\n"," [-0.08078003]\n"," [-0.0557251 ]\n"," [-0.02786255]], shape=(37304, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07519531 -0.06686401 -0.0557251  ... -0.08078003 -0.0557251\n"," -0.02786255], shape=(37304,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02450562]\n"," [0.0249939 ]\n"," [0.0255127 ]\n"," ...\n"," [0.0085144 ]\n"," [0.00750732]\n"," [0.00549316]], shape=(80058, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02450562 0.0249939  0.0255127  ... 0.0085144  0.00750732 0.00549316], shape=(80058,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01550293]\n"," [-0.0255127 ]\n"," [-0.03500366]\n"," ...\n"," [ 0.01550293]\n"," [ 0.01348877]\n"," [ 0.01098633]], shape=(111624, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01550293 -0.0255127  -0.03500366 ...  0.01550293  0.01348877\n","  0.01098633], shape=(111624,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01168823]\n"," [ 0.        ]\n"," [-0.02923584]\n"," ...\n"," [ 0.12866211]\n"," [ 0.12866211]\n"," [ 0.09942627]], shape=(48640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01168823  0.         -0.02923584 ...  0.12866211  0.12866211\n","  0.09942627], shape=(48640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.05700684]\n"," [0.06851196]\n"," [0.07449341]\n"," ...\n"," [0.01300049]\n"," [0.01300049]\n"," [0.01098633]], shape=(23220, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.05700684 0.06851196 0.07449341 ... 0.01300049 0.01300049 0.01098633], shape=(23220,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01998901]\n"," [-0.02249146]\n"," [-0.02249146]\n"," ...\n"," [ 0.00375366]\n"," [ 0.00500488]\n"," [ 0.00750732]], shape=(27474, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01998901 -0.02249146 -0.02249146 ...  0.00375366  0.00500488\n","  0.00750732], shape=(27474,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01199341]\n"," [ 0.01098633]\n"," [ 0.00900269]\n"," ...\n"," [-0.00650024]\n"," [-0.00100708]\n"," [ 0.00201416]], shape=(32156, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01199341  0.01098633  0.00900269 ... -0.00650024 -0.00100708\n","  0.00201416], shape=(32156,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01739502]\n"," [0.03479004]\n"," [0.03479004]\n"," ...\n"," [0.01739502]\n"," [0.00869751]\n"," [0.        ]], shape=(51490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01739502 0.03479004 0.03479004 ... 0.01739502 0.00869751 0.        ], shape=(51490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02923584]\n"," [-0.04092407]\n"," [-0.05847168]\n"," ...\n"," [-0.05847168]\n"," [-0.02923584]\n"," [-0.02923584]], shape=(43880, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02923584 -0.04092407 -0.05847168 ... -0.05847168 -0.02923584\n"," -0.02923584], shape=(43880,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00125122]\n"," [0.00375366]\n"," [0.00250244]\n"," ...\n"," [0.07000732]\n"," [0.06500244]\n"," [0.0562439 ]], shape=(65522, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00125122 0.00375366 0.00250244 ... 0.07000732 0.06500244 0.0562439 ], shape=(65522,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00244141]\n"," [-0.00244141]\n"," [-0.00244141]\n"," ...\n"," [-0.00485229]\n"," [-0.00244141]\n"," [ 0.        ]], shape=(39696, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00244141 -0.00244141 -0.00244141 ... -0.00485229 -0.00244141\n","  0.        ], shape=(39696,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01229858]\n"," [-0.01229858]\n"," [-0.00616455]\n"," ...\n"," [-0.02154541]\n"," [-0.01846313]\n"," [-0.01538086]], shape=(85308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01229858 -0.01229858 -0.00616455 ... -0.02154541 -0.01846313\n"," -0.01538086], shape=(85308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04177856]\n"," [-0.02786255]\n"," [-0.01950073]\n"," ...\n"," [ 0.13650513]\n"," [ 0.11700439]\n"," [ 0.10864258]], shape=(38756, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04177856 -0.02786255 -0.01950073 ...  0.13650513  0.11700439\n","  0.10864258], shape=(38756,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03466797]\n"," [-0.03466797]\n"," [-0.0296936 ]\n"," ...\n"," [-0.06436157]\n"," [-0.07919312]\n"," [-0.07919312]], shape=(37146, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03466797 -0.03466797 -0.0296936  ... -0.06436157 -0.07919312\n"," -0.07919312], shape=(37146,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05227661]\n"," [ 0.04040527]\n"," [ 0.03048706]\n"," ...\n"," [-0.02416992]\n"," [-0.02612305]\n"," [-0.02508545]], shape=(31666, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05227661  0.04040527  0.03048706 ... -0.02416992 -0.02612305\n"," -0.02508545], shape=(31666,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16113281]\n"," [-0.15985107]\n"," [-0.15774536]\n"," ...\n"," [-0.19216919]\n"," [-0.19006348]\n"," [-0.18579102]], shape=(32000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16113281 -0.15985107 -0.15774536 ... -0.19216919 -0.19006348\n"," -0.18579102], shape=(32000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17050171]\n"," [-0.21310425]\n"," [-0.21386719]\n"," ...\n"," [-0.49456787]\n"," [-0.49957275]\n"," [-0.5031433 ]], shape=(36114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17050171 -0.21310425 -0.21386719 ... -0.49456787 -0.49957275\n"," -0.5031433 ], shape=(36114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.01040649]\n"," ...\n"," [0.01040649]\n"," [0.01040649]\n"," [0.01040649]], shape=(18662, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.01040649 ... 0.01040649 0.01040649 0.01040649], shape=(18662,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.6095276 ]\n"," [-0.6145935 ]\n"," [-0.61883545]\n"," ...\n"," [-0.88687134]\n"," [-0.8856201 ]\n"," [-0.8847656 ]], shape=(45474, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.6095276  -0.6145935  -0.61883545 ... -0.88687134 -0.8856201\n"," -0.8847656 ], shape=(45474,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.19534302]\n"," [-0.21282959]\n"," [-0.21572876]\n"," ...\n"," [-0.04666138]\n"," [-0.04373169]\n"," [-0.04373169]], shape=(30760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.19534302 -0.21282959 -0.21572876 ... -0.04666138 -0.04373169\n"," -0.04373169], shape=(30760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.6140137 ]\n"," [-0.69033813]\n"," [-0.75201416]\n"," ...\n"," [ 0.11483765]\n"," [ 0.10400391]\n"," [ 0.08981323]], shape=(102688, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.6140137  -0.69033813 -0.75201416 ...  0.11483765  0.10400391\n","  0.08981323], shape=(102688,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.23913574]\n"," [ 0.26397705]\n"," [ 0.28881836]\n"," ...\n"," [-0.00311279]\n"," [-0.00311279]\n"," [ 0.        ]], shape=(67232, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.23913574  0.26397705  0.28881836 ... -0.00311279 -0.00311279\n","  0.        ], shape=(67232,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03341675]\n"," [0.0557251 ]\n"," [0.07519531]\n"," ...\n"," [0.0557251 ]\n"," [0.0557251 ]\n"," [0.0557251 ]], shape=(42076, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03341675 0.0557251  0.07519531 ... 0.0557251  0.0557251  0.0557251 ], shape=(42076,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03970337]\n"," [-0.03234863]\n"," [-0.02206421]\n"," ...\n"," [-0.01028442]\n"," [-0.00881958]\n"," [-0.01028442]], shape=(50276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03970337 -0.03234863 -0.02206421 ... -0.01028442 -0.00881958\n"," -0.01028442], shape=(50276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00973511]\n"," [ 0.00485229]\n"," [-0.00244141]\n"," ...\n"," [-0.0072937 ]\n"," [-0.00485229]\n"," [ 0.00244141]], shape=(48380, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00973511  0.00485229 -0.00244141 ... -0.0072937  -0.00485229\n","  0.00244141], shape=(48380,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00424194]\n"," [-0.01275635]\n"," [-0.01489258]\n"," ...\n"," [ 0.00213623]\n"," [ 0.0085144 ]\n"," [ 0.01065063]], shape=(80254, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00424194 -0.01275635 -0.01489258 ...  0.00213623  0.0085144\n","  0.01065063], shape=(80254,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02630615]\n"," [-0.02630615]\n"," [-0.01879883]\n"," ...\n"," [ 0.03759766]\n"," [ 0.02630615]\n"," [ 0.01879883]], shape=(106524, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02630615 -0.02630615 -0.01879883 ...  0.03759766  0.02630615\n","  0.01879883], shape=(106524,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03125]\n"," [0.0625 ]\n"," [0.09375]\n"," ...\n"," [0.0625 ]\n"," [0.0625 ]\n"," [0.0625 ]], shape=(35240, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03125 0.0625  0.09375 ... 0.0625  0.0625  0.0625 ], shape=(35240,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03076172]\n"," [-0.02883911]\n"," [-0.02883911]\n"," ...\n"," [-0.13845825]\n"," [-0.14807129]\n"," [-0.14807129]], shape=(30434, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03076172 -0.02883911 -0.02883911 ... -0.13845825 -0.14807129\n"," -0.14807129], shape=(30434,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1720581 ]\n"," [-0.26342773]\n"," [-0.3171997 ]\n"," ...\n"," [-0.03762817]\n"," [-0.05377197]\n"," [-0.03762817]], shape=(31946, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1720581  -0.26342773 -0.3171997  ... -0.03762817 -0.05377197\n"," -0.03762817], shape=(31946,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.32769775]\n"," [-0.37930298]\n"," [-0.34835815]\n"," ...\n"," [ 0.37457275]\n"," [ 0.3821106 ]\n"," [ 0.39022827]], shape=(54754, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.32769775 -0.37930298 -0.34835815 ...  0.37457275  0.3821106\n","  0.39022827], shape=(54754,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0562439 ]\n"," [ 0.05374146]\n"," [ 0.05374146]\n"," ...\n"," [-0.01748657]\n"," [-0.01623535]\n"," [-0.01748657]], shape=(33876, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0562439   0.05374146  0.05374146 ... -0.01748657 -0.01623535\n"," -0.01748657], shape=(33876,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06350708]\n"," [ 0.05291748]\n"," [ 0.04232788]\n"," ...\n"," [-0.02645874]\n"," [-0.02645874]\n"," [-0.0211792 ]], shape=(56668, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06350708  0.05291748  0.04232788 ... -0.02645874 -0.02645874\n"," -0.0211792 ], shape=(56668,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02438354]\n"," [0.00610352]\n"," [0.00610352]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.        ]], shape=(39866, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02438354 0.00610352 0.00610352 ... 0.         0.         0.        ], shape=(39866,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01281738]\n"," [0.01489258]\n"," [0.01358032]], shape=(53770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01281738 0.01489258 0.01358032], shape=(53770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03268433]\n"," [-0.0435791 ]\n"," [-0.04794312]\n"," ...\n"," [ 0.        ]\n"," [-0.01089478]\n"," [-0.02178955]], shape=(56978, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03268433 -0.0435791  -0.04794312 ...  0.         -0.01089478\n"," -0.02178955], shape=(56978,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0050354 ]\n"," [-0.0050354 ]\n"," [ 0.        ]\n"," ...\n"," [-0.02020264]\n"," [-0.05554199]\n"," [-0.1111145 ]], shape=(34074, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0050354  -0.0050354   0.         ... -0.02020264 -0.05554199\n"," -0.1111145 ], shape=(34074,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05831909]\n"," [-0.05831909]\n"," [-0.05249023]\n"," ...\n"," [-0.05831909]\n"," [-0.05831909]\n"," [-0.05831909]], shape=(51472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05831909 -0.05831909 -0.05249023 ... -0.05831909 -0.05831909\n"," -0.05831909], shape=(51472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04394531]\n"," [-0.04943848]\n"," [-0.05981445]\n"," ...\n"," [ 0.02685547]\n"," [ 0.01831055]\n"," [ 0.01098633]], shape=(41244, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04394531 -0.04943848 -0.05981445 ...  0.02685547  0.01831055\n","  0.01098633], shape=(41244,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01000977]\n"," [ 0.00875854]\n"," [ 0.00875854]\n"," ...\n"," [-0.00250244]\n"," [-0.00250244]\n"," [ 0.        ]], shape=(36888, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01000977  0.00875854  0.00875854 ... -0.00250244 -0.00250244\n","  0.        ], shape=(36888,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1315918 ]\n"," [-0.12573242]\n"," [-0.12573242]\n"," ...\n"," [-0.06140137]\n"," [-0.06140137]\n"," [-0.06433105]], shape=(32632, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1315918  -0.12573242 -0.12573242 ... -0.06140137 -0.06140137\n"," -0.06433105], shape=(32632,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04598999]\n"," [ 0.01724243]\n"," [ 0.01150513]\n"," ...\n"," [-0.01724243]\n"," [-0.02297974]\n"," [-0.02297974]], shape=(49332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04598999  0.01724243  0.01150513 ... -0.01724243 -0.02297974\n"," -0.02297974], shape=(49332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.22192383]\n"," [ 0.21148682]\n"," [ 0.1984253 ]\n"," ...\n"," [ 0.03134155]\n"," [-0.00521851]\n"," [-0.03134155]], shape=(56690, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.22192383  0.21148682  0.1984253  ...  0.03134155 -0.00521851\n"," -0.03134155], shape=(56690,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.3265381 ]\n"," [ 0.34014893]\n"," [ 0.3333435 ]\n"," ...\n"," [-0.00680542]\n"," [-0.01361084]\n"," [ 0.        ]], shape=(33826, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.3265381   0.34014893  0.3333435  ... -0.00680542 -0.01361084\n","  0.        ], shape=(33826,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01879883]\n"," [-0.01879883]\n"," [-0.01315308]\n"," ...\n"," [-0.00375366]\n"," [-0.00939941]\n"," [-0.0112915 ]], shape=(45876, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01879883 -0.01879883 -0.01315308 ... -0.00375366 -0.00939941\n"," -0.0112915 ], shape=(45876,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08364868]\n"," [-0.08364868]\n"," [-0.09454346]\n"," ...\n"," [-0.3418274 ]\n"," [-0.32363892]\n"," [-0.31637573]], shape=(39516, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08364868 -0.08364868 -0.09454346 ... -0.3418274  -0.32363892\n"," -0.31637573], shape=(39516,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06555176]\n"," [-0.06832886]\n"," [-0.07058716]\n"," ...\n"," [-0.00045776]\n"," [ 0.00253296]\n"," [ 0.00436401]], shape=(19352, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06555176 -0.06832886 -0.07058716 ... -0.00045776  0.00253296\n","  0.00436401], shape=(19352,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00421143]\n"," [-0.01049805]\n"," [-0.01470947]\n"," ...\n"," [ 0.00421143]\n"," [ 0.00421143]\n"," [ 0.01049805]], shape=(49396, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00421143 -0.01049805 -0.01470947 ...  0.00421143  0.00421143\n","  0.01049805], shape=(49396,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05499268]\n"," [-0.04501343]\n"," [-0.05499268]\n"," ...\n"," [ 0.16000366]\n"," [ 0.14498901]\n"," [ 0.15499878]], shape=(37136, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05499268 -0.04501343 -0.05499268 ...  0.16000366  0.14498901\n","  0.15499878], shape=(37136,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10974121]\n"," [-0.10726929]\n"," [-0.09741211]\n"," ...\n"," [-0.02096558]\n"," [-0.02218628]\n"," [-0.01971436]], shape=(39820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10974121 -0.10726929 -0.09741211 ... -0.02096558 -0.02218628\n"," -0.01971436], shape=(39820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00375366]\n"," [0.00500488]\n"," [0.00750732]\n"," ...\n"," [0.00375366]\n"," [0.00750732]\n"," [0.01126099]], shape=(61218, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00375366 0.00500488 0.00750732 ... 0.00375366 0.00750732 0.01126099], shape=(61218,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08236694]\n"," [0.12942505]\n"," [0.16470337]\n"," ...\n"," [0.37646484]\n"," [0.3529358 ]\n"," [0.24707031]], shape=(49572, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08236694 0.12942505 0.16470337 ... 0.37646484 0.3529358  0.24707031], shape=(49572,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00500488]\n"," [ 0.        ]\n"," [-0.00500488]\n"," ...\n"," [ 0.08499146]\n"," [ 0.06500244]\n"," [ 0.04251099]], shape=(47058, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00500488  0.         -0.00500488 ...  0.08499146  0.06500244\n","  0.04251099], shape=(47058,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1678772 ]\n"," [-0.1642456 ]\n"," [-0.15875244]\n"," ...\n"," [-0.00912476]\n"," [-0.00912476]\n"," [-0.0072937 ]], shape=(38894, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1678772  -0.1642456  -0.15875244 ... -0.00912476 -0.00912476\n"," -0.0072937 ], shape=(38894,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01605225]\n"," [ 0.01605225]\n"," [ 0.02139282]\n"," ...\n"," [-0.01068115]\n"," [-0.00534058]\n"," [-0.01068115]], shape=(45994, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01605225  0.01605225  0.02139282 ... -0.01068115 -0.00534058\n"," -0.01068115], shape=(45994,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08392334]\n"," [-0.06991577]\n"," [-0.06292725]\n"," ...\n"," [ 0.00698853]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(55368, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08392334 -0.06991577 -0.06292725 ...  0.00698853  0.\n","  0.        ], shape=(55368,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06756592]\n"," [-0.0743103 ]\n"," [-0.08108521]\n"," ...\n"," [ 0.01351929]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(100982, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06756592 -0.0743103  -0.08108521 ...  0.01351929  0.\n","  0.        ], shape=(100982,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00299072]\n"," [0.        ]\n"," ...\n"," [0.00598145]\n"," [0.00598145]\n"," [0.00299072]], shape=(46528, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00299072 0.         ... 0.00598145 0.00598145 0.00299072], shape=(46528,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00680542]\n"," [-0.01361084]\n"," ...\n"," [-0.040802  ]\n"," [-0.0340271 ]\n"," [-0.040802  ]], shape=(42698, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00680542 -0.01361084 ... -0.040802   -0.0340271\n"," -0.040802  ], shape=(42698,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.00341797]\n"," ...\n"," [-0.06826782]\n"," [-0.05459595]\n"," [-0.04437256]], shape=(64500, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.00341797 ... -0.06826782 -0.05459595\n"," -0.04437256], shape=(64500,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.12347412]\n"," [0.10317993]\n"," [0.07470703]\n"," ...\n"," [0.01467896]\n"," [0.01467896]\n"," [0.01596069]], shape=(40398, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.12347412 0.10317993 0.07470703 ... 0.01467896 0.01467896 0.01596069], shape=(40398,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03649902]\n"," [ 0.03649902]\n"," [ 0.02554321]\n"," ...\n"," [-0.02554321]\n"," [-0.01824951]\n"," [-0.01824951]], shape=(45298, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03649902  0.03649902  0.02554321 ... -0.02554321 -0.01824951\n"," -0.01824951], shape=(45298,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0032959 ]\n"," [ 0.0065918 ]\n"," [ 0.01321411]\n"," ...\n"," [-0.01651001]\n"," [-0.01321411]\n"," [-0.01321411]], shape=(49718, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0032959   0.0065918   0.01321411 ... -0.01651001 -0.01321411\n"," -0.01321411], shape=(49718,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0015564 ]\n"," [ 0.        ]\n"," [ 0.0015564 ]\n"," ...\n"," [-0.00314331]\n"," [-0.00314331]\n"," [-0.00314331]], shape=(91910, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0015564   0.          0.0015564  ... -0.00314331 -0.00314331\n"," -0.00314331], shape=(91910,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08096313]\n"," [-0.08096313]\n"," [-0.08908081]\n"," ...\n"," [-0.08908081]\n"," [-0.08908081]\n"," [-0.08908081]], shape=(45484, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08096313 -0.08096313 -0.08908081 ... -0.08908081 -0.08908081\n"," -0.08908081], shape=(45484,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0149231 ]\n"," [-0.0149231 ]\n"," [-0.0149231 ]\n"," ...\n"," [ 0.01193237]\n"," [ 0.02090454]\n"," [ 0.03582764]], shape=(38714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0149231  -0.0149231  -0.0149231  ...  0.01193237  0.02090454\n","  0.03582764], shape=(38714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02429199]\n"," [-0.02355957]\n"," [-0.02133179]\n"," ...\n"," [-0.00735474]\n"," [-0.00369263]\n"," [-0.00662231]], shape=(35672, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02429199 -0.02355957 -0.02133179 ... -0.00735474 -0.00369263\n"," -0.00662231], shape=(35672,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0149231 ]\n"," [ 0.        ]\n"," [-0.00598145]\n"," ...\n"," [ 0.00598145]\n"," [ 0.00598145]\n"," [ 0.0149231 ]], shape=(34644, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0149231   0.         -0.00598145 ...  0.00598145  0.00598145\n","  0.0149231 ], shape=(34644,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04348755]\n"," [-0.04348755]\n"," [-0.03726196]\n"," ...\n"," [-0.01242065]\n"," [-0.01242065]\n"," [-0.01864624]], shape=(54696, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04348755 -0.04348755 -0.03726196 ... -0.01242065 -0.01242065\n"," -0.01864624], shape=(54696,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00683594]\n"," [ 0.00683594]\n"," ...\n"," [-0.01705933]\n"," [ 0.00683594]\n"," [ 0.02047729]], shape=(38150, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00683594  0.00683594 ... -0.01705933  0.00683594\n","  0.02047729], shape=(38150,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02822876]\n"," [ 0.02471924]\n"," [ 0.01763916]\n"," ...\n"," [-0.03292847]\n"," [-0.03765869]\n"," [-0.04000854]], shape=(43376, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02822876  0.02471924  0.01763916 ... -0.03292847 -0.03765869\n"," -0.04000854], shape=(43376,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00250244]\n"," [0.00250244]\n"," [0.00250244]\n"," ...\n"," [0.01126099]\n"," [0.01000977]\n"," [0.00875854]], shape=(39708, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00250244 0.00250244 0.00250244 ... 0.01126099 0.01000977 0.00875854], shape=(39708,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01000977]\n"," [0.00875854]\n"," [0.0062561 ]\n"," ...\n"," [0.05374146]\n"," [0.04376221]\n"," [0.03625488]], shape=(85872, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01000977 0.00875854 0.0062561  ... 0.05374146 0.04376221 0.03625488], shape=(85872,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.24850464]\n"," [-0.22698975]\n"," [-0.19799805]\n"," ...\n"," [ 0.00900269]\n"," [ 0.00799561]\n"," [ 0.00601196]], shape=(90582, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.24850464 -0.22698975 -0.19799805 ...  0.00900269  0.00799561\n","  0.00601196], shape=(90582,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07019043]\n"," [-0.01168823]\n"," [-0.09942627]\n"," ...\n"," [-0.04092407]\n"," [-0.05847168]\n"," [-0.04092407]], shape=(45296, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07019043 -0.01168823 -0.09942627 ... -0.04092407 -0.05847168\n"," -0.04092407], shape=(45296,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01922607]\n"," [-0.02746582]\n"," [-0.01922607]\n"," ...\n"," [ 0.00549316]\n"," [ 0.        ]\n"," [ 0.00549316]], shape=(86428, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01922607 -0.02746582 -0.01922607 ...  0.00549316  0.\n","  0.00549316], shape=(86428,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01837158]\n"," [ 0.04043579]\n"," [ 0.04412842]\n"," ...\n"," [-0.01470947]\n"," [-0.01470947]\n"," [-0.00366211]], shape=(53744, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01837158  0.04043579  0.04412842 ... -0.01470947 -0.01470947\n"," -0.00366211], shape=(53744,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14285278]\n"," [ 0.14285278]\n"," [ 0.14285278]\n"," ...\n"," [ 0.14285278]\n"," [ 0.28570557]\n"," [ 0.        ]], shape=(22404, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14285278  0.14285278  0.14285278 ...  0.14285278  0.28570557\n","  0.        ], shape=(22404,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01266479]\n"," [-0.01266479]\n"," [-0.02532959]\n"," ...\n"," [ 0.02532959]\n"," [ 0.02532959]\n"," [ 0.01266479]], shape=(45812, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01266479 -0.01266479 -0.02532959 ...  0.02532959  0.02532959\n","  0.01266479], shape=(45812,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13858032]\n"," [-0.13296509]\n"," [-0.11984253]\n"," ...\n"," [ 0.18164062]\n"," [ 0.16854858]\n"," [ 0.14794922]], shape=(50906, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13858032 -0.13296509 -0.11984253 ...  0.18164062  0.16854858\n","  0.14794922], shape=(50906,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.0057373 ]\n"," [ 0.        ]\n"," ...\n"," [-0.01431274]\n"," [-0.01431274]\n"," [-0.01431274]], shape=(56906, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.0057373   0.         ... -0.01431274 -0.01431274\n"," -0.01431274], shape=(56906,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.209198  ]\n"," [-0.20407104]\n"," [-0.18878174]\n"," ...\n"," [-0.01019287]\n"," [-0.01275635]\n"," [-0.01275635]], shape=(57932, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.209198   -0.20407104 -0.18878174 ... -0.01019287 -0.01275635\n"," -0.01275635], shape=(57932,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00750732]\n"," [ 0.00500488]\n"," [ 0.00375366]\n"," ...\n"," [-0.00875854]\n"," [-0.01376343]\n"," [-0.01873779]], shape=(52710, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00750732  0.00500488  0.00375366 ... -0.00875854 -0.01376343\n"," -0.01873779], shape=(52710,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02099609]\n"," [0.01470947]\n"," [0.01049805]\n"," ...\n"," [0.00421143]\n"," [0.01049805]\n"," [0.00421143]], shape=(40560, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02099609 0.01470947 0.01049805 ... 0.00421143 0.01049805 0.00421143], shape=(40560,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00305176]\n"," [ 0.        ]\n"," [-0.00976562]\n"," ...\n"," [ 0.02990723]\n"," [ 0.03112793]\n"," [ 0.0189209 ]], shape=(33440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00305176  0.         -0.00976562 ...  0.02990723  0.03112793\n","  0.0189209 ], shape=(33440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02502441]\n"," [-0.01913452]\n"," [-0.01251221]\n"," ...\n"," [-0.04046631]\n"," [-0.07064819]\n"," [-0.09344482]], shape=(71430, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02502441 -0.01913452 -0.01251221 ... -0.04046631 -0.07064819\n"," -0.09344482], shape=(71430,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.710022  ]\n"," [-0.90841675]\n"," [-1.        ]\n"," ...\n"," [ 0.6037903 ]\n"," [ 0.55126953]\n"," [ 0.5       ]], shape=(47174, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.710022   -0.90841675 -1.         ...  0.6037903   0.55126953\n","  0.5       ], shape=(47174,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01589966]\n"," [-0.0227356 ]\n"," [-0.0227356 ]\n"," ...\n"," [-0.3727417 ]\n"," [-0.33862305]\n"," [-0.29318237]], shape=(40646, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01589966 -0.0227356  -0.0227356  ... -0.3727417  -0.33862305\n"," -0.29318237], shape=(40646,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00253296]\n"," [ 0.00253296]\n"," [ 0.01522827]\n"," ...\n"," [ 0.25634766]\n"," [ 0.3070984 ]\n"," [ 0.3400879 ]], shape=(19860, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00253296  0.00253296  0.01522827 ...  0.25634766  0.3070984\n","  0.3400879 ], shape=(19860,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01501465]\n"," [-0.01501465]\n"," [-0.02001953]\n"," ...\n"," [-0.02401733]\n"," [-0.02703857]\n"," [-0.02703857]], shape=(47120, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01501465 -0.01501465 -0.02001953 ... -0.02401733 -0.02703857\n"," -0.02703857], shape=(47120,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.00527954]\n"," ...\n"," [-0.0105896 ]\n"," [-0.0105896 ]\n"," [-0.0105896 ]], shape=(56160, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.00527954 ... -0.0105896  -0.0105896\n"," -0.0105896 ], shape=(56160,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1875    ]\n"," [0.1354065 ]\n"," [0.04165649]\n"," ...\n"," [0.2083435 ]\n"," [0.15625   ]\n"," [0.10415649]], shape=(25374, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1875     0.1354065  0.04165649 ... 0.2083435  0.15625    0.10415649], shape=(25374,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01547241]\n"," [ 0.01287842]\n"," [ 0.01287842]\n"," ...\n"," [-0.00256348]\n"," [ 0.        ]\n"," [-0.00256348]], shape=(35214, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01547241  0.01287842  0.01287842 ... -0.00256348  0.\n"," -0.00256348], shape=(35214,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08901978]\n"," [-0.08483887]\n"," [-0.07788086]\n"," ...\n"," [ 0.00973511]\n"," [ 0.01251221]\n"," [ 0.01251221]], shape=(67704, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08901978 -0.08483887 -0.07788086 ...  0.00973511  0.01251221\n","  0.01251221], shape=(67704,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.0062561 ]\n"," [0.        ]\n"," ...\n"," [0.04376221]\n"," [0.0375061 ]\n"," [0.03125   ]], shape=(48478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.0062561  0.         ... 0.04376221 0.0375061  0.03125   ], shape=(48478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05535889]\n"," [-0.05883789]\n"," [-0.06228638]\n"," ...\n"," [-0.11071777]\n"," [-0.11071777]\n"," [-0.12109375]], shape=(37640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05535889 -0.05883789 -0.06228638 ... -0.11071777 -0.11071777\n"," -0.12109375], shape=(37640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15789795]\n"," [-0.11740112]\n"," [-0.09716797]\n"," ...\n"," [-0.04049683]\n"," [-0.04049683]\n"," [-0.04858398]], shape=(51956, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15789795 -0.11740112 -0.09716797 ... -0.04049683 -0.04049683\n"," -0.04858398], shape=(51956,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.20877075]\n"," [ 0.20877075]\n"," [ 0.20959473]\n"," ...\n"," [-0.3541565 ]\n"," [-0.34991455]\n"," [-0.3456726 ]], shape=(55454, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.20877075  0.20877075  0.20959473 ... -0.3541565  -0.34991455\n"," -0.3456726 ], shape=(55454,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0105896 ]\n"," [-0.01177979]\n"," [-0.00704956]\n"," ...\n"," [-0.09881592]\n"," [-0.07647705]\n"," [-0.04000854]], shape=(53334, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0105896  -0.01177979 -0.00704956 ... -0.09881592 -0.07647705\n"," -0.04000854], shape=(53334,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0149231 ]\n"," [-0.0149231 ]\n"," [-0.02090454]\n"," ...\n"," [ 0.02090454]\n"," [ 0.02984619]\n"," [ 0.03582764]], shape=(45848, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0149231  -0.0149231  -0.02090454 ...  0.02090454  0.02984619\n","  0.03582764], shape=(45848,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00201416]\n"," [ 0.00100708]\n"," [-0.00048828]\n"," ...\n"," [-0.00549316]\n"," [-0.00750732]\n"," [-0.00900269]], shape=(42392, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00201416  0.00100708 -0.00048828 ... -0.00549316 -0.00750732\n"," -0.00900269], shape=(42392,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04095459]\n"," [-0.0307312 ]\n"," [-0.0307312 ]\n"," ...\n"," [-0.07507324]\n"," [-0.05801392]\n"," [-0.03753662]], shape=(76204, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04095459 -0.0307312  -0.0307312  ... -0.07507324 -0.05801392\n"," -0.03753662], shape=(76204,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02133179]\n"," [-0.02133179]\n"," [-0.02346802]\n"," ...\n"," [ 0.03839111]\n"," [ 0.03839111]\n"," [ 0.02770996]], shape=(45978, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02133179 -0.02133179 -0.02346802 ...  0.03839111  0.03839111\n","  0.02770996], shape=(45978,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04794312]\n"," [-0.0435791 ]\n"," [-0.03704834]\n"," ...\n"," [-0.02178955]\n"," [-0.02178955]\n"," [-0.02178955]], shape=(56650, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04794312 -0.0435791  -0.03704834 ... -0.02178955 -0.02178955\n"," -0.02178955], shape=(56650,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01776123]\n"," [0.01565552]\n"," [0.0135498 ]\n"," ...\n"," [0.23773193]\n"," [0.23052979]\n"," [0.22335815]], shape=(49868, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01776123 0.01565552 0.0135498  ... 0.23773193 0.23052979 0.22335815], shape=(49868,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.2624817 ]\n"," [ 0.2559204 ]\n"," [ 0.24407959]\n"," ...\n"," [-0.00131226]\n"," [-0.00131226]\n"," [ 0.00131226]], shape=(46714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.2624817   0.2559204   0.24407959 ... -0.00131226 -0.00131226\n","  0.00131226], shape=(46714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00750732]\n"," [-0.00750732]\n"," [-0.00750732]\n"," ...\n"," [ 0.0062561 ]\n"," [ 0.00750732]\n"," [ 0.00875854]], shape=(101058, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00750732 -0.00750732 -0.00750732 ...  0.0062561   0.00750732\n","  0.00875854], shape=(101058,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02114868]\n"," [-0.01794434]\n"," [-0.01473999]\n"," ...\n"," [ 0.01409912]\n"," [ 0.01281738]\n"," [ 0.01089478]], shape=(23482, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02114868 -0.01794434 -0.01473999 ...  0.01409912  0.01281738\n","  0.01089478], shape=(23482,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00262451]\n"," [0.0027771 ]\n"," [0.00262451]\n"," ...\n"," [0.04852295]\n"," [0.05264282]\n"," [0.05285645]], shape=(49746, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00262451 0.0027771  0.00262451 ... 0.04852295 0.05264282 0.05285645], shape=(49746,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01873779]\n"," [-0.01251221]\n"," [-0.00500488]\n"," ...\n"," [ 0.04626465]\n"," [ 0.04000854]\n"," [ 0.03500366]], shape=(34718, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01873779 -0.01251221 -0.00500488 ...  0.04626465  0.04000854\n","  0.03500366], shape=(34718,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.09945679]\n"," [ 0.10482788]\n"," [ 0.10751343]\n"," ...\n"," [-0.00537109]\n"," [-0.00537109]\n"," [-0.01074219]], shape=(42438, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.09945679  0.10482788  0.10751343 ... -0.00537109 -0.00537109\n"," -0.01074219], shape=(42438,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00598145]\n"," [ 0.01193237]\n"," [ 0.0149231 ]\n"," ...\n"," [-0.11941528]\n"," [-0.11642456]\n"," [-0.11642456]], shape=(44610, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00598145  0.01193237  0.0149231  ... -0.11941528 -0.11642456\n"," -0.11642456], shape=(44610,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09286499]\n"," [-0.10214233]\n"," [-0.11227417]\n"," ...\n"," [ 0.14944458]\n"," [ 0.14224243]\n"," [ 0.1359253 ]], shape=(32918, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09286499 -0.10214233 -0.11227417 ...  0.14944458  0.14224243\n","  0.1359253 ], shape=(32918,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.14285278]\n"," ...\n"," [ 0.        ]\n"," [-0.14285278]\n"," [ 0.        ]], shape=(54294, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.14285278 ...  0.         -0.14285278\n","  0.        ], shape=(54294,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00524902]\n"," [-0.00662231]\n"," [-0.00524902]\n"," ...\n"," [ 0.00463867]\n"," [ 0.00524902]\n"," [ 0.0038147 ]], shape=(38560, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00524902 -0.00662231 -0.00524902 ...  0.00463867  0.00524902\n","  0.0038147 ], shape=(38560,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0062561 ]\n"," [0.00500488]\n"," [0.00250244]\n"," ...\n"," [0.00375366]\n"," [0.00375366]\n"," [0.00125122]], shape=(47378, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0062561  0.00500488 0.00250244 ... 0.00375366 0.00375366 0.00125122], shape=(47378,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.32769775]\n"," [-0.37930298]\n"," [-0.34835815]\n"," ...\n"," [-0.6970825 ]\n"," [-0.7283325 ]\n"," [-0.75601196]], shape=(40790, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.32769775 -0.37930298 -0.34835815 ... -0.6970825  -0.7283325\n"," -0.75601196], shape=(40790,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04971313]\n"," [-0.04971313]\n"," [-0.05847168]\n"," ...\n"," [-0.07019043]\n"," [-0.06726074]\n"," [-0.06433105]], shape=(40044, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04971313 -0.04971313 -0.05847168 ... -0.07019043 -0.06726074\n"," -0.06433105], shape=(40044,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00125122]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.        ]], shape=(84546, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00125122 0.         0.         ... 0.         0.         0.        ], shape=(84546,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03759766]\n"," [ 0.03759766]\n"," [ 0.04324341]\n"," ...\n"," [-0.00375366]\n"," [-0.00375366]\n"," [-0.00375366]], shape=(35240, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03759766  0.03759766  0.04324341 ... -0.00375366 -0.00375366\n"," -0.00375366], shape=(35240,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01049805]\n"," [-0.00421143]\n"," [-0.00421143]\n"," ...\n"," [-0.02099609]\n"," [-0.02099609]\n"," [-0.01049805]], shape=(42770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01049805 -0.00421143 -0.00421143 ... -0.02099609 -0.02099609\n"," -0.01049805], shape=(42770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16491699]\n"," [-0.16226196]\n"," [-0.15435791]\n"," ...\n"," [-0.01452637]\n"," [ 0.        ]\n"," [ 0.01583862]], shape=(45940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16491699 -0.16226196 -0.15435791 ... -0.01452637  0.\n","  0.01583862], shape=(45940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0625   ]\n"," [-0.0546875]\n"," [-0.0546875]\n"," ...\n"," [ 0.0078125]\n"," [ 0.0078125]\n"," [ 0.0078125]], shape=(30204, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.0625    -0.0546875 -0.0546875 ...  0.0078125  0.0078125  0.0078125], shape=(30204,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01156616]\n"," [ 0.00576782]\n"," [ 0.00576782]\n"," ...\n"," [-0.00289917]\n"," [-0.00576782]\n"," [-0.00576782]], shape=(27390, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01156616  0.00576782  0.00576782 ... -0.00289917 -0.00576782\n"," -0.00576782], shape=(27390,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02914429]\n"," [-0.01165771]\n"," [-0.00582886]\n"," ...\n"," [-0.09329224]\n"," [-0.09912109]\n"," [-0.09912109]], shape=(46602, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02914429 -0.01165771 -0.00582886 ... -0.09329224 -0.09912109\n"," -0.09912109], shape=(46602,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.34539795]\n"," [ 0.34210205]\n"," [ 0.33880615]\n"," ...\n"," [-0.05264282]\n"," [-0.0559082 ]\n"," [-0.05264282]], shape=(39808, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.34539795  0.34210205  0.33880615 ... -0.05264282 -0.0559082\n"," -0.05264282], shape=(39808,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0958252 ]\n"," [-0.09075928]\n"," [-0.08569336]\n"," ...\n"," [-0.50823975]\n"," [-0.5145569 ]\n"," [-0.5196228 ]], shape=(26378, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0958252  -0.09075928 -0.08569336 ... -0.50823975 -0.5145569\n"," -0.5196228 ], shape=(26378,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02709961]\n"," [0.02709961]\n"," [0.01898193]\n"," ...\n"," [0.23849487]\n"," [0.21951294]\n"," [0.1734314 ]], shape=(31992, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02709961 0.02709961 0.01898193 ... 0.23849487 0.21951294 0.1734314 ], shape=(31992,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01898193]\n"," [ 0.01898193]\n"," [ 0.02709961]\n"," ...\n"," [-0.00543213]\n"," [-0.00543213]\n"," [-0.00543213]], shape=(160554, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01898193  0.01898193  0.02709961 ... -0.00543213 -0.00543213\n"," -0.00543213], shape=(160554,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07595825]\n"," [ 0.07595825]\n"," [ 0.08859253]\n"," ...\n"," [-0.10125732]\n"," [-0.08859253]\n"," [-0.10125732]], shape=(49394, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07595825  0.07595825  0.08859253 ... -0.10125732 -0.08859253\n"," -0.10125732], shape=(49394,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00299072]\n"," [-0.00549316]\n"," ...\n"," [ 0.01901245]\n"," [ 0.01748657]\n"," [ 0.01599121]], shape=(41980, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00299072 -0.00549316 ...  0.01901245  0.01748657\n","  0.01599121], shape=(41980,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03448486]\n"," [-0.03448486]\n"," [-0.03448486]\n"," ...\n"," [ 0.14941406]\n"," [ 0.10345459]\n"," [ 0.06323242]], shape=(53394, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03448486 -0.03448486 -0.03448486 ...  0.14941406  0.10345459\n","  0.06323242], shape=(53394,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06723022]\n"," [-0.06723022]\n"," [-0.07144165]\n"," ...\n"," [-0.05041504]\n"," [-0.05673218]\n"," [-0.06091309]], shape=(115466, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06723022 -0.06723022 -0.07144165 ... -0.05041504 -0.05673218\n"," -0.06091309], shape=(115466,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0038147 ]\n"," [ 0.00189209]\n"," [ 0.        ]\n"," ...\n"," [-0.02474976]\n"," [-0.03048706]\n"," [-0.04190063]], shape=(46602, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0038147   0.00189209  0.         ... -0.02474976 -0.03048706\n"," -0.04190063], shape=(46602,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00537109]\n"," [ 0.        ]\n"," ...\n"," [-0.0161438 ]\n"," [-0.02151489]\n"," [-0.02151489]], shape=(20882, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00537109  0.         ... -0.0161438  -0.02151489\n"," -0.02151489], shape=(20882,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03500366]\n"," [ 0.04867554]\n"," [ 0.04022217]\n"," ...\n"," [ 0.00024414]\n"," [ 0.00054932]\n"," [-0.00411987]], shape=(53028, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03500366  0.04867554  0.04022217 ...  0.00024414  0.00054932\n"," -0.00411987], shape=(53028,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01431274]\n"," [-0.01431274]\n"," [-0.0057373 ]\n"," ...\n"," [-0.09170532]\n"," [-0.08309937]\n"," [-0.06304932]], shape=(30392, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01431274 -0.01431274 -0.0057373  ... -0.09170532 -0.08309937\n"," -0.06304932], shape=(30392,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16113281]\n"," [-0.15377808]\n"," [-0.14053345]\n"," ...\n"," [-0.0617981 ]\n"," [-0.06991577]\n"," [-0.06842041]], shape=(17426, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16113281 -0.15377808 -0.14053345 ... -0.0617981  -0.06991577\n"," -0.06842041], shape=(17426,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06707764]\n"," [ 0.04269409]\n"," [ 0.14025879]\n"," ...\n"," [ 0.03659058]\n"," [ 0.03048706]\n"," [ 0.03048706]], shape=(25894, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06707764  0.04269409  0.14025879 ...  0.03659058  0.03048706\n","  0.03048706], shape=(25894,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04376221]\n"," [-0.0562439 ]\n"," [-0.0375061 ]\n"," ...\n"," [ 0.01251221]\n"," [-0.0062561 ]\n"," [-0.0562439 ]], shape=(46520, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04376221 -0.0562439  -0.0375061  ...  0.01251221 -0.0062561\n"," -0.0562439 ], shape=(46520,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.      ]\n"," [0.      ]\n"," [0.      ]\n"," ...\n"," [0.027771]\n"," [0.027771]\n"," [0.027771]], shape=(37310, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.       0.       0.       ... 0.027771 0.027771 0.027771], shape=(37310,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01000977]\n"," [0.01126099]\n"," [0.01126099]\n"," ...\n"," [0.00250244]\n"," [0.00250244]\n"," [0.00125122]], shape=(24314, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01000977 0.01126099 0.01126099 ... 0.00250244 0.00250244 0.00125122], shape=(24314,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00250244]\n"," [-0.00250244]\n"," ...\n"," [ 0.01501465]\n"," [ 0.01501465]\n"," [ 0.01748657]], shape=(38802, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00250244 -0.00250244 ...  0.01501465  0.01501465\n","  0.01748657], shape=(38802,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02072144]\n"," [-0.02072144]\n"," [-0.02590942]\n"," ...\n"," [-0.00518799]\n"," [-0.02072144]\n"," [-0.03625488]], shape=(56528, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02072144 -0.02072144 -0.02590942 ... -0.00518799 -0.02072144\n"," -0.03625488], shape=(56528,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.14001465]\n"," [ 0.13500977]\n"," [ 0.11499023]\n"," ...\n"," [-0.01000977]\n"," [-0.01000977]\n"," [-0.0249939 ]], shape=(36426, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.14001465  0.13500977  0.11499023 ... -0.01000977 -0.01000977\n"," -0.0249939 ], shape=(36426,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0032959 ]\n"," [ 0.0065918 ]\n"," [ 0.01315308]\n"," ...\n"," [-0.0032959 ]\n"," [ 0.        ]\n"," [ 0.0032959 ]], shape=(40348, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0032959   0.0065918   0.01315308 ... -0.0032959   0.\n","  0.0032959 ], shape=(40348,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02075195]\n"," [-0.0213623 ]\n"," [-0.02258301]\n"," ...\n"," [-0.0012207 ]\n"," [-0.00793457]\n"," [-0.01159668]], shape=(18478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02075195 -0.0213623  -0.02258301 ... -0.0012207  -0.00793457\n"," -0.01159668], shape=(18478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.43478394]\n"," [-0.3912964 ]\n"," [-0.33914185]\n"," ...\n"," [ 0.11303711]\n"," [ 0.12173462]\n"," [ 0.12173462]], shape=(31838, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.43478394 -0.3912964  -0.33914185 ...  0.11303711  0.12173462\n","  0.12173462], shape=(31838,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02285767]\n"," [ 0.02539062]\n"," [ 0.02285767]\n"," ...\n"," [-0.02285767]\n"," [-0.02539062]\n"," [-0.02539062]], shape=(39978, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02285767  0.02539062  0.02285767 ... -0.02285767 -0.02539062\n"," -0.02539062], shape=(39978,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16299438]\n"," [-0.13369751]\n"," [-0.08364868]\n"," ...\n"," [-0.01708984]\n"," [-0.02868652]\n"," [-0.03540039]], shape=(22862, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16299438 -0.13369751 -0.08364868 ... -0.01708984 -0.02868652\n"," -0.03540039], shape=(22862,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03903198]\n"," [-0.03903198]\n"," [-0.04876709]\n"," ...\n"," [-0.00244141]\n"," [-0.02926636]\n"," [-0.07073975]], shape=(44162, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03903198 -0.03903198 -0.04876709 ... -0.00244141 -0.02926636\n"," -0.07073975], shape=(44162,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00750732]\n"," [-0.00500488]\n"," [-0.00299072]\n"," ...\n"," [ 0.16751099]\n"," [ 0.19299316]\n"," [ 0.21148682]], shape=(24922, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00750732 -0.00500488 -0.00299072 ...  0.16751099  0.19299316\n","  0.21148682], shape=(24922,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0090332 ]\n"," [-0.00637817]\n"," [-0.0022583 ]\n"," ...\n"," [-0.01507568]\n"," [-0.01583862]\n"," [-0.01583862]], shape=(24074, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0090332  -0.00637817 -0.0022583  ... -0.01507568 -0.01583862\n"," -0.01583862], shape=(24074,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.027771]\n"," [ 0.027771]\n"," [ 0.027771]\n"," ...\n"," [ 0.      ]\n"," [ 0.      ]\n"," [-0.027771]], shape=(21592, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.027771  0.027771  0.027771 ...  0.        0.       -0.027771], shape=(21592,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0559082 ]\n"," [0.03619385]\n"," [0.01315308]\n"," ...\n"," [0.02960205]\n"," [0.03289795]\n"," [0.01644897]], shape=(44890, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0559082  0.03619385 0.01315308 ... 0.02960205 0.03289795 0.01644897], shape=(44890,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1869812 ]\n"," [-0.1869812 ]\n"," [-0.17886353]\n"," ...\n"," [-0.10568237]\n"," [-0.12194824]\n"," [-0.14633179]], shape=(33066, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1869812  -0.1869812  -0.17886353 ... -0.10568237 -0.12194824\n"," -0.14633179], shape=(33066,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03125   ]\n"," [ 0.04165649]\n"," [ 0.05209351]\n"," ...\n"," [-0.3020935 ]\n"," [-0.3125    ]\n"," [-0.3541565 ]], shape=(45816, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03125     0.04165649  0.05209351 ... -0.3020935  -0.3125\n"," -0.3541565 ], shape=(45816,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01141357]\n"," [0.01141357]\n"," [0.01333618]\n"," ...\n"," [0.01715088]\n"," [0.01715088]\n"," [0.01333618]], shape=(44388, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01141357 0.01141357 0.01333618 ... 0.01715088 0.01715088 0.01333618], shape=(44388,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04202271]\n"," [-0.04202271]\n"," [-0.04620361]\n"," ...\n"," [ 0.01049805]\n"," [ 0.02520752]\n"," [ 0.03570557]], shape=(23612, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04202271 -0.04202271 -0.04620361 ...  0.01049805  0.02520752\n","  0.03570557], shape=(23612,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00756836]\n"," [ 0.        ]\n"," ...\n"," [-0.05682373]\n"," [-0.05682373]\n"," [-0.05682373]], shape=(44466, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00756836  0.         ... -0.05682373 -0.05682373\n"," -0.05682373], shape=(44466,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00808716]\n"," [ 0.00808716]\n"," [ 0.02023315]\n"," ...\n"," [-0.04858398]\n"," [-0.02835083]\n"," [-0.02023315]], shape=(39478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00808716  0.00808716  0.02023315 ... -0.04858398 -0.02835083\n"," -0.02023315], shape=(39478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02124023]\n"," [-0.01000977]\n"," [-0.01251221]\n"," ...\n"," [-0.0062561 ]\n"," [-0.00250244]\n"," [-0.00250244]], shape=(44640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02124023 -0.01000977 -0.01251221 ... -0.0062561  -0.00250244\n"," -0.00250244], shape=(44640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1951294 ]\n"," [-0.1869812 ]\n"," [-0.1869812 ]\n"," ...\n"," [-0.21139526]\n"," [-0.1951294 ]\n"," [-0.17074585]], shape=(57240, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1951294  -0.1869812  -0.1869812  ... -0.21139526 -0.1951294\n"," -0.17074585], shape=(57240,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03378296]\n"," [ 0.03378296]\n"," [ 0.03378296]\n"," ...\n"," [-0.04730225]\n"," [-0.04730225]\n"," [-0.06756592]], shape=(43126, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03378296  0.03378296  0.03378296 ... -0.04730225 -0.04730225\n"," -0.06756592], shape=(43126,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.02923584]\n"," [-0.02923584]\n"," ...\n"," [-0.07019043]\n"," [-0.07019043]\n"," [-0.08770752]], shape=(60926, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.02923584 -0.02923584 ... -0.07019043 -0.07019043\n"," -0.08770752], shape=(60926,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1000061]\n"," [-0.1000061]\n"," [-0.1000061]\n"," ...\n"," [-0.09375  ]\n"," [-0.09375  ]\n"," [-0.09375  ]], shape=(35114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.1000061 -0.1000061 -0.1000061 ... -0.09375   -0.09375   -0.09375  ], shape=(35114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1687622]\n"," [0.1625061]\n"," [0.1749878]\n"," ...\n"," [0.2000122]\n"," [0.2062378]\n"," [0.2124939]], shape=(51334, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1687622 0.1625061 0.1749878 ... 0.2000122 0.2062378 0.2124939], shape=(51334,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00500488]\n"," [ 0.        ]\n"," [ 0.00500488]\n"," ...\n"," [-0.0249939 ]\n"," [-0.01998901]\n"," [-0.01998901]], shape=(45544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00500488  0.          0.00500488 ... -0.0249939  -0.01998901\n"," -0.01998901], shape=(45544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02182007]\n"," [ 0.02182007]\n"," [ 0.02182007]\n"," ...\n"," [-0.01867676]\n"," [-0.00933838]\n"," [ 0.        ]], shape=(48292, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02182007  0.02182007  0.02182007 ... -0.01867676 -0.00933838\n","  0.        ], shape=(48292,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02603149]\n"," [ 0.02230835]\n"," [ 0.01858521]\n"," ...\n"," [-0.01486206]\n"," [-0.03344727]\n"," [-0.04089355]], shape=(40416, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02603149  0.02230835  0.01858521 ... -0.01486206 -0.03344727\n"," -0.04089355], shape=(40416,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07272339]\n"," [-0.06546021]\n"," [-0.07998657]\n"," ...\n"," [-0.04364014]\n"," [-0.03637695]\n"," [-0.04364014]], shape=(29010, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07272339 -0.06546021 -0.07998657 ... -0.04364014 -0.03637695\n"," -0.04364014], shape=(29010,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03692627]\n"," [ 0.03076172]\n"," [ 0.02462769]\n"," ...\n"," [-0.00921631]\n"," [-0.00616455]\n"," [ 0.        ]], shape=(41078, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03692627  0.03076172  0.02462769 ... -0.00921631 -0.00616455\n","  0.        ], shape=(41078,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00952148]\n"," [ 0.0038147 ]\n"," [ 0.02285767]\n"," ...\n"," [-0.03808594]\n"," [-0.04190063]\n"," [-0.03808594]], shape=(75858, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00952148  0.0038147   0.02285767 ... -0.03808594 -0.04190063\n"," -0.03808594], shape=(75858,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04833984]\n"," [-0.05575562]\n"," [-0.0446167 ]\n"," ...\n"," [ 0.01486206]\n"," [ 0.00372314]\n"," [ 0.00372314]], shape=(44416, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04833984 -0.05575562 -0.0446167  ...  0.01486206  0.00372314\n","  0.00372314], shape=(44416,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.13223267]\n"," [ 0.11019897]\n"," [ 0.07989502]\n"," ...\n"," [-0.00274658]\n"," [-0.00274658]\n"," [ 0.        ]], shape=(68920, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.13223267  0.11019897  0.07989502 ... -0.00274658 -0.00274658\n","  0.        ], shape=(68920,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05328369]\n"," [-0.05328369]\n"," [-0.04702759]\n"," ...\n"," [ 0.056427  ]\n"," [ 0.06582642]\n"," [ 0.06896973]], shape=(42060, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05328369 -0.05328369 -0.04702759 ...  0.056427    0.06582642\n","  0.06896973], shape=(42060,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13366699]\n"," [-0.07919312]\n"," [-0.04949951]\n"," ...\n"," [ 0.26733398]\n"," [ 0.24752808]\n"," [ 0.1930542 ]], shape=(27356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13366699 -0.07919312 -0.04949951 ...  0.26733398  0.24752808\n","  0.1930542 ], shape=(27356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01550293]\n"," [ 0.01748657]\n"," [ 0.02200317]\n"," ...\n"," [-0.01300049]\n"," [-0.01098633]\n"," [-0.01000977]], shape=(50920, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01550293  0.01748657  0.02200317 ... -0.01300049 -0.01098633\n"," -0.01000977], shape=(50920,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01153564]\n"," [-0.01345825]\n"," [-0.01345825]\n"," ...\n"," [ 0.00384521]\n"," [ 0.00961304]\n"," [ 0.01153564]], shape=(32902, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01153564 -0.01345825 -0.01345825 ...  0.00384521  0.00961304\n","  0.01153564], shape=(32902,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.06881714]\n"," [0.06668091]\n"," [0.06237793]\n"," ...\n"," [0.01074219]\n"," [0.01934814]\n"," [0.02151489]], shape=(54290, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.06881714 0.06668091 0.06237793 ... 0.01074219 0.01934814 0.02151489], shape=(54290,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00704956]\n"," [ 0.00769043]\n"," [ 0.00576782]\n"," ...\n"," [-0.00128174]\n"," [-0.00064087]\n"," [-0.00128174]], shape=(35650, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00704956  0.00769043  0.00576782 ... -0.00128174 -0.00064087\n"," -0.00128174], shape=(35650,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00588989]\n"," [-0.00588989]\n"," [-0.00469971]\n"," ...\n"," [-0.00588989]\n"," [-0.00704956]\n"," [-0.0105896 ]], shape=(39220, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00588989 -0.00588989 -0.00469971 ... -0.00588989 -0.00704956\n"," -0.0105896 ], shape=(39220,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10397339]\n"," [-0.09899902]\n"," [-0.08911133]\n"," ...\n"," [-0.05941772]\n"," [-0.05444336]\n"," [-0.04455566]], shape=(48174, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10397339 -0.09899902 -0.08911133 ... -0.05941772 -0.05444336\n"," -0.04455566], shape=(48174,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04794312]\n"," [-0.06317139]\n"," [-0.07406616]\n"," ...\n"," [-0.06970215]\n"," [-0.05883789]\n"," [-0.05883789]], shape=(49482, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04794312 -0.06317139 -0.07406616 ... -0.06970215 -0.05883789\n"," -0.05883789], shape=(49482,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.24746704]\n"," [ 0.24243164]\n"," [ 0.24243164]\n"," ...\n"," [-0.0050354 ]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(38636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.24746704  0.24243164  0.24243164 ... -0.0050354   0.\n","  0.        ], shape=(38636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.10665894]\n"," [ 0.0539856 ]\n"," [-0.00646973]\n"," ...\n"," [-0.01382446]\n"," [-0.00949097]\n"," [-0.00430298]], shape=(40936, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.10665894  0.0539856  -0.00646973 ... -0.01382446 -0.00949097\n"," -0.00430298], shape=(40936,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0072937]\n"," [0.       ]\n"," [0.       ]\n"," ...\n"," [0.0072937]\n"," [0.0072937]\n"," [0.       ]], shape=(42190, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0072937 0.        0.        ... 0.0072937 0.0072937 0.       ], shape=(42190,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.19464111]\n"," [-0.18121338]\n"," [-0.19464111]\n"," ...\n"," [-0.18121338]\n"," [-0.18121338]\n"," [-0.18121338]], shape=(76140, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.19464111 -0.18121338 -0.19464111 ... -0.18121338 -0.18121338\n"," -0.18121338], shape=(76140,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.44909668]\n"," [ 0.4355774 ]\n"," [ 0.42245483]\n"," ...\n"," [-0.08462524]\n"," [-0.08303833]\n"," [-0.08047485]], shape=(52448, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.44909668  0.4355774   0.42245483 ... -0.08462524 -0.08303833\n"," -0.08047485], shape=(52448,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0116272 ]\n"," [-0.0116272 ]\n"," [-0.01251221]\n"," ...\n"," [-0.02197266]\n"," [-0.02542114]\n"," [-0.02929688]], shape=(43820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0116272  -0.0116272  -0.01251221 ... -0.02197266 -0.02542114\n"," -0.02929688], shape=(43820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [ 0.        ]\n"," [ 0.00500488]\n"," ...\n"," [ 0.01000977]\n"," [ 0.00750732]\n"," [ 0.00500488]], shape=(59650, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488  0.          0.00500488 ...  0.01000977  0.00750732\n","  0.00500488], shape=(59650,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02856445]\n"," [0.03570557]\n"," [0.02856445]\n"," ...\n"," [0.01428223]\n"," [0.01428223]\n"," [0.00714111]], shape=(23798, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02856445 0.03570557 0.02856445 ... 0.01428223 0.01428223 0.00714111], shape=(23798,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0071106 ]\n"," [0.00592041]\n"," [0.00415039]\n"," ...\n"," [0.00534058]\n"," [0.00592041]\n"," [0.00534058]], shape=(59546, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0071106  0.00592041 0.00415039 ... 0.00534058 0.00592041 0.00534058], shape=(59546,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04699707]\n"," [-0.05310059]\n"," [-0.16299438]\n"," ...\n"," [-0.03234863]\n"," [-0.02258301]\n"," [-0.0177002 ]], shape=(46678, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04699707 -0.05310059 -0.16299438 ... -0.03234863 -0.02258301\n"," -0.0177002 ], shape=(46678,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12658691]\n"," [-0.11392212]\n"," [-0.10125732]\n"," ...\n"," [-0.11392212]\n"," [-0.10125732]\n"," [-0.10125732]], shape=(105930, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12658691 -0.11392212 -0.10125732 ... -0.11392212 -0.10125732\n"," -0.10125732], shape=(105930,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17010498]\n"," [-0.16494751]\n"," [-0.16494751]\n"," ...\n"," [-0.12371826]\n"," [-0.1340332 ]\n"," [-0.12371826]], shape=(29190, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17010498 -0.16494751 -0.16494751 ... -0.12371826 -0.1340332\n"," -0.12371826], shape=(29190,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00311279]\n"," [-0.00311279]\n"," ...\n"," [ 0.05279541]\n"," [ 0.07452393]\n"," [ 0.10247803]], shape=(28774, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00311279 -0.00311279 ...  0.05279541  0.07452393\n","  0.10247803], shape=(28774,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0227356 ]\n"," [-0.0227356 ]\n"," [-0.0227356 ]\n"," ...\n"," [-0.01589966]\n"," [-0.01589966]\n"," [-0.01135254]], shape=(47256, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0227356  -0.0227356  -0.0227356  ... -0.01589966 -0.01589966\n"," -0.01135254], shape=(47256,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1751709 ]\n"," [0.17434692]\n"," [0.17434692]\n"," ...\n"," [0.4246521 ]\n"," [0.44869995]\n"," [0.47235107]], shape=(59910, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1751709  0.17434692 0.17434692 ... 0.4246521  0.44869995 0.47235107], shape=(59910,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17053223]\n"," [-0.1550293 ]\n"," [-0.17053223]\n"," ...\n"," [-0.20928955]\n"," [-0.18603516]\n"," [-0.18603516]], shape=(42576, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17053223 -0.1550293  -0.17053223 ... -0.20928955 -0.18603516\n"," -0.18603516], shape=(42576,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01266479]\n"," [-0.02532959]\n"," [-0.02532959]\n"," ...\n"," [ 0.05062866]\n"," [ 0.05062866]\n"," [ 0.05062866]], shape=(26508, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01266479 -0.02532959 -0.02532959 ...  0.05062866  0.05062866\n","  0.05062866], shape=(26508,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01730347]\n"," [ 0.0249939 ]\n"," [ 0.03076172]\n"," ...\n"," [-0.00769043]\n"," [-0.00961304]\n"," [-0.00961304]], shape=(37144, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01730347  0.0249939   0.03076172 ... -0.00769043 -0.00961304\n"," -0.00961304], shape=(37144,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17053223]\n"," [-0.17053223]\n"," [-0.18603516]\n"," ...\n"," [-0.30233765]\n"," [-0.30233765]\n"," [-0.30233765]], shape=(45368, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17053223 -0.17053223 -0.18603516 ... -0.30233765 -0.30233765\n"," -0.30233765], shape=(45368,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15109253]\n"," [-0.13308716]\n"," [-0.09713745]\n"," ...\n"," [-0.06115723]\n"," [-0.07192993]\n"," [-0.07913208]], shape=(16812, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15109253 -0.13308716 -0.09713745 ... -0.06115723 -0.07192993\n"," -0.07913208], shape=(16812,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12658691]\n"," [-0.10125732]\n"," [-0.07595825]\n"," ...\n"," [-0.10125732]\n"," [-0.11392212]\n"," [-0.12658691]], shape=(69424, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12658691 -0.10125732 -0.07595825 ... -0.10125732 -0.11392212\n"," -0.12658691], shape=(69424,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00189209]\n"," [-0.0038147 ]\n"," ...\n"," [-0.07046509]\n"," [-0.06286621]\n"," [-0.05142212]], shape=(40916, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00189209 -0.0038147  ... -0.07046509 -0.06286621\n"," -0.05142212], shape=(40916,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00549316]\n"," [ 0.00650024]\n"," [ 0.00650024]\n"," ...\n"," [-0.0255127 ]\n"," [-0.02450562]\n"," [-0.02398682]], shape=(40582, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00549316  0.00650024  0.00650024 ... -0.0255127  -0.02450562\n"," -0.02398682], shape=(40582,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00234985]\n"," [-0.00119019]\n"," [-0.00234985]\n"," ...\n"," [ 0.00704956]\n"," [ 0.00588989]\n"," [ 0.00469971]], shape=(76328, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00234985 -0.00119019 -0.00234985 ...  0.00704956  0.00588989\n","  0.00469971], shape=(76328,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.0005188 ]\n"," [-0.00250244]\n"," ...\n"," [ 0.00317383]\n"," [ 0.        ]\n"," [-0.00292969]], shape=(49616, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.0005188  -0.00250244 ...  0.00317383  0.\n"," -0.00292969], shape=(49616,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02017212]\n"," [-0.00576782]\n"," [ 0.        ]\n"," ...\n"," [ 0.0144043 ]\n"," [ 0.00576782]\n"," [ 0.00286865]], shape=(30060, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02017212 -0.00576782  0.         ...  0.0144043   0.00576782\n","  0.00286865], shape=(30060,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01199341]\n"," [0.00900269]\n"," [0.00601196]\n"," ...\n"," [0.02999878]\n"," [0.03048706]\n"," [0.03100586]], shape=(50750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01199341 0.00900269 0.00601196 ... 0.02999878 0.03048706 0.03100586], shape=(50750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02709961]\n"," [-0.03253174]\n"," [-0.0135498 ]\n"," ...\n"," [-0.10568237]\n"," [-0.11923218]\n"," [-0.11923218]], shape=(51268, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02709961 -0.03253174 -0.0135498  ... -0.10568237 -0.11923218\n"," -0.11923218], shape=(51268,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03125   ]\n"," [-0.04000854]\n"," [-0.04998779]\n"," ...\n"," [ 0.02374268]\n"," [ 0.01998901]\n"," [ 0.01376343]], shape=(44890, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03125    -0.04000854 -0.04998779 ...  0.02374268  0.01998901\n","  0.01376343], shape=(44890,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04544067]\n"," [-0.05682373]\n"," [-0.06439209]\n"," ...\n"," [-0.10986328]\n"," [-0.1022644 ]\n"," [-0.1022644 ]], shape=(41488, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04544067 -0.05682373 -0.06439209 ... -0.10986328 -0.1022644\n"," -0.1022644 ], shape=(41488,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05453491]\n"," [-0.06060791]\n"," [-0.06060791]\n"," ...\n"," [-0.08483887]\n"," [-0.11819458]\n"," [-0.14544678]], shape=(32674, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05453491 -0.06060791 -0.06060791 ... -0.08483887 -0.11819458\n"," -0.14544678], shape=(32674,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.0062561 ]\n"," [ 0.00750732]\n"," ...\n"," [-0.12750244]\n"," [-0.10125732]\n"," [-0.07376099]], shape=(22284, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.0062561   0.00750732 ... -0.12750244 -0.10125732\n"," -0.07376099], shape=(22284,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01177979]\n"," [-0.01568604]\n"," [-0.01568604]\n"," ...\n"," [ 0.00784302]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(52308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01177979 -0.01568604 -0.01568604 ...  0.00784302  0.\n","  0.        ], shape=(52308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02349854]\n"," [-0.02038574]\n"," [-0.01879883]\n"," ...\n"," [-0.01724243]\n"," [-0.01568604]\n"," [-0.01409912]], shape=(30324, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02349854 -0.02038574 -0.01879883 ... -0.01724243 -0.01568604\n"," -0.01409912], shape=(30324,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00750732]\n"," [ 0.00500488]\n"," [ 0.01501465]\n"," ...\n"," [ 0.01000977]\n"," [ 0.01251221]\n"," [ 0.01501465]], shape=(22036, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00750732  0.00500488  0.01501465 ...  0.01000977  0.01251221\n","  0.01501465], shape=(22036,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03408813]\n"," [-0.05682373]\n"," [-0.04260254]\n"," ...\n"," [ 0.09091187]\n"," [ 0.01419067]\n"," [-0.03408813]], shape=(26666, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03408813 -0.05682373 -0.04260254 ...  0.09091187  0.01419067\n"," -0.03408813], shape=(26666,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0062561]\n"," [0.       ]\n"," [0.0062561]\n"," ...\n"," [0.0562439]\n"," [0.0625   ]\n"," [0.0625   ]], shape=(20978, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0062561 0.        0.0062561 ... 0.0562439 0.0625    0.0625   ], shape=(20978,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00183105]\n"," [ 0.00183105]\n"," [ 0.        ]\n"," ...\n"," [-0.00912476]\n"," [-0.0072937 ]\n"," [-0.00183105]], shape=(43446, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00183105  0.00183105  0.         ... -0.00912476 -0.0072937\n"," -0.00183105], shape=(43446,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01428223]\n"," [ 0.02856445]\n"," [ 0.02856445]\n"," ...\n"," [-0.00714111]\n"," [-0.00714111]\n"," [-0.03570557]], shape=(22212, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01428223  0.02856445  0.02856445 ... -0.00714111 -0.00714111\n"," -0.03570557], shape=(22212,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03915405]\n"," [-0.04437256]\n"," [-0.05221558]\n"," ...\n"," [ 0.01828003]\n"," [ 0.01828003]\n"," [ 0.01828003]], shape=(124878, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03915405 -0.04437256 -0.05221558 ...  0.01828003  0.01828003\n","  0.01828003], shape=(124878,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00250244]\n"," [ 0.        ]\n"," ...\n"," [-0.00875854]\n"," [-0.00875854]\n"," [-0.0062561 ]], shape=(26392, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00250244  0.         ... -0.00875854 -0.00875854\n"," -0.0062561 ], shape=(26392,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01898193]\n"," [-0.00543213]\n"," [ 0.00543213]\n"," ...\n"," [-0.00543213]\n"," [ 0.00543213]\n"," [ 0.00543213]], shape=(25208, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01898193 -0.00543213  0.00543213 ... -0.00543213  0.00543213\n","  0.00543213], shape=(25208,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02301025]\n"," [-0.02249146]\n"," [-0.02200317]\n"," ...\n"," [ 0.00750732]\n"," [ 0.00549316]\n"," [ 0.00448608]], shape=(27586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02301025 -0.02249146 -0.02200317 ...  0.00750732  0.00549316\n","  0.00448608], shape=(27586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04544067]\n"," [ 0.04544067]\n"," [ 0.02728271]\n"," ...\n"," [-0.01818848]\n"," [-0.01818848]\n"," [-0.0227356 ]], shape=(47382, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04544067  0.04544067  0.02728271 ... -0.01818848 -0.01818848\n"," -0.0227356 ], shape=(47382,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0227356 ]\n"," [ 0.02728271]\n"," [ 0.02728271]\n"," ...\n"," [-0.0227356 ]\n"," [-0.0227356 ]\n"," [-0.01818848]], shape=(47150, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0227356   0.02728271  0.02728271 ... -0.0227356  -0.0227356\n"," -0.01818848], shape=(47150,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04104614]\n"," [-0.0486145 ]\n"," [-0.05319214]\n"," ...\n"," [ 0.00024414]\n"," [ 0.00152588]\n"," [ 0.00222778]], shape=(36844, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04104614 -0.0486145  -0.05319214 ...  0.00024414  0.00152588\n","  0.00222778], shape=(36844,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00241089]\n"," [-0.00241089]\n"," [-0.00241089]\n"," ...\n"," [-0.00723267]\n"," [-0.00576782]\n"," [-0.00482178]], shape=(20936, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00241089 -0.00241089 -0.00241089 ... -0.00723267 -0.00576782\n"," -0.00482178], shape=(20936,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0072937 ]\n"," [-0.00183105]\n"," [ 0.00183105]\n"," ...\n"," [-0.02008057]\n"," [-0.02371216]\n"," [-0.02191162]], shape=(32464, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0072937  -0.00183105  0.00183105 ... -0.02008057 -0.02371216\n"," -0.02191162], shape=(32464,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0171814 ]\n"," [0.01837158]\n"," [0.01895142]\n"," ...\n"," [0.00592041]\n"," [0.0071106 ]\n"," [0.0071106 ]], shape=(18726, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0171814  0.01837158 0.01895142 ... 0.00592041 0.0071106  0.0071106 ], shape=(18726,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00375366]\n"," [-0.00750732]\n"," ...\n"," [ 0.00375366]\n"," [ 0.00939941]\n"," [ 0.00750732]], shape=(23646, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00375366 -0.00750732 ...  0.00375366  0.00939941\n","  0.00750732], shape=(23646,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0249939 ]\n"," [-0.02450562]\n"," [-0.02099609]\n"," ...\n"," [ 0.00549316]\n"," [ 0.00549316]\n"," [ 0.00350952]], shape=(42630, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0249939  -0.02450562 -0.02099609 ...  0.00549316  0.00549316\n","  0.00350952], shape=(42630,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.015625 ]\n"," [-0.03125  ]\n"," [-0.046875 ]\n"," ...\n"," [ 0.0078125]\n"," [ 0.0078125]\n"," [ 0.0078125]], shape=(42896, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.015625  -0.03125   -0.046875  ...  0.0078125  0.0078125  0.0078125], shape=(42896,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03637695]\n"," [-0.03030396]\n"," [-0.02423096]\n"," ...\n"," [-0.37576294]\n"," [-0.339386  ]\n"," [-0.29092407]], shape=(47282, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03637695 -0.03030396 -0.02423096 ... -0.37576294 -0.339386\n"," -0.29092407], shape=(47282,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00125122]\n"," [ 0.00250244]\n"," [ 0.00375366]\n"," ...\n"," [-0.0062561 ]\n"," [-0.0062561 ]\n"," [-0.00375366]], shape=(69342, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00125122  0.00250244  0.00375366 ... -0.0062561  -0.0062561\n"," -0.00375366], shape=(69342,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02999878]\n"," [-0.02124023]\n"," [-0.00875854]\n"," ...\n"," [-0.00250244]\n"," [-0.00125122]\n"," [ 0.00125122]], shape=(66782, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02999878 -0.02124023 -0.00875854 ... -0.00250244 -0.00125122\n","  0.00125122], shape=(66782,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06747437]\n"," [-0.00613403]\n"," [-0.06134033]\n"," ...\n"," [ 0.02453613]\n"," [ 0.02453613]\n"," [ 0.0184021 ]], shape=(37120, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06747437 -0.00613403 -0.06134033 ...  0.02453613  0.02453613\n","  0.0184021 ], shape=(37120,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.00366211]\n"," ...\n"," [-0.01837158]\n"," [-0.01470947]\n"," [-0.01837158]], shape=(23416, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.00366211 ... -0.01837158 -0.01470947\n"," -0.01837158], shape=(23416,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16992188]\n"," [-0.16992188]\n"," [-0.15686035]\n"," ...\n"," [-0.13070679]\n"," [-0.13070679]\n"," [-0.11764526]], shape=(38684, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16992188 -0.16992188 -0.15686035 ... -0.13070679 -0.13070679\n"," -0.11764526], shape=(38684,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00497437]\n"," [-0.02481079]\n"," [-0.01242065]\n"," ...\n"," [ 0.        ]\n"," [-0.01242065]\n"," [ 0.        ]], shape=(33656, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00497437 -0.02481079 -0.01242065 ...  0.         -0.01242065\n","  0.        ], shape=(33656,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00125122]\n"," [-0.00750732]\n"," [-0.01000977]\n"," ...\n"," [-0.00375366]\n"," [-0.00375366]\n"," [-0.00500488]], shape=(49342, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00125122 -0.00750732 -0.01000977 ... -0.00375366 -0.00375366\n"," -0.00500488], shape=(49342,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00616455]\n"," [-0.00863647]\n"," [-0.00863647]\n"," ...\n"," [-0.05300903]\n"," [-0.04562378]\n"," [-0.04193115]], shape=(22414, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00616455 -0.00863647 -0.00863647 ... -0.05300903 -0.04562378\n"," -0.04193115], shape=(22414,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0045166 ]\n"," [-0.00454712]\n"," [-0.0045166 ]\n"," ...\n"," [-0.01809692]\n"," [-0.01809692]\n"," [-0.01843262]], shape=(54620, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0045166  -0.00454712 -0.0045166  ... -0.01809692 -0.01809692\n"," -0.01843262], shape=(54620,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.10150146]\n"," [ 0.1005249 ]\n"," [ 0.09811401]\n"," ...\n"," [-0.26437378]\n"," [-0.2619629 ]\n"," [-0.25857544]], shape=(16296, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.10150146  0.1005249   0.09811401 ... -0.26437378 -0.2619629\n"," -0.25857544], shape=(16296,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01641846]\n"," [-0.02737427]\n"," ...\n"," [-0.02737427]\n"," [-0.02371216]\n"," [-0.01641846]], shape=(38302, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01641846 -0.02737427 ... -0.02737427 -0.02371216\n"," -0.01641846], shape=(38302,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01644897]\n"," [ 0.0032959 ]\n"," [ 0.0032959 ]\n"," ...\n"," [-0.0032959 ]\n"," [-0.0065918 ]\n"," [-0.01644897]], shape=(38714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01644897  0.0032959   0.0032959  ... -0.0032959  -0.0065918\n"," -0.01644897], shape=(38714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01477051]\n"," [-0.00491333]\n"," [-0.00491333]\n"," ...\n"," [ 0.        ]\n"," [ 0.00491333]\n"," [ 0.00491333]], shape=(78000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01477051 -0.00491333 -0.00491333 ...  0.          0.00491333\n","  0.00491333], shape=(78000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14929199]\n"," [-0.14907837]\n"," [-0.14929199]\n"," ...\n"," [ 0.1614685 ]\n"," [ 0.16488647]\n"," [ 0.16827393]], shape=(45404, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14929199 -0.14907837 -0.14929199 ...  0.1614685   0.16488647\n","  0.16827393], shape=(45404,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.31027222]\n"," [-0.31887817]\n"," [-0.32748413]\n"," ...\n"," [-0.10348511]\n"," [-0.11209106]\n"," [-0.11209106]], shape=(34450, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.31027222 -0.31887817 -0.32748413 ... -0.10348511 -0.11209106\n"," -0.11209106], shape=(34450,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05377197]\n"," [-0.03762817]\n"," [-0.06451416]\n"," ...\n"," [ 0.10751343]\n"," [ 0.11828613]\n"," [ 0.12902832]], shape=(61416, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05377197 -0.03762817 -0.06451416 ...  0.10751343  0.11828613\n","  0.12902832], shape=(61416,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.01998901]\n"," [-0.04251099]\n"," ...\n"," [ 0.00250244]\n"," [-0.00500488]\n"," [-0.01501465]], shape=(29268, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.01998901 -0.04251099 ...  0.00250244 -0.00500488\n"," -0.01501465], shape=(29268,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02581787]\n"," [-0.02157593]\n"," [-0.01776123]\n"," ...\n"," [ 0.01651001]\n"," [ 0.01861572]\n"," [ 0.01776123]], shape=(25310, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02581787 -0.02157593 -0.01776123 ...  0.01651001  0.01861572\n","  0.01776123], shape=(25310,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0710144 ]\n"," [ 0.06350708]\n"," [ 0.05599976]\n"," ...\n"," [-0.00299072]\n"," [-0.00299072]\n"," [-0.00201416]], shape=(56552, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0710144   0.06350708  0.05599976 ... -0.00299072 -0.00299072\n"," -0.00201416], shape=(56552,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.09078979]\n"," [0.08883667]\n"," [0.0843811 ]], shape=(77600, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.09078979 0.08883667 0.0843811 ], shape=(77600,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01605225]\n"," [-0.01605225]\n"," [-0.01605225]\n"," ...\n"," [ 0.        ]\n"," [ 0.00534058]\n"," [ 0.01068115]], shape=(23602, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01605225 -0.01605225 -0.01605225 ...  0.          0.00534058\n","  0.01068115], shape=(23602,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02142334]\n"," [-0.01428223]\n"," [-0.00714111]\n"," ...\n"," [ 0.24285889]\n"," [ 0.2571411 ]\n"," [ 0.27142334]], shape=(38108, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02142334 -0.01428223 -0.00714111 ...  0.24285889  0.2571411\n","  0.27142334], shape=(38108,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00299072]\n"," [ 0.00299072]\n"," [ 0.00598145]\n"," ...\n"," [-0.00299072]\n"," [ 0.00299072]\n"," [ 0.00299072]], shape=(31916, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00299072  0.00299072  0.00598145 ... -0.00299072  0.00299072\n","  0.00299072], shape=(31916,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01412964]\n"," [0.00708008]\n"," [0.01412964]\n"," ...\n"," [0.01412964]\n"," [0.00354004]\n"," [0.00708008]], shape=(161196, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01412964 0.00708008 0.01412964 ... 0.01412964 0.00354004 0.00708008], shape=(161196,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02084351]\n"," [ 0.01040649]\n"," [ 0.01040649]\n"," ...\n"," [-0.0625    ]\n"," [-0.07290649]\n"," [-0.0625    ]], shape=(40544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02084351  0.01040649  0.01040649 ... -0.0625     -0.07290649\n"," -0.0625    ], shape=(40544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08450317]\n"," [-0.07745361]\n"," [-0.07745361]\n"," ...\n"," [-0.14788818]\n"," [-0.14083862]\n"," [-0.11972046]], shape=(120142, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08450317 -0.07745361 -0.07745361 ... -0.14788818 -0.14083862\n"," -0.11972046], shape=(120142,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1315918 ]\n"," [-0.15789795]\n"," [-0.15789795]\n"," ...\n"," [-0.10525513]\n"," [-0.10525513]\n"," [-0.10525513]], shape=(50288, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1315918  -0.15789795 -0.15789795 ... -0.10525513 -0.10525513\n"," -0.10525513], shape=(50288,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16970825]\n"," [-0.18786621]\n"," [-0.2000122 ]\n"," ...\n"," [-0.05453491]\n"," [-0.06060791]\n"," [-0.06668091]], shape=(50752, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16970825 -0.18786621 -0.2000122  ... -0.05453491 -0.06060791\n"," -0.06668091], shape=(50752,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05374146]\n"," [-0.05374146]\n"," [-0.05374146]\n"," ...\n"," [ 0.00375366]\n"," [ 0.00500488]\n"," [ 0.00375366]], shape=(29152, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05374146 -0.05374146 -0.05374146 ...  0.00375366  0.00500488\n","  0.00375366], shape=(29152,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00567627]\n"," [ 0.        ]\n"," ...\n"," [-0.21591187]\n"," [-0.20169067]\n"," [-0.15908813]], shape=(35932, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00567627  0.         ... -0.21591187 -0.20169067\n"," -0.15908813], shape=(35932,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.10250854]\n"," [0.07501221]\n"," [0.0375061 ]\n"," ...\n"," [0.14248657]\n"," [0.15499878]\n"," [0.16500854]], shape=(51056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.10250854 0.07501221 0.0375061  ... 0.14248657 0.15499878 0.16500854], shape=(51056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04000854]\n"," [-0.04626465]\n"," [-0.04873657]\n"," ...\n"," [-0.02624512]\n"," [-0.03500366]\n"," [-0.04000854]], shape=(35418, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04000854 -0.04626465 -0.04873657 ... -0.02624512 -0.03500366\n"," -0.04000854], shape=(35418,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06140137]\n"," [-0.05847168]\n"," [-0.05847168]\n"," ...\n"," [-0.06433105]\n"," [-0.06726074]\n"," [-0.07601929]], shape=(26480, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06140137 -0.05847168 -0.05847168 ... -0.06433105 -0.06726074\n"," -0.07601929], shape=(26480,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08358765]\n"," [0.08358765]\n"," [0.08358765]\n"," ...\n"," [0.16714478]\n"," [0.16589355]\n"," [0.16714478]], shape=(21480, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08358765 0.08358765 0.08358765 ... 0.16714478 0.16589355 0.16714478], shape=(21480,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01342773]\n"," [-0.01074219]\n"," [-0.00805664]\n"," ...\n"," [-0.04840088]\n"," [-0.09677124]\n"," [-0.13708496]], shape=(120236, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01342773 -0.01074219 -0.00805664 ... -0.04840088 -0.09677124\n"," -0.13708496], shape=(120236,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06439209]\n"," [-0.07574463]\n"," [-0.07574463]\n"," ...\n"," [-0.05682373]\n"," [-0.04544067]\n"," [-0.05682373]], shape=(49992, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06439209 -0.07574463 -0.07574463 ... -0.05682373 -0.04544067\n"," -0.05682373], shape=(49992,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00552368]\n"," [-0.00274658]\n"," [-0.00552368]\n"," ...\n"," [-0.01928711]\n"," [-0.01654053]\n"," [-0.01928711]], shape=(57284, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00552368 -0.00274658 -0.00552368 ... -0.01928711 -0.01654053\n"," -0.01928711], shape=(57284,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.02072144]\n"," [ 0.        ]\n"," [-0.02072144]], shape=(72878, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.02072144  0.\n"," -0.02072144], shape=(72878,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02841187]\n"," [-0.02841187]\n"," [-0.02841187]\n"," ...\n"," [-0.01419067]\n"," [-0.01419067]\n"," [-0.01989746]], shape=(40980, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02841187 -0.02841187 -0.02841187 ... -0.01419067 -0.01419067\n"," -0.01989746], shape=(40980,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17749023]\n"," [-0.19000244]\n"," [-0.18249512]\n"," ...\n"," [-0.00500488]\n"," [-0.00750732]\n"," [-0.01998901]], shape=(67800, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17749023 -0.19000244 -0.18249512 ... -0.00500488 -0.00750732\n"," -0.01998901], shape=(67800,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02423096]\n"," [-0.03030396]\n"," [-0.03637695]\n"," ...\n"," [ 0.        ]\n"," [-0.01211548]\n"," [-0.02423096]], shape=(64634, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02423096 -0.03030396 -0.03637695 ...  0.         -0.01211548\n"," -0.02423096], shape=(64634,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01257324]\n"," [-0.01257324]\n"," [-0.01885986]\n"," ...\n"," [-0.01257324]\n"," [-0.01257324]\n"," [-0.00628662]], shape=(20250, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01257324 -0.01257324 -0.01885986 ... -0.01257324 -0.01257324\n"," -0.00628662], shape=(20250,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.5822754 ]\n"," [ 0.5822754 ]\n"," [ 0.5443115 ]\n"," ...\n"," [-0.05062866]\n"," [ 0.01266479]\n"," [ 0.06329346]], shape=(46404, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.5822754   0.5822754   0.5443115  ... -0.05062866  0.01266479\n","  0.06329346], shape=(46404,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00567627]\n"," [0.        ]\n"," [0.01135254]\n"," ...\n"," [0.0227356 ]\n"," [0.00567627]\n"," [0.01135254]], shape=(30202, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00567627 0.         0.01135254 ... 0.0227356  0.00567627 0.01135254], shape=(30202,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07611084]\n"," [-0.07611084]\n"," [-0.07266235]\n"," ...\n"," [-0.08303833]\n"," [-0.08996582]\n"," [-0.07958984]], shape=(61710, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07611084 -0.07611084 -0.07266235 ... -0.08303833 -0.08996582\n"," -0.07958984], shape=(61710,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00427246]\n"," [-0.0085144 ]\n"," [-0.01065063]\n"," ...\n"," [-0.07037354]\n"," [-0.07250977]\n"," [-0.07250977]], shape=(34068, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00427246 -0.0085144  -0.01065063 ... -0.07037354 -0.07250977\n"," -0.07250977], shape=(34068,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02001953]\n"," [0.01852417]\n"," [0.01699829]\n"," ...\n"," [0.00201416]\n"," [0.00048828]\n"," [0.00048828]], shape=(48166, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02001953 0.01852417 0.01699829 ... 0.00201416 0.00048828 0.00048828], shape=(48166,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0135498 ]\n"," [0.01898193]\n"," [0.01898193]\n"," ...\n"," [0.03253174]\n"," [0.04064941]\n"," [0.03253174]], shape=(38186, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0135498  0.01898193 0.01898193 ... 0.03253174 0.04064941 0.03253174], shape=(38186,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14285278]\n"," [ 0.        ]\n"," [-0.14285278]\n"," ...\n"," [-0.14285278]\n"," [-0.14285278]\n"," [ 0.14285278]], shape=(55652, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14285278  0.         -0.14285278 ... -0.14285278 -0.14285278\n","  0.14285278], shape=(55652,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1000061 ]\n"," [-0.09286499]\n"," [-0.07858276]\n"," ...\n"," [ 0.04284668]\n"," [ 0.04998779]\n"," [ 0.04998779]], shape=(28868, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1000061  -0.09286499 -0.07858276 ...  0.04284668  0.04998779\n","  0.04998779], shape=(28868,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01553345]\n"," [ 0.01553345]\n"," [ 0.01553345]\n"," ...\n"," [ 0.        ]\n"," [-0.00311279]\n"," [-0.00930786]], shape=(31878, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01553345  0.01553345  0.01553345 ...  0.         -0.00311279\n"," -0.00930786], shape=(31878,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12789917]\n"," [-0.14013672]\n"," [-0.14944458]\n"," ...\n"," [-0.38961792]\n"," [-0.38580322]\n"," [-0.3824463 ]], shape=(26958, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12789917 -0.14013672 -0.14944458 ... -0.38961792 -0.38580322\n"," -0.3824463 ], shape=(26958,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.25454712]\n"," [-0.21212769]\n"," [-0.17575073]\n"," ...\n"," [ 0.10302734]\n"," [ 0.1272583 ]\n"," [ 0.1333313 ]], shape=(22800, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.25454712 -0.21212769 -0.17575073 ...  0.10302734  0.1272583\n","  0.1333313 ], shape=(22800,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0015564 ]\n"," [ 0.        ]\n"," [-0.0015564 ]\n"," ...\n"," [-0.02038574]\n"," [-0.02508545]\n"," [-0.02038574]], shape=(45128, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0015564   0.         -0.0015564  ... -0.02038574 -0.02508545\n"," -0.02038574], shape=(45128,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07385254]\n"," [-0.07385254]\n"," [-0.0852356 ]\n"," ...\n"," [-0.01135254]\n"," [-0.01135254]\n"," [-0.01135254]], shape=(35712, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07385254 -0.07385254 -0.0852356  ... -0.01135254 -0.01135254\n"," -0.01135254], shape=(35712,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05444336]\n"," [ 0.05740356]\n"," [ 0.0647583 ]\n"," ...\n"," [-0.03091431]\n"," [-0.03237915]\n"," [-0.02941895]], shape=(44482, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05444336  0.05740356  0.0647583  ... -0.03091431 -0.03237915\n"," -0.02941895], shape=(44482,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00421143]\n"," [ 0.01049805]\n"," [ 0.        ]\n"," ...\n"," [ 0.00421143]\n"," [-0.00421143]\n"," [ 0.00421143]], shape=(34382, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00421143  0.01049805  0.         ...  0.00421143 -0.00421143\n","  0.00421143], shape=(34382,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01705933]\n"," [0.01705933]\n"," [0.02047729]\n"," ...\n"," [0.02389526]\n"," [0.0307312 ]\n"," [0.03411865]], shape=(52494, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01705933 0.01705933 0.02047729 ... 0.02389526 0.0307312  0.03411865], shape=(52494,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.13925171]\n"," [0.15188599]\n"," [0.18988037]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.02532959]], shape=(20018, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.13925171 0.15188599 0.18988037 ... 0.         0.         0.02532959], shape=(20018,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07125854]\n"," [-0.0687561 ]\n"," [-0.06500244]\n"," ...\n"," [-0.01126099]\n"," [-0.00875854]\n"," [-0.01126099]], shape=(68736, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07125854 -0.0687561  -0.06500244 ... -0.01126099 -0.00875854\n"," -0.01126099], shape=(68736,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00244141]\n"," [ 0.01220703]\n"," [ 0.02926636]\n"," ...\n"," [ 0.01464844]\n"," [ 0.01220703]\n"," [ 0.01705933]], shape=(16570, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00244141  0.01220703  0.02926636 ...  0.01464844  0.01220703\n","  0.01705933], shape=(16570,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01470947]\n"," [ 0.01049805]\n"," [ 0.00421143]\n"," ...\n"," [ 0.00421143]\n"," [ 0.        ]\n"," [-0.01049805]], shape=(33128, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01470947  0.01049805  0.00421143 ...  0.00421143  0.\n"," -0.01049805], shape=(33128,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00354004]\n"," [ 0.01766968]\n"," [ 0.02474976]\n"," ...\n"," [-0.01412964]\n"," [-0.02120972]\n"," [-0.01766968]], shape=(36362, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00354004  0.01766968  0.02474976 ... -0.01412964 -0.02120972\n"," -0.01766968], shape=(36362,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0015564 ]\n"," [-0.00939941]\n"," [-0.01724243]\n"," ...\n"," [ 0.01879883]\n"," [ 0.01724243]\n"," [ 0.01409912]], shape=(45376, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0015564  -0.00939941 -0.01724243 ...  0.01879883  0.01724243\n","  0.01409912], shape=(45376,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14633179]\n"," [-0.13821411]\n"," [-0.13821411]\n"," ...\n"," [-0.21951294]\n"," [-0.1869812 ]\n"," [-0.14633179]], shape=(39724, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14633179 -0.13821411 -0.13821411 ... -0.21951294 -0.1869812\n"," -0.14633179], shape=(39724,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06164551]\n"," [-0.05859375]\n"," [-0.05859375]\n"," ...\n"," [ 0.17398071]\n"," [ 0.16726685]\n"," [ 0.12515259]], shape=(73498, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06164551 -0.05859375 -0.05859375 ...  0.17398071  0.16726685\n","  0.12515259], shape=(73498,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00100708]\n"," [-0.00048828]\n"," [-0.00250244]\n"," ...\n"," [ 0.02151489]\n"," [ 0.01849365]\n"," [ 0.01348877]], shape=(56204, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00100708 -0.00048828 -0.00250244 ...  0.02151489  0.01849365\n","  0.01348877], shape=(56204,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0479126 ]\n"," [0.04580688]\n"," [0.03921509]\n"," ...\n"," [0.01553345]\n"," [0.02612305]\n"," [0.03091431]], shape=(23764, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0479126  0.04580688 0.03921509 ... 0.01553345 0.02612305 0.03091431], shape=(23764,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00750732]\n"," [0.00875854]\n"," [0.00750732]\n"," ...\n"," [0.00500488]\n"," [0.0062561 ]\n"," [0.00875854]], shape=(28286, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00750732 0.00875854 0.00750732 ... 0.00500488 0.0062561  0.00875854], shape=(28286,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00549316]\n"," [-0.01373291]\n"," ...\n"," [-0.04119873]\n"," [-0.03295898]\n"," [-0.02746582]], shape=(41080, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00549316 -0.01373291 ... -0.04119873 -0.03295898\n"," -0.02746582], shape=(41080,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00714111]\n"," [-0.00714111]\n"," ...\n"," [ 0.04998779]\n"," [ 0.03570557]\n"," [ 0.02856445]], shape=(41922, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00714111 -0.00714111 ...  0.04998779  0.03570557\n","  0.02856445], shape=(41922,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01095581]\n"," [0.        ]\n"," [0.00219727]\n"," ...\n"," [0.04824829]\n"," [0.06140137]\n"," [0.07675171]], shape=(41194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01095581 0.         0.00219727 ... 0.04824829 0.06140137 0.07675171], shape=(41194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04748535]\n"," [-0.04251099]\n"," [-0.03500366]\n"," ...\n"," [-0.26748657]\n"," [-0.31500244]\n"," [-0.32250977]], shape=(46736, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04748535 -0.04251099 -0.03500366 ... -0.26748657 -0.31500244\n"," -0.32250977], shape=(46736,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00860596]\n"," [-0.00732422]\n"," [-0.00515747]\n"," ...\n"," [-0.01464844]\n"," [-0.01379395]\n"," [-0.01379395]], shape=(96430, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00860596 -0.00732422 -0.00515747 ... -0.01464844 -0.01379395\n"," -0.01379395], shape=(96430,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.22351074]\n"," [0.2244873 ]\n"," [0.21798706]\n"," ...\n"," [0.05801392]\n"," [0.05999756]\n"," [0.05999756]], shape=(70038, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.22351074 0.2244873  0.21798706 ... 0.05801392 0.05999756 0.05999756], shape=(70038,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00393677]\n"," [-0.00393677]\n"," [-0.00393677]], shape=(38580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00393677 -0.00393677\n"," -0.00393677], shape=(38580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01611328]\n"," [ 0.01138306]\n"," [ 0.00662231]\n"," ...\n"," [-0.01422119]\n"," [-0.01422119]\n"," [-0.01138306]], shape=(16582, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01611328  0.01138306  0.00662231 ... -0.01422119 -0.01422119\n"," -0.01138306], shape=(16582,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.52856445]\n"," [-0.5       ]\n"," [-0.48571777]\n"," ...\n"," [-0.02856445]\n"," [-0.05712891]\n"," [-0.07144165]], shape=(53102, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.52856445 -0.5        -0.48571777 ... -0.02856445 -0.05712891\n"," -0.07144165], shape=(53102,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [-0.0088501 ]\n"," [-0.01000977]\n"," ...\n"," [ 0.00259399]\n"," [ 0.00250244]\n"," [ 0.00094604]], shape=(37128, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488 -0.0088501  -0.01000977 ...  0.00259399  0.00250244\n","  0.00094604], shape=(37128,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00100708]\n"," [-0.00048828]\n"," [-0.00048828]\n"," ...\n"," [-0.00500488]\n"," [-0.00500488]\n"," [-0.00350952]], shape=(43806, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00100708 -0.00048828 -0.00048828 ... -0.00500488 -0.00500488\n"," -0.00350952], shape=(43806,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07272339]\n"," [-0.07727051]\n"," [-0.08407593]\n"," ...\n"," [ 0.        ]\n"," [-0.00454712]\n"," [-0.00454712]], shape=(42988, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07272339 -0.07727051 -0.08407593 ...  0.         -0.00454712\n"," -0.00454712], shape=(42988,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.12789917]\n"," [ 0.12158203]\n"," [ 0.11355591]\n"," ...\n"," [-0.44110107]\n"," [-0.4381714 ]\n"," [-0.43603516]], shape=(18714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.12789917  0.12158203  0.11355591 ... -0.44110107 -0.4381714\n"," -0.43603516], shape=(18714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.05264282]\n"," [-0.02630615]\n"," ...\n"," [-0.23684692]\n"," [-0.15789795]\n"," [-0.15789795]], shape=(31616, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.05264282 -0.02630615 ... -0.23684692 -0.15789795\n"," -0.15789795], shape=(31616,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03945923]\n"," [-0.02835083]\n"," [-0.01971436]\n"," ...\n"," [-0.02096558]\n"," [-0.02587891]\n"," [-0.02960205]], shape=(74586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03945923 -0.02835083 -0.01971436 ... -0.02096558 -0.02587891\n"," -0.02960205], shape=(74586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.16326904]\n"," [0.14285278]\n"," [0.12243652]\n"," ...\n"," [0.0340271 ]\n"," [0.08843994]\n"," [0.15646362]], shape=(39010, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.16326904 0.14285278 0.12243652 ... 0.0340271  0.08843994 0.15646362], shape=(39010,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00933838]\n"," [ 0.00933838]\n"," [ 0.00622559]\n"," ...\n"," [-0.4392395 ]\n"," [-0.30218506]\n"," [-0.16821289]], shape=(45468, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00933838  0.00933838  0.00622559 ... -0.4392395  -0.30218506\n"," -0.16821289], shape=(45468,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0116272 ]\n"," [-0.0116272 ]\n"," [-0.01034546]\n"," ...\n"," [-0.01034546]\n"," [-0.01034546]\n"," [-0.00949097]], shape=(44232, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0116272  -0.0116272  -0.01034546 ... -0.01034546 -0.01034546\n"," -0.00949097], shape=(44232,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00601196]\n"," [-0.00628662]\n"," [-0.00601196]\n"," ...\n"," [-0.00442505]\n"," [-0.0039978 ]\n"," [-0.00283813]], shape=(169164, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00601196 -0.00628662 -0.00601196 ... -0.00442505 -0.0039978\n"," -0.00283813], shape=(169164,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0249939 ]\n"," [ 0.03460693]\n"," [ 0.04037476]\n"," ...\n"," [-0.04421997]\n"," [-0.04037476]\n"," [-0.04229736]], shape=(35964, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0249939   0.03460693  0.04037476 ... -0.04421997 -0.04037476\n"," -0.04229736], shape=(35964,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02178955]\n"," [-0.01504517]\n"," [-0.00436401]\n"," ...\n"," [ 0.03323364]\n"," [ 0.03485107]\n"," [ 0.03329468]], shape=(44974, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02178955 -0.01504517 -0.00436401 ...  0.03323364  0.03485107\n","  0.03329468], shape=(44974,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04998779]\n"," [ 0.03570557]\n"," [ 0.03570557]\n"," ...\n"," [-0.08572388]\n"," [-0.08572388]\n"," [-0.08572388]], shape=(58632, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04998779  0.03570557  0.03570557 ... -0.08572388 -0.08572388\n"," -0.08572388], shape=(58632,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04910278]\n"," [0.04464722]\n"," [0.04464722]\n"," ...\n"," [0.        ]\n"," [0.00222778]\n"," [0.        ]], shape=(23096, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04910278 0.04464722 0.04464722 ... 0.         0.00222778 0.        ], shape=(23096,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.       ]\n"," [0.       ]\n"," [0.       ]\n"," ...\n"," [0.3611145]\n"," [0.3888855]\n"," [0.3888855]], shape=(74954, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.        0.        0.        ... 0.3611145 0.3888855 0.3888855], shape=(74954,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02786255]\n"," [-0.04736328]\n"," [-0.0557251 ]\n"," ...\n"," [-0.02786255]\n"," [-0.01950073]\n"," [-0.01950073]], shape=(46848, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02786255 -0.04736328 -0.0557251  ... -0.02786255 -0.01950073\n"," -0.01950073], shape=(46848,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05142212]\n"," [-0.04190063]\n"," [-0.02856445]\n"," ...\n"," [-0.0647583 ]\n"," [-0.05142212]\n"," [-0.03237915]], shape=(82652, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05142212 -0.04190063 -0.02856445 ... -0.0647583  -0.05142212\n"," -0.03237915], shape=(82652,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02062988]\n"," [ 0.02062988]\n"," [ 0.00515747]\n"," ...\n"," [-0.07733154]\n"," [-0.07733154]\n"," [-0.05670166]], shape=(28210, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02062988  0.02062988  0.00515747 ... -0.07733154 -0.07733154\n"," -0.05670166], shape=(28210,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.5177002 ]\n"," [0.7350464 ]\n"," [0.6667175 ]\n"," ...\n"," [0.02404785]\n"," [0.02316284]\n"," [0.02301025]], shape=(33274, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.5177002  0.7350464  0.6667175  ... 0.02404785 0.02316284 0.02301025], shape=(33274,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02590942]\n"," [0.01037598]\n"," [0.01037598]\n"," ...\n"," [0.02072144]\n"," [0.01037598]\n"," [0.01037598]], shape=(58722, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02590942 0.01037598 0.01037598 ... 0.02072144 0.01037598 0.01037598], shape=(58722,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01251221]\n"," [-0.00875854]\n"," [-0.00250244]\n"," ...\n"," [-0.00250244]\n"," [-0.00375366]\n"," [-0.00375366]], shape=(29142, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01251221 -0.00875854 -0.00250244 ... -0.00250244 -0.00375366\n"," -0.00375366], shape=(29142,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.5076599 ]\n"," [-0.5114136 ]\n"," [-0.5153198 ]\n"," ...\n"," [ 0.20736694]\n"," [ 0.21173096]\n"," [ 0.21612549]], shape=(61380, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.5076599  -0.5114136  -0.5153198  ...  0.20736694  0.21173096\n","  0.21612549], shape=(61380,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03125]\n"," [0.03125]\n"," [0.     ]\n"," ...\n"," [0.03125]\n"," [0.     ]\n"," [0.     ]], shape=(38740, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03125 0.03125 0.      ... 0.03125 0.      0.     ], shape=(38740,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [-0.02090454]\n"," [-0.02090454]\n"," ...\n"," [ 0.00598145]\n"," [-0.02090454]\n"," [-0.02090454]], shape=(52170, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145 -0.02090454 -0.02090454 ...  0.00598145 -0.02090454\n"," -0.02090454], shape=(52170,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09713745]\n"," [-0.10430908]\n"," [-0.10430908]\n"," ...\n"," [-0.07192993]\n"," [-0.07192993]\n"," [-0.06115723]], shape=(51636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09713745 -0.10430908 -0.10430908 ... -0.07192993 -0.07192993\n"," -0.06115723], shape=(51636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00326538]\n"," [ 0.00161743]\n"," [ 0.00082397]\n"," ...\n"," [-0.00976562]\n"," [-0.00976562]\n"," [-0.00894165]], shape=(30556, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00326538  0.00161743  0.00082397 ... -0.00976562 -0.00976562\n"," -0.00894165], shape=(30556,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.20715332]\n"," [-0.12857056]\n"," [-0.06430054]\n"," ...\n"," [-0.12857056]\n"," [-0.11428833]\n"," [-0.11428833]], shape=(28184, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.20715332 -0.12857056 -0.06430054 ... -0.12857056 -0.11428833\n"," -0.11428833], shape=(28184,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00473022]\n"," [-0.00473022]\n"," [-0.00942993]\n"," ...\n"," [ 0.        ]\n"," [ 0.00473022]\n"," [ 0.00942993]], shape=(31960, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00473022 -0.00473022 -0.00942993 ...  0.          0.00473022\n","  0.00942993], shape=(31960,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17886353]\n"," [-0.17074585]\n"," [-0.14633179]\n"," ...\n"," [-0.14633179]\n"," [-0.17074585]\n"," [-0.16259766]], shape=(36876, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17886353 -0.17074585 -0.14633179 ... -0.14633179 -0.17074585\n"," -0.16259766], shape=(36876,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.40933228]\n"," [-0.4697876 ]\n"," [-0.5109863 ]\n"," ...\n"," [-0.00549316]\n"," [-0.00549316]\n"," [-0.01373291]], shape=(41842, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.40933228 -0.4697876  -0.5109863  ... -0.00549316 -0.00549316\n"," -0.01373291], shape=(41842,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01086426]\n"," [ 0.02172852]\n"," [ 0.03262329]\n"," ...\n"," [-0.07608032]\n"," [-0.07608032]\n"," [-0.06521606]], shape=(38534, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01086426  0.02172852  0.03262329 ... -0.07608032 -0.07608032\n"," -0.06521606], shape=(38534,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17074585]\n"," [-0.17886353]\n"," [-0.16259766]\n"," ...\n"," [-0.17886353]\n"," [-0.17886353]\n"," [-0.1869812 ]], shape=(47902, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17074585 -0.17886353 -0.16259766 ... -0.17886353 -0.17886353\n"," -0.1869812 ], shape=(47902,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01470947]\n"," [-0.02206421]\n"," [-0.02206421]\n"," ...\n"," [-0.04043579]\n"," [-0.05514526]\n"," [-0.04779053]], shape=(32074, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01470947 -0.02206421 -0.02206421 ... -0.04043579 -0.05514526\n"," -0.04779053], shape=(32074,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.21517944]\n"," [0.20254517]\n"," [0.18988037]\n"," ...\n"," [0.02532959]\n"," [0.06329346]\n"," [0.05062866]], shape=(16250, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.21517944 0.20254517 0.18988037 ... 0.02532959 0.06329346 0.05062866], shape=(16250,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01177979]\n"," [-0.01104736]\n"," [-0.009552  ]\n"," ...\n"," [-0.00662231]\n"," [-0.00735474]\n"," [-0.00808716]], shape=(24408, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01177979 -0.01104736 -0.009552   ... -0.00662231 -0.00735474\n"," -0.00808716], shape=(24408,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.006073  ]\n"," [ 0.02423096]\n"," [ 0.01211548]\n"," ...\n"," [ 0.01211548]\n"," [ 0.006073  ]\n"," [-0.006073  ]], shape=(48348, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.006073    0.02423096  0.01211548 ...  0.01211548  0.006073\n"," -0.006073  ], shape=(48348,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01068115]\n"," [0.01605225]\n"," [0.01605225]\n"," ...\n"," [0.02139282]\n"," [0.02139282]\n"," [0.02139282]], shape=(24886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01068115 0.01605225 0.01605225 ... 0.02139282 0.02139282 0.02139282], shape=(24886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14056396]\n"," [-0.15185547]\n"," [-0.15994263]\n"," ...\n"," [-0.03231812]\n"," [-0.02908325]\n"," [-0.02746582]], shape=(41082, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14056396 -0.15185547 -0.15994263 ... -0.03231812 -0.02908325\n"," -0.02746582], shape=(41082,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00506592]\n"," [-0.02539062]\n"," [-0.0406189 ]\n"," ...\n"," [-0.00506592]\n"," [ 0.02539062]\n"," [ 0.04315186]], shape=(57274, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00506592 -0.02539062 -0.0406189  ... -0.00506592  0.02539062\n","  0.04315186], shape=(57274,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1048584 ]\n"," [0.08987427]\n"," [0.0786438 ]\n"," ...\n"," [0.01873779]\n"," [0.02807617]\n"," [0.03182983]], shape=(63112, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1048584  0.08987427 0.0786438  ... 0.01873779 0.02807617 0.03182983], shape=(63112,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11550903]\n"," [-0.10699463]\n"," [-0.09851074]\n"," ...\n"," [-0.07000732]\n"," [-0.0710144 ]\n"," [-0.07199097]], shape=(26770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11550903 -0.10699463 -0.09851074 ... -0.07000732 -0.0710144\n"," -0.07199097], shape=(26770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00314331]\n"," [0.01568604]\n"," [0.03448486]\n"," ...\n"," [0.0501709 ]\n"," [0.04074097]\n"," [0.01568604]], shape=(56006, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00314331 0.01568604 0.03448486 ... 0.0501709  0.04074097 0.01568604], shape=(56006,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00064087]\n"," [-0.00064087]\n"," ...\n"," [-0.00640869]\n"," [-0.00704956]\n"," [-0.00769043]], shape=(74962, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00064087 -0.00064087 ... -0.00640869 -0.00704956\n"," -0.00769043], shape=(74962,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.        ]\n"," [-0.63220215]\n"," [ 0.00305176]\n"," ...\n"," [-0.00289917]\n"," [-0.006073  ]\n"," [-0.00854492]], shape=(56100, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.         -0.63220215  0.00305176 ... -0.00289917 -0.006073\n"," -0.00854492], shape=(56100,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.3015747 ]\n"," [-0.34127808]\n"," [-0.39682007]\n"," ...\n"," [ 0.00793457]\n"," [ 0.00793457]\n"," [ 0.00793457]], shape=(50980, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.3015747  -0.34127808 -0.39682007 ...  0.00793457  0.00793457\n","  0.00793457], shape=(50980,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11184692]\n"," [-0.10195923]\n"," [-0.07894897]\n"," ...\n"," [ 0.0559082 ]\n"," [ 0.0690918 ]\n"," [ 0.0690918 ]], shape=(50876, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11184692 -0.10195923 -0.07894897 ...  0.0559082   0.0690918\n","  0.0690918 ], shape=(50876,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00375366]\n"," [ 0.00375366]\n"," [ 0.00250244]\n"," ...\n"," [-0.01251221]\n"," [-0.01126099]\n"," [-0.00750732]], shape=(53232, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00375366  0.00375366  0.00250244 ... -0.01251221 -0.01126099\n"," -0.00750732], shape=(53232,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01501465]\n"," [-0.0249939 ]\n"," [-0.03500366]\n"," ...\n"," [ 0.18499756]\n"," [ 0.22000122]\n"," [ 0.24249268]], shape=(115134, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01501465 -0.0249939  -0.03500366 ...  0.18499756  0.22000122\n","  0.24249268], shape=(115134,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00704956]\n"," [-0.01089478]\n"," [-0.01345825]\n"," ...\n"," [ 0.00961304]\n"," [ 0.0083313 ]\n"," [ 0.00448608]], shape=(41816, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00704956 -0.01089478 -0.01345825 ...  0.00961304  0.0083313\n","  0.00448608], shape=(41816,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04748535]\n"," [-0.02124023]\n"," [ 0.00750732]\n"," ...\n"," [ 0.00750732]\n"," [ 0.00750732]\n"," [ 0.00750732]], shape=(34300, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04748535 -0.02124023  0.00750732 ...  0.00750732  0.00750732\n","  0.00750732], shape=(34300,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00341797]\n"," [-0.00683594]\n"," [-0.01705933]\n"," ...\n"," [ 0.01364136]\n"," [ 0.00341797]\n"," [ 0.        ]], shape=(56660, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00341797 -0.00683594 -0.01705933 ...  0.01364136  0.00341797\n","  0.        ], shape=(56660,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.11013794]\n"," [ 0.12335205]\n"," [ 0.13568115]\n"," ...\n"," [-0.00177002]\n"," [-0.00527954]\n"," [-0.0123291 ]], shape=(51614, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.11013794  0.12335205  0.13568115 ... -0.00177002 -0.00527954\n"," -0.0123291 ], shape=(51614,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04299927]\n"," [0.04299927]\n"," [0.04299927]\n"," ...\n"," [0.00537109]\n"," [0.00537109]\n"," [0.0161438 ]], shape=(95080, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04299927 0.04299927 0.04299927 ... 0.00537109 0.00537109 0.0161438 ], shape=(95080,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00546265]\n"," [-0.01367188]\n"," [-0.01913452]\n"," ...\n"," [ 0.00546265]\n"," [ 0.01092529]\n"," [ 0.01092529]], shape=(44022, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00546265 -0.01367188 -0.01913452 ...  0.00546265  0.01092529\n","  0.01092529], shape=(44022,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07250977]\n"," [-0.07751465]\n"," [-0.07751465]\n"," ...\n"," [ 0.05749512]\n"," [ 0.04998779]\n"," [ 0.04000854]], shape=(38550, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07250977 -0.07751465 -0.07751465 ...  0.05749512  0.04998779\n","  0.04000854], shape=(38550,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00537109]\n"," [0.00537109]\n"," [0.00805664]\n"," ...\n"," [0.01748657]\n"," [0.0161438 ]\n"," [0.0161438 ]], shape=(26264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00537109 0.00537109 0.00805664 ... 0.01748657 0.0161438  0.0161438 ], shape=(26264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01135254]\n"," [0.00567627]\n"," [0.00567627]\n"," ...\n"," [0.3125    ]\n"," [0.34658813]\n"," [0.34658813]], shape=(187068, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01135254 0.00567627 0.00567627 ... 0.3125     0.34658813 0.34658813], shape=(187068,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00524902]\n"," [ 0.01138306]\n"," [ 0.01577759]\n"," ...\n"," [-0.00921631]\n"," [-0.01315308]\n"," [-0.01516724]], shape=(36492, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00524902  0.01138306  0.01577759 ... -0.00921631 -0.01315308\n"," -0.01516724], shape=(36492,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08581543]\n"," [-0.08911133]\n"," [-0.09570312]\n"," ...\n"," [ 0.05609131]\n"," [ 0.04949951]\n"," [ 0.03961182]], shape=(17724, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08581543 -0.08911133 -0.09570312 ...  0.05609131  0.04949951\n","  0.03961182], shape=(17724,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00201416]\n"," [-0.00100708]\n"," [-0.00201416]\n"," ...\n"," [-0.00201416]\n"," [-0.00250244]\n"," [-0.00299072]], shape=(32732, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00201416 -0.00100708 -0.00201416 ... -0.00201416 -0.00250244\n"," -0.00299072], shape=(32732,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.050354  ]\n"," [-0.06515503]\n"," [-0.08233643]\n"," ...\n"," [-0.00415039]\n"," [-0.00057983]\n"," [ 0.00057983]], shape=(106816, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.050354   -0.06515503 -0.08233643 ... -0.00415039 -0.00057983\n","  0.00057983], shape=(106816,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.32235718]\n"," [0.23077393]\n"," [0.15200806]\n"," ...\n"," [0.31011963]\n"," [0.24664307]\n"," [0.18435669]], shape=(34820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.32235718 0.23077393 0.15200806 ... 0.31011963 0.24664307 0.18435669], shape=(34820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00250244]\n"," [-0.00250244]\n"," ...\n"," [-0.00250244]\n"," [-0.00250244]\n"," [-0.00250244]], shape=(87630, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00250244 -0.00250244 ... -0.00250244 -0.00250244\n"," -0.00250244], shape=(87630,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00350952]\n"," [0.00350952]\n"," [0.00500488]\n"," ...\n"," [0.00601196]\n"," [0.00549316]\n"," [0.00299072]], shape=(46450, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00350952 0.00350952 0.00500488 ... 0.00601196 0.00549316 0.00299072], shape=(46450,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.20791626]\n"," [0.20239258]\n"," [0.19854736]\n"," ...\n"," [0.2036438 ]\n"," [0.20578003]\n"," [0.20663452]], shape=(28334, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.20791626 0.20239258 0.19854736 ... 0.2036438  0.20578003 0.20663452], shape=(28334,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02902222]\n"," [ 0.015625  ]\n"," [ 0.01339722]\n"," ...\n"," [-0.01116943]\n"," [-0.00894165]\n"," [-0.00445557]], shape=(39182, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02902222  0.015625    0.01339722 ... -0.01116943 -0.00894165\n"," -0.00445557], shape=(39182,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00750732]\n"," [ 0.0062561 ]\n"," [ 0.0062561 ]\n"," ...\n"," [-0.03500366]\n"," [-0.02999878]\n"," [-0.0249939 ]], shape=(39494, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00750732  0.0062561   0.0062561  ... -0.03500366 -0.02999878\n"," -0.0249939 ], shape=(39494,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00942993]\n"," [0.00942993]\n"," [0.00473022]], shape=(39534, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00942993 0.00942993 0.00473022], shape=(39534,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0012207 ]\n"," [ 0.0012207 ]\n"," [-0.00549316]\n"," ...\n"," [-0.0189209 ]\n"," [-0.02075195]\n"," [-0.0213623 ]], shape=(44334, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0012207   0.0012207  -0.00549316 ... -0.0189209  -0.02075195\n"," -0.0213623 ], shape=(44334,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00454712]\n"," [-0.01135254]\n"," ...\n"," [ 0.16137695]\n"," [ 0.2000122 ]\n"," [ 0.21591187]], shape=(47018, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00454712 -0.01135254 ...  0.16137695  0.2000122\n","  0.21591187], shape=(47018,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05426025]\n"," [-0.11627197]\n"," [-0.17053223]\n"," ...\n"," [-0.07751465]\n"," [-0.07751465]\n"," [-0.07751465]], shape=(31526, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05426025 -0.11627197 -0.17053223 ... -0.07751465 -0.07751465\n"," -0.07751465], shape=(31526,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13009644]\n"," [-0.16259766]\n"," [-0.16259766]\n"," ...\n"," [-0.22763062]\n"," [-0.21951294]\n"," [-0.21951294]], shape=(52996, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13009644 -0.16259766 -0.16259766 ... -0.22763062 -0.21951294\n"," -0.21951294], shape=(52996,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [-0.00048828]\n"," [-0.00350952]\n"," ...\n"," [-0.01300049]\n"," [-0.01098633]\n"," [-0.00900269]], shape=(72710, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244 -0.00048828 -0.00350952 ... -0.01300049 -0.01098633\n"," -0.00900269], shape=(72710,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.47476196]\n"," [0.5050354 ]\n"," [0.5505066 ]\n"," ...\n"," [0.0050354 ]\n"," [0.0050354 ]\n"," [0.0050354 ]], shape=(31082, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.47476196 0.5050354  0.5505066  ... 0.0050354  0.0050354  0.0050354 ], shape=(31082,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00201416]\n"," [-0.00100708]\n"," [-0.00448608]\n"," ...\n"," [ 0.00799561]\n"," [ 0.00650024]\n"," [ 0.00500488]], shape=(75424, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00201416 -0.00100708 -0.00448608 ...  0.00799561  0.00650024\n","  0.00500488], shape=(75424,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.027771  ]\n"," [-0.027771  ]\n"," [-0.01852417]\n"," ...\n"," [ 0.        ]\n"," [ 0.00924683]\n"," [ 0.00924683]], shape=(40306, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.027771   -0.027771   -0.01852417 ...  0.          0.00924683\n","  0.00924683], shape=(40306,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02209473]\n"," [ 0.02761841]\n"," [ 0.03039551]\n"," ...\n"," [-0.01657104]\n"," [-0.02209473]\n"," [-0.02761841]], shape=(41522, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02209473  0.02761841  0.03039551 ... -0.01657104 -0.02209473\n"," -0.02761841], shape=(41522,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05264282]\n"," [-0.05264282]\n"," [-0.10525513]\n"," ...\n"," [ 0.02630615]\n"," [ 0.        ]\n"," [ 0.02630615]], shape=(49060, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05264282 -0.05264282 -0.10525513 ...  0.02630615  0.\n","  0.02630615], shape=(49060,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.02359009]\n"," ...\n"," [0.00473022]\n"," [0.00473022]\n"," [0.00473022]], shape=(47606, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.02359009 ... 0.00473022 0.00473022 0.00473022], shape=(47606,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01242065]\n"," [-0.00622559]\n"," [ 0.        ]\n"," ...\n"," [-0.03726196]\n"," [-0.04348755]\n"," [-0.04348755]], shape=(37640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01242065 -0.00622559  0.         ... -0.03726196 -0.04348755\n"," -0.04348755], shape=(37640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01766968]\n"," [-0.01766968]\n"," [-0.01766968]\n"," ...\n"," [ 0.00354004]\n"," [-0.00354004]\n"," [-0.01412964]], shape=(27448, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01766968 -0.01766968 -0.01766968 ...  0.00354004 -0.00354004\n"," -0.01412964], shape=(27448,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0602417 ]\n"," [-0.0602417 ]\n"," [-0.07229614]\n"," ...\n"," [-0.01205444]\n"," [-0.04818726]\n"," [-0.08435059]], shape=(54146, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0602417  -0.0602417  -0.07229614 ... -0.01205444 -0.04818726\n"," -0.08435059], shape=(54146,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07913208]\n"," [-0.07913208]\n"," [-0.07913208]\n"," ...\n"," [-0.10430908]\n"," [-0.13308716]\n"," [-0.15826416]], shape=(18166, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07913208 -0.07913208 -0.07913208 ... -0.10430908 -0.13308716\n"," -0.15826416], shape=(18166,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05654907]\n"," [ 0.06784058]\n"," [ 0.06784058]\n"," ...\n"," [-0.0904541 ]\n"," [-0.10824585]\n"," [-0.12762451]], shape=(82180, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05654907  0.06784058  0.06784058 ... -0.0904541  -0.10824585\n"," -0.12762451], shape=(82180,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00799561]\n"," [0.00549316]\n"," [0.00299072]\n"," ...\n"," [0.00650024]\n"," [0.00799561]\n"," [0.0085144 ]], shape=(30790, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00799561 0.00549316 0.00299072 ... 0.00650024 0.00799561 0.0085144 ], shape=(30790,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01998901]\n"," [-0.01998901]\n"," [-0.01998901]\n"," ...\n"," [-0.01998901]\n"," [-0.01000977]\n"," [-0.01000977]], shape=(37986, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01998901 -0.01998901 -0.01998901 ... -0.01998901 -0.01000977\n"," -0.01000977], shape=(37986,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00534058]\n"," [-0.01068115]\n"," [-0.00534058]\n"," ...\n"," [-0.03207397]\n"," [-0.0267334 ]\n"," [-0.02139282]], shape=(47788, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00534058 -0.01068115 -0.00534058 ... -0.03207397 -0.0267334\n"," -0.02139282], shape=(47788,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01138306]\n"," [-0.00473022]\n"," [ 0.        ]\n"," ...\n"," [-0.18103027]\n"," [-0.1876831 ]\n"," [-0.19241333]], shape=(29004, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01138306 -0.00473022  0.         ... -0.18103027 -0.1876831\n"," -0.19241333], shape=(29004,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06686401]\n"," [-0.08914185]\n"," [-0.09469604]\n"," ...\n"," [-0.01391602]\n"," [-0.00558472]\n"," [ 0.00558472]], shape=(27898, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06686401 -0.08914185 -0.09469604 ... -0.01391602 -0.00558472\n","  0.00558472], shape=(27898,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04611206]\n"," [ 0.01153564]\n"," [-0.01730347]\n"," ...\n"," [ 0.02017212]\n"," [ 0.02593994]\n"," [ 0.03170776]], shape=(56614, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04611206  0.01153564 -0.01730347 ...  0.02017212  0.02593994\n","  0.03170776], shape=(56614,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00372314]\n"," [0.00372314]\n"," [0.00744629]\n"," ...\n"," [0.0632019 ]\n"," [0.05575562]\n"," [0.03717041]], shape=(48928, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00372314 0.00372314 0.00744629 ... 0.0632019  0.05575562 0.03717041], shape=(48928,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02288818]\n"," [-0.02288818]\n"," [-0.0269165 ]\n"," ...\n"," [-0.02960205]\n"," [-0.03634644]\n"," [-0.03634644]], shape=(48670, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02288818 -0.02288818 -0.0269165  ... -0.02960205 -0.03634644\n"," -0.03634644], shape=(48670,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00256348]\n"," [-0.00256348]\n"," [ 0.        ]\n"," ...\n"," [-0.21939087]\n"," [-0.21429443]\n"," [-0.1913147 ]], shape=(38592, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00256348 -0.00256348  0.         ... -0.21939087 -0.21429443\n"," -0.1913147 ], shape=(38592,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02124023]\n"," [-0.02999878]\n"," [-0.04125977]\n"," ...\n"," [ 0.00125122]\n"," [ 0.00250244]\n"," [ 0.00375366]], shape=(78152, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02124023 -0.02999878 -0.04125977 ...  0.00125122  0.00250244\n","  0.00375366], shape=(78152,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00125122]\n"," [-0.00125122]\n"," ...\n"," [-0.03375244]\n"," [-0.02999878]\n"," [-0.02624512]], shape=(27426, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00125122 -0.00125122 ... -0.03375244 -0.02999878\n"," -0.02624512], shape=(27426,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05606079]\n"," [-0.052948  ]\n"," [-0.04983521]\n"," ...\n"," [-0.13708496]\n"," [-0.13708496]\n"," [-0.13082886]], shape=(31940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05606079 -0.052948   -0.04983521 ... -0.13708496 -0.13708496\n"," -0.13082886], shape=(31940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15609741]\n"," [-0.1512146 ]\n"," [-0.1512146 ]\n"," ...\n"," [-0.08291626]\n"," [-0.08779907]\n"," [-0.08291626]], shape=(22068, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15609741 -0.1512146  -0.1512146  ... -0.08291626 -0.08779907\n"," -0.08291626], shape=(22068,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08779907]\n"," [-0.0975647 ]\n"," [-0.08779907]\n"," ...\n"," [-0.10733032]\n"," [-0.10244751]\n"," [-0.10244751]], shape=(41154, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08779907 -0.0975647  -0.08779907 ... -0.10733032 -0.10244751\n"," -0.10244751], shape=(41154,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00274658]\n"," [-0.00274658]\n"," [-0.00274658]\n"," ...\n"," [-0.2479248 ]\n"," [-0.22589111]\n"," [-0.18457031]], shape=(42644, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00274658 -0.00274658 -0.00274658 ... -0.2479248  -0.22589111\n"," -0.18457031], shape=(42644,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01791382]\n"," [ 0.00299072]\n"," [ 0.02685547]\n"," ...\n"," [-0.01193237]\n"," [-0.01193237]\n"," [ 0.00299072]], shape=(38338, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01791382  0.00299072  0.02685547 ... -0.01193237 -0.01193237\n","  0.00299072], shape=(38338,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04846191]\n"," [-0.040802  ]\n"," [-0.03317261]\n"," ...\n"," [ 0.06121826]\n"," [ 0.03317261]\n"," [-0.00256348]], shape=(35118, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04846191 -0.040802   -0.03317261 ...  0.06121826  0.03317261\n"," -0.00256348], shape=(35118,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01086426]\n"," [0.01086426]\n"," [0.01086426]\n"," ...\n"," [0.05435181]\n"," [0.06521606]\n"," [0.05435181]], shape=(44740, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01086426 0.01086426 0.01086426 ... 0.05435181 0.06521606 0.05435181], shape=(44740,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11206055]\n"," [-0.11206055]\n"," [-0.11206055]\n"," ...\n"," [-0.07757568]\n"," [-0.06896973]\n"," [-0.07757568]], shape=(35694, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11206055 -0.11206055 -0.11206055 ... -0.07757568 -0.06896973\n"," -0.07757568], shape=(35694,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.006073  ]\n"," [0.01211548]\n"," [0.006073  ]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.006073  ]], shape=(71500, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.006073   0.01211548 0.006073   ... 0.         0.         0.006073  ], shape=(71500,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01898193]\n"," [-0.02709961]\n"," [-0.03253174]\n"," ...\n"," [-0.05419922]\n"," [-0.05419922]\n"," [-0.04064941]], shape=(39868, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01898193 -0.02709961 -0.03253174 ... -0.05419922 -0.05419922\n"," -0.04064941], shape=(39868,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00485229]\n"," [0.0072937 ]\n"," ...\n"," [0.00973511]\n"," [0.01217651]\n"," [0.00485229]], shape=(54158, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00485229 0.0072937  ... 0.00973511 0.01217651 0.00485229], shape=(54158,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07022095]\n"," [ 0.07022095]\n"," [ 0.06594849]\n"," ...\n"," [-0.02127075]\n"," [-0.03405762]\n"," [-0.04467773]], shape=(30366, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07022095  0.07022095  0.06594849 ... -0.02127075 -0.03405762\n"," -0.04467773], shape=(30366,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18707275]\n"," [-0.18283081]\n"," [-0.17773438]\n"," ...\n"," [-0.07781982]\n"," [-0.07992554]\n"," [-0.07992554]], shape=(64484, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18707275 -0.18283081 -0.17773438 ... -0.07781982 -0.07992554\n"," -0.07992554], shape=(64484,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00366211]\n"," [-0.00366211]\n"," [ 0.00183105]\n"," ...\n"," [-0.18249512]\n"," [-0.1751709 ]\n"," [-0.17337036]], shape=(43804, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00366211 -0.00366211  0.00183105 ... -0.18249512 -0.1751709\n"," -0.17337036], shape=(43804,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00064087]\n"," [-0.00064087]\n"," [-0.00064087]\n"," ...\n"," [ 0.03845215]\n"," [ 0.05059814]\n"," [ 0.06341553]], shape=(72676, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00064087 -0.00064087 -0.00064087 ...  0.03845215  0.05059814\n","  0.06341553], shape=(72676,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04730225]\n"," [0.02703857]\n"," [0.02703857]\n"," ...\n"," [0.04052734]\n"," [0.02703857]\n"," [0.03378296]], shape=(21950, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04730225 0.02703857 0.02703857 ... 0.04052734 0.02703857 0.03378296], shape=(21950,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0267334 ]\n"," [-0.03744507]\n"," [-0.03744507]\n"," ...\n"," [-0.00534058]\n"," [-0.01605225]\n"," [-0.01068115]], shape=(61354, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0267334  -0.03744507 -0.03744507 ... -0.00534058 -0.01605225\n"," -0.01068115], shape=(61354,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00250244]\n"," [0.00201416]\n"," [0.00250244]\n"," ...\n"," [0.00799561]\n"," [0.00601196]\n"," [0.00500488]], shape=(48342, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00250244 0.00201416 0.00250244 ... 0.00799561 0.00601196 0.00500488], shape=(48342,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01559448]\n"," [ 0.02337646]\n"," [ 0.02337646]\n"," ...\n"," [-0.02078247]\n"," [-0.02337646]\n"," [-0.03115845]], shape=(52774, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01559448  0.02337646  0.02337646 ... -0.02078247 -0.02337646\n"," -0.03115845], shape=(52774,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01300049]\n"," [-0.02597046]\n"," [-0.03375244]\n"," ...\n"," [ 0.09869385]\n"," [ 0.07012939]\n"," [ 0.05194092]], shape=(58636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01300049 -0.02597046 -0.03375244 ...  0.09869385  0.07012939\n","  0.05194092], shape=(58636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11016846]\n"," [-0.11227417]\n"," [-0.11355591]\n"," ...\n"," [-0.18869019]\n"," [-0.22161865]\n"," [-0.25369263]], shape=(18874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11016846 -0.11227417 -0.11355591 ... -0.18869019 -0.22161865\n"," -0.25369263], shape=(18874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06710815]\n"," [-0.08053589]\n"," [-0.08053589]\n"," ...\n"," [-0.08053589]\n"," [-0.07382202]\n"," [-0.08053589]], shape=(78386, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06710815 -0.08053589 -0.08053589 ... -0.08053589 -0.07382202\n"," -0.08053589], shape=(78386,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04949951]\n"," [-0.06436157]\n"," [-0.05941772]\n"," ...\n"," [-0.2128601 ]\n"," [-0.2128601 ]\n"," [-0.21783447]], shape=(38106, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04949951 -0.06436157 -0.05941772 ... -0.2128601  -0.2128601\n"," -0.21783447], shape=(38106,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.18249512]\n"," [ 0.20251465]\n"," [ 0.21749878]\n"," ...\n"," [-0.0249939 ]\n"," [-0.02749634]\n"," [-0.02749634]], shape=(53770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.18249512  0.20251465  0.21749878 ... -0.0249939  -0.02749634\n"," -0.02749634], shape=(53770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02923584]\n"," [-0.07019043]\n"," [-0.04092407]\n"," ...\n"," [-0.04092407]\n"," [-0.02923584]\n"," [-0.04092407]], shape=(36330, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02923584 -0.07019043 -0.04092407 ... -0.04092407 -0.02923584\n"," -0.04092407], shape=(36330,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06604004]\n"," [ 0.08963013]\n"," [ 0.09906006]\n"," ...\n"," [-0.03775024]\n"," [-0.03302002]\n"," [-0.02359009]], shape=(46594, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06604004  0.08963013  0.09906006 ... -0.03775024 -0.03302002\n"," -0.02359009], shape=(46594,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0307312 ]\n"," [0.0307312 ]\n"," [0.02389526]\n"," ...\n"," [0.02047729]\n"," [0.00683594]\n"," [0.00683594]], shape=(82328, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0307312  0.0307312  0.02389526 ... 0.02047729 0.00683594 0.00683594], shape=(82328,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22958374]\n"," [-0.23043823]\n"," [-0.23171997]\n"," ...\n"," [ 0.21896362]\n"," [ 0.21514893]\n"," [ 0.21173096]], shape=(50490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22958374 -0.23043823 -0.23171997 ...  0.21896362  0.21514893\n","  0.21173096], shape=(50490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02374268]\n"," [-0.01623535]\n"," [-0.00875854]\n"," ...\n"," [ 0.00250244]\n"," [ 0.0062561 ]\n"," [ 0.0062561 ]], shape=(46966, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02374268 -0.01623535 -0.00875854 ...  0.00250244  0.0062561\n","  0.0062561 ], shape=(46966,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00201416]\n"," [-0.00100708]\n"," ...\n"," [-0.01000977]\n"," [-0.00900269]\n"," [-0.00799561]], shape=(89858, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00201416 -0.00100708 ... -0.01000977 -0.00900269\n"," -0.00799561], shape=(89858,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04092407]\n"," [-0.05847168]\n"," [-0.05847168]\n"," ...\n"," [-0.08770752]\n"," [-0.07019043]\n"," [-0.05847168]], shape=(17900, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04092407 -0.05847168 -0.05847168 ... -0.08770752 -0.07019043\n"," -0.05847168], shape=(17900,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00537109]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.04840088]\n"," [0.05377197]\n"," [0.05377197]], shape=(36760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00537109 0.         0.         ... 0.04840088 0.05377197 0.05377197], shape=(36760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07608032]\n"," [ 0.08694458]\n"," [ 0.07608032]\n"," ...\n"," [-0.01086426]\n"," [-0.01086426]\n"," [-0.01086426]], shape=(46254, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07608032  0.08694458  0.07608032 ... -0.01086426 -0.01086426\n"," -0.01086426], shape=(46254,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03048706]\n"," [-0.03048706]\n"," [-0.03048706]\n"," ...\n"," [-0.01904297]\n"," [-0.02285767]\n"," [-0.02285767]], shape=(39378, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03048706 -0.03048706 -0.03048706 ... -0.01904297 -0.02285767\n"," -0.02285767], shape=(39378,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0105896 ]\n"," [ 0.0105896 ]\n"," [ 0.04232788]\n"," ...\n"," [ 0.07406616]\n"," [ 0.06878662]\n"," [ 0.06350708]], shape=(19832, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0105896   0.0105896   0.04232788 ...  0.07406616  0.06878662\n","  0.06350708], shape=(19832,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07192993]\n"," [-0.07913208]\n"," [-0.09713745]\n"," ...\n"," [-0.12231445]\n"," [-0.07192993]\n"," [-0.025177  ]], shape=(42366, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07192993 -0.07913208 -0.09713745 ... -0.12231445 -0.07192993\n"," -0.025177  ], shape=(42366,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16546631]\n"," [-0.17626953]\n"," [-0.19424438]\n"," ...\n"," [-0.09713745]\n"," [-0.08633423]\n"," [-0.08633423]], shape=(31184, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16546631 -0.17626953 -0.19424438 ... -0.09713745 -0.08633423\n"," -0.08633423], shape=(31184,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01251221]\n"," [-0.01251221]\n"," [-0.01251221]\n"," ...\n"," [-0.09375   ]\n"," [-0.09375   ]\n"," [-0.09375   ]], shape=(20532, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01251221 -0.01251221 -0.01251221 ... -0.09375    -0.09375\n"," -0.09375   ], shape=(20532,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15933228]\n"," [-0.10440063]\n"," [-0.06286621]\n"," ...\n"," [ 0.04943848]\n"," [-0.02868652]\n"," [-0.09951782]], shape=(38618, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15933228 -0.10440063 -0.06286621 ...  0.04943848 -0.02868652\n"," -0.09951782], shape=(38618,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01000977]\n"," [-0.00500488]\n"," [-0.00500488]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(54372, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01000977 -0.00500488 -0.00500488 ...  0.          0.\n","  0.        ], shape=(54372,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [-0.00765991]\n"," [-0.01251221]\n"," ...\n"," [-0.00317383]\n"," [-0.00500488]\n"," [-0.00524902]], shape=(39506, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488 -0.00765991 -0.01251221 ... -0.00317383 -0.00500488\n"," -0.00524902], shape=(39506,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04663086]\n"," [-0.05700684]\n"," [-0.07772827]\n"," ...\n"," [ 0.00518799]\n"," [ 0.        ]\n"," [-0.00518799]], shape=(53530, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04663086 -0.05700684 -0.07772827 ...  0.00518799  0.\n"," -0.00518799], shape=(53530,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.14285278]\n"," ...\n"," [ 0.        ]\n"," [-0.14285278]\n"," [-0.14285278]], shape=(68624, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.14285278 ...  0.         -0.14285278\n"," -0.14285278], shape=(68624,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02462769]\n"," [-0.02728271]\n"," [-0.03030396]\n"," ...\n"," [-0.2107544 ]\n"," [-0.19424438]\n"," [-0.17123413]], shape=(38358, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02462769 -0.02728271 -0.03030396 ... -0.2107544  -0.19424438\n"," -0.17123413], shape=(38358,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06027222]\n"," [-0.06903076]\n"," [-0.06027222]\n"," ...\n"," [-0.13790894]\n"," [-0.12069702]\n"," [-0.12930298]], shape=(39444, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06027222 -0.06903076 -0.06027222 ... -0.13790894 -0.12069702\n"," -0.12930298], shape=(39444,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1373291 ]\n"," [-0.12017822]\n"," [-0.10299683]\n"," ...\n"," [-0.0171814 ]\n"," [-0.00857544]\n"," [-0.00430298]], shape=(50668, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1373291  -0.12017822 -0.10299683 ... -0.0171814  -0.00857544\n"," -0.00430298], shape=(50668,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02648926]\n"," [0.02801514]\n"," [0.0295105 ]\n"," ...\n"," [0.01199341]\n"," [0.01348877]\n"," [0.01348877]], shape=(16682, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02648926 0.02801514 0.0295105  ... 0.01199341 0.01348877 0.01348877], shape=(16682,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02438354]\n"," [-0.02438354]\n"," [-0.02438354]\n"," ...\n"," [ 0.01220703]\n"," [ 0.01220703]\n"," [ 0.02438354]], shape=(33474, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02438354 -0.02438354 -0.02438354 ...  0.01220703  0.01220703\n","  0.02438354], shape=(33474,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01409912]\n"," [-0.00939941]\n"," [-0.00314331]\n"," ...\n"," [-0.0015564 ]\n"," [ 0.00314331]\n"," [ 0.        ]], shape=(82524, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01409912 -0.00939941 -0.00314331 ... -0.0015564   0.00314331\n","  0.        ], shape=(82524,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02749634]\n"," [-0.02749634]\n"," [-0.02749634]\n"," ...\n"," [-0.04000854]\n"," [-0.02749634]\n"," [-0.01748657]], shape=(53988, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02749634 -0.02749634 -0.02749634 ... -0.04000854 -0.02749634\n"," -0.01748657], shape=(53988,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03030396]\n"," [-0.03637695]\n"," [-0.04241943]\n"," ...\n"," [ 0.01211548]\n"," [-0.006073  ]\n"," [-0.03637695]], shape=(45604, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03030396 -0.03637695 -0.04241943 ...  0.01211548 -0.006073\n"," -0.03637695], shape=(45604,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00875854]\n"," [-0.00750732]\n"," [-0.00750732]\n"," ...\n"," [ 0.00375366]\n"," [ 0.00375366]\n"," [ 0.00375366]], shape=(40558, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00875854 -0.00750732 -0.00750732 ...  0.00375366  0.00375366\n","  0.00375366], shape=(40558,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22763062]\n"," [-0.22763062]\n"," [-0.23577881]\n"," ...\n"," [-0.12194824]\n"," [-0.13009644]\n"," [-0.14633179]], shape=(55530, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22763062 -0.22763062 -0.23577881 ... -0.12194824 -0.13009644\n"," -0.14633179], shape=(55530,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14807129]\n"," [-0.14038086]\n"," [-0.13461304]\n"," ...\n"," [-0.00769043]\n"," [ 0.00769043]\n"," [ 0.01922607]], shape=(40590, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14807129 -0.14038086 -0.13461304 ... -0.00769043  0.00769043\n","  0.01922607], shape=(40590,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01998901]\n"," [-0.02374268]\n"," [-0.02624512]\n"," ...\n"," [-0.00250244]\n"," [-0.00250244]\n"," [-0.00250244]], shape=(21376, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01998901 -0.02374268 -0.02624512 ... -0.00250244 -0.00250244\n"," -0.00250244], shape=(21376,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00299072]\n"," [-0.00250244]\n"," [-0.00250244]\n"," ...\n"," [ 0.00100708]\n"," [ 0.00201416]\n"," [ 0.        ]], shape=(39764, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00299072 -0.00250244 -0.00250244 ...  0.00100708  0.00201416\n","  0.        ], shape=(39764,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02429199]\n"," [ 0.01766968]\n"," [ 0.01104736]\n"," ...\n"," [-0.02502441]\n"," [-0.02429199]\n"," [-0.02429199]], shape=(35624, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02429199  0.01766968  0.01104736 ... -0.02502441 -0.02429199\n"," -0.02429199], shape=(35624,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.2147522 ]\n"," [-0.19464111]\n"," [-0.19464111]\n"," ...\n"," [-0.18121338]\n"," [-0.18121338]\n"," [-0.19464111]], shape=(59834, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.2147522  -0.19464111 -0.19464111 ... -0.18121338 -0.18121338\n"," -0.19464111], shape=(59834,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0249939]\n"," [0.0249939]\n"," [0.       ]\n"," ...\n"," [0.1499939]\n"," [0.1375122]\n"," [0.1437378]], shape=(27940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0249939 0.0249939 0.        ... 0.1499939 0.1375122 0.1437378], shape=(27940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01348877]\n"," [ 0.01098633]\n"," [ 0.00650024]\n"," ...\n"," [-0.01348877]\n"," [-0.0085144 ]\n"," [-0.00299072]], shape=(68046, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01348877  0.01098633  0.00650024 ... -0.01348877 -0.0085144\n"," -0.00299072], shape=(68046,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00289917]\n"," [ 0.        ]\n"," [-0.00576782]\n"," ...\n"," [ 0.        ]\n"," [-0.00289917]\n"," [-0.00289917]], shape=(43900, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00289917  0.         -0.00576782 ...  0.         -0.00289917\n"," -0.00289917], shape=(43900,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04064941]\n"," [ 0.02709961]\n"," [-0.00543213]\n"," ...\n"," [-0.05419922]\n"," [-0.05963135]\n"," [-0.06503296]], shape=(48402, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04064941  0.02709961 -0.00543213 ... -0.05419922 -0.05963135\n"," -0.06503296], shape=(48402,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01998901]\n"," [-0.01000977]\n"," [-0.01000977]\n"," ...\n"," [-0.00500488]\n"," [ 0.00500488]\n"," [ 0.01000977]], shape=(53956, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01998901 -0.01000977 -0.01000977 ... -0.00500488  0.00500488\n","  0.01000977], shape=(53956,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01168823]\n"," [-0.01168823]\n"," [-0.02923584]\n"," ...\n"," [-0.01168823]\n"," [-0.04092407]\n"," [-0.02923584]], shape=(39954, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01168823 -0.01168823 -0.02923584 ... -0.01168823 -0.04092407\n"," -0.02923584], shape=(39954,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00744629]\n"," [ 0.00744629]\n"," [-0.00372314]\n"," ...\n"," [ 0.00372314]\n"," [ 0.00372314]\n"," [ 0.        ]], shape=(31116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00744629  0.00744629 -0.00372314 ...  0.00372314  0.00372314\n","  0.        ], shape=(31116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.26315308]\n"," [-0.28945923]\n"," [-0.28945923]\n"," ...\n"," [-0.26315308]\n"," [-0.26315308]\n"," [-0.26315308]], shape=(38748, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.26315308 -0.28945923 -0.28945923 ... -0.26315308 -0.26315308\n"," -0.26315308], shape=(38748,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03192139]\n"," [ 0.03036499]\n"," [ 0.02886963]\n"," ...\n"," [-0.02334595]\n"," [-0.03039551]\n"," [-0.03536987]], shape=(40482, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03192139  0.03036499  0.02886963 ... -0.02334595 -0.03039551\n"," -0.03536987], shape=(40482,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1666565 ]\n"," [0.1666565 ]\n"," [0.1458435 ]\n"," ...\n"," [0.11459351]\n"," [0.1354065 ]\n"," [0.15625   ]], shape=(24580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1666565  0.1666565  0.1458435  ... 0.11459351 0.1354065  0.15625   ], shape=(24580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05142212]\n"," [ 0.04953003]\n"," [ 0.04953003]\n"," ...\n"," [ 0.        ]\n"," [ 0.00189209]\n"," [-0.00189209]], shape=(49220, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05142212  0.04953003  0.04953003 ...  0.          0.00189209\n"," -0.00189209], shape=(49220,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00808716]\n"," [-0.02023315]\n"," [-0.04858398]\n"," ...\n"," [-0.02835083]\n"," [-0.02023315]\n"," [-0.02023315]], shape=(30934, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00808716 -0.02023315 -0.04858398 ... -0.02835083 -0.02023315\n"," -0.02023315], shape=(30934,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02410889]\n"," [-0.02410889]\n"," [-0.03613281]\n"," ...\n"," [-0.07229614]\n"," [-0.0602417 ]\n"," [-0.04818726]], shape=(39440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02410889 -0.02410889 -0.03613281 ... -0.07229614 -0.0602417\n"," -0.04818726], shape=(39440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.59524536]\n"," [ 0.59310913]\n"," [ 0.5909729 ]\n"," ...\n"," [-0.29507446]\n"," [-0.28955078]\n"," [-0.28359985]], shape=(35270, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.59524536  0.59310913  0.5909729  ... -0.29507446 -0.28955078\n"," -0.28359985], shape=(35270,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08569336]\n"," [0.08358765]\n"," [0.08148193]\n"," ...\n"," [0.07217407]\n"," [0.08441162]\n"," [0.09707642]], shape=(34164, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08569336 0.08358765 0.08148193 ... 0.07217407 0.08441162 0.09707642], shape=(34164,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.22180176]\n"," [0.21990967]\n"," [0.20675659]\n"," ...\n"," [0.00375366]\n"," [0.01879883]\n"," [0.03009033]], shape=(47320, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.22180176 0.21990967 0.20675659 ... 0.00375366 0.01879883 0.03009033], shape=(47320,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00494385]\n"," [-0.08911133]\n"," [-0.10891724]\n"," ...\n"," [-0.41583252]\n"," [-0.3069458 ]\n"," [-0.2128601 ]], shape=(33770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00494385 -0.08911133 -0.10891724 ... -0.41583252 -0.3069458\n"," -0.2128601 ], shape=(33770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00875854]\n"," [ 0.00875854]\n"," [ 0.00875854]\n"," ...\n"," [-0.06124878]\n"," [-0.05374146]\n"," [-0.04873657]], shape=(26580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00875854  0.00875854  0.00875854 ... -0.06124878 -0.05374146\n"," -0.04873657], shape=(26580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [-0.00500488]\n"," [-0.00500488]\n"," ...\n"," [ 0.01623535]\n"," [ 0.01623535]\n"," [ 0.01376343]], shape=(50886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488 -0.00500488 -0.00500488 ...  0.01623535  0.01623535\n","  0.01376343], shape=(50886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.1937561 ]\n"," [ 0.20220947]\n"," [ 0.21020508]\n"," ...\n"," [-0.06500244]\n"," [-0.07302856]\n"," [-0.08230591]], shape=(34536, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.1937561   0.20220947  0.21020508 ... -0.06500244 -0.07302856\n"," -0.08230591], shape=(34536,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01748657]\n"," [ 0.01873779]\n"," [ 0.01748657]\n"," ...\n"," [-0.0249939 ]\n"," [-0.01251221]\n"," [ 0.00250244]], shape=(59190, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01748657  0.01873779  0.01748657 ... -0.0249939  -0.01251221\n","  0.00250244], shape=(59190,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00250244]\n"," [0.00500488]\n"," [0.00601196]\n"," ...\n"," [0.00299072]\n"," [0.00500488]\n"," [0.00750732]], shape=(87526, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00250244 0.00500488 0.00601196 ... 0.00299072 0.00500488 0.00750732], shape=(87526,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0112915 ]\n"," [-0.01306152]\n"," [-0.0112915 ]\n"," ...\n"," [-0.00186157]\n"," [-0.0022583 ]\n"," [-0.00170898]], shape=(97596, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0112915  -0.01306152 -0.0112915  ... -0.00186157 -0.0022583\n"," -0.00170898], shape=(97596,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02630615]\n"," [-0.02630615]\n"," [-0.02630615]\n"," ...\n"," [-0.05264282]\n"," [-0.05264282]\n"," [-0.05264282]], shape=(52374, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02630615 -0.02630615 -0.02630615 ... -0.05264282 -0.05264282\n"," -0.05264282], shape=(52374,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00274658]\n"," [0.00457764]\n"," [0.00723267]\n"," ...\n"," [0.00112915]\n"," [0.00143433]\n"," [0.0007019 ]], shape=(40870, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00274658 0.00457764 0.00723267 ... 0.00112915 0.00143433 0.0007019 ], shape=(40870,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01205444]\n"," [-0.01205444]\n"," [-0.01687622]\n"," ...\n"," [ 0.10601807]\n"," [ 0.10601807]\n"," [ 0.10601807]], shape=(51774, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01205444 -0.01205444 -0.01687622 ...  0.10601807  0.10601807\n","  0.10601807], shape=(51774,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.3125    ]\n"," [-0.2999878 ]\n"," [-0.3062439 ]\n"," ...\n"," [ 0.09375   ]\n"," [ 0.10626221]\n"," [ 0.1000061 ]], shape=(80196, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.3125     -0.2999878  -0.3062439  ...  0.09375     0.10626221\n","  0.1000061 ], shape=(80196,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02441406]\n"," [-0.03723145]\n"," [-0.04638672]\n"," ...\n"," [ 0.01953125]\n"," [-0.00488281]\n"," [-0.03479004]], shape=(26568, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02441406 -0.03723145 -0.04638672 ...  0.01953125 -0.00488281\n"," -0.03479004], shape=(26568,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01000977]\n"," [-0.01000977]\n"," [-0.00875854]\n"," ...\n"," [ 0.00250244]\n"," [ 0.00250244]\n"," [ 0.00375366]], shape=(54462, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01000977 -0.01000977 -0.00875854 ...  0.00250244  0.00250244\n","  0.00375366], shape=(54462,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0249939 ]\n"," [0.0249939 ]\n"," [0.0062561 ]\n"," ...\n"," [0.0062561 ]\n"," [0.0249939 ]\n"," [0.01251221]], shape=(40448, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0249939  0.0249939  0.0062561  ... 0.0062561  0.0249939  0.01251221], shape=(40448,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01098633]\n"," [-0.00601196]\n"," [-0.00299072]\n"," ...\n"," [ 0.00299072]\n"," [ 0.00448608]\n"," [ 0.00750732]], shape=(43200, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01098633 -0.00601196 -0.00299072 ...  0.00299072  0.00448608\n","  0.00750732], shape=(43200,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0065918 ]\n"," [-0.0032959 ]\n"," [ 0.        ]\n"," ...\n"," [ 0.0296936 ]\n"," [ 0.04290771]\n"," [ 0.05941772]], shape=(53540, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0065918  -0.0032959   0.         ...  0.0296936   0.04290771\n","  0.05941772], shape=(53540,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02923584]\n"," [0.03509521]\n"," [0.02923584]\n"," ...\n"," [0.06433105]\n"," [0.07019043]\n"," [0.02047729]], shape=(35112, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02923584 0.03509521 0.02923584 ... 0.06433105 0.07019043 0.02047729], shape=(35112,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00601196]\n"," [-0.00201416]\n"," [ 0.00100708]\n"," ...\n"," [ 0.00100708]\n"," [ 0.00100708]\n"," [ 0.00100708]], shape=(46886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00601196 -0.00201416  0.00100708 ...  0.00100708  0.00100708\n","  0.00100708], shape=(46886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.06549072]\n"," [0.05813599]\n"," [0.05004883]\n"," ...\n"," [0.04119873]\n"," [0.03604126]\n"," [0.03091431]], shape=(32522, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.06549072 0.05813599 0.05004883 ... 0.04119873 0.03604126 0.03091431], shape=(32522,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16107178]\n"," [-0.18121338]\n"," [-0.19464111]\n"," ...\n"," [ 0.14764404]\n"," [ 0.19464111]\n"," [ 0.2147522 ]], shape=(59276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16107178 -0.18121338 -0.19464111 ...  0.14764404  0.19464111\n","  0.2147522 ], shape=(59276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02929688]\n"," [ 0.03048706]\n"," [ 0.02749634]\n"," ...\n"," [-0.00299072]\n"," [-0.00418091]\n"," [-0.00418091]], shape=(38914, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02929688  0.03048706  0.02749634 ... -0.00299072 -0.00418091\n"," -0.00418091], shape=(38914,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.4375 ]\n"," [0.4375 ]\n"," [0.40625]\n"," ...\n"," [0.03125]\n"," [0.03125]\n"," [0.     ]], shape=(57642, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.4375  0.4375  0.40625 ... 0.03125 0.03125 0.     ], shape=(57642,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00650024]\n"," [0.00750732]\n"," [0.00750732]\n"," ...\n"," [0.00201416]\n"," [0.00100708]\n"," [0.00250244]], shape=(47744, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00650024 0.00750732 0.00750732 ... 0.00201416 0.00100708 0.00250244], shape=(47744,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01931763]\n"," [-0.01931763]\n"," ...\n"," [-0.00772095]\n"," [-0.00772095]\n"," [-0.01931763]], shape=(38452, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01931763 -0.01931763 ... -0.00772095 -0.00772095\n"," -0.01931763], shape=(38452,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02807617]\n"," [-0.02246094]\n"," [-0.0168457 ]\n"," ...\n"," [-0.05432129]\n"," [-0.05618286]\n"," [-0.05432129]], shape=(34378, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02807617 -0.02246094 -0.0168457  ... -0.05432129 -0.05618286\n"," -0.05432129], shape=(34378,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07382202]\n"," [-0.06710815]\n"," [-0.07382202]\n"," ...\n"," [-0.07382202]\n"," [-0.07382202]\n"," [-0.06710815]], shape=(38938, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07382202 -0.06710815 -0.07382202 ... -0.07382202 -0.07382202\n"," -0.06710815], shape=(38938,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08102417]\n"," [-0.08529663]\n"," [-0.08102417]\n"," ...\n"," [ 0.        ]\n"," [ 0.00213623]\n"," [ 0.00213623]], shape=(30310, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08102417 -0.08529663 -0.08102417 ...  0.          0.00213623\n","  0.00213623], shape=(30310,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03408813]\n"," [-0.02728271]\n"," [-0.03408813]\n"," ...\n"," [-0.38409424]\n"," [-0.4272766 ]\n"," [-0.45455933]], shape=(38558, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03408813 -0.02728271 -0.03408813 ... -0.38409424 -0.4272766\n"," -0.45455933], shape=(38558,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00942993]\n"," [ 0.01416016]\n"," [ 0.00942993]\n"," ...\n"," [ 0.00473022]\n"," [-0.00942993]\n"," [-0.00473022]], shape=(38314, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00942993  0.01416016  0.00942993 ...  0.00473022 -0.00942993\n"," -0.00473022], shape=(38314,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03012085]\n"," [-0.03985596]\n"," [-0.04504395]\n"," ...\n"," [-0.10675049]\n"," [-0.10217285]\n"," [-0.09408569]], shape=(66654, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03012085 -0.03985596 -0.04504395 ... -0.10675049 -0.10217285\n"," -0.09408569], shape=(66654,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.417511  ]\n"," [-0.42001343]\n"," [-0.42001343]\n"," ...\n"," [-0.10998535]\n"," [-0.14248657]\n"," [-0.16500854]], shape=(19308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.417511   -0.42001343 -0.42001343 ... -0.10998535 -0.14248657\n"," -0.16500854], shape=(19308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02999878]\n"," [-0.02999878]\n"," [-0.03250122]\n"," ...\n"," [ 0.11999512]\n"," [ 0.11499023]\n"," [ 0.10501099]], shape=(78094, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02999878 -0.02999878 -0.03250122 ...  0.11999512  0.11499023\n","  0.10501099], shape=(78094,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10244751]\n"," [-0.10244751]\n"," [-0.11218262]\n"," ...\n"," [-0.08779907]\n"," [-0.08779907]\n"," [-0.10244751]], shape=(74948, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10244751 -0.10244751 -0.11218262 ... -0.08779907 -0.08779907\n"," -0.10244751], shape=(74948,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01898193]\n"," [-0.01898193]\n"," [-0.01812744]\n"," ...\n"," [-0.01034546]\n"," [-0.01379395]\n"," [-0.01724243]], shape=(78272, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01898193 -0.01898193 -0.01812744 ... -0.01034546 -0.01379395\n"," -0.01724243], shape=(78272,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04217529]\n"," [-0.02481079]\n"," [-0.04217529]\n"," ...\n"," [ 0.11413574]\n"," [ 0.06698608]\n"," [ 0.00497437]], shape=(63856, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04217529 -0.02481079 -0.04217529 ...  0.11413574  0.06698608\n","  0.00497437], shape=(63856,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02630615]\n"," [-0.03289795]\n"," [-0.03509521]\n"," ...\n"," [-0.01095581]\n"," [-0.01535034]\n"," [-0.02630615]], shape=(62366, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02630615 -0.03289795 -0.03509521 ... -0.01095581 -0.01535034\n"," -0.02630615], shape=(62366,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.1937561 ]\n"," [ 0.2000122 ]\n"," [ 0.1937561 ]\n"," ...\n"," [-0.01251221]\n"," [-0.0062561 ]\n"," [-0.0062561 ]], shape=(39086, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.1937561   0.2000122   0.1937561  ... -0.01251221 -0.0062561\n"," -0.0062561 ], shape=(39086,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.3289795 ]\n"," [-0.43572998]\n"," [-0.5054321 ]\n"," ...\n"," [-0.00436401]\n"," [-0.01525879]\n"," [-0.03268433]], shape=(49968, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.3289795  -0.43572998 -0.5054321  ... -0.00436401 -0.01525879\n"," -0.03268433], shape=(49968,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00128174]\n"," [-0.00128174]\n"," [-0.00320435]\n"," ...\n"," [ 0.0166626 ]\n"," [ 0.00769043]\n"," [ 0.00256348]], shape=(37934, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00128174 -0.00128174 -0.00320435 ...  0.0166626   0.00769043\n","  0.00256348], shape=(37934,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01321411]\n"," [-0.01184082]\n"," [-0.00299072]\n"," ...\n"," [ 0.00421143]\n"," [ 0.00604248]\n"," [ 0.00378418]], shape=(38000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01321411 -0.01184082 -0.00299072 ...  0.00421143  0.00604248\n","  0.00378418], shape=(38000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03897095]\n"," [-0.04510498]\n"," [-0.0473938 ]\n"," ...\n"," [-0.01913452]\n"," [-0.01034546]\n"," [ 0.00109863]], shape=(51680, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03897095 -0.04510498 -0.0473938  ... -0.01913452 -0.01034546\n","  0.00109863], shape=(51680,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [ 0.        ]\n"," [ 0.00125122]\n"," ...\n"," [ 0.00125122]\n"," [ 0.00250244]\n"," [ 0.00375366]], shape=(31358, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366  0.          0.00125122 ...  0.00125122  0.00250244\n","  0.00375366], shape=(31358,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03067017]\n"," [-0.0184021 ]\n"," [-0.00613403]\n"," ...\n"," [ 0.01226807]\n"," [ 0.0184021 ]\n"," [ 0.0184021 ]], shape=(38824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03067017 -0.0184021  -0.00613403 ...  0.01226807  0.0184021\n","  0.0184021 ], shape=(38824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05459595]\n"," [-0.09677124]\n"," [-0.14639282]\n"," ...\n"," [ 0.26550293]\n"," [ 0.27294922]\n"," [ 0.26550293]], shape=(43988, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05459595 -0.09677124 -0.14639282 ...  0.26550293  0.27294922\n","  0.26550293], shape=(43988,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00311279]\n"," [-0.00311279]\n"," ...\n"," [ 0.01553345]\n"," [ 0.01553345]\n"," [ 0.01553345]], shape=(34726, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00311279 -0.00311279 ...  0.01553345  0.01553345\n","  0.01553345], shape=(34726,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15789795]\n"," [-0.17105103]\n"," [-0.1315918 ]\n"," ...\n"," [-0.03945923]\n"," [-0.01315308]\n"," [-0.01315308]], shape=(68628, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15789795 -0.17105103 -0.1315918  ... -0.03945923 -0.01315308\n"," -0.01315308], shape=(68628,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01229858]\n"," [-0.01229858]\n"," [-0.01229858]\n"," ...\n"," [ 0.08615112]\n"," [ 0.0892334 ]\n"," [ 0.09539795]], shape=(49850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01229858 -0.01229858 -0.01229858 ...  0.08615112  0.0892334\n","  0.09539795], shape=(49850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08248901]\n"," [0.0625    ]\n"," [0.0375061 ]\n"," ...\n"," [0.0249939 ]\n"," [0.01998901]\n"," [0.01000977]], shape=(78234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08248901 0.0625     0.0375061  ... 0.0249939  0.01998901 0.01000977], shape=(78234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0696106 ]\n"," [-0.04577637]\n"," [ 0.00366211]\n"," ...\n"," [-0.00976562]\n"," [-0.00427246]\n"," [-0.00610352]], shape=(40222, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0696106  -0.04577637  0.00366211 ... -0.00976562 -0.00427246\n"," -0.00610352], shape=(40222,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0062561 ]\n"," [ 0.0062561 ]\n"," [ 0.00375366]\n"," ...\n"," [-0.0062561 ]\n"," [-0.00500488]\n"," [-0.00250244]], shape=(43178, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0062561   0.0062561   0.00375366 ... -0.0062561  -0.00500488\n"," -0.00250244], shape=(43178,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05062866]\n"," [ 0.06329346]\n"," [ 0.05062866]\n"," ...\n"," [ 0.11392212]\n"," [ 0.02532959]\n"," [-0.01266479]], shape=(24622, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05062866  0.06329346  0.05062866 ...  0.11392212  0.02532959\n"," -0.01266479], shape=(24622,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02160645]\n"," [ 0.00219727]\n"," [-0.01412964]\n"," ...\n"," [-0.01278687]\n"," [-0.00881958]\n"," [-0.00527954]], shape=(42248, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02160645  0.00219727 -0.01412964 ... -0.01278687 -0.00881958\n"," -0.00527954], shape=(42248,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01306152]\n"," [0.00927734]\n"," [0.00869751]\n"," ...\n"," [0.08673096]\n"," [0.09146118]\n"," [0.09197998]], shape=(16638, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01306152 0.00927734 0.00869751 ... 0.08673096 0.09146118 0.09197998], shape=(16638,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00436401]\n"," [-0.00469971]\n"," [ 0.        ]\n"," ...\n"," [ 0.03372192]\n"," [ 0.02612305]\n"," [ 0.01879883]], shape=(42916, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00436401 -0.00469971  0.         ...  0.03372192  0.02612305\n","  0.01879883], shape=(42916,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.00125122]\n"," ...\n"," [ 0.        ]\n"," [ 0.00375366]\n"," [ 0.0062561 ]], shape=(39522, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.00125122 ...  0.          0.00375366\n","  0.0062561 ], shape=(39522,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01638794]\n"," [-0.01638794]\n"," [-0.03277588]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [-0.00820923]], shape=(62112, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01638794 -0.01638794 -0.03277588 ...  0.          0.\n"," -0.00820923], shape=(62112,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14981079]\n"," [-0.1376648 ]\n"," [-0.14981079]\n"," ...\n"," [-0.08096313]\n"," [-0.08096313]\n"," [-0.08908081]], shape=(37752, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14981079 -0.1376648  -0.14981079 ... -0.08096313 -0.08096313\n"," -0.08908081], shape=(37752,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01098633]\n"," [-0.01000977]\n"," [-0.01049805]\n"," ...\n"," [-0.25650024]\n"," [-0.2630005 ]\n"," [-0.26049805]], shape=(40256, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01098633 -0.01000977 -0.01049805 ... -0.25650024 -0.2630005\n"," -0.26049805], shape=(40256,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00588989]\n"," [-0.00588989]\n"," [-0.00292969]\n"," ...\n"," [-0.06616211]\n"," [-0.05587769]\n"," [-0.04705811]], shape=(22480, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00588989 -0.00588989 -0.00292969 ... -0.06616211 -0.05587769\n"," -0.04705811], shape=(22480,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02017212]\n"," [-0.0161438 ]\n"," [-0.01748657]\n"," ...\n"," [-0.0161438 ]\n"," [-0.02420044]\n"," [-0.03762817]], shape=(52890, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02017212 -0.0161438  -0.01748657 ... -0.0161438  -0.02420044\n"," -0.03762817], shape=(52890,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03237915]\n"," [-0.03808594]\n"," [-0.03808594]\n"," ...\n"," [ 0.02285767]\n"," [ 0.03237915]\n"," [ 0.02856445]], shape=(69088, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03237915 -0.03808594 -0.03808594 ...  0.02285767  0.03237915\n","  0.02856445], shape=(69088,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.19073486]\n"," [-0.11856079]\n"," [-0.11856079]\n"," ...\n"," [-0.14431763]\n"," [-0.13916016]\n"," [-0.14431763]], shape=(42530, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.19073486 -0.11856079 -0.11856079 ... -0.14431763 -0.13916016\n"," -0.14431763], shape=(42530,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00585938]\n"," [-0.00585938]\n"," [-0.01461792]\n"," ...\n"," [-0.10818481]\n"," [-0.20761108]\n"," [-0.277771  ]], shape=(49338, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00585938 -0.00585938 -0.01461792 ... -0.10818481 -0.20761108\n"," -0.277771  ], shape=(49338,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17999268]\n"," [-0.19250488]\n"," [-0.19750977]\n"," ...\n"," [-0.04748535]\n"," [-0.03500366]\n"," [-0.0249939 ]], shape=(94126, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17999268 -0.19250488 -0.19750977 ... -0.04748535 -0.03500366\n"," -0.0249939 ], shape=(94126,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0536499 ]\n"," [-0.04962158]\n"," [-0.04510498]\n"," ...\n"," [-0.01831055]\n"," [-0.02005005]\n"," [-0.0173645 ]], shape=(19374, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0536499  -0.04962158 -0.04510498 ... -0.01831055 -0.02005005\n"," -0.0173645 ], shape=(19374,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02868652]\n"," [-0.02722168]\n"," [-0.02355957]\n"," ...\n"," [ 0.03900146]\n"," [ 0.03604126]\n"," [ 0.03091431]], shape=(26862, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02868652 -0.02722168 -0.02355957 ...  0.03900146  0.03604126\n","  0.03091431], shape=(26862,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00448608]\n"," [-0.00500488]\n"," [-0.00601196]\n"," ...\n"," [ 0.00799561]\n"," [ 0.00750732]\n"," [ 0.00750732]], shape=(52246, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00448608 -0.00500488 -0.00601196 ...  0.00799561  0.00750732\n","  0.00750732], shape=(52246,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22875977]\n"," [-0.08496094]\n"," [-0.09805298]\n"," ...\n"," [-0.13070679]\n"," [-0.11764526]\n"," [-0.11764526]], shape=(76606, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22875977 -0.08496094 -0.09805298 ... -0.13070679 -0.11764526\n"," -0.11764526], shape=(76606,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.09051514]\n"," [ 0.09100342]\n"," [ 0.08999634]\n"," ...\n"," [-0.00100708]\n"," [-0.00201416]\n"," [-0.00250244]], shape=(49350, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.09051514  0.09100342  0.08999634 ... -0.00100708 -0.00201416\n"," -0.00250244], shape=(49350,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02474976]\n"," [-0.00189209]\n"," [ 0.02285767]\n"," ...\n"," [ 0.00952148]\n"," [ 0.00762939]\n"," [ 0.00762939]], shape=(33108, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02474976 -0.00189209  0.02285767 ...  0.00952148  0.00762939\n","  0.00762939], shape=(33108,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08483887]\n"," [-0.09393311]\n"," [-0.08789062]\n"," ...\n"," [-0.03939819]\n"," [-0.03939819]\n"," [-0.04544067]], shape=(32820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08483887 -0.09393311 -0.08789062 ... -0.03939819 -0.03939819\n"," -0.04544067], shape=(32820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.23806763]\n"," [-0.11862183]\n"," [ 0.01351929]\n"," ...\n"," [ 0.0793457 ]\n"," [ 0.08358765]\n"," [ 0.08441162]], shape=(37564, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.23806763 -0.11862183  0.01351929 ...  0.0793457   0.08358765\n","  0.08441162], shape=(37564,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03173828]\n"," [-0.00793457]\n"," [-0.01586914]\n"," ...\n"," [-0.34921265]\n"," [-0.19049072]\n"," [-0.05554199]], shape=(46398, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03173828 -0.00793457 -0.01586914 ... -0.34921265 -0.19049072\n"," -0.05554199], shape=(46398,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01376343]\n"," [ 0.01251221]\n"," [ 0.01251221]\n"," ...\n"," [-0.00500488]\n"," [-0.00500488]\n"," [-0.00375366]], shape=(20278, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01376343  0.01251221  0.01251221 ... -0.00500488 -0.00500488\n"," -0.00375366], shape=(20278,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01513672]\n"," [-0.02728271]\n"," [-0.06668091]\n"," ...\n"," [-0.06060791]\n"," [-0.05453491]\n"," [-0.05453491]], shape=(26938, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01513672 -0.02728271 -0.06668091 ... -0.06060791 -0.05453491\n"," -0.05453491], shape=(26938,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00750732]\n"," [ 0.00650024]\n"," [ 0.00350952]\n"," ...\n"," [-0.02398682]\n"," [-0.0255127 ]\n"," [-0.0255127 ]], shape=(70804, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00750732  0.00650024  0.00350952 ... -0.02398682 -0.0255127\n"," -0.0255127 ], shape=(70804,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00192261]\n"," [-0.00192261]\n"," ...\n"," [ 0.01730347]\n"," [ 0.01730347]\n"," [ 0.01153564]], shape=(31916, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00192261 -0.00192261 ...  0.01730347  0.01730347\n","  0.01153564], shape=(31916,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02124023]\n"," [-0.01748657]\n"," [-0.01748657]\n"," ...\n"," [-0.00500488]\n"," [-0.0062561 ]\n"," [-0.00750732]], shape=(35964, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02124023 -0.01748657 -0.01748657 ... -0.00500488 -0.0062561\n"," -0.00750732], shape=(35964,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0022583 ]\n"," [ 0.0039978 ]\n"," [ 0.0045166 ]\n"," ...\n"," [-0.00537109]\n"," [-0.0045166 ]\n"," [-0.00436401]], shape=(36840, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0022583   0.0039978   0.0045166  ... -0.00537109 -0.0045166\n"," -0.00436401], shape=(36840,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00048828]\n"," [-0.00100708]\n"," [-0.00100708]\n"," ...\n"," [ 0.01849365]\n"," [ 0.02151489]\n"," [ 0.02450562]], shape=(55662, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00048828 -0.00100708 -0.00100708 ...  0.01849365  0.02151489\n","  0.02450562], shape=(55662,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.3999939 ]\n"," [ 0.4428711 ]\n"," [ 0.4428711 ]\n"," ...\n"," [-0.18569946]\n"," [-0.18569946]\n"," [-0.21429443]], shape=(60242, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.3999939   0.4428711   0.4428711  ... -0.18569946 -0.18569946\n"," -0.21429443], shape=(60242,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00473022]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00473022]\n"," [0.00942993]\n"," [0.00942993]], shape=(45470, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00473022 0.         0.         ... 0.00473022 0.00942993 0.00942993], shape=(45470,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12069702]\n"," [-0.10348511]\n"," [-0.10348511]\n"," ...\n"," [ 0.18096924]\n"," [ 0.18096924]\n"," [ 0.16375732]], shape=(21160, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12069702 -0.10348511 -0.10348511 ...  0.18096924  0.18096924\n","  0.16375732], shape=(21160,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01739502]\n"," [ 0.02609253]\n"," [ 0.02609253]\n"," ...\n"," [-0.38259888]\n"," [-0.35653687]\n"," [-0.31304932]], shape=(25290, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01739502  0.02609253  0.02609253 ... -0.38259888 -0.35653687\n"," -0.31304932], shape=(25290,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04229736]\n"," [-0.04037476]\n"," [-0.04229736]\n"," ...\n"," [-0.04229736]\n"," [-0.04037476]\n"," [-0.03845215]], shape=(34766, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04229736 -0.04037476 -0.04229736 ... -0.04229736 -0.04037476\n"," -0.03845215], shape=(34766,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04278564]\n"," [0.03744507]\n"," [0.03744507]\n"," ...\n"," [0.        ]\n"," [0.00534058]\n"," [0.00534058]], shape=(56042, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04278564 0.03744507 0.03744507 ... 0.         0.00534058 0.00534058], shape=(56042,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.08508301]\n"," [ 0.0980835 ]\n"," [ 0.11212158]\n"," ...\n"," [-0.02902222]\n"," [-0.03204346]\n"," [-0.03204346]], shape=(28308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.08508301  0.0980835   0.11212158 ... -0.02902222 -0.03204346\n"," -0.03204346], shape=(28308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01266479]\n"," [-0.02532959]\n"," [-0.06329346]\n"," ...\n"," [-0.02532959]\n"," [-0.05062866]\n"," [-0.01266479]], shape=(38670, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01266479 -0.02532959 -0.06329346 ... -0.02532959 -0.05062866\n"," -0.01266479], shape=(38670,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.00250244]\n"," [ 0.00250244]\n"," ...\n"," [-0.00500488]\n"," [-0.00500488]\n"," [-0.00250244]], shape=(44272, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.00250244  0.00250244 ... -0.00500488 -0.00500488\n"," -0.00250244], shape=(44272,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18008423]\n"," [-0.2753296 ]\n"," [-0.36203003]\n"," ...\n"," [ 0.02746582]\n"," [ 0.01708984]\n"," [-0.00549316]], shape=(31714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18008423 -0.2753296  -0.36203003 ...  0.02746582  0.01708984\n"," -0.00549316], shape=(31714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02539062]\n"," [-0.01776123]\n"," [-0.01269531]\n"," ...\n"," [ 0.01269531]\n"," [ 0.01522827]\n"," [ 0.01522827]], shape=(52472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02539062 -0.01776123 -0.01269531 ...  0.01269531  0.01522827\n","  0.01522827], shape=(52472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06668091]\n"," [-0.10910034]\n"," [-0.14544678]\n"," ...\n"," [ 0.006073  ]\n"," [ 0.02423096]\n"," [ 0.006073  ]], shape=(37188, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06668091 -0.10910034 -0.14544678 ...  0.006073    0.02423096\n","  0.006073  ], shape=(37188,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00521851]\n"," [ 0.00521851]\n"," ...\n"," [-0.00521851]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(19900, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00521851  0.00521851 ... -0.00521851  0.\n","  0.        ], shape=(19900,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00939941]\n"," [ 0.02194214]\n"," [ 0.03134155]\n"," ...\n"," [ 0.03762817]\n"," [ 0.01254272]\n"," [-0.01254272]], shape=(53874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00939941  0.02194214  0.03134155 ...  0.03762817  0.01254272\n"," -0.01254272], shape=(53874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [-0.00299072]\n"," [ 0.        ]\n"," ...\n"," [-0.01193237]\n"," [ 0.        ]\n"," [-0.00299072]], shape=(39676, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145 -0.00299072  0.         ... -0.01193237  0.\n"," -0.00299072], shape=(39676,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00131226]\n"," [-0.00262451]\n"," [-0.00131226]\n"," ...\n"," [-0.00787354]\n"," [-0.00918579]\n"," [-0.00787354]], shape=(43258, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00131226 -0.00262451 -0.00131226 ... -0.00787354 -0.00918579\n"," -0.00787354], shape=(43258,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.216156  ]\n"," [0.20855713]\n"," [0.20263672]\n"," ...\n"," [0.85025024]\n"," [0.81430054]\n"," [0.7741089 ]], shape=(26056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.216156   0.20855713 0.20263672 ... 0.85025024 0.81430054 0.7741089 ], shape=(26056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03582764]\n"," [ 0.03582764]\n"," [ 0.03582764]\n"," ...\n"," [-0.00598145]\n"," [ 0.        ]\n"," [ 0.00598145]], shape=(56366, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03582764  0.03582764  0.03582764 ... -0.00598145  0.\n","  0.00598145], shape=(56366,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0072937 ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.04379272]\n"," [0.02554321]\n"," [0.03649902]], shape=(95016, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0072937  0.         0.         ... 0.04379272 0.02554321 0.03649902], shape=(95016,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00588989]\n"," [ 0.00588989]\n"," [ 0.00588989]\n"," ...\n"," [-0.01324463]\n"," [-0.01617432]\n"," [-0.019104  ]], shape=(57122, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00588989  0.00588989  0.00588989 ... -0.01324463 -0.01617432\n"," -0.019104  ], shape=(57122,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03866577]\n"," [-0.03314209]\n"," [-0.02209473]\n"," ...\n"," [ 0.01382446]\n"," [ 0.01382446]\n"," [ 0.01657104]], shape=(112268, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03866577 -0.03314209 -0.02209473 ...  0.01382446  0.01382446\n","  0.01657104], shape=(112268,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01165771]\n"," [-0.01382446]\n"," [-0.01812744]\n"," ...\n"," [ 0.06735229]\n"," [ 0.07815552]\n"," [ 0.08334351]], shape=(35948, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01165771 -0.01382446 -0.01812744 ...  0.06735229  0.07815552\n","  0.08334351], shape=(35948,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00543213]\n"," [-0.00473022]\n"," [-0.00549316]\n"," ...\n"," [-0.73934937]\n"," [-0.7569885 ]\n"," [-0.76431274]], shape=(46270, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00543213 -0.00473022 -0.00549316 ... -0.73934937 -0.7569885\n"," -0.76431274], shape=(46270,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.2784729 ]\n"," [-0.27294922]\n"," [-0.2669983 ]\n"," ...\n"," [-0.24829102]\n"," [-0.26062012]\n"," [-0.269989  ]], shape=(29618, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.2784729  -0.27294922 -0.2669983  ... -0.24829102 -0.26062012\n"," -0.269989  ], shape=(29618,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06341553]\n"," [-0.05853271]\n"," [-0.05853271]\n"," ...\n"," [-0.0975647 ]\n"," [-0.09512329]\n"," [-0.09268188]], shape=(42802, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06341553 -0.05853271 -0.05853271 ... -0.0975647  -0.09512329\n"," -0.09268188], shape=(42802,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.52597046]\n"," [-0.5310364 ]\n"," [-0.5361023 ]\n"," ...\n"," [-0.10299683]\n"," [-0.10806274]\n"," [-0.11355591]], shape=(56976, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.52597046 -0.5310364  -0.5361023  ... -0.10299683 -0.10806274\n"," -0.11355591], shape=(56976,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.13699341]\n"," [ 0.1880188 ]\n"," [ 0.2401123 ]\n"," ...\n"," [-0.0289917 ]\n"," [-0.03356934]\n"," [-0.03787231]], shape=(70894, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.13699341  0.1880188   0.2401123  ... -0.0289917  -0.03356934\n"," -0.03787231], shape=(70894,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04904175]\n"," [-0.04403687]\n"," [-0.04403687]\n"," ...\n"," [ 0.01702881]\n"," [ 0.01202393]\n"," [ 0.01202393]], shape=(71450, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04904175 -0.04403687 -0.04403687 ...  0.01702881  0.01202393\n","  0.01202393], shape=(71450,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05682373]\n"," [ 0.06817627]\n"," [ 0.06817627]\n"," ...\n"," [-0.0227356 ]\n"," [-0.01135254]\n"," [-0.0227356 ]], shape=(42486, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05682373  0.06817627  0.06817627 ... -0.0227356  -0.01135254\n"," -0.0227356 ], shape=(42486,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.22805786]\n"," [0.25732422]\n"," [0.28656006]\n"," ...\n"," [0.01168823]\n"," [0.        ]\n"," [0.        ]], shape=(37770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.22805786 0.25732422 0.28656006 ... 0.01168823 0.         0.        ], shape=(37770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02352905]\n"," [-0.02352905]\n"," [-0.0196228 ]\n"," ...\n"," [-0.01177979]\n"," [-0.00784302]\n"," [-0.00393677]], shape=(56484, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02352905 -0.02352905 -0.0196228  ... -0.01177979 -0.00784302\n"," -0.00393677], shape=(56484,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02401733]\n"," [-0.02703857]\n"," [-0.02703857]\n"," ...\n"," [-0.02902222]\n"," [-0.0340271 ]\n"," [-0.03903198]], shape=(36032, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02401733 -0.02703857 -0.02703857 ... -0.02902222 -0.0340271\n"," -0.03903198], shape=(36032,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00683594]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01705933]\n"," [-0.00683594]\n"," [ 0.        ]], shape=(39770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00683594  0.          0.         ... -0.01705933 -0.00683594\n","  0.        ], shape=(39770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01376343]\n"," [-0.01654053]\n"," [-0.01101685]\n"," ...\n"," [ 0.00552368]\n"," [ 0.        ]\n"," [ 0.00552368]], shape=(119382, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01376343 -0.01654053 -0.01101685 ...  0.00552368  0.\n","  0.00552368], shape=(119382,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08779907]\n"," [-0.08779907]\n"," [-0.08779907]\n"," ...\n"," [-0.13171387]\n"," [-0.14144897]\n"," [-0.1512146 ]], shape=(37678, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08779907 -0.08779907 -0.08779907 ... -0.13171387 -0.14144897\n"," -0.1512146 ], shape=(37678,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05276489]\n"," [-0.04644775]\n"," [-0.04138184]\n"," ...\n"," [ 0.2731018 ]\n"," [ 0.41748047]\n"," [ 0.56100464]], shape=(22114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05276489 -0.04644775 -0.04138184 ...  0.2731018   0.41748047\n","  0.56100464], shape=(22114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02438354]\n"," [ 0.00610352]\n"," [ 0.        ]\n"," ...\n"," [-0.3902588 ]\n"," [-0.28048706]\n"," [-0.17074585]], shape=(95144, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02438354  0.00610352  0.         ... -0.3902588  -0.28048706\n"," -0.17074585], shape=(95144,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01177979]\n"," [-0.02352905]\n"," [-0.03530884]\n"," ...\n"," [-0.02352905]\n"," [ 0.        ]\n"," [ 0.03530884]], shape=(21156, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01177979 -0.02352905 -0.03530884 ... -0.02352905  0.\n","  0.03530884], shape=(21156,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14633179]\n"," [-0.17074585]\n"," [-0.17886353]\n"," ...\n"," [-0.17074585]\n"," [-0.17074585]\n"," [-0.17074585]], shape=(53470, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14633179 -0.17074585 -0.17886353 ... -0.17074585 -0.17074585\n"," -0.17074585], shape=(53470,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15109253]\n"," [-0.07192993]\n"," [-0.00720215]\n"," ...\n"," [-0.09713745]\n"," [-0.07913208]\n"," [-0.07192993]], shape=(45316, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15109253 -0.07192993 -0.00720215 ... -0.09713745 -0.07913208\n"," -0.07192993], shape=(45316,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.      ]\n"," [ 0.027771]\n"," [ 0.027771]\n"," ...\n"," [-0.027771]\n"," [-0.027771]\n"," [ 0.      ]], shape=(47390, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.        0.027771  0.027771 ... -0.027771 -0.027771  0.      ], shape=(47390,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.29888916]\n"," [-0.28146362]\n"," [-0.26361084]\n"," ...\n"," [ 0.08120728]\n"," [ 0.08291626]\n"," [ 0.08502197]], shape=(53888, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.29888916 -0.28146362 -0.26361084 ...  0.08120728  0.08291626\n","  0.08502197], shape=(53888,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00393677]\n"," [-0.00784302]\n"," [-0.01177979]\n"," ...\n"," [-0.00393677]\n"," [-0.00393677]\n"," [ 0.        ]], shape=(47400, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00393677 -0.00784302 -0.01177979 ... -0.00393677 -0.00393677\n","  0.        ], shape=(47400,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00622559]\n"," [-0.00311279]\n"," [ 0.        ]\n"," ...\n"," [-0.00311279]\n"," [-0.00311279]\n"," [-0.00622559]], shape=(53896, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00622559 -0.00311279  0.         ... -0.00311279 -0.00311279\n"," -0.00622559], shape=(53896,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00335693]\n"," [-0.00311279]\n"," [-0.003479  ]], shape=(20318, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00335693 -0.00311279\n"," -0.003479  ], shape=(20318,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03570557]\n"," [-0.06121826]\n"," [-0.06887817]\n"," ...\n"," [ 0.0255127 ]\n"," [ 0.01275635]\n"," [ 0.00765991]], shape=(39514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03570557 -0.06121826 -0.06887817 ...  0.0255127   0.01275635\n","  0.00765991], shape=(39514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02410889]\n"," [-0.02410889]\n"," [-0.02410889]\n"," ...\n"," [-0.0602417 ]\n"," [-0.0602417 ]\n"," [-0.0602417 ]], shape=(24928, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02410889 -0.02410889 -0.02410889 ... -0.0602417  -0.0602417\n"," -0.0602417 ], shape=(24928,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01098633]\n"," [-0.01199341]\n"," [-0.01199341]\n"," ...\n"," [ 0.01300049]\n"," [ 0.01550293]\n"," [ 0.01901245]], shape=(107436, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01098633 -0.01199341 -0.01199341 ...  0.01300049  0.01550293\n","  0.01901245], shape=(107436,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01153564]\n"," [ 0.01089478]\n"," [ 0.00961304]\n"," ...\n"," [ 0.0166626 ]\n"," [ 0.00769043]\n"," [-0.00064087]], shape=(18194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01153564  0.01089478  0.00961304 ...  0.0166626   0.00769043\n"," -0.00064087], shape=(18194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04455566]\n"," [-0.04455566]\n"," [-0.04455566]\n"," ...\n"," [-0.04455566]\n"," [-0.05444336]\n"," [-0.05444336]], shape=(100664, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04455566 -0.04455566 -0.04455566 ... -0.04455566 -0.05444336\n"," -0.05444336], shape=(100664,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0050354 ]\n"," [0.0050354 ]\n"," [0.0050354 ]\n"," ...\n"," [0.03533936]\n"," [0.04544067]\n"," [0.04544067]], shape=(198404, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0050354  0.0050354  0.0050354  ... 0.03533936 0.04544067 0.04544067], shape=(198404,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00875854]\n"," [ 0.00875854]\n"," [ 0.00875854]\n"," ...\n"," [-0.00750732]\n"," [-0.0062561 ]\n"," [-0.0062561 ]], shape=(80626, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00875854  0.00875854  0.00875854 ... -0.00750732 -0.0062561\n"," -0.0062561 ], shape=(80626,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00875854]\n"," [ 0.00750732]\n"," [ 0.00750732]\n"," ...\n"," [-0.0062561 ]\n"," [-0.0062561 ]\n"," [-0.0062561 ]], shape=(47846, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00875854  0.00750732  0.00750732 ... -0.0062561  -0.0062561\n"," -0.0062561 ], shape=(47846,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00750732]\n"," [ 0.00100708]\n"," [-0.00500488]\n"," ...\n"," [ 0.00650024]\n"," [ 0.00448608]\n"," [ 0.00299072]], shape=(50904, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00750732  0.00100708 -0.00500488 ...  0.00650024  0.00448608\n","  0.00299072], shape=(50904,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.027771 ]\n"," [ 0.       ]\n"," [ 0.027771 ]\n"," ...\n"," [-0.5833435]\n"," [-0.5833435]\n"," [-0.6111145]], shape=(42098, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.027771   0.         0.027771  ... -0.5833435 -0.5833435 -0.6111145], shape=(42098,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01596069]\n"," [0.01596069]\n"," [0.01596069]\n"," ...\n"," [0.17617798]\n"," [0.1675415 ]\n"," [0.14465332]], shape=(42994, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01596069 0.01596069 0.01596069 ... 0.17617798 0.1675415  0.14465332], shape=(42994,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00161743]\n"," [0.00222778]\n"," [0.00143433]], shape=(42362, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00161743 0.00222778 0.00143433], shape=(42362,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01385498]\n"," [-0.00344849]\n"," [-0.00344849]\n"," ...\n"," [ 0.02075195]\n"," [ 0.01385498]\n"," [-0.00344849]], shape=(31330, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01385498 -0.00344849 -0.00344849 ...  0.02075195  0.01385498\n"," -0.00344849], shape=(31330,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0607605 ]\n"," [ 0.04971313]\n"," [ 0.03314209]\n"," ...\n"," [ 0.        ]\n"," [-0.01104736]\n"," [-0.02761841]], shape=(44906, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0607605   0.04971313  0.03314209 ...  0.         -0.01104736\n"," -0.02761841], shape=(44906,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06921387]\n"," [-0.06228638]\n"," [-0.06228638]\n"," ...\n"," [-0.06921387]\n"," [-0.06921387]\n"," [-0.06921387]], shape=(32972, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06921387 -0.06228638 -0.06228638 ... -0.06921387 -0.06921387\n"," -0.06921387], shape=(32972,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00152588]\n"," [-0.00192261]\n"," [ 0.        ]\n"," ...\n"," [ 0.03033447]\n"," [ 0.03039551]\n"," [ 0.03164673]], shape=(32878, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00152588 -0.00192261  0.         ...  0.03033447  0.03039551\n","  0.03164673], shape=(32878,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0065918 ]\n"," [0.03289795]\n"," [0.04934692]\n"," ...\n"," [0.16119385]\n"," [0.16119385]\n"," [0.14804077]], shape=(36168, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0065918  0.03289795 0.04934692 ... 0.16119385 0.16119385 0.14804077], shape=(36168,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.11499023]\n"," [ 0.11801147]\n"," [ 0.12051392]\n"," ...\n"," [-0.02249146]\n"," [-0.03100586]\n"," [-0.03948975]], shape=(43856, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.11499023  0.11801147  0.12051392 ... -0.02249146 -0.03100586\n"," -0.03948975], shape=(43856,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03945923]\n"," [0.02630615]\n"," [0.01315308]\n"," ...\n"," [0.23684692]\n"," [0.26315308]\n"," [0.27630615]], shape=(44016, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03945923 0.02630615 0.01315308 ... 0.23684692 0.26315308 0.27630615], shape=(44016,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05172729]\n"," [-0.06033325]\n"," [-0.06033325]\n"," ...\n"," [-0.07757568]\n"," [-0.07757568]\n"," [-0.06896973]], shape=(51624, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05172729 -0.06033325 -0.06033325 ... -0.07757568 -0.07757568\n"," -0.06896973], shape=(51624,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00985718]\n"," [-0.00491333]\n"," [-0.00491333]\n"," ...\n"," [ 0.16748047]\n"," [ 0.21182251]\n"," [ 0.26602173]], shape=(44408, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00985718 -0.00491333 -0.00491333 ...  0.16748047  0.21182251\n","  0.26602173], shape=(44408,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03048706]\n"," [-0.02438354]\n"," [-0.04269409]\n"," ...\n"," [ 0.02438354]\n"," [ 0.01220703]\n"," [ 0.02438354]], shape=(45374, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03048706 -0.02438354 -0.04269409 ...  0.02438354  0.01220703\n","  0.02438354], shape=(45374,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0161438 ]\n"," [ 0.0161438 ]\n"," [ 0.02151489]\n"," ...\n"," [-0.02688599]\n"," [-0.0161438 ]\n"," [-0.01074219]], shape=(23372, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0161438   0.0161438   0.02151489 ... -0.02688599 -0.0161438\n"," -0.01074219], shape=(23372,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01306152]\n"," [-0.00521851]\n"," [-0.01828003]\n"," ...\n"," [ 0.        ]\n"," [ 0.00521851]\n"," [ 0.        ]], shape=(24942, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01306152 -0.00521851 -0.01828003 ...  0.          0.00521851\n","  0.        ], shape=(24942,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04620361]\n"," [ 0.05673218]\n"," [ 0.07144165]\n"," ...\n"," [-0.19537354]\n"," [-0.17016602]\n"," [-0.13446045]], shape=(46034, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04620361  0.05673218  0.07144165 ... -0.19537354 -0.17016602\n"," -0.13446045], shape=(46034,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00445557]\n"," [-0.00445557]\n"," [ 0.        ]\n"," ...\n"," [-0.01116943]\n"," [-0.015625  ]\n"," [-0.02008057]], shape=(53028, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00445557 -0.00445557  0.         ... -0.01116943 -0.015625\n"," -0.02008057], shape=(53028,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00869751]\n"," [-0.01739502]\n"," [-0.02609253]\n"," ...\n"," [ 0.01739502]\n"," [ 0.00869751]\n"," [ 0.00869751]], shape=(48146, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00869751 -0.01739502 -0.02609253 ...  0.01739502  0.00869751\n","  0.00869751], shape=(48146,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [ 0.00250244]\n"," [ 0.01251221]\n"," ...\n"," [-0.05749512]\n"," [-0.05999756]\n"," [-0.06750488]], shape=(54508, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488  0.00250244  0.01251221 ... -0.05749512 -0.05999756\n"," -0.06750488], shape=(54508,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0446167 ]\n"," [-0.03717041]\n"," [-0.02230835]\n"," ...\n"," [-0.01486206]\n"," [-0.01486206]\n"," [-0.01858521]], shape=(43000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0446167  -0.03717041 -0.02230835 ... -0.01486206 -0.01486206\n"," -0.01858521], shape=(43000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00894165]\n"," [-0.00894165]\n"," [-0.00976562]\n"," ...\n"," [-0.01382446]\n"," [-0.01382446]\n"," [-0.01220703]], shape=(52682, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00894165 -0.00894165 -0.00976562 ... -0.01382446 -0.01382446\n"," -0.01220703], shape=(52682,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02359009]\n"," [0.02828979]\n"," [0.02359009]\n"," ...\n"," [0.01416016]\n"," [0.01416016]\n"," [0.00473022]], shape=(51142, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02359009 0.02828979 0.02359009 ... 0.01416016 0.01416016 0.00473022], shape=(51142,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [-0.00601196]\n"," [-0.00549316]\n"," ...\n"," [ 0.00750732]\n"," [ 0.00549316]\n"," [ 0.00201416]], shape=(34392, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488 -0.00601196 -0.00549316 ...  0.00750732  0.00549316\n","  0.00201416], shape=(34392,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00430298]\n"," [ 0.00430298]\n"," [ 0.00857544]\n"," ...\n"," [-0.09442139]\n"," [-0.11587524]\n"," [-0.13305664]], shape=(59348, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00430298  0.00430298  0.00857544 ... -0.09442139 -0.11587524\n"," -0.13305664], shape=(59348,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.691864  ]\n"," [ 0.79907227]\n"," [ 0.87631226]\n"," ...\n"," [-0.1114502 ]\n"," [-0.10638428]\n"," [-0.10214233]], shape=(59664, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.691864    0.79907227  0.87631226 ... -0.1114502  -0.10638428\n"," -0.10214233], shape=(59664,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04776001]\n"," [ 0.05075073]\n"," [ 0.03881836]\n"," ...\n"," [-0.01791382]\n"," [-0.0149231 ]\n"," [-0.0149231 ]], shape=(47950, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04776001  0.05075073  0.03881836 ... -0.01791382 -0.0149231\n"," -0.0149231 ], shape=(47950,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06329346]\n"," [ 0.05062866]\n"," [ 0.03796387]\n"," ...\n"," [-0.17721558]\n"," [-0.16455078]\n"," [-0.16455078]], shape=(24592, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06329346  0.05062866  0.03796387 ... -0.17721558 -0.16455078\n"," -0.16455078], shape=(24592,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [ 0.01251221]\n"," [ 0.01251221]\n"," ...\n"," [ 0.        ]\n"," [-0.0062561 ]\n"," [-0.01251221]], shape=(35464, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561   0.01251221  0.01251221 ...  0.         -0.0062561\n"," -0.01251221], shape=(35464,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0743103 ]\n"," [0.08007812]\n"," [0.08135986]\n"," ...\n"," [0.00448608]\n"," [0.00576782]\n"," [0.00448608]], shape=(58546, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0743103  0.08007812 0.08135986 ... 0.00448608 0.00576782 0.00448608], shape=(58546,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00244141]\n"," [0.00244141]\n"," ...\n"," [0.00244141]\n"," [0.        ]\n"," [0.        ]], shape=(52974, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00244141 0.00244141 ... 0.00244141 0.         0.        ], shape=(52974,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18121338]\n"," [-0.13421631]\n"," [-0.13421631]\n"," ...\n"," [-0.18121338]\n"," [-0.18121338]\n"," [-0.19464111]], shape=(70258, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18121338 -0.13421631 -0.13421631 ... -0.18121338 -0.18121338\n"," -0.19464111], shape=(70258,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01153564]\n"," [-0.01730347]\n"," [-0.02593994]\n"," ...\n"," [-0.01730347]\n"," [ 0.01730347]\n"," [ 0.05187988]], shape=(65004, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01153564 -0.01730347 -0.02593994 ... -0.01730347  0.01730347\n","  0.05187988], shape=(65004,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00119019]\n"," [ 0.00299072]\n"," [-0.00119019]\n"," ...\n"," [-0.01315308]\n"," [-0.00897217]\n"," [-0.00299072]], shape=(57998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00119019  0.00299072 -0.00119019 ... -0.01315308 -0.00897217\n"," -0.00299072], shape=(57998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00482178]\n"," [ 0.00482178]\n"," [ 0.00482178]\n"," ...\n"," [-0.01205444]\n"," [-0.00482178]\n"," [-0.01687622]], shape=(78136, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00482178  0.00482178  0.00482178 ... -0.01205444 -0.00482178\n"," -0.01687622], shape=(78136,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00299072]\n"," [ 0.00100708]\n"," [ 0.00048828]\n"," ...\n"," [-0.00448608]\n"," [-0.00601196]\n"," [-0.00650024]], shape=(18926, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00299072  0.00100708  0.00048828 ... -0.00448608 -0.00601196\n"," -0.00650024], shape=(18926,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00515747]\n"," [-0.01031494]\n"," [-0.01803589]\n"," ...\n"," [ 0.02578735]\n"," [ 0.02062988]\n"," [ 0.01547241]], shape=(35920, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00515747 -0.01031494 -0.01803589 ...  0.02578735  0.02062988\n","  0.01547241], shape=(35920,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01464844]\n"," [-0.01464844]\n"," [-0.02075195]\n"," ...\n"," [-0.53967285]\n"," [-0.55126953]\n"," [-0.52075195]], shape=(32518, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01464844 -0.01464844 -0.02075195 ... -0.53967285 -0.55126953\n"," -0.52075195], shape=(32518,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06356812]\n"," [-0.05508423]\n"," [-0.04660034]\n"," ...\n"," [-0.01693726]\n"," [-0.0211792 ]\n"," [-0.01693726]], shape=(37702, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06356812 -0.05508423 -0.04660034 ... -0.01693726 -0.0211792\n"," -0.01693726], shape=(37702,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0105896 ]\n"," [-0.01300049]\n"," [-0.01638794]\n"," ...\n"," [-0.01879883]\n"," [-0.01782227]\n"," [-0.01782227]], shape=(33966, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0105896  -0.01300049 -0.01638794 ... -0.01879883 -0.01782227\n"," -0.01782227], shape=(33966,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08334351]\n"," [-0.07574463]\n"," [-0.04544067]\n"," ...\n"," [-0.03787231]\n"," [-0.19317627]\n"," [-0.3522644 ]], shape=(51500, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08334351 -0.07574463 -0.04544067 ... -0.03787231 -0.19317627\n"," -0.3522644 ], shape=(51500,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01367188]\n"," [-0.01913452]\n"," [-0.01092529]\n"," ...\n"," [ 0.00274658]\n"," [ 0.00274658]\n"," [-0.00274658]], shape=(18978, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01367188 -0.01913452 -0.01092529 ...  0.00274658  0.00274658\n"," -0.00274658], shape=(18978,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03616333]\n"," [-0.03405762]\n"," [-0.03405762]\n"," ...\n"," [-0.01489258]\n"," [-0.02340698]\n"," [-0.03829956]], shape=(21946, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03616333 -0.03405762 -0.03405762 ... -0.01489258 -0.02340698\n"," -0.03829956], shape=(21946,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02023315]\n"," [-0.04049683]\n"," [-0.04858398]\n"," ...\n"," [-0.04049683]\n"," [-0.02023315]\n"," [-0.02023315]], shape=(24012, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02023315 -0.04049683 -0.04858398 ... -0.04049683 -0.02023315\n"," -0.02023315], shape=(24012,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.23275757]\n"," [ 0.28448486]\n"," [ 0.32757568]\n"," ...\n"," [-0.14654541]\n"," [-0.12930298]\n"," [-0.09481812]], shape=(73830, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.23275757  0.28448486  0.32757568 ... -0.14654541 -0.12930298\n"," -0.09481812], shape=(73830,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00344849]\n"," [-0.00518799]\n"," [-0.00863647]\n"," ...\n"," [ 0.0017395 ]\n"," [ 0.00604248]\n"," [ 0.00949097]], shape=(58010, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00344849 -0.00518799 -0.00863647 ...  0.0017395   0.00604248\n","  0.00949097], shape=(58010,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00799561]\n"," [-0.00650024]\n"," [-0.00500488]\n"," ...\n"," [ 0.00549316]\n"," [ 0.        ]\n"," [-0.00601196]], shape=(35642, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00799561 -0.00650024 -0.00500488 ...  0.00549316  0.\n"," -0.00601196], shape=(35642,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08822632]\n"," [-0.06723022]\n"," [-0.04620361]\n"," ...\n"," [-0.01470947]\n"," [-0.01470947]\n"," [-0.02099609]], shape=(43824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08822632 -0.06723022 -0.04620361 ... -0.01470947 -0.01470947\n"," -0.02099609], shape=(43824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01242065]\n"," [ 0.00622559]\n"," [-0.00622559]\n"," ...\n"," [-0.04968262]\n"," [-0.04968262]\n"," [-0.04348755]], shape=(35458, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01242065  0.00622559 -0.00622559 ... -0.04968262 -0.04968262\n"," -0.04348755], shape=(35458,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.01074219]\n"," ...\n"," [-0.0161438 ]\n"," [-0.00537109]\n"," [ 0.        ]], shape=(31616, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.01074219 ... -0.0161438  -0.00537109\n","  0.        ], shape=(31616,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00491333]\n"," [ 0.00985718]\n"," [ 0.01477051]\n"," ...\n"," [-0.1182251 ]\n"," [-0.10836792]\n"," [-0.10345459]], shape=(44276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00491333  0.00985718  0.01477051 ... -0.1182251  -0.10836792\n"," -0.10345459], shape=(44276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01324463]\n"," [-0.01324463]\n"," [-0.01324463]\n"," ...\n"," [ 0.        ]\n"," [ 0.00146484]\n"," [ 0.00146484]], shape=(37208, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01324463 -0.01324463 -0.01324463 ...  0.          0.00146484\n","  0.00146484], shape=(37208,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.37799072]\n"," [0.5038147 ]\n"," [0.53912354]\n"," ...\n"," [0.57440186]\n"," [0.57440186]\n"," [0.57525635]], shape=(56988, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.37799072 0.5038147  0.53912354 ... 0.57440186 0.57440186 0.57525635], shape=(56988,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01675415]\n"," [-0.01583862]\n"," [-0.01443481]\n"," ...\n"," [ 0.012146  ]\n"," [ 0.01229858]\n"," [ 0.01226807]], shape=(25342, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01675415 -0.01583862 -0.01443481 ...  0.012146    0.01229858\n","  0.01226807], shape=(25342,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00848389]\n"," [-0.00848389]\n"," [-0.00848389]\n"," ...\n"," [-0.09744263]\n"," [-0.08898926]\n"," [-0.07626343]], shape=(37804, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00848389 -0.00848389 -0.00848389 ... -0.09744263 -0.08898926\n"," -0.07626343], shape=(37804,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01031494]\n"," [-0.03607178]\n"," [-0.05670166]\n"," ...\n"," [-0.19586182]\n"," [-0.20101929]\n"," [-0.19586182]], shape=(19866, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01031494 -0.03607178 -0.05670166 ... -0.19586182 -0.20101929\n"," -0.19586182], shape=(19866,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02047729]\n"," [-0.08480835]\n"," [-0.14910889]\n"," ...\n"," [-0.02923584]\n"," [-0.02047729]\n"," [-0.02923584]], shape=(23248, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02047729 -0.08480835 -0.14910889 ... -0.02923584 -0.02047729\n"," -0.02923584], shape=(23248,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00750732]\n"," [ 0.        ]\n"," [-0.00750732]\n"," ...\n"," [-0.02630615]\n"," [-0.03759766]\n"," [-0.03759766]], shape=(45418, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00750732  0.         -0.00750732 ... -0.02630615 -0.03759766\n"," -0.03759766], shape=(45418,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00714111]\n"," [ 0.        ]\n"," ...\n"," [ 0.18569946]\n"," [ 0.18569946]\n"," [ 0.17141724]], shape=(24652, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00714111  0.         ...  0.18569946  0.18569946\n","  0.17141724], shape=(24652,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00848389]\n"," [ 0.00030518]\n"," [ 0.00848389]\n"," ...\n"," [-0.01715088]\n"," [-0.00848389]\n"," [-0.0057373 ]], shape=(18518, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00848389  0.00030518  0.00848389 ... -0.01715088 -0.00848389\n"," -0.0057373 ], shape=(18518,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04092407]\n"," [ 0.        ]\n"," [-0.02923584]\n"," ...\n"," [-0.01168823]\n"," [-0.01168823]\n"," [-0.04092407]], shape=(33332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04092407  0.         -0.02923584 ... -0.01168823 -0.01168823\n"," -0.04092407], shape=(33332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.05145264]\n"," [0.03060913]\n"," [0.00695801]\n"," ...\n"," [0.01669312]\n"," [0.01669312]\n"," [0.01806641]], shape=(48670, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.05145264 0.03060913 0.00695801 ... 0.01669312 0.01669312 0.01806641], shape=(48670,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11950684]\n"," [-0.1512146 ]\n"," [-0.18048096]\n"," ...\n"," [-0.06829834]\n"," [-0.06585693]\n"," [-0.06341553]], shape=(49702, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11950684 -0.1512146  -0.18048096 ... -0.06829834 -0.06585693\n"," -0.06341553], shape=(49702,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04092407]\n"," [-0.02728271]\n"," [-0.04092407]\n"," ...\n"," [ 0.0227356 ]\n"," [ 0.01818848]\n"," [ 0.0227356 ]], shape=(33268, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04092407 -0.02728271 -0.04092407 ...  0.0227356   0.01818848\n","  0.0227356 ], shape=(33268,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01818848]\n"," [ 0.01818848]\n"," [ 0.01818848]\n"," ...\n"," [-0.04092407]\n"," [-0.04092407]\n"," [-0.02728271]], shape=(54138, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01818848  0.01818848  0.01818848 ... -0.04092407 -0.04092407\n"," -0.02728271], shape=(54138,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04055786]\n"," [-0.03900146]\n"," [-0.03759766]\n"," ...\n"," [ 0.00775146]\n"," [ 0.00561523]\n"," [ 0.00326538]], shape=(41224, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04055786 -0.03900146 -0.03759766 ...  0.00775146  0.00561523\n","  0.00326538], shape=(41224,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00808716]\n"," [-0.00808716]\n"," [ 0.        ]\n"," ...\n"," [-0.00808716]\n"," [ 0.        ]\n"," [-0.00808716]], shape=(55236, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00808716 -0.00808716  0.         ... -0.00808716  0.\n"," -0.00808716], shape=(55236,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00518799]\n"," [ 0.00778198]\n"," [ 0.01559448]\n"," ...\n"," [-0.03115845]\n"," [-0.01559448]\n"," [ 0.00259399]], shape=(44078, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00518799  0.00778198  0.01559448 ... -0.03115845 -0.01559448\n","  0.00259399], shape=(44078,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0526123 ]\n"," [-0.04544067]\n"," [-0.03347778]\n"," ...\n"," [ 0.21459961]\n"," [ 0.20739746]\n"," [ 0.19726562]], shape=(24088, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0526123  -0.04544067 -0.03347778 ...  0.21459961  0.20739746\n","  0.19726562], shape=(24088,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0375061 ]\n"," [0.0249939 ]\n"," [0.01501465]\n"," ...\n"," [0.00750732]\n"," [0.00500488]\n"," [0.00500488]], shape=(51182, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0375061  0.0249939  0.01501465 ... 0.00750732 0.00500488 0.00500488], shape=(51182,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13150024]\n"," [-0.13494873]\n"," [-0.13839722]\n"," ...\n"," [-0.06228638]\n"," [-0.07266235]\n"," [-0.07266235]], shape=(56546, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13150024 -0.13494873 -0.13839722 ... -0.06228638 -0.07266235\n"," -0.07266235], shape=(56546,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04165649]\n"," [ 0.04165649]\n"," [ 0.05209351]\n"," ...\n"," [-0.01040649]\n"," [-0.02084351]\n"," [-0.02084351]], shape=(40968, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04165649  0.04165649  0.05209351 ... -0.01040649 -0.02084351\n"," -0.02084351], shape=(40968,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1210022 ]\n"," [-0.11599731]\n"," [-0.10501099]\n"," ...\n"," [ 0.00549316]\n"," [ 0.00500488]\n"," [ 0.00350952]], shape=(31896, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1210022  -0.11599731 -0.10501099 ...  0.00549316  0.00500488\n","  0.00350952], shape=(31896,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02017212]\n"," [-0.01153564]\n"," [ 0.        ]\n"," ...\n"," [-0.00286865]\n"," [ 0.        ]\n"," [ 0.00576782]], shape=(74396, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02017212 -0.01153564  0.         ... -0.00286865  0.\n","  0.00576782], shape=(74396,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01104736]\n"," [0.01104736]\n"," [0.01104736]\n"," ...\n"," [0.00552368]\n"," [0.        ]\n"," [0.        ]], shape=(47590, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01104736 0.01104736 0.01104736 ... 0.00552368 0.         0.        ], shape=(47590,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00720215]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.09713745]\n"," [-0.13308716]\n"," [-0.15109253]], shape=(17924, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00720215  0.          0.         ... -0.09713745 -0.13308716\n"," -0.15109253], shape=(17924,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.14285278]\n"," [ 0.        ]\n"," ...\n"," [ 0.14285278]\n"," [-0.28570557]\n"," [ 0.        ]], shape=(34838, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.14285278  0.         ...  0.14285278 -0.28570557\n","  0.        ], shape=(34838,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.23727417]\n"," [ 0.22457886]\n"," [ 0.19067383]\n"," ...\n"," [ 0.00848389]\n"," [ 0.00424194]\n"," [-0.00424194]], shape=(42560, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.23727417  0.22457886  0.19067383 ...  0.00848389  0.00424194\n"," -0.00424194], shape=(42560,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.3128662 ]\n"," [-0.30700684]\n"," [-0.27194214]\n"," ...\n"," [ 0.09356689]\n"," [ 0.07894897]\n"," [ 0.07019043]], shape=(36680, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.3128662  -0.30700684 -0.27194214 ...  0.09356689  0.07894897\n","  0.07019043], shape=(36680,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11856079]\n"," [-0.12371826]\n"," [-0.12371826]\n"," ...\n"," [-0.25256348]\n"," [-0.25772095]\n"," [-0.25256348]], shape=(49102, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11856079 -0.12371826 -0.12371826 ... -0.25256348 -0.25772095\n"," -0.25256348], shape=(49102,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.20056152]\n"," [0.19561768]\n"," [0.1928711 ]\n"," ...\n"," [0.24108887]\n"," [0.24383545]\n"," [0.24603271]], shape=(17264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.20056152 0.19561768 0.1928711  ... 0.24108887 0.24383545 0.24603271], shape=(17264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02865601]\n"," [-0.02005005]\n"," [-0.02865601]\n"," ...\n"," [-0.0057373 ]\n"," [ 0.0057373 ]\n"," [ 0.        ]], shape=(178544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02865601 -0.02005005 -0.02865601 ... -0.0057373   0.0057373\n","  0.        ], shape=(178544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.480011  ]\n"," [-0.46798706]\n"," [-0.45300293]\n"," ...\n"," [-0.13800049]\n"," [-0.13049316]\n"," [-0.12249756]], shape=(21442, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.480011   -0.46798706 -0.45300293 ... -0.13800049 -0.13049316\n"," -0.12249756], shape=(21442,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.05264282]\n"," [ 0.        ]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(40512, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.05264282  0.         ...  0.          0.\n","  0.        ], shape=(40512,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00250244]\n"," [-0.00500488]\n"," ...\n"," [-0.01000977]\n"," [-0.01126099]\n"," [-0.00875854]], shape=(38304, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00250244 -0.00500488 ... -0.01000977 -0.01126099\n"," -0.00875854], shape=(38304,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.0062561 ]\n"," [-0.00750732]\n"," ...\n"," [ 0.01251221]\n"," [ 0.01251221]\n"," [ 0.01251221]], shape=(76206, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.0062561  -0.00750732 ...  0.01251221  0.01251221\n","  0.01251221], shape=(76206,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.0072937 ]\n"," [0.00244141]\n"," ...\n"," [0.01217651]\n"," [0.01217651]\n"," [0.00973511]], shape=(39102, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.0072937  0.00244141 ... 0.01217651 0.01217651 0.00973511], shape=(39102,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.40234375]\n"," [ 0.36471558]\n"," [ 0.31292725]\n"," ...\n"," [-0.01177979]\n"," [-0.01412964]\n"," [-0.0211792 ]], shape=(19106, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.40234375  0.36471558  0.31292725 ... -0.01177979 -0.01412964\n"," -0.0211792 ], shape=(19106,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01168823]\n"," [-0.02923584]\n"," ...\n"," [ 0.25732422]\n"," [ 0.21636963]\n"," [ 0.15789795]], shape=(42754, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01168823 -0.02923584 ...  0.25732422  0.21636963\n","  0.15789795], shape=(42754,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03881836]\n"," [ 0.04776001]\n"," [ 0.03881836]\n"," ...\n"," [-0.01193237]\n"," [-0.01193237]\n"," [-0.01193237]], shape=(72194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03881836  0.04776001  0.03881836 ... -0.01193237 -0.01193237\n"," -0.01193237], shape=(72194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01202393]\n"," [ 0.00701904]\n"," [ 0.01000977]\n"," ...\n"," [-0.05606079]\n"," [-0.05404663]\n"," [-0.04904175]], shape=(54386, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01202393  0.00701904  0.01000977 ... -0.05606079 -0.05404663\n"," -0.04904175], shape=(54386,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00424194]\n"," [0.00552368]\n"," [0.00335693]\n"," ...\n"," [0.0020752 ]\n"," [0.00219727]\n"," [0.00125122]], shape=(54932, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00424194 0.00552368 0.00335693 ... 0.0020752  0.00219727 0.00125122], shape=(54932,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01834106]\n"," [0.01834106]\n"," [0.01834106]\n"," ...\n"," [0.06420898]\n"," [0.08258057]\n"," [0.09173584]], shape=(84414, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01834106 0.01834106 0.01834106 ... 0.06420898 0.08258057 0.09173584], shape=(84414,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01693726]\n"," [-0.01791382]\n"," [-0.01693726]\n"," ...\n"," [-0.00668335]\n"," [-0.00848389]\n"," [-0.01092529]], shape=(25356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01693726 -0.01791382 -0.01693726 ... -0.00668335 -0.00848389\n"," -0.01092529], shape=(25356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00125122]\n"," [ 0.        ]\n"," ...\n"," [-0.00500488]\n"," [-0.01000977]\n"," [-0.01376343]], shape=(48044, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00125122  0.         ... -0.00500488 -0.01000977\n"," -0.01376343], shape=(48044,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01867676]\n"," [-0.02182007]\n"," [-0.01867676]\n"," ...\n"," [ 0.01556396]\n"," [ 0.01245117]\n"," [ 0.01867676]], shape=(34458, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01867676 -0.02182007 -0.01867676 ...  0.01556396  0.01245117\n","  0.01867676], shape=(34458,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08712769]\n"," [0.07888794]\n"," [0.06970215]\n"," ...\n"," [0.00167847]\n"," [0.00436401]\n"," [0.00653076]], shape=(38640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08712769 0.07888794 0.06970215 ... 0.00167847 0.00436401 0.00653076], shape=(38640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.08358765]\n"," [ 0.10949707]\n"," [ 0.11526489]\n"," ...\n"," [-0.15274048]\n"," [-0.21325684]\n"," [-0.2737732 ]], shape=(77490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.08358765  0.10949707  0.11526489 ... -0.15274048 -0.21325684\n"," -0.2737732 ], shape=(77490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00750732]\n"," [-0.00875854]\n"," [-0.01000977]\n"," ...\n"," [ 0.00500488]\n"," [ 0.00875854]\n"," [ 0.00750732]], shape=(67198, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00750732 -0.00875854 -0.01000977 ...  0.00500488  0.00875854\n","  0.00750732], shape=(67198,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.06082153]\n"," [0.06082153]\n"," [0.0743103 ]\n"," ...\n"," [0.0743103 ]\n"," [0.06756592]\n"," [0.06756592]], shape=(45822, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.06082153 0.06082153 0.0743103  ... 0.0743103  0.06756592 0.06756592], shape=(45822,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02792358]\n"," [ 0.01776123]\n"," [-0.00253296]\n"," ...\n"," [ 0.01016235]\n"," [ 0.01269531]\n"," [ 0.01269531]], shape=(83170, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02792358  0.01776123 -0.00253296 ...  0.01016235  0.01269531\n","  0.01269531], shape=(83170,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02630615]\n"," [-0.02630615]\n"," [-0.01879883]\n"," ...\n"," [ 0.00750732]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(58648, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02630615 -0.02630615 -0.01879883 ...  0.00750732  0.\n","  0.        ], shape=(58648,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06521606]\n"," [-0.05435181]\n"," [-0.04348755]\n"," ...\n"," [-0.02172852]\n"," [-0.02172852]\n"," [-0.01086426]], shape=(32628, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06521606 -0.05435181 -0.04348755 ... -0.02172852 -0.02172852\n"," -0.01086426], shape=(32628,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03106689]\n"," [-0.03726196]\n"," [-0.03106689]\n"," ...\n"," [-0.08074951]\n"," [-0.04348755]\n"," [-0.00622559]], shape=(39900, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03106689 -0.03726196 -0.03106689 ... -0.08074951 -0.04348755\n"," -0.00622559], shape=(39900,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01513672]\n"," [-0.01470947]\n"," [-0.01260376]\n"," ...\n"," [-0.05697632]\n"," [-0.06051636]\n"," [-0.06317139]], shape=(53498, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01513672 -0.01470947 -0.01260376 ... -0.05697632 -0.06051636\n"," -0.06317139], shape=(53498,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1000061]\n"," [-0.1499939]\n"," [-0.2062378]\n"," ...\n"," [-0.03125  ]\n"," [-0.03125  ]\n"," [-0.0062561]], shape=(52904, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.1000061 -0.1499939 -0.2062378 ... -0.03125   -0.03125   -0.0062561], shape=(52904,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00765991]\n"," [ 0.01019287]\n"," ...\n"," [-0.00765991]\n"," [-0.01019287]\n"," [-0.01019287]], shape=(78428, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00765991  0.01019287 ... -0.00765991 -0.01019287\n"," -0.01019287], shape=(78428,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01879883]\n"," [ 0.02508545]\n"," [ 0.03134155]\n"," ...\n"," [-0.04074097]\n"," [-0.03292847]\n"," [-0.02349854]], shape=(75238, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01879883  0.02508545  0.03134155 ... -0.04074097 -0.03292847\n"," -0.02349854], shape=(75238,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.07595825]\n"," [0.07595825]\n"," [0.08859253]\n"," ...\n"," [0.08859253]\n"," [0.10125732]\n"," [0.10125732]], shape=(52114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.07595825 0.07595825 0.08859253 ... 0.08859253 0.10125732 0.10125732], shape=(52114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04626465]\n"," [ 0.04501343]\n"," [ 0.04376221]\n"," ...\n"," [-0.01000977]\n"," [-0.01501465]\n"," [-0.02249146]], shape=(36492, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04626465  0.04501343  0.04376221 ... -0.01000977 -0.01501465\n"," -0.02249146], shape=(36492,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01583862]\n"," [-0.01593018]\n"," [-0.01583862]\n"," ...\n"," [-0.01022339]\n"," [-0.0045166 ]\n"," [-0.00036621]], shape=(17258, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01583862 -0.01593018 -0.01583862 ... -0.01022339 -0.0045166\n"," -0.00036621], shape=(17258,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04623413]\n"," [ 0.05780029]\n"," [ 0.06646729]\n"," ...\n"," [-0.03756714]\n"," [-0.04336548]\n"," [-0.04623413]], shape=(32550, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04623413  0.05780029  0.06646729 ... -0.03756714 -0.04336548\n"," -0.04623413], shape=(32550,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11218262]\n"," [-0.10244751]\n"," [-0.10733032]\n"," ...\n"," [-0.08779907]\n"," [-0.08779907]\n"," [-0.08291626]], shape=(31654, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11218262 -0.10244751 -0.10733032 ... -0.08779907 -0.08779907\n"," -0.08291626], shape=(31654,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03408813]\n"," [-0.02841187]\n"," [-0.03408813]\n"," ...\n"," [ 0.00567627]\n"," [-0.01419067]\n"," [-0.00567627]], shape=(34886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03408813 -0.02841187 -0.03408813 ...  0.00567627 -0.01419067\n"," -0.00567627], shape=(34886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11627197]\n"," [-0.17053223]\n"," [-0.20928955]\n"," ...\n"," [-0.1550293 ]\n"," [-0.11627197]\n"," [-0.07751465]], shape=(23150, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11627197 -0.17053223 -0.20928955 ... -0.1550293  -0.11627197\n"," -0.07751465], shape=(23150,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.14944458]\n"," [ 0.14648438]\n"," [ 0.14352417]\n"," ...\n"," [-0.0713501 ]\n"," [-0.06585693]\n"," [-0.05993652]], shape=(30954, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.14944458  0.14648438  0.14352417 ... -0.0713501  -0.06585693\n"," -0.05993652], shape=(30954,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00308228]\n"," [ 0.00442505]\n"," [ 0.00527954]\n"," ...\n"," [-0.00088501]\n"," [ 0.00088501]\n"," [ 0.00308228]], shape=(35412, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00308228  0.00442505  0.00527954 ... -0.00088501  0.00088501\n","  0.00308228], shape=(35412,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00189209]\n"," [ 0.        ]\n"," [-0.00375366]\n"," ...\n"," [ 0.        ]\n"," [ 0.00375366]\n"," [ 0.00375366]], shape=(26820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00189209  0.         -0.00375366 ...  0.          0.00375366\n","  0.00375366], shape=(26820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.01281738]\n"," ...\n"," [0.00640869]\n"," [0.00640869]\n"," [0.00640869]], shape=(96422, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.01281738 ... 0.00640869 0.00640869 0.00640869], shape=(96422,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.12368774]\n"," [ 0.12158203]\n"," [ 0.12158203]\n"," ...\n"," [-0.0949707 ]\n"," [-0.10638428]\n"," [-0.11734009]], shape=(39676, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.12368774  0.12158203  0.12158203 ... -0.0949707  -0.10638428\n"," -0.11734009], shape=(39676,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02249146]\n"," [-0.02249146]\n"," [-0.01998901]\n"," ...\n"," [-0.09500122]\n"," [-0.13000488]\n"," [-0.16000366]], shape=(16544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02249146 -0.02249146 -0.01998901 ... -0.09500122 -0.13000488\n"," -0.16000366], shape=(16544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05847168]\n"," [-0.04092407]\n"," [-0.04092407]\n"," ...\n"," [-0.04092407]\n"," [-0.02923584]\n"," [-0.04092407]], shape=(40886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05847168 -0.04092407 -0.04092407 ... -0.04092407 -0.02923584\n"," -0.04092407], shape=(40886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04620361]\n"," [ 0.06091309]\n"," [ 0.07772827]\n"," ...\n"," [-0.26260376]\n"," [-0.26260376]\n"," [-0.2668152 ]], shape=(25830, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04620361  0.06091309  0.07772827 ... -0.26260376 -0.26260376\n"," -0.2668152 ], shape=(25830,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02902222]\n"," [-0.03204346]\n"," [-0.02902222]\n"," ...\n"," [-0.02703857]\n"," [-0.02401733]\n"," [-0.02703857]], shape=(52726, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02902222 -0.03204346 -0.02902222 ... -0.02703857 -0.02401733\n"," -0.02703857], shape=(52726,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.3333435 ]\n"," [-0.3137207 ]\n"," [-0.28103638]\n"," ...\n"," [-0.13726807]\n"," [-0.15686035]\n"," [-0.17648315]], shape=(61156, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.3333435  -0.3137207  -0.28103638 ... -0.13726807 -0.15686035\n"," -0.17648315], shape=(61156,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0065918 ]\n"," [-0.0032959 ]\n"," [-0.01321411]\n"," ...\n"," [ 0.0032959 ]\n"," [ 0.0032959 ]\n"," [ 0.0065918 ]], shape=(35538, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0065918  -0.0032959  -0.01321411 ...  0.0032959   0.0032959\n","  0.0065918 ], shape=(35538,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01190186]\n"," [-0.01190186]\n"," [-0.0105896 ]\n"," ...\n"," [-0.0163269 ]\n"," [-0.01498413]\n"," [-0.01190186]], shape=(56030, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01190186 -0.01190186 -0.0105896  ... -0.0163269  -0.01498413\n"," -0.01190186], shape=(56030,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05075073]\n"," [ 0.05075073]\n"," [ 0.05075073]\n"," ...\n"," [-0.00598145]\n"," [-0.00598145]\n"," [-0.00598145]], shape=(38320, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05075073  0.05075073  0.05075073 ... -0.00598145 -0.00598145\n"," -0.00598145], shape=(38320,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02218628]\n"," [-0.02218628]\n"," [-0.02218628]\n"," ...\n"," [-0.00863647]\n"," [-0.00738525]\n"," [-0.00863647]], shape=(100234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02218628 -0.02218628 -0.02218628 ... -0.00863647 -0.00738525\n"," -0.00863647], shape=(100234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.38034058]\n"," [-0.37820435]\n"," [-0.37527466]\n"," ...\n"," [-0.3258667 ]\n"," [-0.31658936]\n"," [-0.30603027]], shape=(30214, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.38034058 -0.37820435 -0.37527466 ... -0.3258667  -0.31658936\n"," -0.30603027], shape=(30214,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00714111]\n"," [-0.00714111]\n"," ...\n"," [ 0.        ]\n"," [-0.01428223]\n"," [-0.00714111]], shape=(42706, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00714111 -0.00714111 ...  0.         -0.01428223\n"," -0.00714111], shape=(42706,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01361084]\n"," [-0.01361084]\n"," [-0.01361084]\n"," ...\n"," [ 0.21768188]\n"," [ 0.2585144 ]\n"," [ 0.30612183]], shape=(40762, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01361084 -0.01361084 -0.01361084 ...  0.21768188  0.2585144\n","  0.30612183], shape=(40762,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.35671997]\n"," [-0.3684082 ]\n"," [-0.36550903]\n"," ...\n"," [-0.08187866]\n"," [-0.08187866]\n"," [-0.08187866]], shape=(16240, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.35671997 -0.3684082  -0.36550903 ... -0.08187866 -0.08187866\n"," -0.08187866], shape=(16240,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01251221]\n"," [ 0.01000977]\n"," [ 0.00750732]\n"," ...\n"," [-0.00500488]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(74470, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01251221  0.01000977  0.00750732 ... -0.00500488  0.\n","  0.        ], shape=(74470,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06414795]\n"," [-0.06704712]\n"," [-0.06414795]\n"," ...\n"," [-0.13412476]\n"," [-0.15744019]\n"," [-0.18075562]], shape=(53848, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06414795 -0.06704712 -0.06414795 ... -0.13412476 -0.15744019\n"," -0.18075562], shape=(53848,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00100708]\n"," [0.00500488]\n"," [0.00650024]\n"," ...\n"," [0.01049805]\n"," [0.01098633]\n"," [0.01300049]], shape=(187462, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00100708 0.00500488 0.00650024 ... 0.01049805 0.01098633 0.01300049], shape=(187462,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01348877]\n"," [ 0.01449585]\n"," [ 0.01550293]\n"," ...\n"," [-0.00350952]\n"," [-0.00350952]\n"," [-0.00500488]], shape=(22134, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01348877  0.01449585  0.01550293 ... -0.00350952 -0.00350952\n"," -0.00500488], shape=(22134,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01275635]\n"," [0.0255127 ]\n"," [0.040802  ]\n"," ...\n"," [0.02807617]\n"," [0.03826904]\n"," [0.03826904]], shape=(21220, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01275635 0.0255127  0.040802   ... 0.02807617 0.03826904 0.03826904], shape=(21220,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01000977]\n"," [-0.0062561 ]\n"," [-0.00125122]\n"," ...\n"," [-0.00875854]\n"," [-0.01998901]\n"," [-0.02999878]], shape=(36570, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01000977 -0.0062561  -0.00125122 ... -0.00875854 -0.01998901\n"," -0.02999878], shape=(36570,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01730347]\n"," [0.01730347]\n"," [0.01730347]\n"," ...\n"," [0.03170776]\n"," [0.03457642]\n"," [0.02880859]], shape=(82962, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01730347 0.01730347 0.01730347 ... 0.03170776 0.03457642 0.02880859], shape=(82962,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00772095]\n"," [-0.01931763]\n"," [ 0.        ]\n"," ...\n"," [ 0.        ]\n"," [ 0.00772095]\n"," [ 0.00772095]], shape=(32250, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00772095 -0.01931763  0.         ...  0.          0.00772095\n","  0.00772095], shape=(32250,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.28451538]\n"," [-0.31237793]\n"," [-0.34024048]\n"," ...\n"," [ 0.09286499]\n"," [ 0.09371948]\n"," [ 0.0949707 ]], shape=(56028, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.28451538 -0.31237793 -0.34024048 ...  0.09286499  0.09371948\n","  0.0949707 ], shape=(56028,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.0005188 ]\n"," [-0.0005188 ]\n"," ...\n"," [-0.0005188 ]\n"," [-0.00100708]\n"," [-0.00100708]], shape=(34674, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.0005188  -0.0005188  ... -0.0005188  -0.00100708\n"," -0.00100708], shape=(34674,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00878906]\n"," [-0.01507568]\n"," [-0.00628662]], shape=(42524, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.          0.         ... -0.00878906 -0.01507568\n"," -0.00628662], shape=(42524,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01623535]\n"," [0.02249146]\n"," [0.02749634]\n"," ...\n"," [0.0062561 ]\n"," [0.00500488]\n"," [0.00500488]], shape=(75298, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01623535 0.02249146 0.02749634 ... 0.0062561  0.00500488 0.00500488], shape=(75298,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00183105]\n"," [0.00183105]\n"," ...\n"," [0.03103638]\n"," [0.02920532]\n"," [0.01824951]], shape=(19256, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00183105 0.00183105 ... 0.03103638 0.02920532 0.01824951], shape=(19256,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [ 0.00500488]\n"," [ 0.01126099]\n"," ...\n"," [-0.02124023]\n"," [-0.01998901]\n"," [-0.01873779]], shape=(60712, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244  0.00500488  0.01126099 ... -0.02124023 -0.01998901\n"," -0.01873779], shape=(60712,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00769043]\n"," [-0.01153564]\n"," [-0.01409912]\n"," ...\n"," [ 0.00640869]\n"," [ 0.00704956]\n"," [ 0.00769043]], shape=(48850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00769043 -0.01153564 -0.01409912 ...  0.00640869  0.00704956\n","  0.00769043], shape=(48850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04501343]\n"," [-0.04998779]\n"," [-0.05123901]\n"," ...\n"," [-0.07376099]\n"," [-0.07376099]\n"," [-0.07376099]], shape=(18164, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04501343 -0.04998779 -0.05123901 ... -0.07376099 -0.07376099\n"," -0.07376099], shape=(18164,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09658813]\n"," [-0.14489746]\n"," [-0.20169067]\n"," ...\n"," [-0.00567627]\n"," [ 0.00567627]\n"," [-0.00567627]], shape=(44046, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09658813 -0.14489746 -0.20169067 ... -0.00567627  0.00567627\n"," -0.00567627], shape=(44046,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.255188  ]\n"," [-0.2527771 ]\n"," [-0.2503662 ]\n"," ...\n"," [-0.08990479]\n"," [-0.08602905]\n"," [-0.08169556]], shape=(41344, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.255188   -0.2527771  -0.2503662  ... -0.08990479 -0.08602905\n"," -0.08169556], shape=(41344,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08120728]\n"," [-0.08291626]\n"," [-0.084198  ]\n"," ...\n"," [-0.22958374]\n"," [-0.228302  ]\n"," [-0.22958374]], shape=(39024, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08120728 -0.08291626 -0.084198   ... -0.22958374 -0.228302\n"," -0.22958374], shape=(39024,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10290527]\n"," [-0.10397339]\n"," [-0.10501099]\n"," ...\n"," [-0.15124512]\n"," [-0.15057373]\n"," [-0.1496582 ]], shape=(32602, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10290527 -0.10397339 -0.10501099 ... -0.15124512 -0.15057373\n"," -0.1496582 ], shape=(32602,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0072937 ]\n"," [-0.00912476]\n"," [-0.00366211]\n"," ...\n"," [ 0.00366211]\n"," [ 0.00183105]\n"," [-0.00183105]], shape=(100458, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0072937  -0.00912476 -0.00366211 ...  0.00366211  0.00183105\n"," -0.00183105], shape=(100458,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07519531]\n"," [ 0.07519531]\n"," [ 0.06686401]\n"," ...\n"," [-0.01950073]\n"," [-0.0557251 ]\n"," [-0.06686401]], shape=(43580, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07519531  0.07519531  0.06686401 ... -0.01950073 -0.0557251\n"," -0.06686401], shape=(43580,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00500488]\n"," [ 0.        ]\n"," [-0.00375366]\n"," ...\n"," [-0.0375061 ]\n"," [-0.01873779]\n"," [ 0.        ]], shape=(32914, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00500488  0.         -0.00375366 ... -0.0375061  -0.01873779\n","  0.        ], shape=(32914,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0149231 ]\n"," [-0.02984619]\n"," [-0.0149231 ]\n"," ...\n"," [-0.0149231 ]\n"," [-0.0149231 ]\n"," [-0.00598145]], shape=(25384, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0149231  -0.02984619 -0.0149231  ... -0.0149231  -0.0149231\n"," -0.00598145], shape=(25384,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [ 0.00784302]\n"," [ 0.02038574]\n"," ...\n"," [ 0.01568604]\n"," [ 0.01409912]\n"," [ 0.01409912]], shape=(45292, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561   0.00784302  0.02038574 ...  0.01568604  0.01409912\n","  0.01409912], shape=(45292,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17272949]\n"," [-0.08181763]\n"," [-0.08181763]\n"," ...\n"," [-0.20303345]\n"," [-0.2000122 ]\n"," [-0.18182373]], shape=(47872, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17272949 -0.08181763 -0.08181763 ... -0.20303345 -0.2000122\n"," -0.18182373], shape=(47872,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09539795]\n"," [-0.09539795]\n"," [-0.09539795]\n"," ...\n"," [-0.08615112]\n"," [-0.10461426]\n"," [-0.12307739]], shape=(93212, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09539795 -0.09539795 -0.09539795 ... -0.08615112 -0.10461426\n"," -0.12307739], shape=(93212,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00268555]\n"," [-0.01208496]\n"," [-0.02151489]\n"," ...\n"," [ 0.00134277]\n"," [ 0.00134277]\n"," [ 0.00134277]], shape=(47004, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00268555 -0.01208496 -0.02151489 ...  0.00134277  0.00134277\n","  0.00134277], shape=(47004,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00881958]\n"," [-0.00588989]\n"," [-0.00588989]\n"," ...\n"," [ 0.08383179]\n"," [ 0.04998779]\n"," [ 0.01763916]], shape=(44308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00881958 -0.00588989 -0.00588989 ...  0.08383179  0.04998779\n","  0.01763916], shape=(44308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01852417]\n"," [-0.027771  ]\n"," [-0.01852417]\n"," ...\n"," [ 0.027771  ]\n"," [ 0.027771  ]\n"," [ 0.01852417]], shape=(81738, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01852417 -0.027771   -0.01852417 ...  0.027771    0.027771\n","  0.01852417], shape=(81738,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02737427]\n"," [-0.02737427]\n"," [-0.02008057]\n"," ...\n"," [ 0.10220337]\n"," [ 0.12225342]\n"," [ 0.13504028]], shape=(42316, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02737427 -0.02737427 -0.02008057 ...  0.10220337  0.12225342\n","  0.13504028], shape=(42316,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01480103]\n"," [-0.02096558]\n"," [-0.0246582 ]\n"," ...\n"," [-0.00863647]\n"," [-0.00738525]\n"," [-0.00616455]], shape=(58438, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01480103 -0.02096558 -0.0246582  ... -0.00863647 -0.00738525\n"," -0.00616455], shape=(58438,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13943481]\n"," [-0.13943481]\n"," [-0.13943481]\n"," ...\n"," [ 0.06317139]\n"," [-0.06317139]\n"," [-0.2026062 ]], shape=(59716, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13943481 -0.13943481 -0.13943481 ...  0.06317139 -0.06317139\n"," -0.2026062 ], shape=(59716,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01242065]\n"," [-0.01242065]\n"," [-0.01553345]\n"," ...\n"," [ 0.        ]\n"," [-0.00311279]\n"," [-0.00311279]], shape=(53794, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01242065 -0.01242065 -0.01553345 ...  0.         -0.00311279\n"," -0.00311279], shape=(53794,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03866577]\n"," [-0.00552368]\n"," [-0.04418945]\n"," ...\n"," [-0.03314209]\n"," [-0.03866577]\n"," [-0.04144287]], shape=(24224, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03866577 -0.00552368 -0.04418945 ... -0.03314209 -0.03866577\n"," -0.04144287], shape=(24224,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00808716]\n"," [ 0.00646973]\n"," [ 0.00161743]\n"," ...\n"," [-0.25039673]\n"," [-0.2164917 ]\n"," [-0.16799927]], shape=(90350, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00808716  0.00646973  0.00161743 ... -0.25039673 -0.2164917\n"," -0.16799927], shape=(90350,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02249146]\n"," [-0.02624512]\n"," [-0.03125   ]\n"," ...\n"," [ 0.01501465]\n"," [ 0.01251221]\n"," [ 0.00750732]], shape=(27330, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02249146 -0.02624512 -0.03125    ...  0.01501465  0.01251221\n","  0.00750732], shape=(27330,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03570557]\n"," [-0.04284668]\n"," [-0.04284668]\n"," ...\n"," [-0.1499939 ]\n"," [-0.14285278]\n"," [-0.12142944]], shape=(24438, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03570557 -0.04284668 -0.04284668 ... -0.1499939  -0.14285278\n"," -0.12142944], shape=(24438,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14624023]\n"," [-0.13000488]\n"," [-0.10876465]\n"," ...\n"," [-0.03125   ]\n"," [-0.03625488]\n"," [-0.04000854]], shape=(57272, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14624023 -0.13000488 -0.10876465 ... -0.03125    -0.03625488\n"," -0.04000854], shape=(57272,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00985718]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00985718]\n"," [-0.00985718]\n"," [-0.01477051]], shape=(57100, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00985718  0.          0.         ... -0.00985718 -0.00985718\n"," -0.01477051], shape=(57100,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01190186]\n"," [-0.01544189]\n"," [-0.04016113]\n"," ...\n"," [ 0.0055542 ]\n"," [-0.00073242]\n"," [-0.00149536]], shape=(45634, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01190186 -0.01544189 -0.04016113 ...  0.0055542  -0.00073242\n"," -0.00149536], shape=(45634,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00970459]\n"," [-0.00970459]\n"," [-0.00750732]\n"," ...\n"," [-0.00970459]\n"," [-0.00970459]\n"," [-0.00970459]], shape=(46020, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00970459 -0.00970459 -0.00750732 ... -0.00970459 -0.00970459\n"," -0.00970459], shape=(46020,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.15625]\n"," [0.15625]\n"," [0.15625]\n"," ...\n"," [0.0625 ]\n"," [0.0625 ]\n"," [0.0625 ]], shape=(51518, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.15625 0.15625 0.15625 ... 0.0625  0.0625  0.0625 ], shape=(51518,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01623535]\n"," [ 0.03250122]\n"," [ 0.04501343]\n"," ...\n"," [-0.01376343]\n"," [-0.01251221]\n"," [-0.01251221]], shape=(65206, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01623535  0.03250122  0.04501343 ... -0.01376343 -0.01251221\n"," -0.01251221], shape=(65206,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.01315308]\n"," ...\n"," [-0.02630615]\n"," [-0.03945923]\n"," [-0.03945923]], shape=(49822, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.01315308 ... -0.02630615 -0.03945923\n"," -0.03945923], shape=(49822,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00085449]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01901245]\n"," [-0.01901245]\n"," [-0.01901245]], shape=(35234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00085449  0.          0.         ... -0.01901245 -0.01901245\n"," -0.01901245], shape=(35234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04272461]\n"," [-0.02764893]\n"," [-0.01882935]\n"," ...\n"," [-0.00628662]\n"," [-0.00878906]\n"," [-0.00628662]], shape=(29902, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04272461 -0.02764893 -0.01882935 ... -0.00628662 -0.00878906\n"," -0.00628662], shape=(29902,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01019287]\n"," [-0.00765991]\n"," [-0.00256348]\n"," ...\n"," [-0.01019287]\n"," [-0.01019287]\n"," [-0.01275635]], shape=(55994, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01019287 -0.00765991 -0.00256348 ... -0.01019287 -0.01019287\n"," -0.01275635], shape=(55994,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00372314]\n"," [0.01281738]\n"," [0.02682495]\n"," ...\n"," [0.00924683]\n"," [0.00515747]\n"," [0.00296021]], shape=(44508, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00372314 0.01281738 0.02682495 ... 0.00924683 0.00515747 0.00296021], shape=(44508,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04971313]\n"," [-0.05264282]\n"," [-0.04678345]\n"," ...\n"," [-0.04678345]\n"," [-0.04678345]\n"," [-0.04678345]], shape=(38626, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04971313 -0.05264282 -0.04678345 ... -0.04678345 -0.04678345\n"," -0.04678345], shape=(38626,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07781982]\n"," [-0.06915283]\n"," [-0.06051636]\n"," ...\n"," [-0.01153564]\n"," [-0.01153564]\n"," [-0.01153564]], shape=(65044, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07781982 -0.06915283 -0.06051636 ... -0.01153564 -0.01153564\n"," -0.01153564], shape=(65044,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.32019043]\n"," [ 0.37930298]\n"," [ 0.44335938]\n"," ...\n"," [-0.15762329]\n"," [-0.16748047]\n"," [-0.15762329]], shape=(49260, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.32019043  0.37930298  0.44335938 ... -0.15762329 -0.16748047\n"," -0.15762329], shape=(49260,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00750732]\n"," [-0.00750732]\n"," ...\n"," [-0.01879883]\n"," [-0.02630615]\n"," [-0.02630615]], shape=(73600, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00750732 -0.00750732 ... -0.01879883 -0.02630615\n"," -0.02630615], shape=(73600,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01895142]\n"," [-0.00189209]\n"," [-0.02560425]\n"," ...\n"," [ 0.00189209]\n"," [ 0.00949097]\n"," [ 0.01138306]], shape=(75244, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01895142 -0.00189209 -0.02560425 ...  0.00189209  0.00949097\n","  0.01138306], shape=(75244,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02371216]\n"," [-0.02920532]\n"," [-0.03649902]\n"," ...\n"," [ 0.02920532]\n"," [ 0.02920532]\n"," [ 0.03103638]], shape=(39630, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02371216 -0.02920532 -0.03649902 ...  0.02920532  0.02920532\n","  0.03103638], shape=(39630,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08200073]\n"," [-0.10531616]\n"," [-0.12600708]\n"," ...\n"," [ 0.00482178]\n"," [ 0.00201416]\n"," [-0.00265503]], shape=(43950, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08200073 -0.10531616 -0.12600708 ...  0.00482178  0.00201416\n"," -0.00265503], shape=(43950,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02703857]\n"," [-0.01931763]\n"," [-0.00772095]\n"," ...\n"," [ 0.01931763]\n"," [ 0.00772095]\n"," [ 0.00772095]], shape=(23538, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02703857 -0.01931763 -0.00772095 ...  0.01931763  0.00772095\n","  0.00772095], shape=(23538,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01586914]\n"," [0.01464844]\n"," [0.01586914]\n"," ...\n"," [0.02075195]\n"," [0.0177002 ]\n"," [0.0213623 ]], shape=(22112, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01586914 0.01464844 0.01586914 ... 0.02075195 0.0177002  0.0213623 ], shape=(22112,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00537109]\n"," [-0.00537109]\n"," ...\n"," [ 0.        ]\n"," [-0.00537109]\n"," [ 0.        ]], shape=(52168, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00537109 -0.00537109 ...  0.         -0.00537109\n","  0.        ], shape=(52168,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0085144 ]\n"," [ 0.00424194]\n"," [ 0.00424194]\n"," ...\n"," [ 0.        ]\n"," [-0.00213623]\n"," [-0.00424194]], shape=(43366, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0085144   0.00424194  0.00424194 ...  0.         -0.00213623\n"," -0.00424194], shape=(43366,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03451538]\n"," [-0.03823853]\n"," [-0.04315186]\n"," ...\n"," [ 0.        ]\n"," [-0.00247192]\n"," [-0.00738525]], shape=(54710, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03451538 -0.03823853 -0.04315186 ...  0.         -0.00247192\n"," -0.00738525], shape=(54710,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01605225]\n"," [-0.01068115]\n"," [-0.00534058]\n"," ...\n"," [-0.00534058]\n"," [-0.01605225]\n"," [-0.02139282]], shape=(31330, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01605225 -0.01068115 -0.00534058 ... -0.00534058 -0.01605225\n"," -0.02139282], shape=(31330,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09060669]\n"," [-0.09060669]\n"," [-0.08053589]\n"," ...\n"," [-0.09060669]\n"," [-0.09060669]\n"," [-0.09060669]], shape=(30534, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09060669 -0.09060669 -0.08053589 ... -0.09060669 -0.09060669\n"," -0.09060669], shape=(30534,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0269165 ]\n"," [-0.02960205]\n"," [-0.0269165 ]\n"," ...\n"," [-0.0269165 ]\n"," [-0.0269165 ]\n"," [-0.02960205]], shape=(18452, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0269165  -0.02960205 -0.0269165  ... -0.0269165  -0.0269165\n"," -0.02960205], shape=(18452,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.09216309]\n"," [0.07849121]\n"," [0.06143188]\n"," ...\n"," [0.02047729]\n"," [0.02047729]\n"," [0.01705933]], shape=(90266, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.09216309 0.07849121 0.06143188 ... 0.02047729 0.02047729 0.01705933], shape=(90266,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03125  ]\n"," [0.0234375]\n"," [0.       ]\n"," ...\n"," [0.0625   ]\n"," [0.0546875]\n"," [0.046875 ]], shape=(92004, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03125   0.0234375 0.        ... 0.0625    0.0546875 0.046875 ], shape=(92004,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.14285278]\n"," [0.        ]\n"," [0.        ]], shape=(73108, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.14285278 0.         0.        ], shape=(73108,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02346802]\n"," [-0.02770996]\n"," [-0.03198242]\n"," ...\n"," [ 0.00213623]\n"," [ 0.        ]\n"," [-0.00427246]], shape=(38922, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02346802 -0.02770996 -0.03198242 ...  0.00213623  0.\n"," -0.00427246], shape=(38922,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03033447]\n"," [-0.02374268]\n"," [-0.01977539]\n"," ...\n"," [ 0.00790405]\n"," [ 0.00131226]\n"," [-0.00131226]], shape=(39802, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03033447 -0.02374268 -0.01977539 ...  0.00790405  0.00131226\n"," -0.00131226], shape=(39802,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01931763]\n"," [-0.00772095]\n"," ...\n"," [-0.00772095]\n"," [-0.02703857]\n"," [-0.01931763]], shape=(37596, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01931763 -0.00772095 ... -0.00772095 -0.02703857\n"," -0.01931763], shape=(37596,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07626343]\n"," [-0.06002808]\n"," [-0.02542114]\n"," ...\n"," [-0.04772949]\n"," [-0.05084229]\n"," [-0.05413818]], shape=(52194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07626343 -0.06002808 -0.02542114 ... -0.04772949 -0.05084229\n"," -0.05413818], shape=(52194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00500488]\n"," [ 0.00500488]\n"," [ 0.00750732]\n"," ...\n"," [-0.08248901]\n"," [-0.07998657]\n"," [-0.07751465]], shape=(76472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00500488  0.00500488  0.00750732 ... -0.08248901 -0.07998657\n"," -0.07751465], shape=(76472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0072937 ]\n"," [ 0.        ]\n"," [ 0.0072937 ]\n"," ...\n"," [-0.01824951]\n"," [-0.01824951]\n"," [-0.01824951]], shape=(47912, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0072937   0.          0.0072937  ... -0.01824951 -0.01824951\n"," -0.01824951], shape=(47912,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.00421143]\n"," ...\n"," [ 0.        ]\n"," [ 0.00421143]\n"," [-0.00421143]], shape=(47232, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.00421143 ...  0.          0.00421143\n"," -0.00421143], shape=(47232,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09024048]\n"," [-0.08535767]\n"," [-0.08291626]\n"," ...\n"," [-0.0512085 ]\n"," [-0.06341553]\n"," [-0.06829834]], shape=(41316, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09024048 -0.08535767 -0.08291626 ... -0.0512085  -0.06341553\n"," -0.06829834], shape=(41316,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04568481]\n"," [0.04315186]\n"," [0.0329895 ]\n"," ...\n"," [0.        ]\n"," [0.00253296]\n"," [0.00253296]], shape=(20944, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04568481 0.04315186 0.0329895  ... 0.         0.00253296 0.00253296], shape=(20944,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00772095]\n"," [ 0.00772095]\n"," ...\n"," [ 0.        ]\n"," [-0.00772095]\n"," [ 0.00772095]], shape=(41000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00772095  0.00772095 ...  0.         -0.00772095\n","  0.00772095], shape=(41000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03903198]\n"," [-0.03903198]\n"," [-0.03903198]\n"," ...\n"," [-0.02960205]\n"," [-0.0269165 ]\n"," [-0.02960205]], shape=(100446, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03903198 -0.03903198 -0.03903198 ... -0.02960205 -0.0269165\n"," -0.02960205], shape=(100446,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16622925]\n"," [-0.15325928]\n"," [-0.11947632]\n"," ...\n"," [-0.02337646]\n"," [-0.02597046]\n"," [-0.02597046]], shape=(41302, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16622925 -0.15325928 -0.11947632 ... -0.02337646 -0.02597046\n"," -0.02597046], shape=(41302,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03390503]\n"," [ 0.00674438]\n"," [-0.01693726]\n"," ...\n"," [-0.09735107]\n"," [-0.0932312 ]\n"," [-0.08364868]], shape=(51912, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03390503  0.00674438 -0.01693726 ... -0.09735107 -0.0932312\n"," -0.08364868], shape=(51912,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01153564]\n"," [ 0.01153564]\n"," [ 0.01730347]\n"," ...\n"," [-0.03170776]\n"," [-0.02880859]\n"," [-0.02593994]], shape=(48336, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01153564  0.01153564  0.01730347 ... -0.03170776 -0.02880859\n"," -0.02593994], shape=(48336,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.14285278]\n"," [-0.14285278]\n"," ...\n"," [ 0.14285278]\n"," [ 0.14285278]\n"," [-0.28570557]], shape=(59234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.14285278 -0.14285278 ...  0.14285278  0.14285278\n"," -0.28570557], shape=(59234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01141357]\n"," [ 0.01333618]\n"," [ 0.00952148]\n"," ...\n"," [-0.01904297]\n"," [-0.00952148]\n"," [ 0.0038147 ]], shape=(55674, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01141357  0.01333618  0.00952148 ... -0.01904297 -0.00952148\n","  0.0038147 ], shape=(55674,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06140137]\n"," [-0.06433105]\n"," [-0.06140137]\n"," ...\n"," [-0.06726074]\n"," [-0.06433105]\n"," [-0.06433105]], shape=(30220, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06140137 -0.06433105 -0.06140137 ... -0.06726074 -0.06433105\n"," -0.06433105], shape=(30220,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14050293]\n"," [-0.09640503]\n"," [-0.05508423]\n"," ...\n"," [ 0.1873169 ]\n"," [ 0.17907715]\n"," [ 0.15701294]], shape=(23332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14050293 -0.09640503 -0.05508423 ...  0.1873169   0.17907715\n","  0.15701294], shape=(23332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.283844  ]\n"," [-0.283844  ]\n"," [-0.283844  ]\n"," ...\n"," [-0.14025879]\n"," [-0.14190674]\n"," [-0.14300537]], shape=(45704, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.283844   -0.283844   -0.283844   ... -0.14025879 -0.14190674\n"," -0.14300537], shape=(45704,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02575684]\n"," [ 0.02133179]\n"," [ 0.01617432]\n"," ...\n"," [-0.17514038]\n"," [-0.17218018]\n"," [-0.1670227 ]], shape=(34424, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02575684  0.02133179  0.01617432 ... -0.17514038 -0.17218018\n"," -0.1670227 ], shape=(34424,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07781982]\n"," [-0.07296753]\n"," [-0.07104492]\n"," ...\n"," [-0.1769104 ]\n"," [-0.18173218]\n"," [-0.18511963]], shape=(42318, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07781982 -0.07296753 -0.07104492 ... -0.1769104  -0.18173218\n"," -0.18511963], shape=(42318,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02645874]\n"," [-0.01586914]\n"," [-0.0105896 ]\n"," ...\n"," [ 0.        ]\n"," [-0.0105896 ]\n"," [-0.00527954]], shape=(36710, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02645874 -0.01586914 -0.0105896  ...  0.         -0.0105896\n"," -0.00527954], shape=(36710,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00897217]\n"," [0.00753784]\n"," [0.00695801]], shape=(29940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00897217 0.00753784 0.00695801], shape=(29940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01669312]\n"," [-0.01528931]\n"," [-0.01391602]\n"," ...\n"," [-0.0083313 ]\n"," [-0.00695801]\n"," [ 0.        ]], shape=(31182, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01669312 -0.01528931 -0.01391602 ... -0.0083313  -0.00695801\n","  0.        ], shape=(31182,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00244141]\n"," [-0.00244141]\n"," [-0.00491333]\n"," ...\n"," [ 0.03186035]\n"," [ 0.02694702]\n"," [ 0.03677368]], shape=(81562, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00244141 -0.00244141 -0.00491333 ...  0.03186035  0.02694702\n","  0.03677368], shape=(81562,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01748657]\n"," [ 0.02874756]\n"," [ 0.03875732]\n"," ...\n"," [-0.00250244]\n"," [ 0.        ]\n"," [ 0.00125122]], shape=(30038, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01748657  0.02874756  0.03875732 ... -0.00250244  0.\n","  0.00125122], shape=(30038,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06594849]\n"," [-0.05105591]\n"," [-0.03829956]\n"," ...\n"," [-0.03616333]\n"," [-0.03616333]\n"," [-0.03616333]], shape=(37538, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06594849 -0.05105591 -0.03829956 ... -0.03616333 -0.03616333\n"," -0.03616333], shape=(37538,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03729248]\n"," [ 0.02850342]\n"," [ 0.01095581]\n"," ...\n"," [-0.02850342]\n"," [-0.00875854]\n"," [ 0.02630615]], shape=(63620, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03729248  0.02850342  0.01095581 ... -0.02850342 -0.00875854\n","  0.02630615], shape=(63620,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.29455566]\n"," [-0.2763672 ]\n"," [-0.24362183]\n"," ...\n"," [-0.05819702]\n"," [-0.05453491]\n"," [-0.06182861]], shape=(36484, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.29455566 -0.2763672  -0.24362183 ... -0.05819702 -0.05453491\n"," -0.06182861], shape=(36484,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02423096]\n"," [-0.02423096]\n"," [-0.03231812]\n"," ...\n"," [ 0.01132202]\n"," [ 0.00970459]\n"," [ 0.01132202]], shape=(61234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02423096 -0.02423096 -0.03231812 ...  0.01132202  0.00970459\n","  0.01132202], shape=(61234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.25302124]\n"," [-0.1807251 ]\n"," [-0.1204834 ]\n"," ...\n"," [-0.02410889]\n"," [-0.02410889]\n"," [-0.02410889]], shape=(52142, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.25302124 -0.1807251  -0.1204834  ... -0.02410889 -0.02410889\n"," -0.02410889], shape=(52142,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0227356 ]\n"," [-0.02728271]\n"," [-0.0227356 ]\n"," ...\n"," [ 0.05453491]\n"," [ 0.04998779]\n"," [ 0.04998779]], shape=(37696, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0227356  -0.02728271 -0.0227356  ...  0.05453491  0.04998779\n","  0.04998779], shape=(37696,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17886353]\n"," [-0.17074585]\n"," [-0.16259766]\n"," ...\n"," [-0.21139526]\n"," [-0.21951294]\n"," [-0.21951294]], shape=(39364, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17886353 -0.17074585 -0.16259766 ... -0.21139526 -0.21951294\n"," -0.21951294], shape=(39364,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00567627]\n"," [ 0.        ]\n"," [-0.02841187]\n"," ...\n"," [-0.01419067]\n"," [-0.01989746]\n"," [-0.03408813]], shape=(35708, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00567627  0.         -0.02841187 ... -0.01419067 -0.01989746\n"," -0.03408813], shape=(35708,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09664917]\n"," [-0.06091309]\n"," [-0.02520752]\n"," ...\n"," [-0.06723022]\n"," [-0.06723022]\n"," [-0.06723022]], shape=(102146, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09664917 -0.06091309 -0.02520752 ... -0.06723022 -0.06723022\n"," -0.06723022], shape=(102146,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00375366]\n"," [-0.0062561 ]\n"," [-0.01376343]\n"," ...\n"," [ 0.05249023]\n"," [ 0.04998779]\n"," [ 0.04626465]], shape=(36772, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00375366 -0.0062561  -0.01376343 ...  0.05249023  0.04998779\n","  0.04626465], shape=(36772,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07894897]\n"," [-0.07019043]\n"," [-0.06726074]\n"," ...\n"," [-0.11697388]\n"," [-0.11404419]\n"," [-0.1111145 ]], shape=(27578, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07894897 -0.07019043 -0.06726074 ... -0.11697388 -0.11404419\n"," -0.1111145 ], shape=(27578,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06115723]\n"," [-0.06115723]\n"," [-0.06115723]\n"," ...\n"," [-0.3597107 ]\n"," [-0.31655884]\n"," [-0.24459839]], shape=(37318, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06115723 -0.06115723 -0.06115723 ... -0.3597107  -0.31655884\n"," -0.24459839], shape=(37318,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11819458]\n"," [-0.1394043 ]\n"," [-0.1666565 ]\n"," ...\n"," [ 0.03637695]\n"," [ 0.03637695]\n"," [ 0.02728271]], shape=(77766, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11819458 -0.1394043  -0.1666565  ...  0.03637695  0.03637695\n","  0.02728271], shape=(77766,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.1000061 ]\n"," [ 0.10626221]\n"," [ 0.1000061 ]\n"," ...\n"," [-0.0062561 ]\n"," [-0.0062561 ]\n"," [-0.0062561 ]], shape=(22666, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.1000061   0.10626221  0.1000061  ... -0.0062561  -0.0062561\n"," -0.0062561 ], shape=(22666,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0065918 ]\n"," [-0.00790405]\n"," [-0.01452637]\n"," ...\n"," [-0.22427368]\n"," [-0.26385498]\n"," [-0.3060608 ]], shape=(26266, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0065918  -0.00790405 -0.01452637 ... -0.22427368 -0.26385498\n"," -0.3060608 ], shape=(26266,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [-0.01193237]\n"," [-0.01791382]\n"," ...\n"," [ 0.01193237]\n"," [ 0.01193237]\n"," [ 0.01791382]], shape=(39754, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145 -0.01193237 -0.01791382 ...  0.01193237  0.01193237\n","  0.01791382], shape=(39754,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00048828]\n"," [-0.00350952]\n"," [-0.0085144 ]\n"," ...\n"," [ 0.01400757]\n"," [ 0.01300049]\n"," [ 0.01000977]], shape=(23430, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00048828 -0.00350952 -0.0085144  ...  0.01400757  0.01300049\n","  0.01000977], shape=(23430,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01376343]\n"," [0.01501465]\n"," [0.01501465]\n"," ...\n"," [0.00750732]\n"," [0.00375366]\n"," [0.        ]], shape=(44144, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01376343 0.01501465 0.01501465 ... 0.00750732 0.00375366 0.        ], shape=(44144,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00750732]\n"," [-0.00650024]\n"," [-0.00601196]\n"," ...\n"," [ 0.08349609]\n"," [ 0.08599854]\n"," [ 0.08898926]], shape=(29064, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00750732 -0.00650024 -0.00601196 ...  0.08349609  0.08599854\n","  0.08898926], shape=(29064,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01229858]\n"," [-0.00616455]\n"," [-0.00308228]\n"," ...\n"," [-0.01229858]\n"," [-0.01229858]\n"," [-0.01229858]], shape=(56354, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01229858 -0.00616455 -0.00308228 ... -0.01229858 -0.01229858\n"," -0.01229858], shape=(56354,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.17340088]\n"," [ 0.16262817]\n"," [ 0.15322876]\n"," ...\n"," [-0.01342773]\n"," [-0.02151489]\n"," [-0.02151489]], shape=(41050, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.17340088  0.16262817  0.15322876 ... -0.01342773 -0.02151489\n"," -0.02151489], shape=(41050,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00500488]\n"," [0.0062561 ]\n"," [0.00750732]\n"," ...\n"," [0.01000977]\n"," [0.01126099]\n"," [0.01126099]], shape=(44152, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00500488 0.0062561  0.00750732 ... 0.01000977 0.01126099 0.01126099], shape=(44152,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02111816]\n"," [-0.01895142]\n"," [-0.01596069]\n"," ...\n"," [-0.01596069]\n"," [-0.01596069]\n"," [-0.01464844]], shape=(32438, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02111816 -0.01895142 -0.01596069 ... -0.01596069 -0.01596069\n"," -0.01464844], shape=(32438,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.10601807]\n"," [ 0.10119629]\n"," [ 0.10119629]\n"," ...\n"," [-0.01687622]\n"," [-0.01205444]\n"," [-0.01205444]], shape=(39880, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.10601807  0.10119629  0.10119629 ... -0.01687622 -0.01205444\n"," -0.01205444], shape=(39880,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00183105]\n"," [0.00390625]\n"," [0.00289917]\n"," ...\n"," [0.21173096]\n"," [0.20678711]\n"," [0.19192505]], shape=(39618, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00183105 0.00390625 0.00289917 ... 0.21173096 0.20678711 0.19192505], shape=(39618,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00384521]\n"," [-0.01153564]\n"," [-0.00961304]\n"," ...\n"," [ 0.02114868]\n"," [ 0.02307129]\n"," [ 0.02883911]], shape=(20936, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00384521 -0.01153564 -0.00961304 ...  0.02114868  0.02307129\n","  0.02883911], shape=(20936,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06362915]\n"," [-0.06668091]\n"," [-0.06970215]\n"," ...\n"," [-0.08483887]\n"," [-0.08483887]\n"," [-0.08483887]], shape=(49938, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06362915 -0.06668091 -0.06970215 ... -0.08483887 -0.08483887\n"," -0.08483887], shape=(49938,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00100708]\n"," [ 0.00048828]\n"," [ 0.00350952]\n"," ...\n"," [-0.01300049]\n"," [-0.01550293]\n"," [-0.01699829]], shape=(31116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00100708  0.00048828  0.00350952 ... -0.01300049 -0.01550293\n"," -0.01699829], shape=(31116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00982666]\n"," [-0.00656128]\n"," [-0.00656128]\n"," ...\n"," [ 0.00326538]\n"," [ 0.00656128]\n"," [ 0.00326538]], shape=(21278, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00982666 -0.00656128 -0.00656128 ...  0.00326538  0.00656128\n","  0.00326538], shape=(21278,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.12173462]\n"," [ 0.12173462]\n"," [ 0.13043213]\n"," ...\n"," [ 0.00869751]\n"," [ 0.        ]\n"," [-0.00869751]], shape=(50464, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.12173462  0.12173462  0.13043213 ...  0.00869751  0.\n"," -0.00869751], shape=(50464,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.10125732]\n"," [ 0.09500122]\n"," [ 0.08248901]\n"," ...\n"," [-0.02749634]\n"," [-0.0375061 ]\n"," [-0.04626465]], shape=(74774, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.10125732  0.09500122  0.08248901 ... -0.02749634 -0.0375061\n"," -0.04626465], shape=(74774,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.21591187]\n"," [ 0.2000122 ]\n"," [ 0.19317627]\n"," ...\n"," [-0.07272339]\n"," [-0.06591797]\n"," [-0.08407593]], shape=(61326, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.21591187  0.2000122   0.19317627 ... -0.07272339 -0.06591797\n"," -0.08407593], shape=(61326,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01470947]\n"," [ 0.00421143]\n"," [ 0.        ]\n"," ...\n"," [-0.06723022]\n"," [-0.06091309]\n"," [-0.05041504]], shape=(35212, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01470947  0.00421143  0.         ... -0.06723022 -0.06091309\n"," -0.05041504], shape=(35212,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.657074  ]\n"," [ 0.65545654]\n"," [ 0.65496826]\n"," ...\n"," [-0.7335205 ]\n"," [-0.7346802 ]\n"," [-0.7345886 ]], shape=(20752, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.657074    0.65545654  0.65496826 ... -0.7335205  -0.7346802\n"," -0.7345886 ], shape=(20752,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07000732]\n"," [-0.07998657]\n"," [-0.04748535]\n"," ...\n"," [-0.1499939 ]\n"," [-0.11749268]\n"," [-0.08499146]], shape=(50608, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07000732 -0.07998657 -0.04748535 ... -0.1499939  -0.11749268\n"," -0.08499146], shape=(50608,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02749634]\n"," [-0.02511597]\n"," [-0.02511597]\n"," ...\n"," [-0.04663086]\n"," [-0.0526123 ]\n"," [-0.05380249]], shape=(28114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02749634 -0.02511597 -0.02511597 ... -0.04663086 -0.0526123\n"," -0.05380249], shape=(28114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00973511]\n"," [0.00973511]\n"," [0.00695801]], shape=(45230, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00973511 0.00973511 0.00695801], shape=(45230,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.02120972]\n"," [-0.01766968]\n"," [-0.00354004]], shape=(25170, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.02120972 -0.01766968\n"," -0.00354004], shape=(25170,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1437378]\n"," [-0.1375122]\n"," [-0.1375122]\n"," ...\n"," [ 0.0249939]\n"," [ 0.0249939]\n"," [ 0.0249939]], shape=(28142, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.1437378 -0.1375122 -0.1375122 ...  0.0249939  0.0249939  0.0249939], shape=(28142,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.0017395 ]\n"," [-0.00518799]\n"," ...\n"," [ 0.00863647]\n"," [ 0.00863647]\n"," [ 0.01034546]], shape=(58764, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.0017395  -0.00518799 ...  0.00863647  0.00863647\n","  0.01034546], shape=(58764,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0149231 ]\n"," [-0.0149231 ]\n"," [-0.02090454]\n"," ...\n"," [-0.00598145]\n"," [-0.00598145]\n"," [ 0.        ]], shape=(56210, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0149231  -0.0149231  -0.02090454 ... -0.00598145 -0.00598145\n","  0.        ], shape=(56210,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02548218]\n"," [-0.02935791]\n"," [-0.03369141]\n"," ...\n"," [-0.00302124]\n"," [-0.00302124]\n"," [-0.00430298]], shape=(39800, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02548218 -0.02935791 -0.03369141 ... -0.00302124 -0.00302124\n"," -0.00430298], shape=(39800,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.00125122]\n"," [ 0.        ]\n"," ...\n"," [-0.00750732]\n"," [-0.00750732]\n"," [-0.0062561 ]], shape=(37308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.00125122  0.         ... -0.00750732 -0.00750732\n"," -0.0062561 ], shape=(37308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00546265]\n"," [-0.00546265]\n"," [-0.01092529]\n"," ...\n"," [-0.01092529]\n"," [-0.01367188]\n"," [-0.01638794]], shape=(65436, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00546265 -0.00546265 -0.01092529 ... -0.01092529 -0.01367188\n"," -0.01638794], shape=(65436,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03726196]\n"," [0.07452393]\n"," [0.11181641]\n"," ...\n"," [0.08694458]\n"," [0.12423706]\n"," [0.14907837]], shape=(60322, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03726196 0.07452393 0.11181641 ... 0.08694458 0.12423706 0.14907837], shape=(60322,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01251221]\n"," [ 0.01251221]\n"," [ 0.01251221]\n"," ...\n"," [-0.3187561 ]\n"," [-0.3187561 ]\n"," [-0.3125    ]], shape=(51862, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01251221  0.01251221  0.01251221 ... -0.3187561  -0.3187561\n"," -0.3125    ], shape=(51862,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04190063]\n"," [-0.02285767]\n"," [-0.0038147 ]\n"," ...\n"," [-0.0038147 ]\n"," [-0.01904297]\n"," [-0.02856445]], shape=(54830, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04190063 -0.02285767 -0.0038147  ... -0.0038147  -0.01904297\n"," -0.02856445], shape=(54830,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [-0.00549316]\n"," [-0.00650024]\n"," ...\n"," [-0.0085144 ]\n"," [-0.00650024]\n"," [-0.00549316]], shape=(37320, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488 -0.00549316 -0.00650024 ... -0.0085144  -0.00650024\n"," -0.00549316], shape=(37320,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03198242]\n"," [-0.04690552]\n"," [-0.05755615]\n"," ...\n"," [-0.0085144 ]\n"," [-0.01065063]\n"," [-0.0085144 ]], shape=(44984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03198242 -0.04690552 -0.05755615 ... -0.0085144  -0.01065063\n"," -0.0085144 ], shape=(44984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00549316]\n"," [-0.03295898]\n"," [-0.02746582]\n"," ...\n"," [-0.01922607]\n"," [-0.03295898]\n"," [-0.01922607]], shape=(52090, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00549316 -0.03295898 -0.02746582 ... -0.01922607 -0.03295898\n"," -0.01922607], shape=(52090,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01385498]\n"," [-0.03805542]\n"," [-0.05883789]\n"," ...\n"," [-0.05535889]\n"," [-0.0519104 ]\n"," [-0.05883789]], shape=(41478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01385498 -0.03805542 -0.05883789 ... -0.05535889 -0.0519104\n"," -0.05883789], shape=(41478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00393677]\n"," [0.00393677]\n"," ...\n"," [0.        ]\n"," [0.00393677]\n"," [0.        ]], shape=(34282, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00393677 0.00393677 ... 0.         0.00393677 0.        ], shape=(34282,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00924683]\n"," [ 0.00924683]\n"," [ 0.00924683]\n"," ...\n"," [-0.06481934]\n"," [-0.06481934]\n"," [-0.06481934]], shape=(66262, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00924683  0.00924683  0.00924683 ... -0.06481934 -0.06481934\n"," -0.06481934], shape=(66262,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01580811]\n"," [0.03509521]\n"," [0.05950928]\n"," ...\n"," [0.01000977]\n"," [0.0062561 ]\n"," [0.00793457]], shape=(129834, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01580811 0.03509521 0.05950928 ... 0.01000977 0.0062561  0.00793457], shape=(129834,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01922607]\n"," [-0.02307129]\n"," [-0.01922607]\n"," ...\n"," [ 0.45385742]\n"," [ 0.48846436]\n"," [ 0.5057678 ]], shape=(48940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01922607 -0.02307129 -0.01922607 ...  0.45385742  0.48846436\n","  0.5057678 ], shape=(48940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [-0.01000977]\n"," [-0.00875854]\n"," ...\n"," [-0.0062561 ]\n"," [-0.00500488]\n"," [-0.00500488]], shape=(36626, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561  -0.01000977 -0.00875854 ... -0.0062561  -0.00500488\n"," -0.00500488], shape=(36626,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04348755]\n"," [0.04348755]\n"," [0.06521606]\n"," ...\n"," [0.05435181]\n"," [0.06521606]\n"," [0.07608032]], shape=(55578, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04348755 0.04348755 0.06521606 ... 0.05435181 0.06521606 0.07608032], shape=(55578,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07562256]\n"," [-0.08047485]\n"," [-0.08047485]\n"," ...\n"," [-0.10244751]\n"," [-0.10974121]\n"," [-0.12194824]], shape=(23360, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07562256 -0.08047485 -0.08047485 ... -0.10244751 -0.10974121\n"," -0.12194824], shape=(23360,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.62979126]\n"," [0.6289673 ]\n"," [0.6281128 ]\n"," ...\n"," [0.17645264]\n"," [0.17727661]\n"," [0.17645264]], shape=(33158, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.62979126 0.6289673  0.6281128  ... 0.17645264 0.17727661 0.17645264], shape=(33158,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0340271 ]\n"," [-0.040802  ]\n"," [-0.04760742]\n"," ...\n"," [-0.040802  ]\n"," [-0.040802  ]\n"," [-0.040802  ]], shape=(37594, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0340271  -0.040802   -0.04760742 ... -0.040802   -0.040802\n"," -0.040802  ], shape=(37594,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03039551]\n"," [ 0.05801392]\n"," [ 0.08010864]\n"," ...\n"," [ 0.0027771 ]\n"," [-0.0027771 ]\n"," [-0.01104736]], shape=(51482, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03039551  0.05801392  0.08010864 ...  0.0027771  -0.0027771\n"," -0.01104736], shape=(51482,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07937622]\n"," [-0.04760742]\n"," [-0.03967285]\n"," ...\n"," [ 0.05554199]\n"," [ 0.07144165]\n"," [ 0.05554199]], shape=(34320, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07937622 -0.04760742 -0.03967285 ...  0.05554199  0.07144165\n","  0.05554199], shape=(34320,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01315308]\n"," [-0.00897217]\n"," [-0.00299072]\n"," ...\n"," [-0.01434326]\n"," [-0.00897217]\n"," [-0.00299072]], shape=(50928, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01315308 -0.00897217 -0.00299072 ... -0.01434326 -0.00897217\n"," -0.00299072], shape=(50928,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1194458 ]\n"," [-0.12368774]\n"," [-0.12789917]\n"," ...\n"," [-0.37313843]\n"," [-0.3824463 ]\n"," [-0.39086914]], shape=(67420, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1194458  -0.12368774 -0.12789917 ... -0.37313843 -0.3824463\n"," -0.39086914], shape=(67420,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04275513]\n"," [-0.03945923]\n"," [-0.02960205]\n"," ...\n"," [-0.03619385]\n"," [-0.02304077]\n"," [-0.01315308]], shape=(36194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04275513 -0.03945923 -0.02960205 ... -0.03619385 -0.02304077\n"," -0.01315308], shape=(36194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.0050354 ]\n"," ...\n"," [-0.03030396]\n"," [ 0.0050354 ]\n"," [ 0.02523804]], shape=(19552, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.0050354  ... -0.03030396  0.0050354\n","  0.02523804], shape=(19552,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00213623]\n"," [ 0.00213623]\n"," [ 0.01275635]\n"," ...\n"," [ 0.00213623]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(43778, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00213623  0.00213623  0.01275635 ...  0.00213623  0.\n","  0.        ], shape=(43778,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00527954]\n"," [-0.00790405]\n"," [-0.01452637]\n"," ...\n"," [-0.04220581]\n"," [-0.04089355]\n"," [-0.03692627]], shape=(52486, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00527954 -0.00790405 -0.01452637 ... -0.04220581 -0.04089355\n"," -0.03692627], shape=(52486,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02346802]\n"," [ 0.02301025]\n"," [ 0.0213623 ]\n"," ...\n"," [-0.09115601]\n"," [-0.08816528]\n"," [-0.08288574]], shape=(32890, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02346802  0.02301025  0.0213623  ... -0.09115601 -0.08816528\n"," -0.08288574], shape=(32890,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.10012817]\n"," [0.10101318]\n"," [0.10101318]\n"," ...\n"," [0.10992432]\n"," [0.10992432]\n"," [0.10992432]], shape=(42162, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.10012817 0.10101318 0.10101318 ... 0.10992432 0.10992432 0.10992432], shape=(42162,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00186157]\n"," [-0.00186157]\n"," [ 0.        ]\n"," ...\n"," [-0.01123047]\n"," [-0.02059937]\n"," [-0.0262146 ]], shape=(56114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00186157 -0.00186157  0.         ... -0.01123047 -0.02059937\n"," -0.0262146 ], shape=(56114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01467896]\n"," [0.01467896]\n"," [0.01812744]\n"," ...\n"," [0.08282471]\n"," [0.08886719]\n"," [0.0871582 ]], shape=(131454, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01467896 0.01467896 0.01812744 ... 0.08282471 0.08886719 0.0871582 ], shape=(131454,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01000977]\n"," [ 0.01098633]\n"," [ 0.01199341]\n"," ...\n"," [-0.03649902]\n"," [-0.03201294]\n"," [-0.02749634]], shape=(65956, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01000977  0.01098633  0.01199341 ... -0.03649902 -0.03201294\n"," -0.02749634], shape=(65956,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12954712]\n"," [-0.11740112]\n"," [-0.10931396]\n"," ...\n"," [-0.08908081]\n"," [-0.09716797]\n"," [-0.09716797]], shape=(43440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12954712 -0.11740112 -0.10931396 ... -0.08908081 -0.09716797\n"," -0.09716797], shape=(43440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08908081]\n"," [-0.08908081]\n"," [-0.08096313]\n"," ...\n"," [-0.12954712]\n"," [-0.1376648 ]\n"," [-0.1376648 ]], shape=(17828, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08908081 -0.08908081 -0.08096313 ... -0.12954712 -0.1376648\n"," -0.1376648 ], shape=(17828,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02047729]\n"," [-0.02923584]\n"," [-0.02923584]\n"," ...\n"," [-0.04971313]\n"," [-0.05847168]\n"," [-0.04385376]], shape=(89814, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02047729 -0.02923584 -0.02923584 ... -0.04971313 -0.05847168\n"," -0.04385376], shape=(89814,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00250244]\n"," [ 0.        ]\n"," ...\n"," [-0.01251221]\n"," [-0.01251221]\n"," [-0.01251221]], shape=(45040, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00250244  0.         ... -0.01251221 -0.01251221\n"," -0.01251221], shape=(45040,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01998901]\n"," [-0.01873779]\n"," [-0.01998901]\n"," ...\n"," [ 0.03250122]\n"," [ 0.03500366]\n"," [ 0.03625488]], shape=(41294, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01998901 -0.01873779 -0.01998901 ...  0.03250122  0.03500366\n","  0.03625488], shape=(41294,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00469971]\n"," [-0.00469971]\n"," [-0.00469971]\n"," ...\n"," [-0.00469971]\n"," [-0.01177979]\n"," [-0.00939941]], shape=(27332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00469971 -0.00469971 -0.00469971 ... -0.00469971 -0.01177979\n"," -0.00939941], shape=(27332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00082397]\n"," [ 0.00723267]\n"," [ 0.00665283]\n"," ...\n"," [ 0.00799561]\n"," [ 0.01473999]\n"," [ 0.02438354]], shape=(25678, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00082397  0.00723267  0.00665283 ...  0.00799561  0.01473999\n","  0.02438354], shape=(25678,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.3888855]\n"," [0.3888855]\n"," [0.3611145]\n"," ...\n"," [0.027771 ]\n"," [0.027771 ]\n"," [0.027771 ]], shape=(32122, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.3888855 0.3888855 0.3611145 ... 0.027771  0.027771  0.027771 ], shape=(32122,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.1534729 ]\n"," [ 0.08416748]\n"," [ 0.01980591]\n"," ...\n"," [-0.04949951]\n"," [-0.06436157]\n"," [-0.08911133]], shape=(24452, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.1534729   0.08416748  0.01980591 ... -0.04949951 -0.06436157\n"," -0.08911133], shape=(24452,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.13278198]\n"," [ 0.06503296]\n"," [-0.0135498 ]\n"," ...\n"," [ 0.0135498 ]\n"," [ 0.01898193]\n"," [ 0.00543213]], shape=(60450, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.13278198  0.06503296 -0.0135498  ...  0.0135498   0.01898193\n","  0.00543213], shape=(60450,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03030396]\n"," [0.03533936]\n"," [0.02523804]\n"," ...\n"," [0.21212769]\n"," [0.2272644 ]\n"," [0.24243164]], shape=(42218, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03030396 0.03533936 0.02523804 ... 0.21212769 0.2272644  0.24243164], shape=(42218,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01461792]\n"," [ 0.        ]\n"," [-0.00585938]\n"," ...\n"," [-0.01461792]\n"," [-0.01461792]\n"," [-0.00585938]], shape=(33156, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01461792  0.         -0.00585938 ... -0.01461792 -0.01461792\n"," -0.00585938], shape=(33156,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1126709 ]\n"," [-0.11972046]\n"," [-0.1126709 ]\n"," ...\n"," [-0.09155273]\n"," [-0.09155273]\n"," [-0.07745361]], shape=(54166, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1126709  -0.11972046 -0.1126709  ... -0.09155273 -0.09155273\n"," -0.07745361], shape=(54166,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00628662]\n"," [-0.00628662]\n"," [-0.00628662]\n"," ...\n"," [-0.01885986]\n"," [-0.01885986]\n"," [-0.01257324]], shape=(42056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00628662 -0.00628662 -0.00628662 ... -0.01885986 -0.01885986\n"," -0.01257324], shape=(42056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00500488]\n"," [ 0.00250244]\n"," [ 0.00375366]\n"," ...\n"," [-0.00500488]\n"," [-0.00375366]\n"," [-0.00125122]], shape=(66428, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00500488  0.00250244  0.00375366 ... -0.00500488 -0.00375366\n"," -0.00125122], shape=(66428,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00762939]\n"," [-0.01071167]\n"," [-0.00942993]\n"," ...\n"," [ 0.06469727]\n"," [ 0.07720947]\n"," [ 0.09332275]], shape=(27418, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00762939 -0.01071167 -0.00942993 ...  0.06469727  0.07720947\n","  0.09332275], shape=(27418,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [-0.00750732]\n"," [-0.01748657]\n"," ...\n"," [-0.00125122]\n"," [-0.0062561 ]\n"," [-0.01376343]], shape=(25048, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244 -0.00750732 -0.01748657 ... -0.00125122 -0.0062561\n"," -0.01376343], shape=(25048,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00735474]\n"," [-0.00735474]\n"," [ 0.        ]\n"," ...\n"," [-0.04043579]\n"," [-0.01837158]\n"," [-0.00366211]], shape=(54526, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00735474 -0.00735474  0.         ... -0.04043579 -0.01837158\n"," -0.00366211], shape=(54526,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06033325]\n"," [-0.06033325]\n"," [-0.06033325]\n"," ...\n"," [-0.09481812]\n"," [-0.06033325]\n"," [-0.02584839]], shape=(27876, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06033325 -0.06033325 -0.06033325 ... -0.09481812 -0.06033325\n"," -0.02584839], shape=(27876,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.0038147 ]\n"," [0.00119019]\n"," [0.0012207 ]], shape=(94016, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.0038147  0.00119019 0.0012207 ], shape=(94016,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02151489]\n"," [-0.02581787]\n"," [-0.0279541 ]\n"," ...\n"," [-0.01074219]\n"," [-0.01074219]\n"," [-0.01504517]], shape=(34388, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02151489 -0.02581787 -0.0279541  ... -0.01074219 -0.01074219\n"," -0.01504517], shape=(34388,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.30056763]\n"," [0.29223633]\n"," [0.2831421 ]\n"," ...\n"," [0.03399658]\n"," [0.03921509]\n"," [0.04489136]], shape=(40076, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.30056763 0.29223633 0.2831421  ... 0.03399658 0.03921509 0.04489136], shape=(40076,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00680542]\n"," [-0.01361084]\n"," [-0.00680542]\n"," ...\n"," [ 0.        ]\n"," [-0.00680542]\n"," [ 0.        ]], shape=(49368, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00680542 -0.01361084 -0.00680542 ...  0.         -0.00680542\n","  0.        ], shape=(49368,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06060791]\n"," [-0.06060791]\n"," [-0.05453491]\n"," ...\n"," [ 0.03030396]\n"," [ 0.03030396]\n"," [ 0.02423096]], shape=(37220, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06060791 -0.06060791 -0.05453491 ...  0.03030396  0.03030396\n","  0.02423096], shape=(37220,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13253784]\n"," [-0.1807251 ]\n"," [-0.22891235]\n"," ...\n"," [-0.07229614]\n"," [-0.0602417 ]\n"," [-0.0602417 ]], shape=(61276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13253784 -0.1807251  -0.22891235 ... -0.07229614 -0.0602417\n"," -0.0602417 ], shape=(61276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00772095]\n"," [-0.02703857]\n"," [-0.01931763]\n"," ...\n"," [ 0.00772095]\n"," [ 0.00772095]\n"," [ 0.        ]], shape=(38280, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00772095 -0.02703857 -0.01931763 ...  0.00772095  0.00772095\n","  0.        ], shape=(38280,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03881836]\n"," [-0.05645752]\n"," [-0.06704712]\n"," ...\n"," [ 0.04000854]\n"," [ 0.03292847]\n"," [ 0.03057861]], shape=(65676, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03881836 -0.05645752 -0.06704712 ...  0.04000854  0.03292847\n","  0.03057861], shape=(65676,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01852417]\n"," [ 0.00924683]\n"," [ 0.        ]\n"," ...\n"," [-0.10183716]\n"," [-0.10183716]\n"," [-0.09259033]], shape=(57452, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01852417  0.00924683  0.         ... -0.10183716 -0.10183716\n"," -0.09259033], shape=(57452,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1720581 ]\n"," [-0.20431519]\n"," [-0.22579956]\n"," ...\n"," [ 0.03494263]\n"," [ 0.03762817]\n"," [ 0.04031372]], shape=(29798, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1720581  -0.20431519 -0.22579956 ...  0.03494263  0.03762817\n","  0.04031372], shape=(29798,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0602417 ]\n"," [-0.0602417 ]\n"," [-0.0602417 ]\n"," ...\n"," [-0.34939575]\n"," [-0.3373413 ]\n"," [-0.3012085 ]], shape=(104556, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0602417  -0.0602417  -0.0602417  ... -0.34939575 -0.3373413\n"," -0.3012085 ], shape=(104556,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09359741]\n"," [-0.08374023]\n"," [-0.07388306]\n"," ...\n"," [-0.00985718]\n"," [-0.00491333]\n"," [-0.00491333]], shape=(21462, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09359741 -0.08374023 -0.07388306 ... -0.00985718 -0.00491333\n"," -0.00491333], shape=(21462,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00650024]\n"," [-0.00549316]\n"," [-0.0045166 ]\n"," ...\n"," [-0.01049805]\n"," [-0.01150513]\n"," [-0.01101685]], shape=(66382, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00650024 -0.00549316 -0.0045166  ... -0.01049805 -0.01150513\n"," -0.01101685], shape=(66382,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00622559]\n"," [-0.00933838]\n"," [-0.00933838]\n"," ...\n"," [ 0.14642334]\n"," [ 0.07165527]\n"," [-0.00311279]], shape=(57140, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00622559 -0.00933838 -0.00933838 ...  0.14642334  0.07165527\n"," -0.00311279], shape=(57140,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0269165 ]\n"," [-0.02960205]\n"," [-0.02960205]\n"," ...\n"," [-0.02288818]\n"," [-0.02020264]\n"," [-0.02288818]], shape=(27398, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0269165  -0.02960205 -0.02960205 ... -0.02288818 -0.02020264\n"," -0.02288818], shape=(27398,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02090454]\n"," [ 0.02984619]\n"," [ 0.03283691]\n"," ...\n"," [-0.01193237]\n"," [-0.00299072]\n"," [-0.00299072]], shape=(20292, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02090454  0.02984619  0.03283691 ... -0.01193237 -0.00299072\n"," -0.00299072], shape=(20292,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06140137]\n"," [ 0.08770752]\n"," [ 0.09429932]\n"," ...\n"," [-0.02194214]\n"," [-0.02194214]\n"," [-0.02410889]], shape=(55764, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06140137  0.08770752  0.09429932 ... -0.02194214 -0.02194214\n"," -0.02410889], shape=(55764,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01065063]\n"," [-0.01065063]\n"," [-0.01065063]\n"," ...\n"," [-0.00628662]\n"," [-0.00912476]\n"," [-0.01196289]], shape=(46136, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01065063 -0.01065063 -0.01065063 ... -0.00628662 -0.00912476\n"," -0.01196289], shape=(46136,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00146484]\n"," [ 0.00292969]\n"," [ 0.00735474]\n"," ...\n"," [-0.00588989]\n"," [-0.00881958]\n"," [-0.01028442]], shape=(23814, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00146484  0.00292969  0.00735474 ... -0.00588989 -0.00881958\n"," -0.01028442], shape=(23814,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02880859]\n"," [ 0.03170776]\n"," [ 0.03170776]\n"," ...\n"," [-0.02880859]\n"," [-0.02880859]\n"," [-0.03457642]], shape=(80558, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02880859  0.03170776  0.03170776 ... -0.02880859 -0.02880859\n"," -0.03457642], shape=(80558,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00213623]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01504517]\n"," [-0.01934814]\n"," [-0.01934814]], shape=(38108, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00213623  0.          0.         ... -0.01504517 -0.01934814\n"," -0.01934814], shape=(38108,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03201294]\n"," [ 0.03250122]\n"," [ 0.03250122]\n"," ...\n"," [-0.00448608]\n"," [-0.00350952]\n"," [-0.00448608]], shape=(41122, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03201294  0.03250122  0.03250122 ... -0.00448608 -0.00350952\n"," -0.00448608], shape=(41122,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02124023]\n"," [-0.02374268]\n"," [-0.02374268]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(24676, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02124023 -0.02374268 -0.02374268 ...  0.          0.\n","  0.        ], shape=(24676,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.07595825]\n"," [0.08859253]\n"," [0.06329346]\n"," ...\n"," [0.08859253]\n"," [0.08859253]\n"," [0.07595825]], shape=(43452, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.07595825 0.08859253 0.06329346 ... 0.08859253 0.08859253 0.07595825], shape=(43452,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15872192]\n"," [-0.18252563]\n"," [-0.21429443]\n"," ...\n"," [ 0.4761963 ]\n"," [ 0.46826172]\n"," [ 0.45239258]], shape=(42086, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15872192 -0.18252563 -0.21429443 ...  0.4761963   0.46826172\n","  0.45239258], shape=(42086,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00881958]\n"," [-0.00881958]\n"," [-0.00881958]\n"," ...\n"," [ 0.01498413]\n"," [ 0.01278687]\n"," [ 0.00970459]], shape=(39864, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00881958 -0.00881958 -0.00881958 ...  0.01498413  0.01278687\n","  0.00970459], shape=(39864,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04272461]\n"," [-0.03390503]\n"," [-0.02511597]\n"," ...\n"," [-0.01507568]\n"," [-0.00878906]\n"," [-0.01257324]], shape=(43234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04272461 -0.03390503 -0.02511597 ... -0.01507568 -0.00878906\n"," -0.01257324], shape=(43234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06829834]\n"," [-0.06829834]\n"," [-0.06829834]\n"," ...\n"," [-0.07562256]\n"," [-0.06829834]\n"," [-0.06585693]], shape=(53498, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06829834 -0.06829834 -0.06829834 ... -0.07562256 -0.06829834\n"," -0.06585693], shape=(53498,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01065063]\n"," [-0.01397705]\n"," [-0.01824951]\n"," ...\n"," [-0.01351929]\n"," [-0.01367188]\n"," [-0.01226807]], shape=(40158, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01065063 -0.01397705 -0.01824951 ... -0.01351929 -0.01367188\n"," -0.01226807], shape=(40158,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.25402832]\n"," [0.25646973]\n"," [0.25891113]\n"," ...\n"," [0.71810913]\n"," [0.6932068 ]\n"," [0.66586304]], shape=(53062, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.25402832 0.25646973 0.25891113 ... 0.71810913 0.6932068  0.66586304], shape=(53062,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03808594]\n"," [-0.04190063]\n"," [-0.03808594]\n"," ...\n"," [-0.09332275]\n"," [-0.08380127]\n"," [-0.07046509]], shape=(51264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03808594 -0.04190063 -0.03808594 ... -0.09332275 -0.08380127\n"," -0.07046509], shape=(51264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00610352]\n"," [-0.00610352]\n"," [-0.00610352]\n"," ...\n"," [ 0.02438354]\n"," [ 0.02438354]\n"," [ 0.02438354]], shape=(32390, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00610352 -0.00610352 -0.00610352 ...  0.02438354  0.02438354\n","  0.02438354], shape=(32390,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.14233398]\n"," [ 0.13504028]\n"," [ 0.12045288]\n"," ...\n"," [ 0.02008057]\n"," [ 0.0072937 ]\n"," [-0.0072937 ]], shape=(48372, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.14233398  0.13504028  0.12045288 ...  0.02008057  0.0072937\n"," -0.0072937 ], shape=(48372,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03762817]\n"," [-0.02688599]\n"," [-0.03762817]\n"," ...\n"," [-0.06451416]\n"," [-0.08065796]\n"," [-0.08065796]], shape=(38544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03762817 -0.02688599 -0.03762817 ... -0.06451416 -0.08065796\n"," -0.08065796], shape=(38544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00125122]\n"," [0.00500488]\n"," [0.00750732]\n"," ...\n"," [0.01623535]\n"," [0.01501465]\n"," [0.01251221]], shape=(62396, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00125122 0.00500488 0.00750732 ... 0.01623535 0.01501465 0.01251221], shape=(62396,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07400513]\n"," [-0.07501221]\n"," [-0.07751465]\n"," ...\n"," [ 0.10150146]\n"," [ 0.10751343]\n"," [ 0.11248779]], shape=(30496, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07400513 -0.07501221 -0.07751465 ...  0.10150146  0.10751343\n","  0.11248779], shape=(30496,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.        ]\n"," [-0.00250244]\n"," ...\n"," [-0.04898071]\n"," [-0.04647827]\n"," [-0.03643799]], shape=(43022, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.         -0.00250244 ... -0.04898071 -0.04647827\n"," -0.03643799], shape=(43022,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01135254]\n"," [-0.01135254]\n"," ...\n"," [-0.0227356 ]\n"," [-0.02728271]\n"," [-0.0227356 ]], shape=(41458, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01135254 -0.01135254 ... -0.0227356  -0.02728271\n"," -0.0227356 ], shape=(41458,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0249939]\n"," [0.03125  ]\n"," [0.03125  ]\n"," ...\n"," [0.0062561]\n"," [0.       ]\n"," [0.0062561]], shape=(48606, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0249939 0.03125   0.03125   ... 0.0062561 0.        0.0062561], shape=(48606,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08587646]\n"," [0.0736084 ]\n"," [0.0736084 ]\n"," ...\n"," [0.24539185]\n"," [0.19018555]\n"," [0.12884521]], shape=(58882, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08587646 0.0736084  0.0736084  ... 0.24539185 0.19018555 0.12884521], shape=(58882,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.31411743]\n"," [-0.3458252 ]\n"," [-0.35159302]\n"," ...\n"," [ 0.01153564]\n"," [ 0.0144043 ]\n"," [ 0.02017212]], shape=(51704, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.31411743 -0.3458252  -0.35159302 ...  0.01153564  0.0144043\n","  0.02017212], shape=(51704,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03048706]\n"," [0.02825928]\n"," [0.02612305]\n"," ...\n"," [0.31362915]\n"," [0.30926514]\n"," [0.3053589 ]], shape=(49824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03048706 0.02825928 0.02612305 ... 0.31362915 0.30926514 0.3053589 ], shape=(49824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00848389]\n"," [ 0.0211792 ]\n"," [ 0.0211792 ]\n"," ...\n"," [ 0.00424194]\n"," [ 0.        ]\n"," [-0.00424194]], shape=(33004, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00848389  0.0211792   0.0211792  ...  0.00424194  0.\n"," -0.00424194], shape=(33004,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05062866]\n"," [ 0.06329346]\n"," [ 0.05062866]\n"," ...\n"," [-0.02532959]\n"," [-0.01266479]\n"," [-0.02532959]], shape=(28890, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05062866  0.06329346  0.05062866 ... -0.02532959 -0.01266479\n"," -0.02532959], shape=(28890,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.0743103 ]\n"," [ 0.14190674]\n"," ...\n"," [-0.06082153]\n"," [-0.04730225]\n"," [-0.06082153]], shape=(53694, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.0743103   0.14190674 ... -0.06082153 -0.04730225\n"," -0.06082153], shape=(53694,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02401733]\n"," [-0.02401733]\n"," [-0.02203369]\n"," ...\n"," [-0.02401733]\n"," [-0.02401733]\n"," [-0.02703857]], shape=(33544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02401733 -0.02401733 -0.02203369 ... -0.02401733 -0.02401733\n"," -0.02703857], shape=(33544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00949097]\n"," [0.00775146]\n"," [0.00430298]\n"," ...\n"," [0.        ]\n"," [0.00085449]\n"," [0.00085449]], shape=(39336, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00949097 0.00775146 0.00430298 ... 0.         0.00085449 0.00085449], shape=(39336,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03762817]\n"," [-0.05957031]\n"," [-0.08151245]\n"," ...\n"," [ 0.01254272]\n"," [-0.01879883]\n"," [-0.04074097]], shape=(39516, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03762817 -0.05957031 -0.08151245 ...  0.01254272 -0.01879883\n"," -0.04074097], shape=(39516,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00448608]\n"," [-0.00549316]\n"," [-0.00650024]\n"," ...\n"," [-0.10400391]\n"," [-0.11300659]\n"," [-0.11700439]], shape=(54474, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00448608 -0.00549316 -0.00650024 ... -0.10400391 -0.11300659\n"," -0.11700439], shape=(54474,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01693726]\n"," [-0.02542114]\n"," [-0.02966309]\n"," ...\n"," [-0.00424194]\n"," [ 0.00424194]\n"," [ 0.00424194]], shape=(50524, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01693726 -0.02542114 -0.02966309 ... -0.00424194  0.00424194\n","  0.00424194], shape=(50524,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09732056]\n"," [-0.14093018]\n"," [-0.16442871]\n"," ...\n"," [-0.07382202]\n"," [-0.07382202]\n"," [-0.08053589]], shape=(37812, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09732056 -0.14093018 -0.16442871 ... -0.07382202 -0.07382202\n"," -0.08053589], shape=(37812,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05984497]\n"," [-0.08303833]\n"," [-0.09829712]\n"," ...\n"," [-0.11355591]\n"," [-0.11416626]\n"," [-0.10195923]], shape=(32914, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05984497 -0.08303833 -0.09829712 ... -0.11355591 -0.11416626\n"," -0.10195923], shape=(32914,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01266479]\n"," [-0.02532959]\n"," [-0.01266479]\n"," ...\n"," [ 0.21517944]\n"," [ 0.20254517]\n"," [ 0.20254517]], shape=(21470, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01266479 -0.02532959 -0.01266479 ...  0.21517944  0.20254517\n","  0.20254517], shape=(21470,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11703491]\n"," [-0.07446289]\n"," [-0.02764893]\n"," ...\n"," [-0.09786987]\n"," [-0.0914917 ]\n"," [-0.07232666]], shape=(36840, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11703491 -0.07446289 -0.02764893 ... -0.09786987 -0.0914917\n"," -0.07232666], shape=(36840,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [ 0.        ]\n"," [-0.0149231 ]\n"," ...\n"," [ 0.00598145]\n"," [ 0.00598145]\n"," [ 0.00598145]], shape=(55380, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145  0.         -0.0149231  ...  0.00598145  0.00598145\n","  0.00598145], shape=(55380,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.     ]\n"," [0.     ]\n"," [0.     ]\n"," ...\n"," [0.21875]\n"," [0.1875 ]\n"," [0.125  ]], shape=(54394, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.      0.      0.      ... 0.21875 0.1875  0.125  ], shape=(54394,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02514648]\n"," [-0.01885986]\n"," [-0.01885986]\n"," ...\n"," [-0.00628662]\n"," [-0.00628662]\n"," [-0.00628662]], shape=(70650, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02514648 -0.01885986 -0.01885986 ... -0.00628662 -0.00628662\n"," -0.00628662], shape=(70650,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01135254]\n"," [-0.00567627]\n"," [-0.00567627]\n"," ...\n"," [ 0.00567627]\n"," [ 0.01135254]\n"," [ 0.00567627]], shape=(30018, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01135254 -0.00567627 -0.00567627 ...  0.00567627  0.01135254\n","  0.00567627], shape=(30018,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18899536]\n"," [-0.19381714]\n"," [-0.19573975]\n"," ...\n"," [ 0.13919067]\n"," [ 0.1430664 ]\n"," [ 0.14498901]], shape=(29790, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18899536 -0.19381714 -0.19573975 ...  0.13919067  0.1430664\n","  0.14498901], shape=(29790,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0163269 ]\n"," [-0.01412964]\n"," [-0.00970459]\n"," ...\n"," [-0.01498413]\n"," [-0.00881958]\n"," [-0.00308228]], shape=(18576, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0163269  -0.01412964 -0.00970459 ... -0.01498413 -0.00881958\n"," -0.00308228], shape=(18576,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.28427124]\n"," [-0.32232666]\n"," [-0.3477173 ]\n"," ...\n"," [ 0.04315186]\n"," [ 0.04568481]\n"," [ 0.04315186]], shape=(72640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.28427124 -0.32232666 -0.3477173  ...  0.04315186  0.04568481\n","  0.04315186], shape=(72640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22763062]\n"," [-0.22763062]\n"," [-0.25204468]\n"," ...\n"," [-0.14633179]\n"," [-0.16259766]\n"," [-0.16259766]], shape=(21678, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22763062 -0.22763062 -0.25204468 ... -0.14633179 -0.16259766\n"," -0.16259766], shape=(21678,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03384399]\n"," [-0.03384399]\n"," [-0.03076172]\n"," ...\n"," [-0.10153198]\n"," [-0.10769653]\n"," [-0.10769653]], shape=(79166, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03384399 -0.03384399 -0.03076172 ... -0.10153198 -0.10769653\n"," -0.10769653], shape=(79166,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.58480835]\n"," [-0.58480835]\n"," [-0.54385376]\n"," ...\n"," [-0.05847168]\n"," [-0.04092407]\n"," [-0.04092407]], shape=(55372, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.58480835 -0.58480835 -0.54385376 ... -0.05847168 -0.04092407\n"," -0.04092407], shape=(55372,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01477051]\n"," [-0.01971436]\n"," [-0.01971436]\n"," ...\n"," [-0.00985718]\n"," [-0.00985718]\n"," [-0.00985718]], shape=(92238, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01477051 -0.01971436 -0.01971436 ... -0.00985718 -0.00985718\n"," -0.00985718], shape=(92238,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00787354]\n"," [-0.00918579]\n"," [-0.00787354]\n"," ...\n"," [-0.01968384]\n"," [-0.01574707]\n"," [-0.0118103 ]], shape=(44362, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00787354 -0.00918579 -0.00787354 ... -0.01968384 -0.01574707\n"," -0.0118103 ], shape=(44362,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.0173645 ]\n"," [-0.01242065]\n"," ...\n"," [-0.04217529]\n"," [-0.03723145]\n"," [-0.02978516]], shape=(21606, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.0173645  -0.01242065 ... -0.04217529 -0.03723145\n"," -0.02978516], shape=(21606,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.7819214 ]\n"," [-0.8039856 ]\n"," [-0.8240967 ]\n"," ...\n"," [-0.09899902]\n"," [-0.09994507]\n"," [-0.10119629]], shape=(23116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.7819214  -0.8039856  -0.8240967  ... -0.09899902 -0.09994507\n"," -0.10119629], shape=(23116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00256348]\n"," [ 0.00515747]\n"," [ 0.00772095]\n"," ...\n"," [ 0.01031494]\n"," [ 0.        ]\n"," [-0.00772095]], shape=(26532, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00256348  0.00515747  0.00772095 ...  0.01031494  0.\n"," -0.00772095], shape=(26532,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01342773]\n"," [ 0.01342773]\n"," [ 0.00805664]\n"," ...\n"," [-0.00268555]\n"," [-0.00268555]\n"," [ 0.        ]], shape=(55880, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01342773  0.01342773  0.00805664 ... -0.00268555 -0.00268555\n","  0.        ], shape=(55880,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0072937 ]\n"," [-0.0072937 ]\n"," [-0.0072937 ]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.00485229]], shape=(53626, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0072937  -0.0072937  -0.0072937  ...  0.          0.\n","  0.00485229], shape=(53626,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05264282]\n"," [-0.05264282]\n"," [-0.05847168]\n"," ...\n"," [-0.12573242]\n"," [-0.12573242]\n"," [-0.1315918 ]], shape=(31728, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05264282 -0.05264282 -0.05847168 ... -0.12573242 -0.12573242\n"," -0.1315918 ], shape=(31728,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.42105103]\n"," [-0.39474487]\n"," [-0.42105103]\n"," ...\n"," [-0.02630615]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(131006, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.42105103 -0.39474487 -0.42105103 ... -0.02630615  0.\n","  0.        ], shape=(131006,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02352905]\n"," [-0.0211792 ]\n"," [-0.02822876]\n"," ...\n"," [-0.01177979]\n"," [-0.00939941]\n"," [-0.00939941]], shape=(29066, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02352905 -0.0211792  -0.02822876 ... -0.01177979 -0.00939941\n"," -0.00939941], shape=(29066,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00918579]\n"," [0.00787354]\n"," [0.00524902]\n"," ...\n"," [0.17584229]\n"," [0.22439575]\n"," [0.25198364]], shape=(54592, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00918579 0.00787354 0.00524902 ... 0.17584229 0.22439575 0.25198364], shape=(54592,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01464844]\n"," [-0.01464844]\n"," [-0.01464844]\n"," ...\n"," [ 0.03665161]\n"," [ 0.0357666 ]\n"," [ 0.03491211]], shape=(74850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01464844 -0.01464844 -0.01464844 ...  0.03665161  0.0357666\n","  0.03491211], shape=(74850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01397705]\n"," [-0.01300049]\n"," [-0.0105896 ]\n"," ...\n"," [-0.01156616]\n"," [-0.0105896 ]\n"," [-0.00964355]], shape=(56978, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01397705 -0.01300049 -0.0105896  ... -0.01156616 -0.0105896\n"," -0.00964355], shape=(56978,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02630615]\n"," [-0.02630615]\n"," [-0.02630615]\n"," ...\n"," [-0.02630615]\n"," [-0.07894897]\n"," [-0.1315918 ]], shape=(41584, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02630615 -0.02630615 -0.02630615 ... -0.02630615 -0.07894897\n"," -0.1315918 ], shape=(41584,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03448486]\n"," [ 0.02508545]\n"," [ 0.00939941]\n"," ...\n"," [-0.01568604]\n"," [-0.02038574]\n"," [-0.01724243]], shape=(54160, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03448486  0.02508545  0.00939941 ... -0.01568604 -0.02038574\n"," -0.01724243], shape=(54160,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12255859]\n"," [-0.125     ]\n"," [-0.12991333]\n"," ...\n"," [-0.25735474]\n"," [-0.25979614]\n"," [-0.24020386]], shape=(50168, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12255859 -0.125      -0.12991333 ... -0.25735474 -0.25979614\n"," -0.24020386], shape=(50168,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05377197]\n"," [ 0.04840088]\n"," [ 0.04840088]\n"," ...\n"," [-0.00537109]\n"," [-0.00537109]\n"," [-0.00537109]], shape=(43536, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05377197  0.04840088  0.04840088 ... -0.00537109 -0.00537109\n"," -0.00537109], shape=(43536,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.08456421]\n"," [ 0.07678223]\n"," [ 0.06817627]\n"," ...\n"," [-0.00344849]\n"," [-0.00344849]\n"," [-0.00344849]], shape=(37284, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.08456421  0.07678223  0.06817627 ... -0.00344849 -0.00344849\n"," -0.00344849], shape=(37284,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08053589]\n"," [-0.08053589]\n"," [-0.09060669]\n"," ...\n"," [-0.09060669]\n"," [-0.09060669]\n"," [-0.08053589]], shape=(59358, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08053589 -0.08053589 -0.09060669 ... -0.09060669 -0.09060669\n"," -0.08053589], shape=(59358,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.444458  ]\n"," [ 0.43649292]\n"," [ 0.40475464]\n"," ...\n"," [-0.10317993]\n"," [-0.10317993]\n"," [-0.08731079]], shape=(42742, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.444458    0.43649292  0.40475464 ... -0.10317993 -0.10317993\n"," -0.08731079], shape=(42742,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1720581 ]\n"," [-0.19891357]\n"," [-0.19891357]\n"," ...\n"," [-0.03762817]\n"," [-0.03762817]\n"," [-0.03762817]], shape=(36904, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1720581  -0.19891357 -0.19891357 ... -0.03762817 -0.03762817\n"," -0.03762817], shape=(36904,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04089355]\n"," [-0.03033447]\n"," [-0.01715088]\n"," ...\n"," [-0.00790405]\n"," [-0.00527954]\n"," [-0.01187134]], shape=(45774, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04089355 -0.03033447 -0.01715088 ... -0.00790405 -0.00527954\n"," -0.01187134], shape=(45774,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00576782]\n"," [-0.00576782]\n"," [-0.01156616]\n"," ...\n"," [ 0.03466797]\n"," [ 0.03756714]\n"," [ 0.04623413]], shape=(53654, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00576782 -0.00576782 -0.01156616 ...  0.03466797  0.03756714\n","  0.04623413], shape=(53654,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01315308]\n"," [-0.01315308]\n"," [-0.01315308]\n"," ...\n"," [ 0.        ]\n"," [-0.00189209]\n"," [-0.00189209]], shape=(94560, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01315308 -0.01315308 -0.01315308 ...  0.         -0.00189209\n"," -0.00189209], shape=(94560,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16259766]\n"," [-0.17074585]\n"," [-0.17074585]\n"," ...\n"," [-0.23577881]\n"," [-0.21951294]\n"," [-0.1951294 ]], shape=(36868, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16259766 -0.17074585 -0.17074585 ... -0.23577881 -0.21951294\n"," -0.1951294 ], shape=(36868,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03738403]\n"," [ 0.07788086]\n"," [ 0.18380737]\n"," ...\n"," [ 0.01245117]\n"," [ 0.01245117]\n"," [ 0.01867676]], shape=(49200, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03738403  0.07788086  0.18380737 ...  0.01245117  0.01245117\n","  0.01867676], shape=(49200,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04968262]\n"," [-0.04968262]\n"," [-0.04348755]\n"," ...\n"," [ 0.01864624]\n"," [ 0.01864624]\n"," [ 0.01242065]], shape=(32886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04968262 -0.04968262 -0.04348755 ...  0.01864624  0.01864624\n","  0.01242065], shape=(32886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01730347]\n"," [ 0.01730347]\n"," [ 0.01730347]\n"," ...\n"," [-0.00384521]\n"," [-0.00192261]\n"," [-0.00192261]], shape=(34166, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01730347  0.01730347  0.01730347 ... -0.00384521 -0.00192261\n"," -0.00192261], shape=(34166,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0612793 ]\n"," [ 0.0612793 ]\n"," [ 0.07519531]\n"," ...\n"," [-0.0557251 ]\n"," [-0.0557251 ]\n"," [-0.04177856]], shape=(37740, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0612793   0.0612793   0.07519531 ... -0.0557251  -0.0557251\n"," -0.04177856], shape=(37740,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12371826]\n"," [-0.11856079]\n"," [-0.12371826]\n"," ...\n"," [ 0.01031494]\n"," [ 0.01031494]\n"," [ 0.00515747]], shape=(29984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12371826 -0.11856079 -0.12371826 ...  0.01031494  0.01031494\n","  0.00515747], shape=(29984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13415527]\n"," [-0.13903809]\n"," [-0.14633179]\n"," ...\n"," [-0.07073975]\n"," [-0.07562256]\n"," [-0.07806396]], shape=(35960, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13415527 -0.13903809 -0.14633179 ... -0.07073975 -0.07562256\n"," -0.07806396], shape=(35960,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00268555]\n"," [ 0.01342773]\n"," [ 0.02688599]\n"," ...\n"," [-0.00268555]\n"," [-0.00268555]\n"," [-0.00537109]], shape=(21846, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00268555  0.01342773  0.02688599 ... -0.00268555 -0.00268555\n"," -0.00537109], shape=(21846,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.49386597]\n"," [0.51330566]\n"," [0.5310364 ]\n"," ...\n"," [0.16378784]\n"," [0.17434692]\n"," [0.18447876]], shape=(203346, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.49386597 0.51330566 0.5310364  ... 0.16378784 0.17434692 0.18447876], shape=(203346,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02856445]\n"," [-0.01904297]\n"," [-0.01333618]\n"," ...\n"," [-0.04190063]\n"," [-0.03808594]\n"," [-0.04190063]], shape=(95688, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02856445 -0.01904297 -0.01333618 ... -0.04190063 -0.03808594\n"," -0.04190063], shape=(95688,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.4456787 ]\n"," [-0.34921265]\n"," [-0.27593994]\n"," ...\n"," [ 0.4963379 ]\n"," [ 0.44628906]\n"," [ 0.3913269 ]], shape=(38858, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.4456787  -0.34921265 -0.27593994 ...  0.4963379   0.44628906\n","  0.3913269 ], shape=(38858,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01000977]\n"," [ 0.01000977]\n"," [ 0.00750732]\n"," ...\n"," [-0.02374268]\n"," [-0.02124023]\n"," [-0.01623535]], shape=(37590, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01000977  0.01000977  0.00750732 ... -0.02374268 -0.02124023\n"," -0.01623535], shape=(37590,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03747559]\n"," [-0.03457642]\n"," [-0.03747559]\n"," ...\n"," [ 0.16427612]\n"," [ 0.12103271]\n"," [ 0.08068848]], shape=(34730, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03747559 -0.03457642 -0.03747559 ...  0.16427612  0.12103271\n","  0.08068848], shape=(34730,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00375366]\n"," [0.0062561 ]\n"," [0.00500488]\n"," ...\n"," [0.0062561 ]\n"," [0.00750732]\n"," [0.00750732]], shape=(30058, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00375366 0.0062561  0.00500488 ... 0.0062561  0.00750732 0.00750732], shape=(30058,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00308228]\n"," [ 0.00616455]\n"," [ 0.01229858]\n"," ...\n"," [ 0.        ]\n"," [-0.00616455]\n"," [-0.00921631]], shape=(75850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00308228  0.00616455  0.01229858 ...  0.         -0.00616455\n"," -0.00921631], shape=(75850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05999756]\n"," [-0.04000854]\n"," [-0.03500366]\n"," ...\n"," [ 0.05999756]\n"," [ 0.02999878]\n"," [ 0.        ]], shape=(21122, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05999756 -0.04000854 -0.03500366 ...  0.05999756  0.02999878\n","  0.        ], shape=(21122,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00900269]\n"," [0.01098633]\n"," [0.01449585]\n"," ...\n"," [0.09451294]\n"," [0.0874939 ]\n"," [0.07901001]], shape=(50266, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00900269 0.01098633 0.01449585 ... 0.09451294 0.0874939  0.07901001], shape=(50266,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0625   ]\n"," [ 0.0687561]\n"," [ 0.0687561]\n"," ...\n"," [-0.1375122]\n"," [-0.1437378]\n"," [-0.1375122]], shape=(72848, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0625     0.0687561  0.0687561 ... -0.1375122 -0.1437378 -0.1375122], shape=(72848,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04571533]\n"," [-0.05142212]\n"," [-0.05523682]\n"," ...\n"," [ 0.01333618]\n"," [ 0.01141357]\n"," [ 0.01333618]], shape=(24566, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04571533 -0.05142212 -0.05523682 ...  0.01333618  0.01141357\n","  0.01333618], shape=(24566,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03601074]\n"," [ 0.04351807]\n"," [ 0.04702759]\n"," ...\n"," [-0.00201416]\n"," [-0.00201416]\n"," [-0.00250244]], shape=(18640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03601074  0.04351807  0.04702759 ... -0.00201416 -0.00201416\n"," -0.00250244], shape=(18640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02639771]\n"," [-0.02243042]\n"," [-0.02374268]\n"," ...\n"," [-0.0461731 ]\n"," [-0.0461731 ]\n"," [-0.04089355]], shape=(45158, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02639771 -0.02243042 -0.02374268 ... -0.0461731  -0.0461731\n"," -0.04089355], shape=(45158,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.]\n"," [0.]\n"," [0.]\n"," ...\n"," [0.]\n"," [0.]\n"," [0.]], shape=(36030, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(36030,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [-0.01251221]\n"," [-0.0062561 ]\n"," ...\n"," [ 0.1625061 ]\n"," [ 0.1499939 ]\n"," [ 0.1499939 ]], shape=(33898, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561  -0.01251221 -0.0062561  ...  0.1625061   0.1499939\n","  0.1499939 ], shape=(33898,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00848389]\n"," [-0.00848389]\n"," [ 0.        ]\n"," ...\n"," [ 0.13134766]\n"," [ 0.11016846]\n"," [ 0.0932312 ]], shape=(50536, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00848389 -0.00848389  0.         ...  0.13134766  0.11016846\n","  0.0932312 ], shape=(50536,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.00250244]\n"," [ 0.00250244]\n"," ...\n"," [-0.00875854]\n"," [-0.00875854]\n"," [-0.01000977]], shape=(36028, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.00250244  0.00250244 ... -0.00875854 -0.00875854\n"," -0.01000977], shape=(36028,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00900269]\n"," [-0.00448608]\n"," [-0.00048828]\n"," ...\n"," [-0.00549316]\n"," [-0.00299072]\n"," [-0.00201416]], shape=(29596, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00900269 -0.00448608 -0.00048828 ... -0.00549316 -0.00299072\n"," -0.00201416], shape=(29596,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08621216]\n"," [-0.06896973]\n"," [-0.06033325]\n"," ...\n"," [-0.12069702]\n"," [-0.12069702]\n"," [-0.11206055]], shape=(42446, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08621216 -0.06896973 -0.06033325 ... -0.12069702 -0.12069702\n"," -0.11206055], shape=(42446,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07116699]\n"," [-0.08462524]\n"," [-0.10769653]\n"," ...\n"," [-0.0249939 ]\n"," [-0.02883911]\n"," [-0.03460693]], shape=(27762, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07116699 -0.08462524 -0.10769653 ... -0.0249939  -0.02883911\n"," -0.03460693], shape=(27762,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02703857]\n"," [-0.02703857]\n"," [-0.02703857]\n"," ...\n"," [ 0.00772095]\n"," [ 0.01931763]\n"," [-0.00772095]], shape=(38942, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02703857 -0.02703857 -0.02703857 ...  0.00772095  0.01931763\n"," -0.00772095], shape=(38942,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00537109]\n"," [ 0.        ]\n"," [ 0.00268555]\n"," ...\n"," [-0.01074219]\n"," [-0.00805664]\n"," [-0.00268555]], shape=(37450, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00537109  0.          0.00268555 ... -0.01074219 -0.00805664\n"," -0.00268555], shape=(37450,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03466797]\n"," [-0.03756714]\n"," [-0.04336548]\n"," ...\n"," [ 0.        ]\n"," [-0.00289917]\n"," [-0.00576782]], shape=(20630, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03466797 -0.03756714 -0.04336548 ...  0.         -0.00289917\n"," -0.00576782], shape=(20630,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.0015564 ]\n"," [ 0.0022583 ]\n"," ...\n"," [-0.01000977]\n"," [-0.0090332 ]\n"," [-0.00869751]], shape=(56030, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.0015564   0.0022583  ... -0.01000977 -0.0090332\n"," -0.00869751], shape=(56030,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05749512]\n"," [ 0.05706787]\n"," [ 0.05499268]\n"," ...\n"," [-0.5526123 ]\n"," [-0.47750854]\n"," [-0.46572876]], shape=(39124, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05749512  0.05706787  0.05499268 ... -0.5526123  -0.47750854\n"," -0.46572876], shape=(39124,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.16589355]\n"," [ 0.16589355]\n"," [ 0.16503906]\n"," ...\n"," [-0.52890015]\n"," [-0.44448853]\n"," [-0.34655762]], shape=(47872, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.16589355  0.16589355  0.16503906 ... -0.52890015 -0.44448853\n"," -0.34655762], shape=(47872,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01882935]\n"," [-0.0213623 ]\n"," [-0.0218811 ]\n"," ...\n"," [ 0.0005188 ]\n"," [ 0.00100708]\n"," [ 0.0005188 ]], shape=(38918, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01882935 -0.0213623  -0.0218811  ...  0.0005188   0.00100708\n","  0.0005188 ], shape=(38918,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00650024]\n"," [ 0.00650024]\n"," [ 0.00601196]\n"," ...\n"," [-0.00048828]\n"," [-0.00201416]\n"," [-0.00250244]], shape=(86028, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00650024  0.00650024  0.00601196 ... -0.00048828 -0.00201416\n"," -0.00250244], shape=(86028,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02749634]\n"," [-0.04998779]\n"," [-0.06750488]\n"," ...\n"," [-0.00250244]\n"," [ 0.00250244]\n"," [ 0.00250244]], shape=(60138, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02749634 -0.04998779 -0.06750488 ... -0.00250244  0.00250244\n","  0.00250244], shape=(60138,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.0173645 ]\n"," [-0.00497437]\n"," ...\n"," [ 0.02978516]\n"," [ 0.03723145]\n"," [ 0.02978516]], shape=(79424, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.0173645  -0.00497437 ...  0.02978516  0.03723145\n","  0.02978516], shape=(79424,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15237427]\n"," [-0.15237427]\n"," [-0.15237427]\n"," ...\n"," [-0.14285278]\n"," [-0.12380981]\n"," [-0.12380981]], shape=(27714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15237427 -0.15237427 -0.15237427 ... -0.14285278 -0.12380981\n"," -0.12380981], shape=(27714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0065918]\n"," [-0.0032959]\n"," [ 0.       ]\n"," ...\n"," [ 0.       ]\n"," [ 0.       ]\n"," [ 0.0065918]], shape=(34506, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.0065918 -0.0032959  0.        ...  0.         0.         0.0065918], shape=(34506,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00366211]\n"," [-0.00735474]\n"," [-0.01470947]\n"," ...\n"," [-0.00735474]\n"," [-0.01470947]\n"," [-0.01470947]], shape=(31524, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00366211 -0.00735474 -0.01470947 ... -0.00735474 -0.01470947\n"," -0.01470947], shape=(31524,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0269165 ]\n"," [-0.02960205]\n"," [-0.03634644]\n"," ...\n"," [-0.02020264]\n"," [-0.02288818]\n"," [-0.02288818]], shape=(34710, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0269165  -0.02960205 -0.03634644 ... -0.02020264 -0.02288818\n"," -0.02288818], shape=(34710,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00552368]\n"," [ 0.        ]\n"," [ 0.00552368]\n"," ...\n"," [-0.00552368]\n"," [ 0.        ]\n"," [-0.00552368]], shape=(80574, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00552368  0.          0.00552368 ... -0.00552368  0.\n"," -0.00552368], shape=(80574,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.        ]\n"," [-0.00250244]\n"," [-0.00500488]], shape=(31046, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.         -0.00250244\n"," -0.00500488], shape=(31046,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04299927]\n"," [ 0.04641724]\n"," [ 0.05032349]\n"," ...\n"," [-0.16952515]\n"," [-0.17050171]\n"," [-0.17050171]], shape=(43760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04299927  0.04641724  0.05032349 ... -0.16952515 -0.17050171\n"," -0.17050171], shape=(43760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00366211]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.        ]\n"," [ 0.00366211]\n"," [ 0.0072937 ]], shape=(45638, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00366211  0.          0.         ...  0.          0.00366211\n","  0.0072937 ], shape=(45638,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04858398]\n"," [-0.04858398]\n"," [-0.04858398]\n"," ...\n"," [-0.15789795]\n"," [-0.14981079]\n"," [-0.14981079]], shape=(59252, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04858398 -0.04858398 -0.04858398 ... -0.15789795 -0.14981079\n"," -0.14981079], shape=(59252,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01522827]\n"," [ 0.01269531]\n"," [ 0.01269531]\n"," ...\n"," [ 0.00253296]\n"," [-0.00253296]\n"," [-0.00253296]], shape=(61214, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01522827  0.01269531  0.01269531 ...  0.00253296 -0.00253296\n"," -0.00253296], shape=(61214,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.019104  ]\n"," [-0.01324463]\n"," [-0.00735474]\n"," ...\n"," [-0.01028442]\n"," [-0.01324463]\n"," [-0.00881958]], shape=(197984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.019104   -0.01324463 -0.00735474 ... -0.01028442 -0.01324463\n"," -0.00881958], shape=(197984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00790405]\n"," [-0.0085144 ]\n"," [-0.00790405]\n"," ...\n"," [-0.00769043]\n"," [-0.01052856]\n"," [-0.01296997]], shape=(32530, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00790405 -0.0085144  -0.00790405 ... -0.00769043 -0.01052856\n"," -0.01296997], shape=(32530,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18041992]\n"," [-0.17526245]\n"," [-0.14431763]\n"," ...\n"," [-0.05670166]\n"," [-0.03091431]\n"," [ 0.        ]], shape=(26862, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18041992 -0.17526245 -0.14431763 ... -0.05670166 -0.03091431\n","  0.        ], shape=(26862,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-1.        ]\n"," [-1.        ]\n"," [-1.        ]\n"," ...\n"," [ 0.00793457]\n"," [ 0.02319336]\n"," [ 0.03723145]], shape=(33362, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-1.         -1.         -1.         ...  0.00793457  0.02319336\n","  0.03723145], shape=(33362,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03881836]\n"," [ 0.03881836]\n"," [ 0.04776001]\n"," ...\n"," [-0.0925293 ]\n"," [-0.06866455]\n"," [-0.04476929]], shape=(53000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03881836  0.03881836  0.04776001 ... -0.0925293  -0.06866455\n"," -0.04476929], shape=(53000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06439209]\n"," [-0.06439209]\n"," [-0.06439209]\n"," ...\n"," [-0.1022644 ]\n"," [-0.1022644 ]\n"," [-0.10986328]], shape=(47634, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06439209 -0.06439209 -0.06439209 ... -0.1022644  -0.1022644\n"," -0.10986328], shape=(47634,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.00393677]\n"," ...\n"," [0.00393677]\n"," [0.        ]\n"," [0.        ]], shape=(17786, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.00393677 ... 0.00393677 0.         0.        ], shape=(17786,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02893066]\n"," [-0.02893066]\n"," [-0.02893066]\n"," ...\n"," [ 0.        ]\n"," [-0.01205444]\n"," [-0.01205444]], shape=(77540, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02893066 -0.02893066 -0.02893066 ...  0.         -0.01205444\n"," -0.01205444], shape=(77540,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00601196]\n"," [-0.00650024]\n"," [-0.00799561]\n"," ...\n"," [ 0.00799561]\n"," [ 0.00448608]\n"," [-0.00048828]], shape=(33898, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00601196 -0.00650024 -0.00799561 ...  0.00799561  0.00448608\n"," -0.00048828], shape=(33898,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02700806]\n"," [-0.02700806]\n"," [-0.02651978]\n"," ...\n"," [-0.01000977]\n"," [ 0.00750732]\n"," [ 0.02401733]], shape=(70636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02700806 -0.02700806 -0.02651978 ... -0.01000977  0.00750732\n","  0.02401733], shape=(70636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15789795]\n"," [-0.14474487]\n"," [-0.1315918 ]\n"," ...\n"," [-0.01315308]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(31180, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15789795 -0.14474487 -0.1315918  ... -0.01315308  0.\n","  0.        ], shape=(31180,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06970215]\n"," [-0.07879639]\n"," [-0.07879639]\n"," ...\n"," [-0.06362915]\n"," [-0.06060791]\n"," [-0.06060791]], shape=(64128, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06970215 -0.07879639 -0.07879639 ... -0.06362915 -0.06060791\n"," -0.06060791], shape=(64128,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.07519531]\n"," [0.07894897]\n"," [0.08084106]\n"," ...\n"," [0.08270264]\n"," [0.12594604]\n"," [0.15975952]], shape=(47532, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.07519531 0.07894897 0.08084106 ... 0.08270264 0.12594604 0.15975952], shape=(47532,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [-0.00598145]\n"," [-0.00717163]\n"," ...\n"," [-0.02511597]\n"," [-0.02032471]\n"," [-0.0161438 ]], shape=(69516, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145 -0.00598145 -0.00717163 ... -0.02511597 -0.02032471\n"," -0.0161438 ], shape=(69516,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00769043]\n"," [-0.00888062]\n"," [-0.00888062]\n"," ...\n"," [ 0.01184082]\n"," [ 0.01361084]\n"," [ 0.01599121]], shape=(33850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00769043 -0.00888062 -0.00888062 ...  0.01184082  0.01361084\n","  0.01599121], shape=(33850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05264282]\n"," [-0.02630615]\n"," [-0.02630615]\n"," ...\n"," [-0.26315308]\n"," [-0.23684692]\n"," [-0.23684692]], shape=(71290, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05264282 -0.02630615 -0.02630615 ... -0.26315308 -0.23684692\n"," -0.23684692], shape=(71290,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07998657]\n"," [-0.07635498]\n"," [-0.08364868]\n"," ...\n"," [ 0.03271484]\n"," [ 0.01455688]\n"," [ 0.00363159]], shape=(28396, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07998657 -0.07635498 -0.08364868 ...  0.03271484  0.01455688\n","  0.00363159], shape=(28396,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00323486]\n"," [0.        ]\n"," [0.00161743]\n"," ...\n"," [0.19064331]\n"," [0.25524902]\n"," [0.3117981 ]], shape=(57930, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00323486 0.         0.00161743 ... 0.19064331 0.25524902 0.3117981 ], shape=(57930,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00808716]\n"," [-0.00808716]\n"," [-0.02023315]\n"," ...\n"," [-0.02023315]\n"," [-0.02023315]\n"," [-0.02023315]], shape=(33694, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00808716 -0.00808716 -0.02023315 ... -0.02023315 -0.02023315\n"," -0.02023315], shape=(33694,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01367188]\n"," [-0.01394653]\n"," [-0.01367188]\n"," ...\n"," [ 0.01242065]\n"," [ 0.00912476]\n"," [ 0.00305176]], shape=(41468, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01367188 -0.01394653 -0.01367188 ...  0.01242065  0.00912476\n","  0.00305176], shape=(41468,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02639771]\n"," [-0.05276489]\n"," [-0.09365845]\n"," ...\n"," [-0.01977539]\n"," [-0.02111816]\n"," [-0.02111816]], shape=(80514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02639771 -0.05276489 -0.09365845 ... -0.01977539 -0.02111816\n"," -0.02111816], shape=(80514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.19726562]\n"," [ 0.25170898]\n"," [ 0.26531982]\n"," ...\n"," [-0.00680542]\n"," [ 0.        ]\n"," [-0.00680542]], shape=(21086, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.19726562  0.25170898  0.26531982 ... -0.00680542  0.\n"," -0.00680542], shape=(21086,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03051758]\n"," [0.02685547]\n"," [0.02441406]\n"," ...\n"," [0.00305176]\n"," [0.01708984]\n"," [0.02258301]], shape=(33264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03051758 0.02685547 0.02441406 ... 0.00305176 0.01708984 0.02258301], shape=(33264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0390625 ]\n"," [-0.03234863]\n"," [-0.02807617]\n"," ...\n"," [-0.05187988]\n"," [-0.06164551]\n"," [-0.06900024]], shape=(57740, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0390625  -0.03234863 -0.02807617 ... -0.05187988 -0.06164551\n"," -0.06900024], shape=(57740,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14251709]\n"," [-0.1116333 ]\n"," [-0.08346558]\n"," ...\n"," [-0.01391602]\n"," [-0.01504517]\n"," [-0.01635742]], shape=(36244, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14251709 -0.1116333  -0.08346558 ... -0.01391602 -0.01504517\n"," -0.01635742], shape=(36244,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05056763]\n"," [-0.04681396]\n"," [-0.03933716]\n"," ...\n"," [ 0.131073  ]\n"," [ 0.12359619]\n"," [ 0.11422729]], shape=(31668, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05056763 -0.04681396 -0.03933716 ...  0.131073    0.12359619\n","  0.11422729], shape=(31668,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00415039]\n"," [ 0.0071106 ]\n"," [ 0.01184082]\n"," ...\n"," [-0.00238037]\n"," [-0.00119019]\n"," [ 0.00354004]], shape=(57222, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00415039  0.0071106   0.01184082 ... -0.00238037 -0.00119019\n","  0.00354004], shape=(57222,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.3998108 ]\n"," [0.4078369 ]\n"," [0.41625977]\n"," ...\n"," [0.6615906 ]\n"," [0.6604614 ]\n"," [0.6577759 ]], shape=(46102, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.3998108  0.4078369  0.41625977 ... 0.6615906  0.6604614  0.6577759 ], shape=(46102,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02749634]\n"," [0.02249146]\n"," [0.01501465]\n"," ...\n"," [0.00750732]\n"," [0.01251221]\n"," [0.01998901]], shape=(54556, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02749634 0.02249146 0.01501465 ... 0.00750732 0.01251221 0.01998901], shape=(54556,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.06854248]\n"," [ 0.04251099]\n"," [ 0.01751709]\n"," ...\n"," [-0.0255127 ]\n"," [-0.0255127 ]\n"," [-0.02651978]], shape=(33630, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.06854248  0.04251099  0.01751709 ... -0.0255127  -0.0255127\n"," -0.02651978], shape=(33630,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01049805]\n"," [-0.01049805]\n"," ...\n"," [-0.02099609]\n"," [-0.01470947]\n"," [-0.02520752]], shape=(51750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01049805 -0.01049805 ... -0.02099609 -0.01470947\n"," -0.02520752], shape=(51750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00787354]\n"," [-0.00262451]\n"," [ 0.00131226]\n"," ...\n"," [-0.00524902]\n"," [-0.00524902]\n"," [-0.00524902]], shape=(35296, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00787354 -0.00262451  0.00131226 ... -0.00524902 -0.00524902\n"," -0.00524902], shape=(35296,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00714111]\n"," [ 0.01428223]\n"," [ 0.00714111]\n"," ...\n"," [-0.04998779]\n"," [-0.04998779]\n"," [-0.04998779]], shape=(26716, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00714111  0.01428223  0.00714111 ... -0.04998779 -0.04998779\n"," -0.04998779], shape=(26716,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07165527]\n"," [ 0.02984619]\n"," [ 0.08358765]\n"," ...\n"," [ 0.03283691]\n"," [ 0.03881836]\n"," [ 0.04776001]], shape=(44780, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07165527  0.02984619  0.08358765 ...  0.03283691  0.03881836\n","  0.04776001], shape=(44780,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01220703]\n"," [-0.01220703]\n"," [-0.00894165]\n"," ...\n"," [ 0.06671143]\n"," [ 0.06347656]\n"," [ 0.05938721]], shape=(73610, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01220703 -0.01220703 -0.00894165 ...  0.06671143  0.06347656\n","  0.05938721], shape=(73610,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00524902]\n"," [ 0.01321411]\n"," [ 0.02105713]\n"," ...\n"," [-0.00109863]\n"," [ 0.        ]\n"," [ 0.00033569]], shape=(40584, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00524902  0.01321411  0.02105713 ... -0.00109863  0.\n","  0.00033569], shape=(40584,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.17236328]\n"," [ 0.16375732]\n"," [ 0.16375732]\n"," ...\n"," [-0.06903076]\n"," [-0.06903076]\n"," [-0.06903076]], shape=(40734, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.17236328  0.16375732  0.16375732 ... -0.06903076 -0.06903076\n"," -0.06903076], shape=(40734,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06921387]\n"," [-0.06228638]\n"," [-0.06921387]\n"," ...\n"," [-0.05883789]\n"," [-0.06921387]\n"," [-0.07266235]], shape=(48148, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06921387 -0.06228638 -0.06921387 ... -0.05883789 -0.06921387\n"," -0.07266235], shape=(48148,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.28189087]\n"," [-0.24832153]\n"," [-0.22817993]\n"," ...\n"," [-0.18121338]\n"," [-0.16107178]\n"," [-0.18121338]], shape=(65538, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.28189087 -0.24832153 -0.22817993 ... -0.18121338 -0.16107178\n"," -0.18121338], shape=(65538,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00756836]\n"," [-0.00860596]\n"," [-0.00756836]\n"," ...\n"," [-0.01226807]\n"," [-0.01260376]\n"," [-0.01394653]], shape=(29434, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00756836 -0.00860596 -0.00756836 ... -0.01226807 -0.01260376\n"," -0.01394653], shape=(29434,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02438354]\n"," [-0.03048706]\n"," [-0.03048706]\n"," ...\n"," [-0.14025879]\n"," [-0.12194824]\n"," [-0.12194824]], shape=(48578, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02438354 -0.03048706 -0.03048706 ... -0.14025879 -0.12194824\n"," -0.12194824], shape=(48578,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05883789]\n"," [-0.05883789]\n"," [-0.05514526]\n"," ...\n"," [-0.01470947]\n"," [-0.00735474]\n"," [-0.00366211]], shape=(52354, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05883789 -0.05883789 -0.05514526 ... -0.01470947 -0.00735474\n"," -0.00366211], shape=(52354,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01342773]\n"," [-0.00805664]\n"," [-0.00537109]\n"," ...\n"," [ 0.1774292 ]\n"," [ 0.1774292 ]\n"," [ 0.1774292 ]], shape=(53608, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01342773 -0.00805664 -0.00537109 ...  0.1774292   0.1774292\n","  0.1774292 ], shape=(53608,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00219727]\n"," [ 0.00088501]\n"," [-0.00308228]\n"," ...\n"," [-0.01498413]\n"," [-0.01412964]\n"," [-0.01278687]], shape=(39470, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00219727  0.00088501 -0.00308228 ... -0.01498413 -0.01412964\n"," -0.01278687], shape=(39470,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00311279]\n"," [ 0.        ]\n"," ...\n"," [ 0.00311279]\n"," [ 0.00311279]\n"," [ 0.        ]], shape=(50484, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00311279  0.         ...  0.00311279  0.00311279\n","  0.        ], shape=(50484,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00567627]\n"," [0.01135254]\n"," [0.0227356 ]\n"," ...\n"," [0.01135254]\n"," [0.01135254]\n"," [0.01135254]], shape=(32806, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00567627 0.01135254 0.0227356  ... 0.01135254 0.01135254 0.01135254], shape=(32806,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01382446]\n"," [ 0.01934814]\n"," [ 0.01934814]\n"," ...\n"," [-0.06906128]\n"," [-0.08010864]\n"," [-0.09393311]], shape=(27292, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01382446  0.01934814  0.01934814 ... -0.06906128 -0.08010864\n"," -0.09393311], shape=(27292,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01190186]\n"," [-0.01278687]\n"," [-0.01412964]\n"," ...\n"," [ 0.00088501]\n"," [ 0.00219727]\n"," [ 0.00088501]], shape=(38532, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01190186 -0.01278687 -0.01412964 ...  0.00088501  0.00219727\n","  0.00088501], shape=(38532,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03787231]\n"," [-0.02651978]\n"," [-0.02651978]\n"," ...\n"," [-0.1022644 ]\n"," [-0.09091187]\n"," [-0.08334351]], shape=(40054, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03787231 -0.02651978 -0.02651978 ... -0.1022644  -0.09091187\n"," -0.08334351], shape=(40054,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08770752]\n"," [-0.09942627]\n"," [-0.08770752]\n"," ...\n"," [ 0.01168823]\n"," [-0.01168823]\n"," [ 0.        ]], shape=(58032, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08770752 -0.09942627 -0.08770752 ...  0.01168823 -0.01168823\n","  0.        ], shape=(58032,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01153564]\n"," [-0.00576782]\n"," [-0.0144043 ]\n"," ...\n"," [-0.02017212]\n"," [-0.02593994]\n"," [-0.02593994]], shape=(76188, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01153564 -0.00576782 -0.0144043  ... -0.02017212 -0.02593994\n"," -0.02593994], shape=(76188,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07272339]\n"," [-0.07635498]\n"," [-0.07272339]\n"," ...\n"," [-0.06182861]\n"," [-0.06182861]\n"," [-0.06546021]], shape=(48518, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07272339 -0.07635498 -0.07272339 ... -0.06182861 -0.06182861\n"," -0.06546021], shape=(48518,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00500488]\n"," [ 0.00750732]\n"," [ 0.        ]\n"," ...\n"," [-0.00500488]\n"," [-0.01000977]\n"," [-0.01000977]], shape=(37844, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00500488  0.00750732  0.         ... -0.00500488 -0.01000977\n"," -0.01000977], shape=(37844,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02423096]\n"," [-0.04241943]\n"," [-0.04241943]\n"," ...\n"," [ 0.006073  ]\n"," [ 0.006073  ]\n"," [-0.006073  ]], shape=(45302, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02423096 -0.04241943 -0.04241943 ...  0.006073    0.006073\n"," -0.006073  ], shape=(45302,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04348755]\n"," [-0.04968262]\n"," [-0.0559082 ]\n"," ...\n"," [-0.03106689]\n"," [-0.02484131]\n"," [-0.03106689]], shape=(35748, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04348755 -0.04968262 -0.0559082  ... -0.03106689 -0.02484131\n"," -0.03106689], shape=(35748,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05123901]\n"," [-0.05374146]\n"," [-0.05749512]\n"," ...\n"," [ 0.01126099]\n"," [ 0.01000977]\n"," [ 0.01000977]], shape=(73706, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05123901 -0.05374146 -0.05749512 ...  0.01126099  0.01000977\n","  0.01000977], shape=(73706,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00326538]\n"," [0.00326538]\n"," [0.00326538]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.00326538]], shape=(51094, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00326538 0.00326538 0.00326538 ... 0.         0.         0.00326538], shape=(51094,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06433105]\n"," [-0.06726074]\n"," [-0.06433105]\n"," ...\n"," [-0.06726074]\n"," [-0.06433105]\n"," [-0.06433105]], shape=(25892, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06433105 -0.06726074 -0.06433105 ... -0.06726074 -0.06433105\n"," -0.06433105], shape=(25892,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0065918 ]\n"," [-0.01644897]\n"," [-0.02960205]\n"," ...\n"," [-0.10525513]\n"," [-0.10855103]\n"," [-0.11514282]], shape=(34198, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0065918  -0.01644897 -0.02960205 ... -0.10525513 -0.10855103\n"," -0.11514282], shape=(34198,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00274658]\n"," [ 0.        ]\n"," ...\n"," [-0.00274658]\n"," [-0.00274658]\n"," [-0.00274658]], shape=(44858, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00274658  0.         ... -0.00274658 -0.00274658\n"," -0.00274658], shape=(44858,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00192261]\n"," [-0.00192261]\n"," [-0.00384521]\n"," ...\n"," [-0.01730347]\n"," [-0.01922607]\n"," [-0.01345825]], shape=(46250, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00192261 -0.00192261 -0.00384521 ... -0.01730347 -0.01922607\n"," -0.01345825], shape=(46250,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01412964]\n"," [ 0.00939941]\n"," [ 0.00469971]\n"," ...\n"," [-0.0211792 ]\n"," [-0.0211792 ]\n"," [-0.0211792 ]], shape=(47782, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01412964  0.00939941  0.00469971 ... -0.0211792  -0.0211792\n"," -0.0211792 ], shape=(47782,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00262451]\n"," [-0.0065918 ]\n"," [-0.0065918 ]\n"," ...\n"," [-0.01583862]\n"," [-0.00790405]\n"," [-0.00262451]], shape=(65534, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00262451 -0.0065918  -0.0065918  ... -0.01583862 -0.00790405\n"," -0.00262451], shape=(65534,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04760742]\n"," [0.04760742]\n"," [0.03704834]\n"," ...\n"," [0.03173828]\n"," [0.02645874]\n"," [0.03173828]], shape=(70136, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04760742 0.04760742 0.03704834 ... 0.03173828 0.02645874 0.03173828], shape=(70136,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00524902]\n"," [-0.00656128]\n"," [-0.00524902]\n"," ...\n"," [ 0.01574707]\n"," [ 0.01443481]\n"," [ 0.01312256]], shape=(74886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00524902 -0.00656128 -0.00524902 ...  0.01574707  0.01443481\n","  0.01312256], shape=(74886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02770996]\n"," [ 0.01715088]\n"," [-0.00924683]\n"," ...\n"," [-0.01977539]\n"," [-0.02902222]\n"," [-0.03692627]], shape=(53508, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02770996  0.01715088 -0.00924683 ... -0.01977539 -0.02902222\n"," -0.03692627], shape=(53508,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01126099]\n"," [ 0.01501465]\n"," [ 0.01998901]\n"," ...\n"," [-0.02749634]\n"," [-0.02374268]\n"," [-0.01998901]], shape=(63986, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01126099  0.01501465  0.01998901 ... -0.02749634 -0.02374268\n"," -0.01998901], shape=(63986,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00454712]\n"," [-0.01135254]\n"," [-0.00454712]\n"," ...\n"," [-0.18408203]\n"," [-0.17727661]\n"," [-0.16592407]], shape=(43226, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00454712 -0.01135254 -0.00454712 ... -0.18408203 -0.17727661\n"," -0.16592407], shape=(43226,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01306152]\n"," [0.01617432]\n"," [0.02178955]\n"," ...\n"," [0.00714111]\n"," [0.00436401]\n"," [0.00112915]], shape=(48724, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01306152 0.01617432 0.02178955 ... 0.00714111 0.00436401 0.00112915], shape=(48724,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.27142334]\n"," [ 0.27856445]\n"," [ 0.27856445]\n"," ...\n"," [ 0.09286499]\n"," [ 0.02142334]\n"," [-0.05712891]], shape=(38308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.27142334  0.27856445  0.27856445 ...  0.09286499  0.02142334\n"," -0.05712891], shape=(38308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01177979]\n"," [-0.01986694]\n"," [-0.03091431]\n"," ...\n"," [-0.0279541 ]\n"," [-0.02941895]\n"," [-0.02941895]], shape=(21368, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01177979 -0.01986694 -0.03091431 ... -0.0279541  -0.02941895\n"," -0.02941895], shape=(21368,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02297974]\n"," [-0.02297974]\n"," [-0.02297974]\n"," ...\n"," [ 0.03448486]\n"," [ 0.03448486]\n"," [ 0.02874756]], shape=(35182, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02297974 -0.02297974 -0.02297974 ...  0.03448486  0.03448486\n","  0.02874756], shape=(35182,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01568604]\n"," [ 0.0196228 ]\n"," [ 0.0196228 ]\n"," ...\n"," [-0.0196228 ]\n"," [-0.02352905]\n"," [-0.02746582]], shape=(54416, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01568604  0.0196228   0.0196228  ... -0.0196228  -0.02352905\n"," -0.02746582], shape=(54416,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00549316]\n"," [-0.00500488]\n"," [-0.00500488]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.00100708]], shape=(52062, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00549316 -0.00500488 -0.00500488 ...  0.          0.\n","  0.00100708], shape=(52062,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00860596]\n"," [ 0.00430298]\n"," [ 0.01074219]\n"," ...\n"," [-0.02581787]\n"," [-0.02151489]\n"," [-0.01934814]], shape=(49740, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00860596  0.00430298  0.01074219 ... -0.02581787 -0.02151489\n"," -0.01934814], shape=(49740,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10824585]\n"," [-0.10824585]\n"," [-0.10824585]\n"," ...\n"," [-0.11856079]\n"," [-0.11340332]\n"," [-0.11856079]], shape=(55064, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10824585 -0.10824585 -0.10824585 ... -0.11856079 -0.11340332\n"," -0.11856079], shape=(55064,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.     ]\n"," [0.03125]\n"," [0.     ]\n"," ...\n"," [0.     ]\n"," [0.     ]\n"," [0.     ]], shape=(22886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.      0.03125 0.      ... 0.      0.      0.     ], shape=(22886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.60235596]\n"," [ 0.59729004]\n"," [ 0.5900879 ]\n"," ...\n"," [-0.0329895 ]\n"," [-0.03088379]\n"," [-0.02792358]], shape=(46986, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.60235596  0.59729004  0.5900879  ... -0.0329895  -0.03088379\n"," -0.02792358], shape=(46986,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.39678955]\n"," [-0.4022827 ]\n"," [-0.40524292]\n"," ...\n"," [-0.00631714]\n"," [-0.00631714]\n"," [-0.00506592]], shape=(40236, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.39678955 -0.4022827  -0.40524292 ... -0.00631714 -0.00631714\n"," -0.00506592], shape=(40236,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00436401]\n"," [-0.0017395 ]\n"," [-0.00436401]\n"," ...\n"," [ 0.00411987]\n"," [ 0.00869751]\n"," [ 0.01147461]], shape=(48176, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00436401 -0.0017395  -0.00436401 ...  0.00411987  0.00869751\n","  0.01147461], shape=(48176,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00671387]\n"," [-0.00939941]\n"," [-0.01342773]\n"," ...\n"," [-0.00134277]\n"," [ 0.00134277]\n"," [ 0.00537109]], shape=(35218, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00671387 -0.00939941 -0.01342773 ... -0.00134277  0.00134277\n","  0.00537109], shape=(35218,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [-0.00375366]\n"," [-0.00375366]\n"," ...\n"," [ 0.01376343]\n"," [ 0.01501465]\n"," [ 0.01748657]], shape=(50898, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561  -0.00375366 -0.00375366 ...  0.01376343  0.01501465\n","  0.01748657], shape=(50898,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03204346]\n"," [0.01281738]\n"," [0.00640869]\n"," ...\n"," [0.04486084]\n"," [0.03845215]\n"," [0.02563477]], shape=(17982, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03204346 0.01281738 0.00640869 ... 0.04486084 0.03845215 0.02563477], shape=(17982,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00292969]\n"," [ 0.00588989]\n"," [ 0.        ]\n"," ...\n"," [-0.00292969]\n"," [-0.00292969]\n"," [-0.00588989]], shape=(23112, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00292969  0.00588989  0.         ... -0.00292969 -0.00292969\n"," -0.00588989], shape=(23112,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0015564 ]\n"," [ 0.        ]\n"," [ 0.0015564 ]\n"," ...\n"," [ 0.0501709 ]\n"," [ 0.0501709 ]\n"," [ 0.04388428]], shape=(35472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0015564   0.          0.0015564  ...  0.0501709   0.0501709\n","  0.04388428], shape=(35472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04696655]\n"," [-0.04241943]\n"," [-0.03829956]\n"," ...\n"," [ 0.00271606]\n"," [-0.00231934]\n"," [-0.00881958]], shape=(187520, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04696655 -0.04241943 -0.03829956 ...  0.00271606 -0.00231934\n"," -0.00881958], shape=(187520,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03500366]\n"," [ 0.03375244]\n"," [ 0.02874756]\n"," ...\n"," [-0.0625    ]\n"," [-0.07751465]\n"," [-0.09249878]], shape=(43068, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03500366  0.03375244  0.02874756 ... -0.0625     -0.07751465\n"," -0.09249878], shape=(43068,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00134277]\n"," [ 0.00268555]\n"," [ 0.00537109]\n"," ...\n"," [-0.00537109]\n"," [-0.00671387]\n"," [-0.00537109]], shape=(34464, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00134277  0.00268555  0.00537109 ... -0.00537109 -0.00671387\n"," -0.00537109], shape=(34464,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.14144897]\n"," [ 0.125     ]\n"," [ 0.11184692]\n"," ...\n"," [-0.01974487]\n"," [-0.01644897]\n"," [ 0.        ]], shape=(20776, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.14144897  0.125       0.11184692 ... -0.01974487 -0.01644897\n","  0.        ], shape=(20776,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.73635864]\n"," [-0.7366638 ]\n"," [-0.73846436]\n"," ...\n"," [ 0.60324097]\n"," [ 0.62542725]\n"," [ 0.6469116 ]], shape=(20628, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.73635864 -0.7366638  -0.73846436 ...  0.60324097  0.62542725\n","  0.6469116 ], shape=(20628,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06072998]\n"," [-0.06881714]\n"," [-0.08908081]\n"," ...\n"," [-0.00808716]\n"," [-0.02835083]\n"," [-0.00808716]], shape=(38394, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06072998 -0.06881714 -0.08908081 ... -0.00808716 -0.02835083\n"," -0.00808716], shape=(38394,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00875854]\n"," [-0.01126099]\n"," [-0.01376343]\n"," ...\n"," [-0.00875854]\n"," [-0.00875854]\n"," [-0.01000977]], shape=(34958, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00875854 -0.01126099 -0.01376343 ... -0.00875854 -0.00875854\n"," -0.01000977], shape=(34958,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0958252 ]\n"," [0.0958252 ]\n"," [0.0958252 ]\n"," ...\n"," [0.12579346]\n"," [0.12493896]\n"," [0.12368774]], shape=(33844, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0958252  0.0958252  0.0958252  ... 0.12579346 0.12493896 0.12368774], shape=(33844,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02474976]\n"," [0.04190063]\n"," [0.04953003]\n"," ...\n"," [0.04953003]\n"," [0.04953003]\n"," [0.04953003]], shape=(43952, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02474976 0.04190063 0.04953003 ... 0.04953003 0.04953003 0.04953003], shape=(43952,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01351929]\n"," [-0.04052734]\n"," [-0.04052734]\n"," ...\n"," [-0.16217041]\n"," [-0.13513184]\n"," [-0.06082153]], shape=(38400, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01351929 -0.04052734 -0.04052734 ... -0.16217041 -0.13513184\n"," -0.06082153], shape=(38400,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04388428]\n"," [-0.0501709 ]\n"," [-0.05328369]\n"," ...\n"," [ 0.02508545]\n"," [ 0.01568604]\n"," [ 0.00314331]], shape=(23020, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04388428 -0.0501709  -0.05328369 ...  0.02508545  0.01568604\n","  0.00314331], shape=(23020,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.49230957]\n"," [ 0.45962524]\n"," [ 0.40960693]\n"," ...\n"," [-0.05575562]\n"," [-0.07116699]\n"," [-0.08462524]], shape=(61974, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.49230957  0.45962524  0.40960693 ... -0.05575562 -0.07116699\n"," -0.08462524], shape=(61974,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07626343]\n"," [-0.07284546]\n"," [-0.06781006]\n"," ...\n"," [-0.03192139]\n"," [-0.03390503]\n"," [-0.03094482]], shape=(18016, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07626343 -0.07284546 -0.06781006 ... -0.03192139 -0.03390503\n"," -0.03094482], shape=(18016,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.25      ]\n"," [ 0.23999023]\n"," [ 0.2124939 ]\n"," ...\n"," [-0.0375061 ]\n"," [-0.04748535]\n"," [-0.04998779]], shape=(27814, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.25        0.23999023  0.2124939  ... -0.0375061  -0.04748535\n"," -0.04998779], shape=(27814,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06723022]\n"," [-0.0819397 ]\n"," [-0.10293579]\n"," ...\n"," [ 0.00421143]\n"," [ 0.01049805]\n"," [ 0.01470947]], shape=(54052, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06723022 -0.0819397  -0.10293579 ...  0.00421143  0.01049805\n","  0.01470947], shape=(54052,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01724243]\n"," [-0.02297974]\n"," [-0.02297974]\n"," ...\n"," [-0.03448486]\n"," [-0.02874756]\n"," [-0.02874756]], shape=(45600, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01724243 -0.02297974 -0.02297974 ... -0.03448486 -0.02874756\n"," -0.02874756], shape=(45600,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04821777]\n"," [-0.03417969]\n"," [-0.03112793]\n"," ...\n"," [-0.02624512]\n"," [-0.03479004]\n"," [-0.03112793]], shape=(43744, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04821777 -0.03417969 -0.03112793 ... -0.02624512 -0.03479004\n"," -0.03112793], shape=(43744,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01037598]\n"," [-0.01037598]\n"," [-0.02072144]\n"," ...\n"," [ 0.00518799]\n"," [ 0.01037598]\n"," [ 0.01037598]], shape=(32412, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01037598 -0.01037598 -0.02072144 ...  0.00518799  0.01037598\n","  0.01037598], shape=(32412,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00384521]\n"," [ 0.00448608]\n"," [ 0.00448608]\n"," ...\n"," [-0.01281738]\n"," [-0.00961304]\n"," [-0.00640869]], shape=(56972, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00384521  0.00448608  0.00448608 ... -0.01281738 -0.00961304\n"," -0.00640869], shape=(56972,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02359009]\n"," [-0.02359009]\n"," [-0.02359009]\n"," ...\n"," [-0.00942993]\n"," [-0.00473022]\n"," [ 0.        ]], shape=(42304, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02359009 -0.02359009 -0.02359009 ... -0.00942993 -0.00473022\n","  0.        ], shape=(42304,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0562439 ]\n"," [ 0.0562439 ]\n"," [ 0.04376221]\n"," ...\n"," [-0.2062378 ]\n"," [-0.2062378 ]\n"," [-0.2062378 ]], shape=(32174, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0562439   0.0562439   0.04376221 ... -0.2062378  -0.2062378\n"," -0.2062378 ], shape=(32174,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00628662]\n"," [-0.00878906]\n"," [-0.00628662]\n"," ...\n"," [-0.00878906]\n"," [-0.00878906]\n"," [-0.00250244]], shape=(54266, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00628662 -0.00878906 -0.00628662 ... -0.00878906 -0.00878906\n"," -0.00250244], shape=(54266,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04412842]\n"," [0.05636597]\n"," [0.07107544]\n"," ...\n"," [0.07843018]\n"," [0.09313965]\n"," [0.09805298]], shape=(33214, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04412842 0.05636597 0.07107544 ... 0.07843018 0.09313965 0.09805298], shape=(33214,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00311279]\n"," [-0.00311279]\n"," [ 0.        ]\n"," ...\n"," [ 0.00933838]\n"," [ 0.00622559]\n"," [ 0.00933838]], shape=(35306, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00311279 -0.00311279  0.         ...  0.00933838  0.00622559\n","  0.00933838], shape=(35306,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00924683]\n"," [0.00900269]\n"," [0.00012207]\n"," ...\n"," [0.01480103]\n"," [0.01733398]\n"," [0.01681519]], shape=(34466, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00924683 0.00900269 0.00012207 ... 0.01480103 0.01733398 0.01681519], shape=(34466,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01040649]\n"," [0.01040649]\n"," [0.02084351]\n"," ...\n"," [0.10415649]\n"," [0.10415649]\n"," [0.07290649]], shape=(34906, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01040649 0.01040649 0.02084351 ... 0.10415649 0.10415649 0.07290649], shape=(34906,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01098633]\n"," [-0.0062561 ]\n"," [-0.00314331]\n"," ...\n"," [-0.0062561 ]\n"," [-0.00784302]\n"," [-0.01098633]], shape=(68778, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01098633 -0.0062561  -0.00314331 ... -0.0062561  -0.00784302\n"," -0.01098633], shape=(68778,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01315308]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.02630615]\n"," [0.05264282]\n"," [0.0657959 ]], shape=(47762, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01315308 0.         0.         ... 0.02630615 0.05264282 0.0657959 ], shape=(47762,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04434204]\n"," [-0.03762817]\n"," [-0.02822876]\n"," ...\n"," [ 0.00134277]\n"," [ 0.00268555]\n"," [ 0.00268555]], shape=(51066, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04434204 -0.03762817 -0.02822876 ...  0.00134277  0.00268555\n","  0.00268555], shape=(51066,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04202271]\n"," [ 0.04202271]\n"," [ 0.04202271]\n"," ...\n"," [-0.05041504]\n"," [-0.05673218]\n"," [-0.06091309]], shape=(31046, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04202271  0.04202271  0.04202271 ... -0.05041504 -0.05673218\n"," -0.06091309], shape=(31046,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14285278]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.        ]\n"," [-0.14285278]\n"," [-0.14285278]], shape=(71996, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14285278  0.          0.         ...  0.         -0.14285278\n"," -0.14285278], shape=(71996,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.00613403]\n"," ...\n"," [-0.04293823]\n"," [-0.04293823]\n"," [-0.0368042 ]], shape=(48184, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.00613403 ... -0.04293823 -0.04293823\n"," -0.0368042 ], shape=(48184,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05075073]\n"," [-0.12435913]\n"," [-0.18273926]\n"," ...\n"," [ 0.04568481]\n"," [ 0.02792358]\n"," [ 0.01016235]], shape=(41202, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05075073 -0.12435913 -0.18273926 ...  0.04568481  0.02792358\n","  0.01016235], shape=(41202,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00598145]\n"," [ 0.        ]\n"," [-0.0149231 ]\n"," ...\n"," [-0.00598145]\n"," [-0.00598145]\n"," [-0.00598145]], shape=(32466, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00598145  0.         -0.0149231  ... -0.00598145 -0.00598145\n"," -0.00598145], shape=(32466,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00820923]\n"," [ 0.00820923]\n"," [ 0.00820923]\n"," ...\n"," [-0.01638794]\n"," [-0.01638794]\n"," [ 0.        ]], shape=(36994, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00820923  0.00820923  0.00820923 ... -0.01638794 -0.01638794\n","  0.        ], shape=(36994,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02401733]\n"," [-0.02401733]\n"," [-0.02703857]\n"," ...\n"," [ 0.02902222]\n"," [ 0.04605103]\n"," [ 0.06607056]], shape=(67998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02401733 -0.02401733 -0.02703857 ...  0.02902222  0.04605103\n","  0.06607056], shape=(67998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00964355]\n"," [-0.00817871]\n"," [-0.00723267]\n"," ...\n"," [ 0.00576782]\n"," [ 0.00482178]\n"," [ 0.00335693]], shape=(72328, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00964355 -0.00817871 -0.00723267 ...  0.00576782  0.00482178\n","  0.00335693], shape=(72328,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.62979126]\n"," [0.6289673 ]\n"," [0.6281128 ]\n"," ...\n"," [0.08358765]\n"," [0.08358765]\n"," [0.08358765]], shape=(42288, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.62979126 0.6289673  0.6281128  ... 0.08358765 0.08358765 0.08358765], shape=(42288,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0100708 ]\n"," [-0.01119995]\n"," [-0.0100708 ]\n"," ...\n"," [-0.00393677]\n"," [-0.0050354 ]\n"," [-0.00610352]], shape=(44734, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0100708  -0.01119995 -0.0100708  ... -0.00393677 -0.0050354\n"," -0.00610352], shape=(44734,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04501343]\n"," [-0.07501221]\n"," [-0.10501099]\n"," ...\n"," [ 0.05749512]\n"," [ 0.01998901]\n"," [-0.02749634]], shape=(38746, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04501343 -0.07501221 -0.10501099 ...  0.05749512  0.01998901\n"," -0.02749634], shape=(38746,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08706665]\n"," [-0.09176636]\n"," [-0.10116577]\n"," ...\n"," [ 0.00234985]\n"," [ 0.06118774]\n"," [ 0.105896  ]], shape=(26850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08706665 -0.09176636 -0.10116577 ...  0.00234985  0.06118774\n","  0.105896  ], shape=(26850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09091187]\n"," [-0.08334351]\n"," [-0.07574463]\n"," ...\n"," [ 0.00756836]\n"," [ 0.        ]\n"," [ 0.00756836]], shape=(46492, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09091187 -0.08334351 -0.07574463 ...  0.00756836  0.\n","  0.00756836], shape=(46492,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.09286499]\n"," [ 0.09286499]\n"," [ 0.1000061 ]\n"," ...\n"," [-0.02856445]\n"," [-0.02856445]\n"," [-0.02856445]], shape=(58352, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.09286499  0.09286499  0.1000061  ... -0.02856445 -0.02856445\n"," -0.02856445], shape=(58352,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02151489]\n"," [-0.0161438 ]\n"," [-0.01074219]\n"," ...\n"," [ 0.00537109]\n"," [ 0.00537109]\n"," [ 0.01074219]], shape=(34596, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02151489 -0.0161438  -0.01074219 ...  0.00537109  0.00537109\n","  0.01074219], shape=(34596,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00622559]\n"," [-0.00311279]\n"," [-0.00311279]\n"," ...\n"," [-0.00622559]\n"," [-0.00622559]\n"," [-0.00311279]], shape=(97570, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00622559 -0.00311279 -0.00311279 ... -0.00622559 -0.00622559\n"," -0.00311279], shape=(97570,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12231445]\n"," [-0.13308716]\n"," [-0.15109253]\n"," ...\n"," [-0.05395508]\n"," [-0.05395508]\n"," [-0.06115723]], shape=(40476, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12231445 -0.13308716 -0.15109253 ... -0.05395508 -0.05395508\n"," -0.06115723], shape=(40476,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02807617]\n"," [ 0.00765991]\n"," [-0.01275635]\n"," ...\n"," [ 0.04592896]\n"," [ 0.04592896]\n"," [ 0.04592896]], shape=(70516, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02807617  0.00765991 -0.01275635 ...  0.04592896  0.04592896\n","  0.04592896], shape=(70516,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00125122]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.02249146]\n"," [ 0.02249146]\n"," [ 0.02374268]], shape=(42944, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00125122  0.          0.         ...  0.02249146  0.02249146\n","  0.02374268], shape=(42944,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03570557]\n"," [ 0.03152466]\n"," [ 0.01470947]\n"," ...\n"," [-0.01470947]\n"," [-0.00421143]\n"," [-0.02099609]], shape=(52170, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03570557  0.03152466  0.01470947 ... -0.01470947 -0.00421143\n"," -0.02099609], shape=(52170,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11343384]\n"," [-0.10449219]\n"," [-0.09851074]\n"," ...\n"," [ 0.03881836]\n"," [ 0.03881836]\n"," [ 0.03881836]], shape=(29038, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11343384 -0.10449219 -0.09851074 ...  0.03881836  0.03881836\n","  0.03881836], shape=(29038,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00808716]\n"," [-0.00808716]\n"," [-0.00881958]\n"," ...\n"," [-0.00735474]\n"," [-0.01324463]\n"," [-0.01617432]], shape=(93824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00808716 -0.00808716 -0.00881958 ... -0.00735474 -0.01324463\n"," -0.01617432], shape=(93824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00744629]\n"," [0.01486206]\n"," [0.01486206]\n"," ...\n"," [0.02230835]\n"," [0.02230835]\n"," [0.02230835]], shape=(24732, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00744629 0.01486206 0.01486206 ... 0.02230835 0.02230835 0.02230835], shape=(24732,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09231567]\n"," [-0.06768799]\n"," [-0.04614258]\n"," ...\n"," [-0.03076172]\n"," [-0.03384399]\n"," [-0.03384399]], shape=(35984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09231567 -0.06768799 -0.04614258 ... -0.03076172 -0.03384399\n"," -0.03384399], shape=(35984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00942993]\n"," [ 0.        ]\n"," [ 0.00942993]\n"," ...\n"," [-0.00942993]\n"," [-0.00942993]\n"," [-0.01885986]], shape=(37492, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00942993  0.          0.00942993 ... -0.00942993 -0.00942993\n"," -0.01885986], shape=(37492,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00848389]\n"," [-0.00314331]\n"," [ 0.        ]\n"," ...\n"," [ 0.10507202]\n"," [ 0.08474731]\n"," [ 0.05981445]], shape=(39908, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00848389 -0.00314331  0.         ...  0.10507202  0.08474731\n","  0.05981445], shape=(39908,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15188599]\n"," [-0.18988037]\n"," [-0.20254517]\n"," ...\n"," [ 0.08859253]\n"," [ 0.10125732]\n"," [ 0.07595825]], shape=(25904, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15188599 -0.18988037 -0.20254517 ...  0.08859253  0.10125732\n","  0.07595825], shape=(25904,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00289917]\n"," [-0.00289917]\n"," [-0.00576782]\n"," ...\n"," [-0.03466797]\n"," [-0.04336548]\n"," [-0.03756714]], shape=(40092, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00289917 -0.00289917 -0.00576782 ... -0.03466797 -0.04336548\n"," -0.03756714], shape=(40092,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01470947]\n"," [-0.01470947]\n"," [ 0.        ]\n"," ...\n"," [ 0.04620361]\n"," [ 0.05673218]\n"," [ 0.05041504]], shape=(32518, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01470947 -0.01470947  0.         ...  0.04620361  0.05673218\n","  0.05041504], shape=(32518,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0227356 ]\n"," [ 0.0227356 ]\n"," [ 0.0227356 ]\n"," ...\n"," [-0.20907593]\n"," [-0.22271729]\n"," [-0.24090576]], shape=(32112, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0227356   0.0227356   0.0227356  ... -0.20907593 -0.22271729\n"," -0.24090576], shape=(32112,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00250244]\n"," [0.00375366]\n"," [0.00375366]\n"," ...\n"," [0.01623535]\n"," [0.01748657]\n"," [0.01748657]], shape=(20740, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00250244 0.00375366 0.00375366 ... 0.01623535 0.01748657 0.01748657], shape=(20740,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00698853]\n"," [0.        ]\n"," [0.00698853]], shape=(78490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00698853 0.         0.00698853], shape=(78490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00125122]\n"," [0.00375366]\n"," [0.00375366]\n"," ...\n"," [0.00250244]\n"," [0.00250244]\n"," [0.00250244]], shape=(48002, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00125122 0.00375366 0.00375366 ... 0.00250244 0.00250244 0.00250244], shape=(48002,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.02172852]\n"," [-0.03262329]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.01086426]], shape=(45460, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.02172852 -0.03262329 ...  0.          0.\n","  0.01086426], shape=(45460,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18579102]\n"," [-0.18579102]\n"," [-0.19006348]\n"," ...\n"," [-0.2131958 ]\n"," [-0.21575928]\n"," [-0.21575928]], shape=(37042, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18579102 -0.18579102 -0.19006348 ... -0.2131958  -0.21575928\n"," -0.21575928], shape=(37042,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00366211]\n"," [0.00183105]\n"," [0.00183105]\n"," ...\n"," [0.00183105]\n"," [0.0072937 ]\n"," [0.        ]], shape=(22914, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00366211 0.00183105 0.00183105 ... 0.00183105 0.0072937  0.        ], shape=(22914,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00375366]\n"," [-0.00500488]\n"," ...\n"," [ 0.02374268]\n"," [ 0.00250244]\n"," [-0.01873779]], shape=(40158, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00375366 -0.00500488 ...  0.02374268  0.00250244\n"," -0.01873779], shape=(40158,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05831909]\n"," [-0.06121826]\n"," [-0.06121826]\n"," ...\n"," [-0.05831909]\n"," [-0.05831909]\n"," [-0.06414795]], shape=(59658, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05831909 -0.06121826 -0.06121826 ... -0.05831909 -0.05831909\n"," -0.06414795], shape=(59658,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.00656128]\n"," ...\n"," [ 0.02294922]\n"," [ 0.01968384]\n"," [ 0.01638794]], shape=(86456, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.00656128 ...  0.02294922  0.01968384\n","  0.01638794], shape=(86456,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01470947]\n"," [-0.04705811]\n"," [-0.07794189]\n"," ...\n"," [ 0.00881958]\n"," [ 0.00292969]\n"," [-0.00146484]], shape=(39332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01470947 -0.04705811 -0.07794189 ...  0.00881958  0.00292969\n"," -0.00146484], shape=(39332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0144043 ]\n"," [-0.00576782]\n"," [-0.00286865]\n"," ...\n"," [-0.08068848]\n"," [-0.07781982]\n"," [-0.08068848]], shape=(49138, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0144043  -0.00576782 -0.00286865 ... -0.08068848 -0.07781982\n"," -0.08068848], shape=(49138,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00201416]\n"," [-0.00100708]\n"," [-0.00250244]\n"," ...\n"," [ 0.00500488]\n"," [ 0.00549316]\n"," [ 0.00601196]], shape=(19882, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00201416 -0.00100708 -0.00250244 ...  0.00500488  0.00549316\n","  0.00601196], shape=(19882,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.       ]\n"," [0.0005188]\n"," [0.0005188]\n"," ...\n"," [0.       ]\n"," [0.0005188]\n"," [0.0005188]], shape=(47656, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.        0.0005188 0.0005188 ... 0.        0.0005188 0.0005188], shape=(47656,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01568604]\n"," [-0.01254272]\n"," [-0.04074097]\n"," ...\n"," [-0.02508545]\n"," [-0.01568604]\n"," [ 0.        ]], shape=(127194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01568604 -0.01254272 -0.04074097 ... -0.02508545 -0.01568604\n","  0.        ], shape=(127194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00424194]\n"," [-0.00424194]\n"," [-0.00848389]\n"," ...\n"," [-0.11865234]\n"," [-0.06781006]\n"," [-0.00424194]], shape=(26542, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00424194 -0.00424194 -0.00848389 ... -0.11865234 -0.06781006\n"," -0.00424194], shape=(26542,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00219727]\n"," [ 0.        ]\n"," [ 0.00088501]\n"," ...\n"," [-0.00970459]\n"," [-0.0105896 ]\n"," [-0.01190186]], shape=(48568, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00219727  0.          0.00088501 ... -0.00970459 -0.0105896\n"," -0.01190186], shape=(48568,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01812744]\n"," [-0.01812744]\n"," [-0.01724243]\n"," ...\n"," [ 0.00604248]\n"," [ 0.00430298]\n"," [ 0.00085449]], shape=(64812, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01812744 -0.01812744 -0.01724243 ...  0.00604248  0.00430298\n","  0.00085449], shape=(64812,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.11029053]\n"," [ 0.10784912]\n"," [ 0.1053772 ]\n"," ...\n"," [-0.00979614]\n"," [-0.00491333]\n"," [-0.02206421]], shape=(41976, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.11029053  0.10784912  0.1053772  ... -0.00979614 -0.00491333\n"," -0.02206421], shape=(41976,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10699463]\n"," [-0.06600952]\n"," [-0.03201294]\n"," ...\n"," [-0.00650024]\n"," [-0.0085144 ]\n"," [-0.0085144 ]], shape=(55296, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10699463 -0.06600952 -0.03201294 ... -0.00650024 -0.0085144\n"," -0.0085144 ], shape=(55296,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00311279]\n"," [-0.00622559]\n"," [-0.00311279]\n"," ...\n"," [ 0.13354492]\n"," [ 0.17391968]\n"," [ 0.20495605]], shape=(69736, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00311279 -0.00622559 -0.00311279 ...  0.13354492  0.17391968\n","  0.20495605], shape=(69736,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05142212]\n"," [-0.04190063]\n"," [-0.02856445]\n"," ...\n"," [-0.09713745]\n"," [-0.09332275]\n"," [-0.07998657]], shape=(65760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05142212 -0.04190063 -0.02856445 ... -0.09713745 -0.09332275\n"," -0.07998657], shape=(65760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.6388855]\n"," [-0.6388855]\n"," [-0.6388855]\n"," ...\n"," [ 0.       ]\n"," [ 0.027771 ]\n"," [ 0.027771 ]], shape=(77046, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.6388855 -0.6388855 -0.6388855 ...  0.         0.027771   0.027771 ], shape=(77046,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01724243]\n"," [-0.01724243]\n"," [-0.01724243]\n"," ...\n"," [ 0.10345459]\n"," [ 0.13793945]\n"," [ 0.18103027]], shape=(103476, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01724243 -0.01724243 -0.01724243 ...  0.10345459  0.13793945\n","  0.18103027], shape=(103476,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01281738]\n"," [ 0.02563477]\n"," [ 0.00640869]\n"," ...\n"," [-0.09616089]\n"," [-0.07693481]\n"," [-0.06411743]], shape=(61192, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01281738  0.02563477  0.00640869 ... -0.09616089 -0.07693481\n"," -0.06411743], shape=(61192,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04095459]\n"," [ 0.0307312 ]\n"," [ 0.02047729]\n"," ...\n"," [-0.00341797]\n"," [-0.00341797]\n"," [ 0.00341797]], shape=(24984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04095459  0.0307312   0.02047729 ... -0.00341797 -0.00341797\n","  0.00341797], shape=(24984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04165649]\n"," [-0.01040649]\n"," [-0.02084351]\n"," ...\n"," [ 0.125     ]\n"," [ 0.1354065 ]\n"," [ 0.1875    ]], shape=(46122, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04165649 -0.01040649 -0.02084351 ...  0.125       0.1354065\n","  0.1875    ], shape=(46122,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01251221]\n"," [-0.01748657]\n"," [-0.01998901]\n"," ...\n"," [-0.01000977]\n"," [-0.01501465]\n"," [-0.01501465]], shape=(25568, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01251221 -0.01748657 -0.01998901 ... -0.01000977 -0.01501465\n"," -0.01501465], shape=(25568,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06726074]\n"," [-0.06433105]\n"," [-0.06140137]\n"," ...\n"," [-0.04678345]\n"," [-0.04678345]\n"," [-0.04678345]], shape=(44970, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06726074 -0.06433105 -0.06140137 ... -0.04678345 -0.04678345\n"," -0.04678345], shape=(44970,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14633179]\n"," [-0.17074585]\n"," [-0.18902588]\n"," ...\n"," [-0.02438354]\n"," [-0.03048706]\n"," [-0.03048706]], shape=(48360, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14633179 -0.17074585 -0.18902588 ... -0.02438354 -0.03048706\n"," -0.03048706], shape=(48360,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02249146]\n"," [-0.0249939 ]\n"," [-0.02624512]\n"," ...\n"," [-0.00875854]\n"," [-0.00125122]\n"," [ 0.00875854]], shape=(39294, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02249146 -0.0249939  -0.02624512 ... -0.00875854 -0.00125122\n","  0.00875854], shape=(39294,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02120972]\n"," [-0.02474976]\n"," [-0.03533936]\n"," ...\n"," [-0.03179932]\n"," [-0.03179932]\n"," [-0.02474976]], shape=(64520, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02120972 -0.02474976 -0.03533936 ... -0.03179932 -0.03179932\n"," -0.02474976], shape=(64520,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00344849]\n"," [-0.0017395 ]\n"," [-0.0017395 ]\n"," ...\n"," [-0.10009766]\n"," [-0.10095215]\n"," [-0.10009766]], shape=(89576, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00344849 -0.0017395  -0.0017395  ... -0.10009766 -0.10095215\n"," -0.10009766], shape=(89576,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10626221]\n"," [-0.1187439 ]\n"," [-0.12875366]\n"," ...\n"," [ 0.02749634]\n"," [ 0.01998901]\n"," [ 0.01251221]], shape=(46114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10626221 -0.1187439  -0.12875366 ...  0.02749634  0.01998901\n","  0.01251221], shape=(46114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.32791138]\n"," [-0.33047485]\n"," [-0.3347473 ]\n"," ...\n"," [ 0.16351318]\n"," [ 0.16696167]\n"," [ 0.16952515]], shape=(95324, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.32791138 -0.33047485 -0.3347473  ...  0.16351318  0.16696167\n","  0.16952515], shape=(95324,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01275635]\n"," [-0.00765991]\n"," [ 0.        ]\n"," ...\n"," [ 0.02807617]\n"," [ 0.03826904]\n"," [ 0.03570557]], shape=(24144, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01275635 -0.00765991  0.         ...  0.02807617  0.03826904\n","  0.03570557], shape=(24144,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0255127 ]\n"," [-0.01849365]\n"," [-0.01199341]\n"," ...\n"," [-0.00650024]\n"," [-0.00650024]\n"," [-0.00750732]], shape=(23212, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0255127  -0.01849365 -0.01199341 ... -0.00650024 -0.00650024\n"," -0.00750732], shape=(23212,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00744629]\n"," [ 0.        ]\n"," [ 0.00372314]\n"," ...\n"," [ 0.00744629]\n"," [ 0.        ]\n"," [ 0.01486206]], shape=(49226, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00744629  0.          0.00372314 ...  0.00744629  0.\n","  0.01486206], shape=(49226,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00201416]\n"," [0.00250244]\n"," [0.00250244]\n"," ...\n"," [0.00448608]\n"," [0.00448608]\n"," [0.00201416]], shape=(19116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00201416 0.00250244 0.00250244 ... 0.00448608 0.00448608 0.00201416], shape=(19116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.19241333]\n"," [-0.1895752 ]\n"," [-0.1876831 ]\n"," ...\n"," [ 0.00949097]\n"," [ 0.02560425]\n"," [ 0.02749634]], shape=(53422, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.19241333 -0.1895752  -0.1876831  ...  0.00949097  0.02560425\n","  0.02749634], shape=(53422,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06481934]\n"," [-0.06481934]\n"," [-0.05554199]\n"," ...\n"," [-0.027771  ]\n"," [-0.027771  ]\n"," [-0.01852417]], shape=(41356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06481934 -0.06481934 -0.05554199 ... -0.027771   -0.027771\n"," -0.01852417], shape=(41356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.05264282]\n"," [0.02630615]\n"," [0.        ]\n"," ...\n"," [0.02630615]\n"," [0.10525513]\n"," [0.02630615]], shape=(19472, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.05264282 0.02630615 0.         ... 0.02630615 0.10525513 0.02630615], shape=(19472,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00598145]\n"," [ 0.00598145]\n"," [ 0.        ]\n"," ...\n"," [-0.00598145]\n"," [ 0.        ]\n"," [ 0.00598145]], shape=(32212, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00598145  0.00598145  0.         ... -0.00598145  0.\n","  0.00598145], shape=(32212,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01016235]\n"," [-0.00897217]\n"," [-0.00897217]\n"," ...\n"," [-0.02511597]\n"," [-0.02749634]\n"," [-0.03048706]], shape=(61596, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01016235 -0.00897217 -0.00897217 ... -0.02511597 -0.02749634\n"," -0.03048706], shape=(61596,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01049805]\n"," [ 0.0085144 ]\n"," [ 0.00650024]\n"," ...\n"," [-0.23651123]\n"," [-0.19848633]\n"," [-0.15200806]], shape=(16356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01049805  0.0085144   0.00650024 ... -0.23651123 -0.19848633\n"," -0.15200806], shape=(16356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02258301]\n"," [ 0.01831055]\n"," [ 0.02319336]\n"," ...\n"," [-1.        ]\n"," [-1.        ]\n"," [-1.        ]], shape=(35276, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02258301  0.01831055  0.02319336 ... -1.         -1.\n"," -1.        ], shape=(35276,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0249939 ]\n"," [ 0.03500366]\n"," [ 0.04000854]\n"," ...\n"," [-0.0249939 ]\n"," [-0.02249146]\n"," [-0.0249939 ]], shape=(33800, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0249939   0.03500366  0.04000854 ... -0.0249939  -0.02249146\n"," -0.0249939 ], shape=(33800,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00628662]\n"," [-0.00628662]\n"," [-0.00628662]\n"," ...\n"," [-0.03775024]\n"," [-0.03143311]\n"," [-0.03143311]], shape=(56980, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00628662 -0.00628662 -0.00628662 ... -0.03775024 -0.03143311\n"," -0.03143311], shape=(56980,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00311279]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01245117]\n"," [-0.01245117]\n"," [-0.01245117]], shape=(60974, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00311279  0.          0.         ... -0.01245117 -0.01245117\n"," -0.01245117], shape=(60974,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03762817]\n"," [-0.03762817]\n"," [-0.04299927]\n"," ...\n"," [ 0.02151489]\n"," [ 0.0161438 ]\n"," [ 0.01074219]], shape=(27028, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03762817 -0.03762817 -0.04299927 ...  0.02151489  0.0161438\n","  0.01074219], shape=(27028,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.2487793 ]\n"," [ 0.25149536]\n"," [ 0.25424194]\n"," ...\n"," [-0.28659058]\n"," [-0.28494263]\n"," [-0.28494263]], shape=(41016, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.2487793   0.25149536  0.25424194 ... -0.28659058 -0.28494263\n"," -0.28494263], shape=(41016,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.08914185]\n"," [0.10864258]\n"," [0.11700439]], shape=(40124, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.08914185 0.10864258 0.11700439], shape=(40124,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10430908]\n"," [-0.10430908]\n"," [-0.10430908]\n"," ...\n"," [-0.07913208]\n"," [-0.07913208]\n"," [-0.07913208]], shape=(45922, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10430908 -0.10430908 -0.10430908 ... -0.07913208 -0.07913208\n"," -0.07913208], shape=(45922,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01135254]\n"," [ 0.        ]\n"," ...\n"," [ 0.125     ]\n"," [ 0.125     ]\n"," [ 0.11364746]], shape=(121116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01135254  0.         ...  0.125       0.125\n","  0.11364746], shape=(121116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02984619]\n"," [-0.02090454]\n"," [-0.04476929]\n"," ...\n"," [-0.02090454]\n"," [-0.02090454]\n"," [-0.02090454]], shape=(52226, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02984619 -0.02090454 -0.04476929 ... -0.02090454 -0.02090454\n"," -0.02090454], shape=(52226,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00473022]\n"," [ 0.00473022]\n"," ...\n"," [-0.00942993]\n"," [-0.00942993]\n"," [-0.00942993]], shape=(32404, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00473022  0.00473022 ... -0.00942993 -0.00942993\n"," -0.00942993], shape=(32404,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01168823]\n"," [ 0.        ]\n"," [-0.01168823]\n"," ...\n"," [ 0.14035034]\n"," [ 0.18713379]\n"," [ 0.19882202]], shape=(38294, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01168823  0.         -0.01168823 ...  0.14035034  0.18713379\n","  0.19882202], shape=(38294,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02761841]\n"," [0.02209473]\n"," [0.01657104]\n"," ...\n"," [0.02761841]\n"," [0.02209473]\n"," [0.02209473]], shape=(78208, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02761841 0.02209473 0.01657104 ... 0.02761841 0.02209473 0.02209473], shape=(78208,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02624512]\n"," [ 0.02374268]\n"," [ 0.01501465]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [-0.00125122]], shape=(45308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02624512  0.02374268  0.01501465 ...  0.          0.\n"," -0.00125122], shape=(45308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06185913]\n"," [-0.05670166]\n"," [-0.0670166 ]\n"," ...\n"," [-0.11856079]\n"," [-0.11340332]\n"," [-0.11856079]], shape=(18374, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06185913 -0.05670166 -0.0670166  ... -0.11856079 -0.11340332\n"," -0.11856079], shape=(18374,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01251221]\n"," [-0.01382446]\n"," [-0.01251221]\n"," ...\n"," [-0.00430298]\n"," [-0.00646973]\n"," [-0.00863647]], shape=(40000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01251221 -0.01382446 -0.01251221 ... -0.00430298 -0.00646973\n"," -0.00863647], shape=(40000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1126709 ]\n"," [-0.10562134]\n"," [-0.1126709 ]\n"," ...\n"," [-0.09155273]\n"," [-0.09155273]\n"," [-0.1126709 ]], shape=(36108, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1126709  -0.10562134 -0.1126709  ... -0.09155273 -0.09155273\n"," -0.1126709 ], shape=(36108,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18154907]\n"," [-0.17773438]\n"," [-0.17346191]\n"," ...\n"," [-0.3511963 ]\n"," [-0.33459473]\n"," [-0.31674194]], shape=(53192, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18154907 -0.17773438 -0.17346191 ... -0.3511963  -0.33459473\n"," -0.31674194], shape=(53192,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01470947]\n"," [-0.01470947]\n"," [-0.02099609]\n"," ...\n"," [-0.01049805]\n"," [ 0.        ]\n"," [ 0.00421143]], shape=(38090, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01470947 -0.01470947 -0.02099609 ... -0.01049805  0.\n","  0.00421143], shape=(38090,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0300293 ]\n"," [ 0.02752686]\n"," [ 0.0255127 ]\n"," ...\n"," [-0.00250244]\n"," [-0.00250244]\n"," [-0.0045166 ]], shape=(39680, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0300293   0.02752686  0.0255127  ... -0.00250244 -0.00250244\n"," -0.0045166 ], shape=(39680,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01464844]\n"," [ 0.02194214]\n"," [ 0.02194214]\n"," ...\n"," [-0.04876709]\n"," [-0.04876709]\n"," [-0.04147339]], shape=(44662, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01464844  0.02194214  0.02194214 ... -0.04876709 -0.04876709\n"," -0.04147339], shape=(44662,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03173828]\n"," [ 0.03704834]\n"," [ 0.04232788]\n"," ...\n"," [-0.0211792 ]\n"," [-0.0211792 ]\n"," [-0.0211792 ]], shape=(86836, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03173828  0.03704834  0.04232788 ... -0.0211792  -0.0211792\n"," -0.0211792 ], shape=(86836,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.34658813]\n"," [ 0.3352356 ]\n"," [ 0.30114746]\n"," ...\n"," [-0.03408813]\n"," [-0.05114746]\n"," [-0.0625    ]], shape=(33300, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.34658813  0.3352356   0.30114746 ... -0.03408813 -0.05114746\n"," -0.0625    ], shape=(33300,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00567627]\n"," [-0.01419067]\n"," [-0.01419067]\n"," ...\n"," [-0.05682373]\n"," [-0.04830933]\n"," [-0.04260254]], shape=(31750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00567627 -0.01419067 -0.01419067 ... -0.05682373 -0.04830933\n"," -0.04260254], shape=(31750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.040802  ]\n"," [ 0.03826904]\n"," [ 0.03570557]\n"," ...\n"," [-0.15560913]\n"," [-0.18621826]\n"," [-0.20407104]], shape=(42938, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.040802    0.03826904  0.03570557 ... -0.15560913 -0.18621826\n"," -0.20407104], shape=(42938,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05899048]\n"," [ 0.05700684]\n"," [ 0.05450439]\n"," ...\n"," [-0.00750732]\n"," [-0.00500488]\n"," [-0.00299072]], shape=(56528, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05899048  0.05700684  0.05450439 ... -0.00750732 -0.00500488\n"," -0.00299072], shape=(56528,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08334351]\n"," [-0.07406616]\n"," [-0.06481934]\n"," ...\n"," [-0.027771  ]\n"," [-0.027771  ]\n"," [-0.01852417]], shape=(33912, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08334351 -0.07406616 -0.06481934 ... -0.027771   -0.027771\n"," -0.01852417], shape=(33912,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.11514282]\n"," [ 0.10855103]\n"," [ 0.10525513]\n"," ...\n"," [-0.21054077]\n"," [-0.17764282]\n"," [-0.15789795]], shape=(52234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.11514282  0.10855103  0.10525513 ... -0.21054077 -0.17764282\n"," -0.15789795], shape=(52234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04251099]\n"," [ 0.03948975]\n"," [ 0.03549194]\n"," ...\n"," [ 0.01699829]\n"," [ 0.00601196]\n"," [-0.00500488]], shape=(30042, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04251099  0.03948975  0.03549194 ...  0.01699829  0.00601196\n"," -0.00500488], shape=(30042,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.0062561 ]\n"," [0.00500488]\n"," [0.00375366]], shape=(56288, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.0062561  0.00500488 0.00375366], shape=(56288,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16000366]\n"," [ 0.06900024]\n"," [ 0.31549072]\n"," ...\n"," [ 0.01150513]\n"," [ 0.01449585]\n"," [ 0.01950073]], shape=(85642, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16000366  0.06900024  0.31549072 ...  0.01150513  0.01449585\n","  0.01950073], shape=(85642,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11972046]\n"," [-0.1126709 ]\n"," [-0.10562134]\n"," ...\n"," [-0.07043457]\n"," [-0.07745361]\n"," [-0.09155273]], shape=(29416, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11972046 -0.1126709  -0.10562134 ... -0.07043457 -0.07745361\n"," -0.09155273], shape=(29416,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00418091]\n"," [-0.00119019]\n"," [ 0.00418091]\n"," ...\n"," [-0.00598145]\n"," [-0.00598145]\n"," [-0.00299072]], shape=(72490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00418091 -0.00119019  0.00418091 ... -0.00598145 -0.00598145\n"," -0.00299072], shape=(72490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17053223]\n"," [-0.17053223]\n"," [-0.17053223]\n"," ...\n"," [-0.17053223]\n"," [-0.1550293 ]\n"," [-0.1317749 ]], shape=(26022, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17053223 -0.17053223 -0.17053223 ... -0.17053223 -0.1550293\n"," -0.1317749 ], shape=(26022,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14633179]\n"," [-0.14633179]\n"," [-0.17886353]\n"," ...\n"," [-0.14633179]\n"," [-0.13009644]\n"," [-0.13009644]], shape=(82042, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14633179 -0.14633179 -0.17886353 ... -0.14633179 -0.13009644\n"," -0.13009644], shape=(82042,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0105896 ]\n"," [-0.01156616]\n"," [-0.0105896 ]\n"," ...\n"," [ 0.00241089]\n"," [-0.00097656]\n"," [-0.00335693]], shape=(22332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0105896  -0.01156616 -0.0105896  ...  0.00241089 -0.00097656\n"," -0.00335693], shape=(22332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01086426]\n"," [-0.01000977]\n"," [-0.01596069]\n"," ...\n"," [ 0.        ]\n"," [-0.00030518]\n"," [-0.00036621]], shape=(27344, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01086426 -0.01000977 -0.01596069 ...  0.         -0.00030518\n"," -0.00036621], shape=(27344,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01934814]\n"," [-0.01934814]\n"," [-0.01934814]\n"," ...\n"," [ 0.1270752 ]\n"," [ 0.11325073]\n"," [ 0.08010864]], shape=(88584, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01934814 -0.01934814 -0.01934814 ...  0.1270752   0.11325073\n","  0.08010864], shape=(88584,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01135254]\n"," [-0.01135254]\n"," [ 0.01135254]\n"," ...\n"," [ 0.05682373]\n"," [ 0.04544067]\n"," [ 0.05682373]], shape=(40564, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01135254 -0.01135254  0.01135254 ...  0.05682373  0.04544067\n","  0.05682373], shape=(40564,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00750732]\n"," [-0.00189209]\n"," [ 0.00189209]\n"," ...\n"," [ 0.20489502]\n"," [ 0.216156  ]\n"," [ 0.22180176]], shape=(110062, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00750732 -0.00189209  0.00189209 ...  0.20489502  0.216156\n","  0.22180176], shape=(110062,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.45159912]\n"," [-0.45159912]\n"," [-0.42474365]\n"," ...\n"," [ 0.00537109]\n"," [ 0.01074219]\n"," [ 0.0161438 ]], shape=(33350, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.45159912 -0.45159912 -0.42474365 ...  0.00537109  0.01074219\n","  0.0161438 ], shape=(33350,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.12380981]\n"," [-0.14285278]\n"," [-0.14285278]\n"," ...\n"," [-0.14285278]\n"," [-0.14285278]\n"," [-0.12380981]], shape=(35578, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.12380981 -0.14285278 -0.14285278 ... -0.14285278 -0.14285278\n"," -0.12380981], shape=(35578,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01477051]\n"," [ 0.01477051]\n"," [ 0.01342773]\n"," ...\n"," [-0.00939941]\n"," [-0.00939941]\n"," [-0.00805664]], shape=(37690, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01477051  0.01477051  0.01342773 ... -0.00939941 -0.00939941\n"," -0.00805664], shape=(37690,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00424194]\n"," [0.0085144 ]\n"," [0.0085144 ]\n"," ...\n"," [0.01275635]\n"," [0.01275635]\n"," [0.0085144 ]], shape=(49768, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00424194 0.0085144  0.0085144  ... 0.01275635 0.01275635 0.0085144 ], shape=(49768,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02749634]\n"," [-0.04000854]\n"," [-0.05249023]\n"," ...\n"," [-0.04998779]\n"," [-0.05249023]\n"," [-0.0625    ]], shape=(64582, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02749634 -0.04000854 -0.05249023 ... -0.04998779 -0.05249023\n"," -0.0625    ], shape=(64582,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.1842041 ]\n"," [ 0.19924927]\n"," [ 0.20489502]\n"," ...\n"," [-0.02069092]\n"," [-0.01879883]\n"," [-0.01315308]], shape=(99096, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.1842041   0.19924927  0.20489502 ... -0.02069092 -0.01879883\n"," -0.01315308], shape=(99096,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03479004]\n"," [ 0.03051758]\n"," [ 0.02380371]\n"," ...\n"," [ 0.00915527]\n"," [-0.22283936]\n"," [-0.47009277]], shape=(45482, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03479004  0.03051758  0.02380371 ...  0.00915527 -0.22283936\n"," -0.47009277], shape=(45482,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.     ]\n"," [0.     ]\n"," [0.03125]\n"," ...\n"," [0.03125]\n"," [0.03125]\n"," [0.     ]], shape=(38142, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.      0.      0.03125 ... 0.03125 0.03125 0.     ], shape=(38142,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16326904]\n"," [-0.13009644]\n"," [-0.08929443]\n"," ...\n"," [-0.01785278]\n"," [-0.01019287]\n"," [-0.00509644]], shape=(35342, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16326904 -0.13009644 -0.08929443 ... -0.01785278 -0.01019287\n"," -0.00509644], shape=(35342,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [-0.00250244]\n"," [-0.01000977]\n"," ...\n"," [-0.1812439 ]\n"," [-0.17126465]\n"," [-0.16000366]], shape=(16480, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244 -0.00250244 -0.01000977 ... -0.1812439  -0.17126465\n"," -0.16000366], shape=(16480,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00048828]\n"," [ 0.        ]\n"," [ 0.00048828]\n"," ...\n"," [-0.00549316]\n"," [-0.00650024]\n"," [-0.00750732]], shape=(60996, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00048828  0.          0.00048828 ... -0.00549316 -0.00650024\n"," -0.00750732], shape=(60996,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05377197]\n"," [-0.05377197]\n"," [-0.03762817]\n"," ...\n"," [-0.20968628]\n"," [-0.27420044]\n"," [-0.3171997 ]], shape=(47686, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05377197 -0.05377197 -0.03762817 ... -0.20968628 -0.27420044\n"," -0.3171997 ], shape=(47686,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.125     ]\n"," [ 0.11248779]\n"," [ 0.10626221]\n"," ...\n"," [-0.2000122 ]\n"," [-0.1937561 ]\n"," [-0.1937561 ]], shape=(46554, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.125       0.11248779  0.10626221 ... -0.2000122  -0.1937561\n"," -0.1937561 ], shape=(46554,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0249939]\n"," [-0.0249939]\n"," [-0.03125  ]\n"," ...\n"," [-0.0062561]\n"," [ 0.       ]\n"," [ 0.       ]], shape=(37574, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.0249939 -0.0249939 -0.03125   ... -0.0062561  0.         0.       ], shape=(37574,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1111145 ]\n"," [-0.09805298]\n"," [-0.09805298]\n"," ...\n"," [-0.28103638]\n"," [-0.3137207 ]\n"," [-0.3333435 ]], shape=(55626, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1111145  -0.09805298 -0.09805298 ... -0.28103638 -0.3137207\n"," -0.3333435 ], shape=(55626,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00500488]\n"," [0.00375366]\n"," [0.00375366]\n"," ...\n"," [0.00375366]\n"," [0.00500488]\n"," [0.00500488]], shape=(39574, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00500488 0.00375366 0.00375366 ... 0.00375366 0.00500488 0.00500488], shape=(39574,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.21875  ]\n"," [-0.1749878]\n"," [-0.1312561]\n"," ...\n"," [ 0.0375061]\n"," [ 0.03125  ]\n"," [ 0.0249939]], shape=(45638, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.21875   -0.1749878 -0.1312561 ...  0.0375061  0.03125    0.0249939], shape=(45638,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00454712]\n"," [-0.01135254]\n"," ...\n"," [ 0.16592407]\n"," [ 0.17272949]\n"," [ 0.16592407]], shape=(24056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00454712 -0.01135254 ...  0.16592407  0.17272949\n","  0.16592407], shape=(24056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.2911377 ]\n"," [ 0.2658081 ]\n"," [ 0.20254517]\n"," ...\n"," [ 0.        ]\n"," [-0.05062866]\n"," [-0.11392212]], shape=(57938, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.2911377   0.2658081   0.20254517 ...  0.         -0.05062866\n"," -0.11392212], shape=(57938,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.53048706]\n"," [-0.42681885]\n"," [-0.32925415]\n"," ...\n"," [-0.00610352]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(34290, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.53048706 -0.42681885 -0.32925415 ... -0.00610352  0.\n","  0.        ], shape=(34290,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.24090576]\n"," [-0.25      ]\n"," [-0.24090576]\n"," ...\n"," [-0.0227356 ]\n"," [-0.0227356 ]\n"," [-0.0227356 ]], shape=(51360, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.24090576 -0.25       -0.24090576 ... -0.0227356  -0.0227356\n"," -0.0227356 ], shape=(51360,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00772095]\n"," [ 0.01931763]\n"," [ 0.02703857]\n"," ...\n"," [-0.02703857]\n"," [ 0.00772095]\n"," [-0.01931763]], shape=(40466, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00772095  0.01931763  0.02703857 ... -0.02703857  0.00772095\n"," -0.01931763], shape=(40466,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01220703]\n"," [ 0.00610352]\n"," [ 0.        ]\n"," ...\n"," [-0.73172   ]\n"," [-0.68292236]\n"," [-0.6097412 ]], shape=(19116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01220703  0.00610352  0.         ... -0.73172    -0.68292236\n"," -0.6097412 ], shape=(19116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14007568]\n"," [-0.12414551]\n"," [-0.10214233]\n"," ...\n"," [-0.01379395]\n"," [-0.01379395]\n"," [-0.01379395]], shape=(49728, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14007568 -0.12414551 -0.10214233 ... -0.01379395 -0.01379395\n"," -0.01379395], shape=(49728,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03048706]\n"," [ 0.03048706]\n"," [ 0.02438354]\n"," ...\n"," [-0.0975647 ]\n"," [-0.10974121]\n"," [-0.13415527]], shape=(56948, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03048706  0.03048706  0.02438354 ... -0.0975647  -0.10974121\n"," -0.13415527], shape=(56948,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00393677]\n"," [0.00784302]\n"," ...\n"," [0.00784302]\n"," [0.00784302]\n"," [0.01177979]], shape=(19866, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00393677 0.00784302 ... 0.00784302 0.00784302 0.01177979], shape=(19866,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01040649]\n"," [ 0.02084351]\n"," [ 0.04165649]\n"," ...\n"," [-0.125     ]\n"," [-0.0625    ]\n"," [-0.02084351]], shape=(36246, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01040649  0.02084351  0.04165649 ... -0.125      -0.0625\n"," -0.02084351], shape=(36246,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.08334351]\n"," [0.08334351]\n"," [0.07019043]\n"," ...\n"," [0.02630615]\n"," [0.02850342]\n"," [0.03509521]], shape=(36316, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.08334351 0.08334351 0.07019043 ... 0.02630615 0.02850342 0.03509521], shape=(36316,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0322876 ]\n"," [-0.0322876 ]\n"," [-0.02960205]\n"," ...\n"," [-0.0269165 ]\n"," [-0.0322876 ]\n"," [-0.02960205]], shape=(99600, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0322876  -0.0322876  -0.02960205 ... -0.0269165  -0.0322876\n"," -0.02960205], shape=(99600,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04000854]\n"," [0.04000854]\n"," [0.04376221]\n"," ...\n"," [0.        ]\n"," [0.00375366]\n"," [0.00750732]], shape=(27232, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04000854 0.04000854 0.04376221 ... 0.         0.00375366 0.00750732], shape=(27232,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01251221]\n"," [-0.01251221]\n"," [-0.01251221]\n"," ...\n"," [-0.02197266]\n"," [-0.02328491]\n"," [-0.02328491]], shape=(32484, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01251221 -0.01251221 -0.01251221 ... -0.02197266 -0.02328491\n"," -0.02328491], shape=(32484,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00521851]\n"," [ 0.00521851]\n"," [ 0.        ]\n"," ...\n"," [-0.01306152]\n"," [-0.01828003]\n"," [-0.01828003]], shape=(20010, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00521851  0.00521851  0.         ... -0.01306152 -0.01828003\n"," -0.01828003], shape=(20010,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04898071]\n"," [-0.04898071]\n"," [-0.04638672]\n"," ...\n"," [-0.03866577]\n"," [-0.04898071]\n"," [-0.04898071]], shape=(43850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04898071 -0.04898071 -0.04638672 ... -0.03866577 -0.04898071\n"," -0.04898071], shape=(43850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01818848]\n"," [-0.03271484]\n"," [-0.04364014]\n"," ...\n"," [-0.04000854]\n"," [-0.04364014]\n"," [-0.04000854]], shape=(50856, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01818848 -0.03271484 -0.04364014 ... -0.04000854 -0.04364014\n"," -0.04000854], shape=(50856,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01525879]\n"," [-0.01586914]\n"," [-0.01525879]\n"," ...\n"," [-0.8406677 ]\n"," [-0.7136841 ]\n"," [-0.55981445]], shape=(38240, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01525879 -0.01586914 -0.01525879 ... -0.8406677  -0.7136841\n"," -0.55981445], shape=(38240,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00250244]\n"," [ 0.        ]\n"," ...\n"," [-0.05374146]\n"," [-0.05374146]\n"," [-0.05374146]], shape=(35014, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00250244  0.         ... -0.05374146 -0.05374146\n"," -0.05374146], shape=(35014,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.05209351]\n"," [0.04165649]\n"," [0.04165649]\n"," ...\n"," [0.01040649]\n"," [0.01040649]\n"," [0.02084351]], shape=(37898, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.05209351 0.04165649 0.04165649 ... 0.01040649 0.01040649 0.02084351], shape=(37898,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01000977]\n"," [-0.01000977]\n"," [-0.01998901]\n"," ...\n"," [-0.03500366]\n"," [-0.02999878]\n"," [-0.02999878]], shape=(25838, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01000977 -0.01000977 -0.01998901 ... -0.03500366 -0.02999878\n"," -0.02999878], shape=(25838,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09091187]\n"," [-0.09091187]\n"," [-0.09091187]\n"," ...\n"," [-0.07574463]\n"," [-0.07574463]\n"," [-0.06439209]], shape=(26852, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09091187 -0.09091187 -0.09091187 ... -0.07574463 -0.07574463\n"," -0.06439209], shape=(26852,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03533936]\n"," [0.03533936]\n"," [0.03030396]\n"," ...\n"," [0.30303955]\n"," [0.36364746]\n"," [0.42425537]], shape=(36638, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03533936 0.03533936 0.03030396 ... 0.30303955 0.36364746 0.42425537], shape=(36638,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0085144 ]\n"," [-0.0085144 ]\n"," [-0.01278687]\n"," ...\n"," [ 0.0831604 ]\n"," [ 0.11514282]\n"," [ 0.14285278]], shape=(22586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0085144  -0.0085144  -0.01278687 ...  0.0831604   0.11514282\n","  0.14285278], shape=(22586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02874756]\n"," [ 0.02249146]\n"," [ 0.01748657]\n"," ...\n"," [-0.00375366]\n"," [-0.0062561 ]\n"," [-0.0062561 ]], shape=(16148, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02874756  0.02249146  0.01748657 ... -0.00375366 -0.0062561\n"," -0.0062561 ], shape=(16148,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03277588]\n"," [ 0.03277588]\n"," [ 0.01638794]\n"," ...\n"," [ 0.00820923]\n"," [ 0.        ]\n"," [-0.00820923]], shape=(63806, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03277588  0.03277588  0.01638794 ...  0.00820923  0.\n"," -0.00820923], shape=(63806,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0173645 ]\n"," [ 0.00497437]\n"," [-0.01242065]\n"," ...\n"," [-0.03723145]\n"," [-0.04217529]\n"," [-0.03723145]], shape=(62022, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0173645   0.00497437 -0.01242065 ... -0.03723145 -0.04217529\n"," -0.03723145], shape=(62022,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01556396]\n"," [-0.01556396]\n"," [-0.01867676]\n"," ...\n"," [-0.01867676]\n"," [-0.01867676]\n"," [-0.02182007]], shape=(29066, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01556396 -0.01556396 -0.01867676 ... -0.01867676 -0.01867676\n"," -0.02182007], shape=(29066,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03295898]\n"," [-0.03295898]\n"," [-0.01922607]\n"," ...\n"," [-0.25549316]\n"," [-0.30218506]\n"," [-0.36264038]], shape=(35984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03295898 -0.03295898 -0.01922607 ... -0.25549316 -0.30218506\n"," -0.36264038], shape=(35984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02630615]\n"," [ 0.        ]\n"," [ 0.02630615]\n"," ...\n"," [ 0.        ]\n"," [-0.02630615]\n"," [ 0.        ]], shape=(73892, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02630615  0.          0.02630615 ...  0.         -0.02630615\n","  0.        ], shape=(73892,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00653076]\n"," [-0.00592041]\n"," [-0.00592041]\n"," ...\n"," [-0.00354004]\n"," [-0.00592041]\n"," [-0.00592041]], shape=(18442, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00653076 -0.00592041 -0.00592041 ... -0.00354004 -0.00592041\n"," -0.00592041], shape=(18442,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.00274658]\n"," ...\n"," [-0.01092529]\n"," [-0.01367188]\n"," [-0.01367188]], shape=(42834, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.00274658 ... -0.01092529 -0.01367188\n"," -0.01367188], shape=(42834,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01989746]\n"," [-0.01989746]\n"," [ 0.        ]\n"," ...\n"," [-0.05682373]\n"," [-0.04260254]\n"," [-0.03408813]], shape=(42008, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01989746 -0.01989746  0.         ... -0.05682373 -0.04260254\n"," -0.03408813], shape=(42008,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09060669]\n"," [-0.09060669]\n"," [-0.07382202]\n"," ...\n"," [ 0.        ]\n"," [-0.02349854]\n"," [-0.05703735]], shape=(21000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09060669 -0.09060669 -0.07382202 ...  0.         -0.02349854\n"," -0.05703735], shape=(21000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01998901]\n"," [-0.02182007]\n"," [-0.02398682]\n"," ...\n"," [-0.00286865]\n"," [-0.02999878]\n"," [-0.05667114]], shape=(78712, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01998901 -0.02182007 -0.02398682 ... -0.00286865 -0.02999878\n"," -0.05667114], shape=(78712,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04125977]\n"," [-0.03500366]\n"," [-0.02374268]\n"," ...\n"," [-0.01998901]\n"," [-0.01501465]\n"," [-0.01623535]], shape=(46640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04125977 -0.03500366 -0.02374268 ... -0.01998901 -0.01501465\n"," -0.01623535], shape=(46640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00982666]\n"," [-0.00982666]\n"," [ 0.        ]\n"," ...\n"," [ 0.01312256]\n"," [ 0.00982666]\n"," [ 0.00326538]], shape=(36376, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00982666 -0.00982666  0.         ...  0.01312256  0.00982666\n","  0.00326538], shape=(36376,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00576782]\n"," [-0.00576782]\n"," [-0.00723267]\n"," ...\n"," [-0.00817871]\n"," [-0.00964355]\n"," [-0.00964355]], shape=(19762, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00576782 -0.00576782 -0.00723267 ... -0.00817871 -0.00964355\n"," -0.00964355], shape=(19762,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01849365]\n"," [-0.02554321]\n"," [-0.0369873 ]\n"," ...\n"," [ 0.02554321]\n"," [ 0.02731323]\n"," [ 0.0352478 ]], shape=(37940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01849365 -0.02554321 -0.0369873  ...  0.02554321  0.02731323\n","  0.0352478 ], shape=(37940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07595825]\n"," [-0.07595825]\n"," [-0.08859253]\n"," ...\n"," [-0.01266479]\n"," [-0.05062866]\n"," [-0.10125732]], shape=(153994, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07595825 -0.07595825 -0.08859253 ... -0.01266479 -0.05062866\n"," -0.10125732], shape=(153994,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00201416]\n"," [-0.00039673]\n"," [ 0.00201416]\n"," ...\n"," [-0.00952148]\n"," [-0.01599121]\n"," [-0.01916504]], shape=(56454, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00201416 -0.00039673  0.00201416 ... -0.00952148 -0.01599121\n"," -0.01916504], shape=(56454,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0027771 ]\n"," [ 0.0083313 ]\n"," [ 0.01251221]\n"," ...\n"," [-0.04730225]\n"," [-0.06954956]\n"," [-0.08343506]], shape=(51002, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0027771   0.0083313   0.01251221 ... -0.04730225 -0.06954956\n"," -0.08343506], shape=(51002,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04049683]\n"," [-0.04858398]\n"," [-0.04049683]\n"," ...\n"," [ 0.        ]\n"," [-0.02023315]\n"," [-0.04049683]], shape=(27752, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04049683 -0.04858398 -0.04049683 ...  0.         -0.02023315\n"," -0.04049683], shape=(27752,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00350952]\n"," [-0.00549316]\n"," [-0.00601196]\n"," ...\n"," [-0.00750732]\n"," [-0.01049805]\n"," [-0.01348877]], shape=(45874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00350952 -0.00549316 -0.00601196 ... -0.00750732 -0.01049805\n"," -0.01348877], shape=(45874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00704956]\n"," [ 0.05764771]\n"," [ 0.10940552]\n"," ...\n"," [-0.0105896 ]\n"," [-0.00823975]\n"," [-0.0105896 ]], shape=(38814, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00704956  0.05764771  0.10940552 ... -0.0105896  -0.00823975\n"," -0.0105896 ], shape=(38814,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0249939 ]\n"," [-0.02999878]\n"," [-0.01998901]\n"," ...\n"," [-0.03500366]\n"," [-0.02999878]\n"," [-0.01998901]], shape=(21786, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0249939  -0.02999878 -0.01998901 ... -0.03500366 -0.02999878\n"," -0.01998901], shape=(21786,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02630615]\n"," [ 0.02630615]\n"," [-0.02630615]\n"," ...\n"," [ 0.10525513]\n"," [ 0.05264282]\n"," [ 0.10525513]], shape=(50674, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02630615  0.02630615 -0.02630615 ...  0.10525513  0.05264282\n","  0.10525513], shape=(50674,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.38949585]\n"," [-0.21673584]\n"," [-0.04577637]\n"," ...\n"," [-0.01342773]\n"," [-0.01098633]\n"," [-0.01098633]], shape=(19186, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.38949585 -0.21673584 -0.04577637 ... -0.01342773 -0.01098633\n"," -0.01098633], shape=(19186,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00308228]\n"," [ 0.01190186]\n"," [ 0.01852417]\n"," ...\n"," [-0.01940918]\n"," [-0.02822876]\n"," [-0.03439331]], shape=(29648, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00308228  0.01190186  0.01852417 ... -0.01940918 -0.02822876\n"," -0.03439331], shape=(29648,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03115845]\n"," [-0.03115845]\n"," [-0.02856445]\n"," ...\n"," [-0.1324768 ]\n"," [-0.15063477]\n"," [-0.16622925]], shape=(128640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03115845 -0.03115845 -0.02856445 ... -0.1324768  -0.15063477\n"," -0.16622925], shape=(128640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00787354]\n"," [-0.00656128]\n"," [-0.00656128]\n"," ...\n"," [-0.00656128]\n"," [-0.00787354]\n"," [-0.00787354]], shape=(40162, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00787354 -0.00656128 -0.00656128 ... -0.00656128 -0.00787354\n"," -0.00787354], shape=(40162,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.        ]\n"," [-0.00250244]\n"," ...\n"," [ 0.02999878]\n"," [ 0.03250122]\n"," [ 0.03250122]], shape=(20900, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.         -0.00250244 ...  0.02999878  0.03250122\n","  0.03250122], shape=(20900,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09716797]\n"," [-0.10931396]\n"," [-0.10931396]\n"," ...\n"," [-0.08096313]\n"," [-0.08908081]\n"," [-0.08096313]], shape=(49754, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09716797 -0.10931396 -0.10931396 ... -0.08096313 -0.08908081\n"," -0.08096313], shape=(49754,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02749634]\n"," [ 0.01748657]\n"," [ 0.01501465]\n"," ...\n"," [-0.00750732]\n"," [-0.00750732]\n"," [-0.01000977]], shape=(61368, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02749634  0.01748657  0.01501465 ... -0.00750732 -0.00750732\n"," -0.01000977], shape=(61368,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01251221]\n"," [-0.01000977]\n"," [-0.01251221]\n"," ...\n"," [ 0.01748657]\n"," [-0.00750732]\n"," [-0.03250122]], shape=(37996, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01251221 -0.01000977 -0.01251221 ...  0.01748657 -0.00750732\n"," -0.03250122], shape=(37996,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.015625 ]\n"," [-0.03125  ]\n"," [-0.03125  ]\n"," ...\n"," [ 0.078125 ]\n"," [ 0.0625   ]\n"," [ 0.0390625]], shape=(57562, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.015625  -0.03125   -0.03125   ...  0.078125   0.0625     0.0390625], shape=(57562,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16259766]\n"," [-0.17886353]\n"," [-0.17886353]\n"," ...\n"," [-0.17886353]\n"," [-0.1869812 ]\n"," [-0.1951294 ]], shape=(28660, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16259766 -0.17886353 -0.17886353 ... -0.17886353 -0.1869812\n"," -0.1951294 ], shape=(28660,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00375366]\n"," [-0.00375366]\n"," [-0.01126099]\n"," ...\n"," [ 0.00375366]\n"," [ 0.00375366]\n"," [ 0.00500488]], shape=(45130, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00375366 -0.00375366 -0.01126099 ...  0.00375366  0.00375366\n","  0.00500488], shape=(45130,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02203369]\n"," [-0.02401733]\n"," [-0.02401733]\n"," ...\n"," [-0.02401733]\n"," [-0.02001953]\n"," [-0.01501465]], shape=(52922, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02203369 -0.02401733 -0.02401733 ... -0.02401733 -0.02001953\n"," -0.01501465], shape=(52922,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01882935]\n"," [-0.01507568]\n"," [-0.01257324]\n"," ...\n"," [-0.0640564 ]\n"," [-0.06155396]\n"," [-0.04647827]], shape=(37980, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01882935 -0.01507568 -0.01257324 ... -0.0640564  -0.06155396\n"," -0.04647827], shape=(37980,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03723145]\n"," [-0.05126953]\n"," [-0.05615234]\n"," ...\n"," [ 0.09951782]\n"," [ 0.02380371]\n"," [-0.0696106 ]], shape=(29950, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03723145 -0.05126953 -0.05615234 ...  0.09951782  0.02380371\n"," -0.0696106 ], shape=(29950,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13446045]\n"," [-0.11764526]\n"," [-0.09664917]\n"," ...\n"," [-0.08822632]\n"," [-0.0819397 ]\n"," [-0.07144165]], shape=(99348, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13446045 -0.11764526 -0.09664917 ... -0.08822632 -0.0819397\n"," -0.07144165], shape=(99348,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [-0.00500488]\n"," [-0.00500488]\n"," ...\n"," [ 0.04626465]\n"," [ 0.04626465]\n"," [ 0.04626465]], shape=(41120, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488 -0.00500488 -0.00500488 ...  0.04626465  0.04626465\n","  0.04626465], shape=(41120,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01290894]\n"," [-0.01504517]\n"," [-0.01074219]\n"," ...\n"," [-0.00213623]\n"," [-0.00860596]\n"," [-0.00430298]], shape=(36782, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01290894 -0.01504517 -0.01074219 ... -0.00213623 -0.00860596\n"," -0.00430298], shape=(36782,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05209351]\n"," [ 0.01040649]\n"," [-0.04165649]\n"," ...\n"," [-0.04165649]\n"," [-0.01040649]\n"," [-0.04165649]], shape=(49848, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05209351  0.01040649 -0.04165649 ... -0.04165649 -0.01040649\n"," -0.04165649], shape=(49848,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08908081]\n"," [-0.09716797]\n"," [-0.09716797]\n"," ...\n"," [-0.23886108]\n"," [-0.21862793]\n"," [-0.18624878]], shape=(68408, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08908081 -0.09716797 -0.09716797 ... -0.23886108 -0.21862793\n"," -0.18624878], shape=(68408,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1086731 ]\n"," [0.10501099]\n"," [0.10317993]\n"," ...\n"," [0.00976562]\n"," [0.01647949]\n"," [0.01342773]], shape=(43858, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1086731  0.10501099 0.10317993 ... 0.00976562 0.01647949 0.01342773], shape=(43858,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02450562]\n"," [ 0.02749634]\n"," [ 0.02648926]\n"," ...\n"," [ 0.0085144 ]\n"," [-0.00100708]\n"," [-0.00500488]], shape=(35080, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02450562  0.02749634  0.02648926 ...  0.0085144  -0.00100708\n"," -0.00500488], shape=(35080,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14144897]\n"," [-0.1315918 ]\n"," [-0.11184692]\n"," ...\n"," [ 0.0559082 ]\n"," [ 0.0657959 ]\n"," [ 0.07235718]], shape=(42888, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14144897 -0.1315918  -0.11184692 ...  0.0559082   0.0657959\n","  0.07235718], shape=(42888,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01501465]\n"," [-0.01501465]\n"," [-0.01251221]\n"," ...\n"," [-0.0249939 ]\n"," [-0.02749634]\n"," [-0.02749634]], shape=(35378, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01501465 -0.01501465 -0.01251221 ... -0.0249939  -0.02749634\n"," -0.02749634], shape=(35378,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09155273]\n"," [-0.07745361]\n"," [-0.09155273]\n"," ...\n"," [-0.1126709 ]\n"," [-0.10562134]\n"," [-0.09155273]], shape=(50534, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09155273 -0.07745361 -0.09155273 ... -0.1126709  -0.10562134\n"," -0.09155273], shape=(50534,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.21875  ]\n"," [ 0.2437439]\n"," [ 0.2687378]\n"," ...\n"," [-0.375    ]\n"," [-0.3125   ]\n"," [-0.2687378]], shape=(42786, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.21875    0.2437439  0.2687378 ... -0.375     -0.3125    -0.2687378], shape=(42786,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00964355]\n"," [-0.01397705]\n"," [-0.01782227]\n"," ...\n"," [-0.01397705]\n"," [-0.00817871]\n"," [-0.00335693]], shape=(54194, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00964355 -0.01397705 -0.01782227 ... -0.01397705 -0.00817871\n"," -0.00335693], shape=(54194,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.0043335 ]\n"," [0.00799561]\n"," ...\n"," [0.41485596]\n"," [0.31201172]\n"," [0.18075562]], shape=(31056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.0043335  0.00799561 ... 0.41485596 0.31201172 0.18075562], shape=(31056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06500244]\n"," [-0.07250977]\n"," [-0.07998657]\n"," ...\n"," [-0.00750732]\n"," [-0.00500488]\n"," [-0.00250244]], shape=(84686, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06500244 -0.07250977 -0.07998657 ... -0.00750732 -0.00500488\n"," -0.00250244], shape=(84686,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07751465]\n"," [-0.11627197]\n"," [-0.1550293 ]\n"," ...\n"," [-0.18603516]\n"," [-0.18603516]\n"," [-0.18603516]], shape=(21366, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07751465 -0.11627197 -0.1550293  ... -0.18603516 -0.18603516\n"," -0.18603516], shape=(21366,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.22479248]\n"," [-0.24804688]\n"," [-0.24804688]\n"," ...\n"," [-0.01550293]\n"," [-0.05426025]\n"," [-0.07751465]], shape=(21792, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.22479248 -0.24804688 -0.24804688 ... -0.01550293 -0.05426025\n"," -0.07751465], shape=(21792,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00924683]\n"," [0.        ]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.00924683]], shape=(49786, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00924683 0.         ... 0.         0.         0.00924683], shape=(49786,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04998779]\n"," [ 0.04940796]\n"," [ 0.04736328]\n"," ...\n"," [-0.00375366]\n"," [ 0.        ]\n"," [ 0.0032959 ]], shape=(49384, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04998779  0.04940796  0.04736328 ... -0.00375366  0.\n","  0.0032959 ], shape=(49384,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.00244141]\n"," [0.        ]\n"," ...\n"," [0.0072937 ]\n"," [0.00973511]\n"," [0.00485229]], shape=(50636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.00244141 0.         ... 0.0072937  0.00973511 0.00485229], shape=(50636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01000977]\n"," [ 0.0085144 ]\n"," [ 0.0085144 ]\n"," ...\n"," [-0.00350952]\n"," [-0.00201416]\n"," [-0.00299072]], shape=(16114, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01000977  0.0085144   0.0085144  ... -0.00350952 -0.00201416\n"," -0.00299072], shape=(16114,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00863647]\n"," [-0.00738525]\n"," [-0.0111084 ]\n"," ...\n"," [-0.0123291 ]\n"," [-0.0123291 ]\n"," [-0.0123291 ]], shape=(28490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00863647 -0.00738525 -0.0111084  ... -0.0123291  -0.0123291\n"," -0.0123291 ], shape=(28490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01986694]\n"," [-0.01986694]\n"," [-0.01901245]\n"," ...\n"," [-0.00518799]\n"," [-0.01251221]\n"," [-0.01901245]], shape=(19916, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01986694 -0.01986694 -0.01901245 ... -0.00518799 -0.01251221\n"," -0.01901245], shape=(19916,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06710815]\n"," [-0.06710815]\n"," [-0.05703735]\n"," ...\n"," [-0.06710815]\n"," [-0.07382202]\n"," [-0.07382202]], shape=(58542, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06710815 -0.06710815 -0.05703735 ... -0.06710815 -0.07382202\n"," -0.07382202], shape=(58542,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00750732]\n"," [0.        ]\n"," [0.00189209]\n"," ...\n"," [0.00939941]\n"," [0.0112915 ]\n"," [0.0112915 ]], shape=(25646, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00750732 0.         0.00189209 ... 0.00939941 0.0112915  0.0112915 ], shape=(25646,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.14587402]\n"," [0.16940308]\n"," [0.17410278]\n"," ...\n"," [0.04705811]\n"," [0.04705811]\n"," [0.04705811]], shape=(41118, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.14587402 0.16940308 0.17410278 ... 0.04705811 0.04705811 0.04705811], shape=(41118,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0112915 ]\n"," [ 0.0112915 ]\n"," [ 0.0112915 ]\n"," ...\n"," [-0.01690674]\n"," [-0.01690674]\n"," [-0.01690674]], shape=(16936, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0112915   0.0112915   0.0112915  ... -0.01690674 -0.01690674\n"," -0.01690674], shape=(16936,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00244141]\n"," [ 0.        ]\n"," [ 0.00244141]\n"," ...\n"," [-0.00979614]\n"," [-0.00491333]\n"," [ 0.        ]], shape=(34048, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00244141  0.          0.00244141 ... -0.00979614 -0.00491333\n","  0.        ], shape=(34048,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.13430786]\n"," [ 0.09768677]\n"," [ 0.08303833]\n"," ...\n"," [-0.11172485]\n"," [-0.15261841]\n"," [-0.1666565 ]], shape=(46188, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.13430786  0.09768677  0.08303833 ... -0.11172485 -0.15261841\n"," -0.1666565 ], shape=(46188,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0173645 ]\n"," [0.02481079]\n"," [0.0173645 ]\n"," ...\n"," [0.02481079]\n"," [0.0173645 ]\n"," [0.01242065]], shape=(99298, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0173645  0.02481079 0.0173645  ... 0.02481079 0.0173645  0.01242065], shape=(99298,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00750732]\n"," [0.0085144 ]\n"," [0.00900269]\n"," ...\n"," [0.00350952]\n"," [0.00448608]\n"," [0.00601196]], shape=(36938, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00750732 0.0085144  0.00900269 ... 0.00350952 0.00448608 0.00601196], shape=(36938,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07400513]\n"," [-0.04199219]\n"," [-0.01150513]\n"," ...\n"," [-0.00201416]\n"," [-0.00201416]\n"," [-0.00201416]], shape=(40392, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07400513 -0.04199219 -0.01150513 ... -0.00201416 -0.00201416\n"," -0.00201416], shape=(40392,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00640869]\n"," [ 0.        ]\n"," [-0.01281738]\n"," ...\n"," [ 0.00640869]\n"," [ 0.        ]\n"," [-0.00640869]], shape=(48098, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00640869  0.         -0.01281738 ...  0.00640869  0.\n"," -0.00640869], shape=(48098,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01519775]\n"," [-0.02053833]\n"," [-0.02496338]\n"," ...\n"," [-0.02130127]\n"," [-0.02230835]\n"," [-0.02310181]], shape=(19856, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01519775 -0.02053833 -0.02496338 ... -0.02130127 -0.02230835\n"," -0.02310181], shape=(19856,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04165649]\n"," [ 0.02084351]\n"," [-0.01040649]\n"," ...\n"," [ 0.04165649]\n"," [ 0.04165649]\n"," [ 0.02084351]], shape=(32720, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04165649  0.02084351 -0.01040649 ...  0.04165649  0.04165649\n","  0.02084351], shape=(32720,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00048828]\n"," [ 0.00048828]\n"," [ 0.00100708]\n"," ...\n"," [ 0.00100708]\n"," [-0.00201416]\n"," [-0.00350952]], shape=(36062, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00048828  0.00048828  0.00100708 ...  0.00100708 -0.00201416\n"," -0.00350952], shape=(36062,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02127075]\n"," [ 0.02127075]\n"," [ 0.02340698]\n"," ...\n"," [-0.02764893]\n"," [-0.03192139]\n"," [-0.03405762]], shape=(37214, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02127075  0.02127075  0.02340698 ... -0.02764893 -0.03192139\n"," -0.03405762], shape=(37214,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01715088]\n"," [ 0.02474976]\n"," [ 0.03048706]\n"," ...\n"," [-0.02285767]\n"," [-0.02856445]\n"," [-0.03048706]], shape=(49424, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01715088  0.02474976  0.03048706 ... -0.02285767 -0.02856445\n"," -0.03048706], shape=(49424,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00942993]\n"," [0.00473022]\n"," [0.        ]\n"," ...\n"," [0.01885986]\n"," [0.01416016]\n"," [0.00473022]], shape=(19588, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00942993 0.00473022 0.         ... 0.01885986 0.01416016 0.00473022], shape=(19588,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05249023]\n"," [-0.0562439 ]\n"," [-0.06124878]\n"," ...\n"," [ 0.01998901]\n"," [ 0.01251221]\n"," [ 0.00500488]], shape=(30016, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05249023 -0.0562439  -0.06124878 ...  0.01998901  0.01251221\n","  0.00500488], shape=(30016,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00549316]\n"," [-0.00549316]\n"," [-0.00900269]\n"," ...\n"," [ 0.12805176]\n"," [ 0.11355591]\n"," [ 0.0930481 ]], shape=(29672, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00549316 -0.00549316 -0.00900269 ...  0.12805176  0.11355591\n","  0.0930481 ], shape=(29672,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00192261]\n"," [-0.00384521]\n"," [-0.00192261]\n"," ...\n"," [ 0.00192261]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(51348, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00192261 -0.00384521 -0.00192261 ...  0.00192261  0.\n","  0.        ], shape=(51348,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08236694]\n"," [-0.01528931]\n"," [ 0.03765869]\n"," ...\n"," [-0.03057861]\n"," [-0.03411865]\n"," [-0.03646851]], shape=(41018, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08236694 -0.01528931  0.03765869 ... -0.03057861 -0.03411865\n"," -0.03646851], shape=(41018,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03173828]\n"," [ 0.01586914]\n"," [ 0.03173828]\n"," ...\n"," [-0.21429443]\n"," [-0.24603271]\n"," [-0.26190186]], shape=(56226, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03173828  0.01586914  0.03173828 ... -0.21429443 -0.24603271\n"," -0.26190186], shape=(56226,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03048706]\n"," [ 0.03048706]\n"," [ 0.03048706]\n"," ...\n"," [-0.02438354]\n"," [-0.01220703]\n"," [-0.01220703]], shape=(114720, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03048706  0.03048706  0.03048706 ... -0.02438354 -0.01220703\n"," -0.01220703], shape=(114720,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.00942993]\n"," ...\n"," [0.04244995]\n"," [0.04718018]\n"," [0.06130981]], shape=(19608, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.00942993 ... 0.04244995 0.04718018 0.06130981], shape=(19608,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.11016846]\n"," [ 0.12493896]\n"," [ 0.138031  ]\n"," ...\n"," [-0.59265137]\n"," [-0.59814453]\n"," [-0.60406494]], shape=(26928, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.11016846  0.12493896  0.138031   ... -0.59265137 -0.59814453\n"," -0.60406494], shape=(26928,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01687622]\n"," [-0.01205444]\n"," [-0.01205444]\n"," ...\n"," [-0.01205444]\n"," [-0.02410889]\n"," [-0.02893066]], shape=(75552, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01687622 -0.01205444 -0.01205444 ... -0.01205444 -0.02410889\n"," -0.02893066], shape=(75552,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03375244]\n"," [ 0.03875732]\n"," [ 0.04251099]\n"," ...\n"," [-0.03125   ]\n"," [-0.03125   ]\n"," [-0.02999878]], shape=(39936, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03375244  0.03875732  0.04251099 ... -0.03125    -0.03125\n"," -0.02999878], shape=(39936,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.      ]\n"," [0.027771]\n"," [0.027771]\n"," ...\n"," [0.      ]\n"," [0.      ]\n"," [0.027771]], shape=(29004, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.       0.027771 0.027771 ... 0.       0.       0.027771], shape=(29004,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17886353]\n"," [-0.16259766]\n"," [-0.14633179]\n"," ...\n"," [-0.13821411]\n"," [-0.13821411]\n"," [-0.13821411]], shape=(29948, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17886353 -0.16259766 -0.14633179 ... -0.13821411 -0.13821411\n"," -0.13821411], shape=(29948,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0057373 ]\n"," [-0.01431274]\n"," [-0.02865601]\n"," ...\n"," [-0.01431274]\n"," [-0.01431274]\n"," [-0.01431274]], shape=(46722, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0057373  -0.01431274 -0.02865601 ... -0.01431274 -0.01431274\n"," -0.01431274], shape=(46722,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02200317]\n"," [ 0.02648926]\n"," [ 0.03048706]\n"," ...\n"," [-0.00500488]\n"," [-0.00448608]\n"," [-0.00299072]], shape=(63544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02200317  0.02648926  0.03048706 ... -0.00500488 -0.00448608\n"," -0.00299072], shape=(63544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03613281]\n"," [-0.1204834 ]\n"," [-0.10842896]\n"," ...\n"," [-0.02410889]\n"," [-0.02410889]\n"," [-0.03613281]], shape=(31118, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03613281 -0.1204834  -0.10842896 ... -0.02410889 -0.02410889\n"," -0.03613281], shape=(31118,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07073975]\n"," [ 0.05853271]\n"," [ 0.05609131]\n"," ...\n"," [-0.0512085 ]\n"," [-0.03659058]\n"," [-0.01705933]], shape=(94626, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07073975  0.05853271  0.05609131 ... -0.0512085  -0.03659058\n"," -0.01705933], shape=(94626,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02182007]\n"," [ 0.03427124]\n"," [ 0.04672241]\n"," ...\n"," [ 0.        ]\n"," [-0.00311279]\n"," [-0.00311279]], shape=(25530, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02182007  0.03427124  0.04672241 ...  0.         -0.00311279\n"," -0.00311279], shape=(25530,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1869812 ]\n"," [-0.17886353]\n"," [-0.16259766]\n"," ...\n"," [-0.26016235]\n"," [-0.26828003]\n"," [-0.26828003]], shape=(28446, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1869812  -0.17886353 -0.16259766 ... -0.26016235 -0.26828003\n"," -0.26828003], shape=(28446,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02874756]\n"," [0.02374268]\n"," [0.01998901]\n"," ...\n"," [0.01748657]\n"," [0.02249146]\n"," [0.02624512]], shape=(39362, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02874756 0.02374268 0.01998901 ... 0.01748657 0.02249146 0.02624512], shape=(39362,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02059937]\n"," [ 0.02200317]\n"," [ 0.02362061]\n"," ...\n"," [-0.03536987]\n"," [-0.03451538]\n"," [-0.03372192]], shape=(30092, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02059937  0.02200317  0.02362061 ... -0.03536987 -0.03451538\n"," -0.03372192], shape=(30092,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.13650513]\n"," [ 0.13650513]\n"," [ 0.13650513]\n"," ...\n"," [-0.01950073]\n"," [-0.04177856]\n"," [-0.0557251 ]], shape=(38926, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.13650513  0.13650513  0.13650513 ... -0.01950073 -0.04177856\n"," -0.0557251 ], shape=(38926,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.0062561 ]\n"," [0.01251221]\n"," ...\n"," [0.01251221]\n"," [0.01251221]\n"," [0.01251221]], shape=(40514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.0062561  0.01251221 ... 0.01251221 0.01251221 0.01251221], shape=(40514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09692383]\n"," [-0.01132202]\n"," [ 0.07754517]\n"," ...\n"," [-0.00161743]\n"," [ 0.00161743]\n"," [ 0.        ]], shape=(27442, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09692383 -0.01132202  0.07754517 ... -0.00161743  0.00161743\n","  0.        ], shape=(27442,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0072937]\n"," [ 0.       ]\n"," [ 0.       ]\n"," ...\n"," [ 0.       ]\n"," [ 0.       ]\n"," [ 0.       ]], shape=(82688, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.0072937  0.         0.        ...  0.         0.         0.       ], shape=(82688,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.04251099]\n"," [0.04251099]\n"," [0.04251099]\n"," ...\n"," [0.00125122]\n"," [0.        ]\n"," [0.        ]], shape=(29154, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.04251099 0.04251099 0.04251099 ... 0.00125122 0.         0.        ], shape=(29154,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04412842]\n"," [-0.05883789]\n"," [-0.06863403]\n"," ...\n"," [ 0.17156982]\n"," [ 0.17156982]\n"," [ 0.17401123]], shape=(16488, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04412842 -0.05883789 -0.06863403 ...  0.17156982  0.17156982\n","  0.17401123], shape=(16488,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02249146]\n"," [0.02249146]\n"," [0.02124023]\n"," ...\n"," [0.0062561 ]\n"," [0.01000977]\n"," [0.01623535]], shape=(114778, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02249146 0.02249146 0.02124023 ... 0.0062561  0.01000977 0.01623535], shape=(114778,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01251221]\n"," [ 0.01251221]\n"," [ 0.01251221]\n"," ...\n"," [-0.03125   ]\n"," [-0.01251221]\n"," [-0.0249939 ]], shape=(37872, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01251221  0.01251221  0.01251221 ... -0.03125    -0.01251221\n"," -0.0249939 ], shape=(37872,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00598145]\n"," [0.00598145]\n"," [0.0149231 ]\n"," ...\n"," [0.05374146]\n"," [0.04776001]\n"," [0.03582764]], shape=(32354, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00598145 0.00598145 0.0149231  ... 0.05374146 0.04776001 0.03582764], shape=(32354,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.732666  ]\n"," [ 0.6890869 ]\n"," [ 0.64889526]\n"," ...\n"," [-0.00634766]\n"," [-0.00424194]\n"," [-0.00210571]], shape=(60616, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.732666    0.6890869   0.64889526 ... -0.00634766 -0.00424194\n"," -0.00210571], shape=(60616,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0838623 ]\n"," [0.0838623 ]\n"," [0.07763672]\n"," ...\n"," [0.01242065]\n"," [0.00930786]\n"," [0.00311279]], shape=(84478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0838623  0.0838623  0.07763672 ... 0.01242065 0.00930786 0.00311279], shape=(84478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00299072]\n"," [0.01016235]\n"," [0.01434326]\n"," ...\n"," [0.00119019]\n"," [0.01434326]\n"," [0.02511597]], shape=(31818, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00299072 0.01016235 0.01434326 ... 0.00119019 0.01434326 0.02511597], shape=(31818,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03170776]\n"," [ 0.02880859]\n"," [ 0.01153564]\n"," ...\n"," [-0.04611206]\n"," [-0.03170776]\n"," [-0.02017212]], shape=(69498, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03170776  0.02880859  0.01153564 ... -0.04611206 -0.03170776\n"," -0.02017212], shape=(69498,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02966309]\n"," [ 0.05508423]\n"," [ 0.07202148]\n"," ...\n"," [-0.02542114]\n"," [-0.01693726]\n"," [-0.02542114]], shape=(34258, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02966309  0.05508423  0.07202148 ... -0.02542114 -0.01693726\n"," -0.02542114], shape=(34258,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06362915]\n"," [-0.06970215]\n"," [-0.09393311]\n"," ...\n"," [-0.01818848]\n"," [-0.05453491]\n"," [-0.09393311]], shape=(42906, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06362915 -0.06970215 -0.09393311 ... -0.01818848 -0.05453491\n"," -0.09393311], shape=(42906,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.15652466]\n"," [0.11038208]\n"," [0.06958008]\n"," ...\n"," [0.08590698]\n"," [0.06115723]\n"," [0.03381348]], shape=(50672, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.15652466 0.11038208 0.06958008 ... 0.08590698 0.06115723 0.03381348], shape=(50672,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.027771  ]\n"," [0.027771  ]\n"," [0.03704834]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.        ]], shape=(37396, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.027771   0.027771   0.03704834 ... 0.         0.         0.        ], shape=(37396,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.2000122 ]\n"," [-0.2000122 ]\n"," [-0.19049072]\n"," ...\n"," [ 0.19049072]\n"," [ 0.09524536]\n"," [-0.01904297]], shape=(194030, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.2000122  -0.2000122  -0.19049072 ...  0.19049072  0.09524536\n"," -0.01904297], shape=(194030,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.00598145]\n"," ...\n"," [ 0.00598145]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(47744, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.00598145 ...  0.00598145  0.\n","  0.        ], shape=(47744,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03030396]\n"," [0.02423096]\n"," [0.02423096]\n"," ...\n"," [0.006073  ]\n"," [0.006073  ]\n"," [0.006073  ]], shape=(129676, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03030396 0.02423096 0.02423096 ... 0.006073   0.006073   0.006073  ], shape=(129676,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08303833]\n"," [-0.07611084]\n"," [-0.06921387]\n"," ...\n"," [-0.06921387]\n"," [-0.06921387]\n"," [-0.06228638]], shape=(77086, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08303833 -0.07611084 -0.06921387 ... -0.06921387 -0.06921387\n"," -0.06228638], shape=(77086,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1666565 ]\n"," [-0.1394043 ]\n"," [-0.10604858]\n"," ...\n"," [-0.00302124]\n"," [ 0.00302124]\n"," [ 0.00302124]], shape=(34298, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1666565  -0.1394043  -0.10604858 ... -0.00302124  0.00302124\n","  0.00302124], shape=(34298,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03613281]\n"," [-0.04818726]\n"," [-0.0602417 ]\n"," ...\n"," [-0.04818726]\n"," [-0.0602417 ]\n"," [-0.0602417 ]], shape=(30604, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03613281 -0.04818726 -0.0602417  ... -0.04818726 -0.0602417\n"," -0.0602417 ], shape=(30604,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01000977]\n"," [-0.01000977]\n"," [-0.0249939 ]\n"," ...\n"," [-0.05499268]\n"," [-0.05999756]\n"," [-0.04501343]], shape=(45054, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01000977 -0.01000977 -0.0249939  ... -0.05499268 -0.05999756\n"," -0.04501343], shape=(45054,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02749634]\n"," [0.02874756]\n"," [0.02749634]\n"," ...\n"," [0.00750732]\n"," [0.00750732]\n"," [0.00750732]], shape=(59538, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02749634 0.02874756 0.02749634 ... 0.00750732 0.00750732 0.00750732], shape=(59538,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.25216675]\n"," [-0.18261719]\n"," [-0.09564209]\n"," ...\n"," [-0.00869751]\n"," [ 0.        ]\n"," [ 0.00869751]], shape=(40242, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.25216675 -0.18261719 -0.09564209 ... -0.00869751  0.\n","  0.00869751], shape=(40242,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14431763]\n"," [-0.13916016]\n"," [-0.13916016]\n"," ...\n"," [-0.14431763]\n"," [-0.15979004]\n"," [-0.1494751 ]], shape=(36908, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14431763 -0.13916016 -0.13916016 ... -0.14431763 -0.15979004\n"," -0.1494751 ], shape=(36908,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.32791138]\n"," [-0.33047485]\n"," [-0.3347473 ]\n"," ...\n"," [-0.17807007]\n"," [-0.17980957]\n"," [-0.18408203]], shape=(45498, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.32791138 -0.33047485 -0.3347473  ... -0.17807007 -0.17980957\n"," -0.18408203], shape=(45498,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0249939 ]\n"," [-0.0249939 ]\n"," [-0.0249939 ]\n"," ...\n"," [ 0.0062561 ]\n"," [ 0.01251221]\n"," [ 0.0249939 ]], shape=(41122, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0249939  -0.0249939  -0.0249939  ...  0.0062561   0.01251221\n","  0.0249939 ], shape=(41122,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01074219]\n"," [ 0.02151489]\n"," [ 0.02688599]\n"," ...\n"," [-0.04299927]\n"," [-0.03762817]\n"," [-0.03762817]], shape=(17958, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01074219  0.02151489  0.02688599 ... -0.04299927 -0.03762817\n"," -0.03762817], shape=(17958,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00735474]\n"," [-0.01470947]\n"," [-0.01470947]\n"," ...\n"," [-0.01470947]\n"," [-0.01470947]\n"," [-0.00735474]], shape=(37620, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00735474 -0.01470947 -0.01470947 ... -0.01470947 -0.01470947\n"," -0.00735474], shape=(37620,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0322876]\n"," [-0.0322876]\n"," [-0.0322876]\n"," ...\n"," [-0.0269165]\n"," [-0.0269165]\n"," [-0.0269165]], shape=(38444, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([-0.0322876 -0.0322876 -0.0322876 ... -0.0269165 -0.0269165 -0.0269165], shape=(38444,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03485107]\n"," [-0.03173828]\n"," [-0.03048706]\n"," ...\n"," [ 0.01092529]\n"," [ 0.00436401]\n"," [-0.00094604]], shape=(27468, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03485107 -0.03173828 -0.03048706 ...  0.01092529  0.00436401\n"," -0.00094604], shape=(27468,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02728271]\n"," [-0.0227356 ]\n"," [-0.0227356 ]\n"," ...\n"," [ 0.02728271]\n"," [ 0.03182983]\n"," [ 0.02728271]], shape=(25674, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02728271 -0.0227356  -0.0227356  ...  0.02728271  0.03182983\n","  0.02728271], shape=(25674,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00500488]\n"," [0.00375366]\n"," [0.00125122]\n"," ...\n"," [0.00125122]\n"," [0.00125122]\n"," [0.00250244]], shape=(46172, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00500488 0.00375366 0.00125122 ... 0.00125122 0.00125122 0.00250244], shape=(46172,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00244141]\n"," [0.00384521]\n"," [0.00439453]\n"," ...\n"," [0.3197937 ]\n"," [0.30847168]\n"," [0.2982483 ]], shape=(30910, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00244141 0.00384521 0.00439453 ... 0.3197937  0.30847168 0.2982483 ], shape=(30910,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10903931]\n"," [-0.09970093]\n"," [-0.07476807]\n"," ...\n"," [-0.02182007]\n"," [-0.02182007]\n"," [-0.01867676]], shape=(53538, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10903931 -0.09970093 -0.07476807 ... -0.02182007 -0.02182007\n"," -0.01867676], shape=(53538,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00375366]\n"," [-0.00500488]\n"," ...\n"," [-0.01501465]\n"," [-0.01748657]\n"," [-0.01998901]], shape=(49490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00375366 -0.00500488 ... -0.01501465 -0.01748657\n"," -0.01998901], shape=(49490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0022583 ]\n"," [-0.00189209]\n"," [-0.0022583 ]\n"," ...\n"," [-0.01098633]\n"," [-0.0090332 ]\n"," [-0.00909424]], shape=(41286, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0022583  -0.00189209 -0.0022583  ... -0.01098633 -0.0090332\n"," -0.00909424], shape=(41286,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0078125]\n"," [ 0.0078125]\n"," [ 0.015625 ]\n"," ...\n"," [-0.0078125]\n"," [-0.0078125]\n"," [-0.0078125]], shape=(26224, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0078125  0.0078125  0.015625  ... -0.0078125 -0.0078125 -0.0078125], shape=(26224,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05453491]\n"," [-0.05453491]\n"," [-0.06668091]\n"," ...\n"," [-0.07272339]\n"," [-0.06970215]\n"," [-0.06970215]], shape=(40918, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05453491 -0.05453491 -0.06668091 ... -0.07272339 -0.06970215\n"," -0.06970215], shape=(40918,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10668945]\n"," [-0.11700439]\n"," [-0.11700439]\n"," ...\n"," [ 0.08535767]\n"," [ 0.08093262]\n"," [ 0.07357788]], shape=(58316, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10668945 -0.11700439 -0.11700439 ...  0.08535767  0.08093262\n","  0.07357788], shape=(58316,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01602173]\n"," [-0.01602173]\n"," [-0.01602173]\n"," ...\n"," [-0.01480103]\n"," [-0.01849365]\n"," [-0.01602173]], shape=(38448, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01602173 -0.01602173 -0.01602173 ... -0.01480103 -0.01849365\n"," -0.01602173], shape=(38448,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03076172]\n"," [0.03460693]\n"," [0.04037476]\n"," ...\n"," [0.03460693]\n"," [0.03076172]\n"," [0.01345825]], shape=(28310, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03076172 0.03460693 0.04037476 ... 0.03460693 0.03076172 0.01345825], shape=(28310,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0161438 ]\n"," [-0.01074219]\n"," [-0.0161438 ]\n"," ...\n"," [-0.02688599]\n"," [-0.02688599]\n"," [-0.02151489]], shape=(70734, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0161438  -0.01074219 -0.0161438  ... -0.02688599 -0.02688599\n"," -0.02151489], shape=(70734,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04382324]\n"," [ 0.0335083 ]\n"," [ 0.02319336]\n"," ...\n"," [-0.01547241]\n"," [-0.00515747]\n"," [ 0.        ]], shape=(189436, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04382324  0.0335083   0.02319336 ... -0.01547241 -0.00515747\n","  0.        ], shape=(189436,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01315308]\n"," [-0.01071167]\n"," [-0.00790405]\n"," ...\n"," [-0.00241089]\n"," [-0.00262451]\n"," [-0.003479  ]], shape=(32816, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01315308 -0.01071167 -0.00790405 ... -0.00241089 -0.00262451\n"," -0.003479  ], shape=(32816,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03570557]\n"," [ 0.03060913]\n"," [ 0.0255127 ]\n"," ...\n"," [-0.01019287]\n"," [-0.00765991]\n"," [-0.00509644]], shape=(25014, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03570557  0.03060913  0.0255127  ... -0.01019287 -0.00765991\n"," -0.00509644], shape=(25014,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18603516]\n"," [-0.18603516]\n"," [-0.18603516]\n"," ...\n"," [-0.22479248]\n"," [-0.20928955]\n"," [-0.20928955]], shape=(22356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18603516 -0.18603516 -0.18603516 ... -0.22479248 -0.20928955\n"," -0.20928955], shape=(22356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00473022]\n"," [-0.00473022]\n"," [-0.00473022]\n"," ...\n"," [ 0.03695679]\n"," [ 0.03222656]\n"," [ 0.02560425]], shape=(53820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00473022 -0.00473022 -0.00473022 ...  0.03695679  0.03222656\n","  0.02560425], shape=(53820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0625   ]\n"," [ 0.0375061]\n"," [ 0.0249939]\n"," ...\n"," [-0.0062561]\n"," [-0.0062561]\n"," [-0.0062561]], shape=(42376, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0625     0.0375061  0.0249939 ... -0.0062561 -0.0062561 -0.0062561], shape=(42376,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01501465]\n"," [0.01251221]\n"," [0.01251221]\n"," ...\n"," [0.01501465]\n"," [0.01501465]\n"," [0.01251221]], shape=(60150, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01501465 0.01251221 0.01251221 ... 0.01501465 0.01501465 0.01251221], shape=(60150,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01220703]\n"," [0.01220703]\n"," [0.01220703]], shape=(20156, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01220703 0.01220703 0.01220703], shape=(20156,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05264282]\n"," [ 0.02630615]\n"," [ 0.01315308]\n"," ...\n"," [-0.05264282]\n"," [-0.01315308]\n"," [-0.01315308]], shape=(76094, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05264282  0.02630615  0.01315308 ... -0.05264282 -0.01315308\n"," -0.01315308], shape=(76094,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0105896 ]\n"," [-0.00527954]\n"," [ 0.        ]\n"," ...\n"," [ 0.        ]\n"," [ 0.00527954]\n"," [ 0.        ]], shape=(43792, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0105896  -0.00527954  0.         ...  0.          0.00527954\n","  0.        ], shape=(43792,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[5.0354004e-03]\n"," [5.1574707e-03]\n"," [5.0354004e-03]\n"," ...\n"," [3.0517578e-04]\n"," [0.0000000e+00]\n"," [3.0517578e-05]], shape=(52366, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[5.0354004e-03 5.1574707e-03 5.0354004e-03 ... 3.0517578e-04 0.0000000e+00\n"," 3.0517578e-05], shape=(52366,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0090332 ]\n"," [-0.00994873]\n"," [-0.0112915 ]\n"," ...\n"," [-0.0027771 ]\n"," [-0.0045166 ]\n"," [-0.00344849]], shape=(31362, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0090332  -0.00994873 -0.0112915  ... -0.0027771  -0.0045166\n"," -0.00344849], shape=(31362,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01879883]\n"," [-0.04702759]\n"," [-0.07211304]\n"," ...\n"," [-0.03134155]\n"," [-0.03448486]\n"," [-0.04074097]], shape=(67372, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01879883 -0.04702759 -0.07211304 ... -0.03134155 -0.03448486\n"," -0.04074097], shape=(67372,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00628662]\n"," [ 0.00628662]\n"," ...\n"," [-0.00628662]\n"," [-0.00250244]\n"," [-0.00250244]], shape=(42408, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00628662  0.00628662 ... -0.00628662 -0.00250244\n"," -0.00250244], shape=(42408,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02487183]\n"," [-0.01657104]\n"," [-0.01382446]\n"," ...\n"," [ 0.00830078]\n"," [ 0.00830078]\n"," [ 0.00830078]], shape=(23474, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02487183 -0.01657104 -0.01382446 ...  0.00830078  0.00830078\n","  0.00830078], shape=(23474,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06582642]\n"," [-0.07522583]\n"," [-0.08462524]\n"," ...\n"," [ 0.12225342]\n"," [ 0.11599731]\n"," [ 0.10345459]], shape=(39970, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06582642 -0.07522583 -0.08462524 ...  0.12225342  0.11599731\n","  0.10345459], shape=(39970,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00714111]\n"," [-0.02856445]\n"," [-0.00714111]\n"," ...\n"," [-0.16427612]\n"," [-0.2000122 ]\n"," [-0.20715332]], shape=(30730, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00714111 -0.02856445 -0.00714111 ... -0.16427612 -0.2000122\n"," -0.20715332], shape=(30730,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0173645 ]\n"," [ 0.        ]\n"," [-0.00497437]\n"," ...\n"," [-0.03723145]\n"," [-0.02481079]\n"," [-0.0173645 ]], shape=(37356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0173645   0.         -0.00497437 ... -0.03723145 -0.02481079\n"," -0.0173645 ], shape=(37356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01065063]\n"," [0.01065063]\n"," [0.01065063]\n"," ...\n"," [0.01275635]\n"," [0.01275635]\n"," [0.02127075]], shape=(47936, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01065063 0.01065063 0.01065063 ... 0.01275635 0.01275635 0.02127075], shape=(47936,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00500488]\n"," [-0.00375366]\n"," ...\n"," [ 0.0062561 ]\n"," [ 0.00500488]\n"," [ 0.00375366]], shape=(62706, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00500488 -0.00375366 ...  0.0062561   0.00500488\n","  0.00375366], shape=(62706,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00820923]\n"," [ 0.01638794]\n"," ...\n"," [ 0.        ]\n"," [-0.00820923]\n"," [ 0.        ]], shape=(86126, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00820923  0.01638794 ...  0.         -0.00820923\n","  0.        ], shape=(86126,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09622192]\n"," [-0.09329224]\n"," [-0.09329224]\n"," ...\n"," [-0.05831909]\n"," [-0.05831909]\n"," [-0.05831909]], shape=(42704, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09622192 -0.09329224 -0.09329224 ... -0.05831909 -0.05831909\n"," -0.05831909], shape=(42704,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03903198]\n"," [-0.03903198]\n"," [-0.03659058]\n"," ...\n"," [-0.03170776]\n"," [-0.03659058]\n"," [-0.03170776]], shape=(32458, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03903198 -0.03903198 -0.03659058 ... -0.03170776 -0.03659058\n"," -0.03170776], shape=(32458,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00048828]\n"," [-0.00250244]\n"," [-0.00549316]\n"," ...\n"," [ 0.00650024]\n"," [ 0.00750732]\n"," [ 0.00750732]], shape=(44824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00048828 -0.00250244 -0.00549316 ...  0.00650024  0.00750732\n","  0.00750732], shape=(44824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00201416]\n"," [-0.00448608]\n"," [-0.00601196]\n"," ...\n"," [-0.03500366]\n"," [-0.0335083 ]\n"," [-0.0335083 ]], shape=(55778, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00201416 -0.00448608 -0.00601196 ... -0.03500366 -0.0335083\n"," -0.0335083 ], shape=(55778,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03363037]\n"," [ 0.0357666 ]\n"," [ 0.03793335]\n"," ...\n"," [-0.01251221]\n"," [-0.01251221]\n"," [-0.01379395]], shape=(43930, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03363037  0.0357666   0.03793335 ... -0.01251221 -0.01251221\n"," -0.01379395], shape=(43930,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03845215]\n"," [-0.03204346]\n"," [-0.00640869]\n"," ...\n"," [-0.10256958]\n"," [-0.10256958]\n"," [-0.07693481]], shape=(18102, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03845215 -0.03204346 -0.00640869 ... -0.10256958 -0.10256958\n"," -0.07693481], shape=(18102,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03182983]\n"," [0.02996826]\n"," [0.02807617]\n"," ...\n"," [0.10113525]\n"," [0.15356445]\n"," [0.20599365]], shape=(27892, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03182983 0.02996826 0.02807617 ... 0.10113525 0.15356445 0.20599365], shape=(27892,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00808716]\n"," [-0.02023315]\n"," [-0.02023315]\n"," ...\n"," [ 0.        ]\n"," [-0.02023315]\n"," [-0.02835083]], shape=(21880, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00808716 -0.02023315 -0.02023315 ...  0.         -0.02023315\n"," -0.02835083], shape=(21880,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03479004]\n"," [-0.02609253]\n"," [-0.02609253]\n"," ...\n"," [-0.04348755]\n"," [-0.05218506]\n"," [-0.04348755]], shape=(58984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03479004 -0.02609253 -0.02609253 ... -0.04348755 -0.05218506\n"," -0.04348755], shape=(58984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1550293 ]\n"," [-0.22479248]\n"," [-0.22479248]\n"," ...\n"," [-0.18603516]\n"," [-0.18603516]\n"," [-0.18603516]], shape=(47148, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1550293  -0.22479248 -0.22479248 ... -0.18603516 -0.18603516\n"," -0.18603516], shape=(47148,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09899902]\n"," [-0.08911133]\n"," [-0.08911133]\n"," ...\n"," [-0.03466797]\n"," [-0.04455566]\n"," [-0.04455566]], shape=(30838, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09899902 -0.08911133 -0.08911133 ... -0.03466797 -0.04455566\n"," -0.04455566], shape=(30838,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07751465]\n"," [-0.07000732]\n"," [-0.07000732]\n"," ...\n"," [ 0.11499023]\n"," [ 0.125     ]\n"," [ 0.11999512]], shape=(43096, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07751465 -0.07000732 -0.07000732 ...  0.11499023  0.125\n","  0.11999512], shape=(43096,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00750732]\n"," [ 0.0085144 ]\n"," [ 0.01049805]\n"," ...\n"," [-0.01199341]\n"," [-0.01199341]\n"," [-0.01150513]], shape=(62760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00750732  0.0085144   0.01049805 ... -0.01199341 -0.01199341\n"," -0.01150513], shape=(62760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02703857]\n"," [-0.01931763]\n"," [-0.02703857]\n"," ...\n"," [ 0.01931763]\n"," [ 0.        ]\n"," [ 0.00772095]], shape=(18824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02703857 -0.01931763 -0.02703857 ...  0.01931763  0.\n","  0.00772095], shape=(18824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.30233765]\n"," [-0.28683472]\n"," [-0.26358032]\n"," ...\n"," [-0.17053223]\n"," [-0.17053223]\n"," [-0.17053223]], shape=(36004, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.30233765 -0.28683472 -0.26358032 ... -0.17053223 -0.17053223\n"," -0.17053223], shape=(36004,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02127075]\n"," [ 0.00424194]\n"," [-0.01275635]\n"," ...\n"," [ 0.03616333]\n"," [ 0.0489502 ]\n"," [ 0.06170654]], shape=(48068, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02127075  0.00424194 -0.01275635 ...  0.03616333  0.0489502\n","  0.06170654], shape=(48068,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.13537598]\n"," [-0.1446228 ]\n"," [-0.14770508]\n"," ...\n"," [-0.07998657]\n"," [-0.09844971]\n"," [-0.10153198]], shape=(64082, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.13537598 -0.1446228  -0.14770508 ... -0.07998657 -0.09844971\n"," -0.10153198], shape=(64082,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0625 ]\n"," [ 0.     ]\n"," [-0.03125]\n"," ...\n"," [ 0.     ]\n"," [ 0.03125]\n"," [ 0.03125]], shape=(41790, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0625   0.      -0.03125 ...  0.       0.03125  0.03125], shape=(41790,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.35531616]\n"," [0.34518433]\n"," [0.3197937 ]\n"," ...\n"," [0.12435913]\n"," [0.08377075]\n"," [0.02539062]], shape=(62976, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.35531616 0.34518433 0.3197937  ... 0.12435913 0.08377075 0.02539062], shape=(62976,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00576782]\n"," [ 0.01153564]\n"," [ 0.00576782]\n"," ...\n"," [-0.01730347]\n"," [-0.01730347]\n"," [-0.02880859]], shape=(39090, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00576782  0.01153564  0.00576782 ... -0.01730347 -0.01730347\n"," -0.02880859], shape=(39090,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01657104]\n"," [0.01104736]\n"," [0.01104736]\n"," ...\n"," [0.07183838]\n"," [0.07183838]\n"," [0.07183838]], shape=(22548, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01657104 0.01104736 0.01104736 ... 0.07183838 0.07183838 0.07183838], shape=(22548,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01904297]\n"," [-0.01904297]\n"," [-0.01333618]\n"," ...\n"," [-0.00189209]\n"," [-0.0038147 ]\n"," [-0.0038147 ]], shape=(38966, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01904297 -0.01904297 -0.01333618 ... -0.00189209 -0.0038147\n"," -0.0038147 ], shape=(38966,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01153564]\n"," [-0.0144043 ]\n"," [-0.01153564]\n"," ...\n"," [ 0.01730347]\n"," [ 0.0144043 ]\n"," [ 0.01730347]], shape=(48666, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01153564 -0.0144043  -0.01153564 ...  0.01730347  0.0144043\n","  0.01730347], shape=(48666,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00500488]\n"," [-0.0055542 ]\n"," [-0.00500488]\n"," ...\n"," [ 0.04656982]\n"," [ 0.05249023]\n"," [ 0.05633545]], shape=(56182, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00500488 -0.0055542  -0.00500488 ...  0.04656982  0.05249023\n","  0.05633545], shape=(56182,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.00793457]\n"," ...\n"," [0.00793457]\n"," [0.01586914]\n"," [0.01586914]], shape=(44356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.00793457 ... 0.00793457 0.01586914 0.01586914], shape=(44356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09301758]\n"," [-0.05426025]\n"," [-0.05426025]\n"," ...\n"," [-0.17053223]\n"," [-0.17053223]\n"," [-0.17053223]], shape=(41966, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09301758 -0.05426025 -0.05426025 ... -0.17053223 -0.17053223\n"," -0.17053223], shape=(41966,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01669312]\n"," [0.01806641]\n"," [0.01806641]\n"," ...\n"," [0.1182251 ]\n"," [0.09735107]\n"," [0.07369995]], shape=(53430, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01669312 0.01806641 0.01806641 ... 0.1182251  0.09735107 0.07369995], shape=(53430,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00524902]\n"," [0.00338745]\n"," [0.00262451]\n"," ...\n"," [0.02642822]\n"," [0.02105713]\n"," [0.01638794]], shape=(31800, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00524902 0.00338745 0.00262451 ... 0.02642822 0.02105713 0.01638794], shape=(31800,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00549316]\n"," [-0.00500488]\n"," [-0.00100708]\n"," ...\n"," [-0.01449585]\n"," [-0.00900269]\n"," [-0.00448608]], shape=(72628, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00549316 -0.00500488 -0.00100708 ... -0.01449585 -0.00900269\n"," -0.00448608], shape=(72628,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00772095]\n"," [0.01287842]\n"," [0.02319336]\n"," ...\n"," [0.13659668]\n"," [0.10824585]\n"," [0.07989502]], shape=(32234, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00772095 0.01287842 0.02319336 ... 0.13659668 0.10824585 0.07989502], shape=(32234,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.14285278]\n"," ...\n"," [ 0.        ]\n"," [ 0.14285278]\n"," [ 0.        ]], shape=(36820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.14285278 ...  0.          0.14285278\n","  0.        ], shape=(36820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.70666504]\n"," [ 0.70581055]\n"," [ 0.70492554]\n"," ...\n"," [-0.4124756 ]\n"," [-0.40289307]\n"," [-0.39328003]], shape=(52784, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.70666504  0.70581055  0.70492554 ... -0.4124756  -0.40289307\n"," -0.39328003], shape=(52784,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00598145]\n"," [-0.00598145]\n"," [ 0.        ]], shape=(49274, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145  0.          0.         ... -0.00598145 -0.00598145\n","  0.        ], shape=(49274,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04998779]\n"," [ 0.00714111]\n"," [ 0.07144165]\n"," ...\n"," [-0.01428223]\n"," [-0.01428223]\n"," [-0.03570557]], shape=(49362, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04998779  0.00714111  0.07144165 ... -0.01428223 -0.01428223\n"," -0.03570557], shape=(49362,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00823975]\n"," [-0.0105896 ]\n"," [-0.00704956]\n"," ...\n"," [-0.01412964]\n"," [-0.00823975]\n"," [-0.00588989]], shape=(35336, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00823975 -0.0105896  -0.00704956 ... -0.01412964 -0.00823975\n"," -0.00588989], shape=(35336,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00250244]\n"," [-0.00250244]\n"," [-0.00299072]\n"," ...\n"," [-0.00350952]\n"," [-0.0045166 ]\n"," [-0.00350952]], shape=(44754, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00250244 -0.00250244 -0.00299072 ... -0.00350952 -0.0045166\n"," -0.00350952], shape=(44754,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01428223]\n"," [0.01428223]\n"," [0.01428223]\n"," ...\n"," [0.07144165]\n"," [0.08572388]\n"," [0.07144165]], shape=(60282, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01428223 0.01428223 0.01428223 ... 0.07144165 0.08572388 0.07144165], shape=(60282,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.3440857 ]\n"," [-0.38171387]\n"," [-0.40859985]\n"," ...\n"," [-0.09140015]\n"," [-0.09140015]\n"," [-0.12902832]], shape=(18216, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.3440857  -0.38171387 -0.40859985 ... -0.09140015 -0.09140015\n"," -0.12902832], shape=(18216,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.16455078]\n"," [-0.17721558]\n"," [-0.15188599]\n"," ...\n"," [ 0.05062866]\n"," [ 0.05062866]\n"," [ 0.06329346]], shape=(84270, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.16455078 -0.17721558 -0.15188599 ...  0.05062866  0.05062866\n","  0.06329346], shape=(84270,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05532837]\n"," [ 0.05371094]\n"," [ 0.04882812]\n"," ...\n"," [-0.01220703]\n"," [-0.01220703]\n"," [-0.0105896 ]], shape=(53862, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05532837  0.05371094  0.04882812 ... -0.01220703 -0.01220703\n"," -0.0105896 ], shape=(53862,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05926514]\n"," [ 0.03607178]\n"," [ 0.01287842]\n"," ...\n"," [ 0.        ]\n"," [-0.01031494]\n"," [-0.01803589]], shape=(35902, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05926514  0.03607178  0.01287842 ...  0.         -0.01031494\n"," -0.01803589], shape=(35902,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10366821]\n"," [-0.09146118]\n"," [-0.07318115]\n"," ...\n"," [ 0.00610352]\n"," [ 0.00610352]\n"," [ 0.00610352]], shape=(56990, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10366821 -0.09146118 -0.07318115 ...  0.00610352  0.00610352\n","  0.00610352], shape=(56990,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05023193]\n"," [ 0.03790283]\n"," [ 0.02996826]\n"," ...\n"," [-0.10308838]\n"," [-0.11013794]\n"," [-0.11190796]], shape=(41230, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05023193  0.03790283  0.02996826 ... -0.10308838 -0.11013794\n"," -0.11190796], shape=(41230,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02612305]\n"," [ 0.00521851]\n"," [ 0.01306152]\n"," ...\n"," [-0.02612305]\n"," [-0.01828003]\n"," [-0.01828003]], shape=(65810, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02612305  0.00521851  0.01306152 ... -0.02612305 -0.01828003\n"," -0.01828003], shape=(65810,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0065918 ]\n"," [0.01974487]\n"," [0.02960205]\n"," ...\n"," [0.02960205]\n"," [0.03289795]\n"," [0.02960205]], shape=(51890, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0065918  0.01974487 0.02960205 ... 0.02960205 0.03289795 0.02960205], shape=(51890,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00048828]\n"," [0.00299072]\n"," [0.00650024]\n"," ...\n"," [0.00500488]\n"," [0.00350952]\n"," [0.00299072]], shape=(32046, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00048828 0.00299072 0.00650024 ... 0.00500488 0.00350952 0.00299072], shape=(32046,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02151489]\n"," [-0.02151489]\n"," [-0.0279541 ]\n"," ...\n"," [-0.01074219]\n"," [-0.01074219]\n"," [-0.01074219]], shape=(36604, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02151489 -0.02151489 -0.0279541  ... -0.01074219 -0.01074219\n"," -0.01074219], shape=(36604,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02423096]\n"," [ 0.03030396]\n"," [ 0.03030396]\n"," ...\n"," [-0.03030396]\n"," [-0.03030396]\n"," [-0.02423096]], shape=(25850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02423096  0.03030396  0.03030396 ... -0.03030396 -0.03030396\n"," -0.02423096], shape=(25850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0057373 ]\n"," [-0.0057373 ]\n"," [-0.02865601]\n"," ...\n"," [ 0.01431274]\n"," [ 0.0057373 ]\n"," [ 0.0057373 ]], shape=(32668, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0057373  -0.0057373  -0.02865601 ...  0.01431274  0.0057373\n","  0.0057373 ], shape=(32668,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02072144]\n"," [0.01037598]\n"," [0.01037598]\n"," ...\n"," [0.02590942]\n"," [0.02590942]\n"," [0.03109741]], shape=(38444, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02072144 0.01037598 0.01037598 ... 0.02590942 0.02590942 0.03109741], shape=(38444,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01040649]\n"," [0.        ]\n"," [0.01040649]\n"," ...\n"," [0.        ]\n"," [0.02084351]\n"," [0.01040649]], shape=(26804, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01040649 0.         0.01040649 ... 0.         0.02084351 0.01040649], shape=(26804,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.32156372]\n"," [ 0.3333435 ]\n"," [ 0.34509277]\n"," ...\n"," [-0.00784302]\n"," [-0.01177979]\n"," [-0.01177979]], shape=(36670, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.32156372  0.3333435   0.34509277 ... -0.00784302 -0.01177979\n"," -0.01177979], shape=(36670,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05453491]\n"," [-0.23635864]\n"," [-0.21817017]\n"," ...\n"," [-0.08728027]\n"," [-0.08728027]\n"," [-0.07998657]], shape=(38270, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05453491 -0.23635864 -0.21817017 ... -0.08728027 -0.08728027\n"," -0.07998657], shape=(38270,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01998901]\n"," [0.02124023]\n"," [0.02124023]\n"," ...\n"," [0.00750732]\n"," [0.00875854]\n"," [0.00750732]], shape=(79340, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01998901 0.02124023 0.02124023 ... 0.00750732 0.00875854 0.00750732], shape=(79340,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00305176]\n"," [0.00442505]\n"," [0.006073  ]\n"," ...\n"," [0.09680176]\n"," [0.09118652]\n"," [0.08581543]], shape=(35186, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00305176 0.00442505 0.006073   ... 0.09680176 0.09118652 0.08581543], shape=(35186,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.25842285]\n"," [ 0.31085205]\n"," [ 0.35766602]\n"," ...\n"," [-0.06365967]\n"," [-0.08987427]\n"," [-0.11236572]], shape=(72480, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.25842285  0.31085205  0.35766602 ... -0.06365967 -0.08987427\n"," -0.11236572], shape=(72480,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03179932]\n"," [-0.03179932]\n"," [-0.02600098]\n"," ...\n"," [ 0.02890015]\n"," [ 0.03466797]\n"," [ 0.03756714]], shape=(46478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03179932 -0.03179932 -0.02600098 ...  0.02890015  0.03466797\n","  0.03756714], shape=(46478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05593872]\n"," [-0.04046631]\n"," [-0.0279541 ]\n"," ...\n"," [-0.01766968]\n"," [-0.01470947]\n"," [-0.01251221]], shape=(82878, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05593872 -0.04046631 -0.0279541  ... -0.01766968 -0.01470947\n"," -0.01251221], shape=(82878,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18121338]\n"," [-0.18121338]\n"," [-0.18121338]\n"," ...\n"," [-0.34228516]\n"," [-0.34228516]\n"," [-0.30871582]], shape=(22950, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18121338 -0.18121338 -0.18121338 ... -0.34228516 -0.34228516\n"," -0.30871582], shape=(22950,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01470947]\n"," [-0.02450562]\n"," [-0.02450562]\n"," ...\n"," [-0.00244141]\n"," [-0.00491333]\n"," [-0.00244141]], shape=(64190, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01470947 -0.02450562 -0.02450562 ... -0.00244141 -0.00491333\n"," -0.00244141], shape=(64190,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15826416]\n"," [-0.18344116]\n"," [-0.21221924]\n"," ...\n"," [-0.07913208]\n"," [-0.08633423]\n"," [-0.10430908]], shape=(201940, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15826416 -0.18344116 -0.21221924 ... -0.07913208 -0.08633423\n"," -0.10430908], shape=(201940,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00201416]\n"," [-0.00048828]\n"," [-0.00048828]\n"," ...\n"," [-0.04748535]\n"," [-0.04150391]\n"," [-0.03250122]], shape=(46332, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00201416 -0.00048828 -0.00048828 ... -0.04748535 -0.04150391\n"," -0.03250122], shape=(46332,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01730347]\n"," [-0.01986694]\n"," [-0.01730347]\n"," ...\n"," [-0.01281738]\n"," [-0.01730347]\n"," [-0.02050781]], shape=(60476, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01730347 -0.01986694 -0.01730347 ... -0.01281738 -0.01730347\n"," -0.02050781], shape=(60476,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.     ]\n"," [0.03125]\n"," [0.03125]\n"," ...\n"," [0.     ]\n"," [0.     ]\n"," [0.     ]], shape=(25174, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.      0.03125 0.03125 ... 0.      0.      0.     ], shape=(25174,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0329895 ]\n"," [ 0.02310181]\n"," [ 0.01651001]\n"," ...\n"," [-0.0032959 ]\n"," [-0.0065918 ]\n"," [-0.0065918 ]], shape=(55370, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0329895   0.02310181  0.01651001 ... -0.0032959  -0.0065918\n"," -0.0065918 ], shape=(55370,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.00131226]\n"," [ 0.00131226]\n"," ...\n"," [-0.10891724]\n"," [-0.0892334 ]\n"," [-0.06954956]], shape=(18522, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.00131226  0.00131226 ... -0.10891724 -0.0892334\n"," -0.06954956], shape=(18522,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00772095]\n"," [-0.01931763]\n"," [-0.01931763]\n"," ...\n"," [-0.00772095]\n"," [ 0.        ]\n"," [-0.00772095]], shape=(46516, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00772095 -0.01931763 -0.01931763 ... -0.00772095  0.\n"," -0.00772095], shape=(46516,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01974487]\n"," [-0.01974487]\n"," [-0.01644897]\n"," ...\n"," [ 0.29605103]\n"," [ 0.32235718]\n"," [ 0.34210205]], shape=(43822, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01974487 -0.01974487 -0.01644897 ...  0.29605103  0.32235718\n","  0.34210205], shape=(43822,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01013184]\n"," [ 0.00073242]\n"," [ 0.01196289]\n"," ...\n"," [-0.01306152]\n"," [-0.02038574]\n"," [-0.02993774]], shape=(28662, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01013184  0.00073242  0.01196289 ... -0.01306152 -0.02038574\n"," -0.02993774], shape=(28662,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.01818848]\n"," [-0.0333252 ]\n"," ...\n"," [-0.1394043 ]\n"," [-0.10302734]\n"," [-0.07272339]], shape=(70572, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.01818848 -0.0333252  ... -0.1394043  -0.10302734\n"," -0.07272339], shape=(70572,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0062561 ]\n"," [ 0.00375366]\n"," [ 0.00250244]\n"," ...\n"," [-0.00500488]\n"," [-0.00500488]\n"," [-0.00500488]], shape=(53972, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0062561   0.00375366  0.00250244 ... -0.00500488 -0.00500488\n"," -0.00500488], shape=(53972,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04177856]\n"," [-0.03341675]\n"," [-0.03341675]\n"," ...\n"," [-0.0557251 ]\n"," [-0.0557251 ]\n"," [-0.0557251 ]], shape=(45548, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04177856 -0.03341675 -0.03341675 ... -0.0557251  -0.0557251\n"," -0.0557251 ], shape=(45548,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0072937 ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00485229]\n"," [-0.0072937 ]\n"," [-0.00485229]], shape=(35224, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0072937   0.          0.         ... -0.00485229 -0.0072937\n"," -0.00485229], shape=(35224,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02612305]\n"," [ 0.01480103]\n"," [ 0.00436401]\n"," ...\n"," [-0.07107544]\n"," [-0.05664062]\n"," [-0.0428772 ]], shape=(31034, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02612305  0.01480103  0.00436401 ... -0.07107544 -0.05664062\n"," -0.0428772 ], shape=(31034,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0980835 ]\n"," [-0.10961914]\n"," [-0.11923218]\n"," ...\n"," [-0.02307129]\n"," [-0.02883911]\n"," [-0.02883911]], shape=(45400, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0980835  -0.10961914 -0.11923218 ... -0.02307129 -0.02883911\n"," -0.02883911], shape=(45400,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03091431]\n"," [0.04122925]\n"," [0.04898071]\n"," ...\n"," [0.02062988]\n"," [0.01803589]\n"," [0.01547241]], shape=(25886, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03091431 0.04122925 0.04898071 ... 0.02062988 0.01803589 0.01547241], shape=(25886,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00048828]\n"," [0.00485229]\n"," [0.00360107]\n"," ...\n"," [0.00302124]\n"," [0.00415039]\n"," [0.00085449]], shape=(27354, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00048828 0.00485229 0.00360107 ... 0.00302124 0.00415039 0.00085449], shape=(27354,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03060913]\n"," [-0.02844238]\n"," [-0.02328491]\n"," ...\n"," [-0.01464844]\n"," [-0.01464844]\n"," [-0.01596069]], shape=(27678, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03060913 -0.02844238 -0.02328491 ... -0.01464844 -0.01464844\n"," -0.01596069], shape=(27678,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0234375]\n"," [ 0.03125  ]\n"," [ 0.03125  ]\n"," ...\n"," [-0.1171875]\n"," [-0.1015625]\n"," [-0.0859375]], shape=(35728, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0234375  0.03125    0.03125   ... -0.1171875 -0.1015625 -0.0859375], shape=(35728,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01345825]\n"," [ 0.01391602]\n"," [ 0.01416016]\n"," ...\n"," [-0.01602173]\n"," [-0.01654053]\n"," [-0.0151062 ]], shape=(51278, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01345825  0.01391602  0.01416016 ... -0.01602173 -0.01654053\n"," -0.0151062 ], shape=(51278,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0625 ]\n"," [ 0.03125]\n"," [ 0.03125]\n"," ...\n"," [ 0.     ]\n"," [ 0.     ]\n"," [-0.03125]], shape=(46814, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0625   0.03125  0.03125 ...  0.       0.      -0.03125], shape=(46814,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05413818]\n"," [-0.05670166]\n"," [-0.05413818]\n"," ...\n"," [ 0.07733154]\n"," [ 0.0670166 ]\n"," [ 0.05670166]], shape=(82218, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05413818 -0.05670166 -0.05413818 ...  0.07733154  0.0670166\n","  0.05670166], shape=(82218,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08026123]\n"," [-0.07705688]\n"," [-0.0730896 ]\n"," ...\n"," [ 0.49014282]\n"," [ 0.47628784]\n"," [ 0.46398926]], shape=(33824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08026123 -0.07705688 -0.0730896  ...  0.49014282  0.47628784\n","  0.46398926], shape=(33824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.18389893]\n"," [-0.1666565 ]\n"," [-0.14367676]\n"," ...\n"," [-0.03448486]\n"," [-0.02874756]\n"," [-0.03448486]], shape=(43560, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.18389893 -0.1666565  -0.14367676 ... -0.03448486 -0.02874756\n"," -0.03448486], shape=(43560,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.14544678]\n"," [0.15151978]\n"," [0.16363525]\n"," ...\n"," [0.04849243]\n"," [0.06060791]\n"," [0.06668091]], shape=(45980, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.14544678 0.15151978 0.16363525 ... 0.04849243 0.06060791 0.06668091], shape=(45980,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07318115]\n"," [-0.09146118]\n"," [-0.0975647 ]\n"," ...\n"," [-0.03048706]\n"," [-0.03048706]\n"," [-0.03048706]], shape=(38060, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07318115 -0.09146118 -0.0975647  ... -0.03048706 -0.03048706\n"," -0.03048706], shape=(38060,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00213623]\n"," [-0.00213623]\n"," ...\n"," [ 0.0085144 ]\n"," [ 0.00424194]\n"," [ 0.00424194]], shape=(42770, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00213623 -0.00213623 ...  0.0085144   0.00424194\n","  0.00424194], shape=(42770,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00543213]\n"," [-0.0135498 ]\n"," [ 0.        ]\n"," ...\n"," [-0.02709961]\n"," [-0.02709961]\n"," [-0.01898193]], shape=(77432, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00543213 -0.0135498   0.         ... -0.02709961 -0.02709961\n"," -0.01898193], shape=(77432,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00372314]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.18588257]\n"," [ 0.17843628]\n"," [ 0.16357422]], shape=(36752, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00372314  0.          0.         ...  0.18588257  0.17843628\n","  0.16357422], shape=(36752,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0057373 ]\n"," [-0.0057373 ]\n"," [-0.01724243]\n"," ...\n"," [-0.18389893]\n"," [-0.20114136]\n"," [-0.19540405]], shape=(37618, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0057373  -0.0057373  -0.01724243 ... -0.18389893 -0.20114136\n"," -0.19540405], shape=(37618,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0234375]\n"," [ 0.0234375]\n"," [ 0.03125  ]\n"," ...\n"," [ 0.015625 ]\n"," [ 0.0078125]\n"," [-0.0078125]], shape=(32188, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0234375  0.0234375  0.03125   ...  0.015625   0.0078125 -0.0078125], shape=(32188,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0062561 ]\n"," [ 0.        ]\n"," [-0.0249939 ]\n"," ...\n"," [ 0.09375   ]\n"," [ 0.08123779]\n"," [ 0.0687561 ]], shape=(45858, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0062561   0.         -0.0249939  ...  0.09375     0.08123779\n","  0.0687561 ], shape=(45858,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07589722]\n"," [ 0.10562134]\n"," [ 0.13861084]\n"," ...\n"," [-0.0032959 ]\n"," [ 0.0032959 ]\n"," [ 0.0065918 ]], shape=(34446, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07589722  0.10562134  0.13861084 ... -0.0032959   0.0032959\n","  0.0065918 ], shape=(34446,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00292969]\n"," [ 0.        ]\n"," [-0.00588989]\n"," ...\n"," [ 0.00881958]\n"," [ 0.00735474]\n"," [ 0.00588989]], shape=(29490, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00292969  0.         -0.00588989 ...  0.00881958  0.00735474\n","  0.00588989], shape=(29490,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.2026062 ]\n"," [-0.21569824]\n"," [-0.22875977]\n"," ...\n"," [-0.13726807]\n"," [-0.14379883]\n"," [-0.15686035]], shape=(42532, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.2026062  -0.21569824 -0.22875977 ... -0.13726807 -0.14379883\n"," -0.15686035], shape=(42532,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.15823364]\n"," [-0.24050903]\n"," [-0.32278442]\n"," ...\n"," [ 0.09494019]\n"," [ 0.09494019]\n"," [ 0.10760498]], shape=(71360, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.15823364 -0.24050903 -0.32278442 ...  0.09494019  0.09494019\n","  0.10760498], shape=(71360,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01226807]\n"," [0.01226807]\n"," [0.01226807]\n"," ...\n"," [0.0736084 ]\n"," [0.07974243]\n"," [0.07974243]], shape=(74760, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01226807 0.01226807 0.01226807 ... 0.0736084  0.07974243 0.07974243], shape=(74760,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03704834]\n"," [-0.03329468]\n"," [-0.02966309]\n"," ...\n"," [ 0.11566162]\n"," [ 0.08551025]\n"," [ 0.0458374 ]], shape=(36436, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03704834 -0.03329468 -0.02966309 ...  0.11566162  0.08551025\n","  0.0458374 ], shape=(36436,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.18569946]\n"," [0.1928711 ]\n"," [0.18569946]\n"," ...\n"," [0.08572388]\n"," [0.07144165]\n"," [0.04284668]], shape=(24608, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.18569946 0.1928711  0.18569946 ... 0.08572388 0.07144165 0.04284668], shape=(24608,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06817627]\n"," [-0.06817627]\n"," [-0.06817627]\n"," ...\n"," [-0.05114746]\n"," [-0.0625    ]\n"," [-0.06817627]], shape=(41666, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06817627 -0.06817627 -0.06817627 ... -0.05114746 -0.0625\n"," -0.06817627], shape=(41666,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.20343018]\n"," [-0.1446228 ]\n"," [-0.08334351]\n"," ...\n"," [ 0.00979614]\n"," [-0.01470947]\n"," [-0.03186035]], shape=(20618, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.20343018 -0.1446228  -0.08334351 ...  0.00979614 -0.01470947\n"," -0.03186035], shape=(20618,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.8826599 ]\n"," [-0.8813782 ]\n"," [-0.8805542 ]\n"," ...\n"," [ 0.15997314]\n"," [ 0.15661621]\n"," [ 0.15280151]], shape=(34440, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.8826599  -0.8813782  -0.8805542  ...  0.15997314  0.15661621\n","  0.15280151], shape=(34440,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03329468]\n"," [-0.03451538]\n"," [-0.03329468]\n"," ...\n"," [-0.07644653]\n"," [-0.09371948]\n"," [-0.10357666]], shape=(54266, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03329468 -0.03451538 -0.03329468 ... -0.07644653 -0.09371948\n"," -0.10357666], shape=(54266,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01168823]\n"," [-0.01168823]\n"," [-0.01168823]\n"," ...\n"," [ 0.02923584]\n"," [ 0.04092407]\n"," [ 0.04092407]], shape=(99888, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01168823 -0.01168823 -0.01168823 ...  0.02923584  0.04092407\n","  0.04092407], shape=(99888,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.02630615]\n"," [ 0.02630615]\n"," ...\n"," [-0.05264282]\n"," [-0.05264282]\n"," [-0.05264282]], shape=(25804, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.02630615  0.02630615 ... -0.05264282 -0.05264282\n"," -0.05264282], shape=(25804,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.09844971]\n"," [-0.0892334 ]\n"," [-0.07693481]\n"," ...\n"," [ 0.04309082]\n"," [ 0.04309082]\n"," [ 0.04000854]], shape=(16238, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.09844971 -0.0892334  -0.07693481 ...  0.04309082  0.04309082\n","  0.04000854], shape=(16238,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04293823]\n"," [ 0.0368042 ]\n"," [ 0.0368042 ]\n"," ...\n"," [-0.01226807]\n"," [-0.0184021 ]\n"," [-0.01226807]], shape=(44808, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04293823  0.0368042   0.0368042  ... -0.01226807 -0.0184021\n"," -0.01226807], shape=(44808,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.00534058]\n"," ...\n"," [ 0.0267334 ]\n"," [ 0.03744507]\n"," [ 0.03744507]], shape=(53916, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.00534058 ...  0.0267334   0.03744507\n","  0.03744507], shape=(53916,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.17648315]\n"," [ 0.18136597]\n"," [ 0.19363403]\n"," ...\n"," [ 0.00244141]\n"," [ 0.00491333]\n"," [-0.00244141]], shape=(57144, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.17648315  0.18136597  0.19363403 ...  0.00244141  0.00491333\n"," -0.00244141], shape=(57144,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.1499939 ]\n"," [ 0.1227417 ]\n"," [ 0.10455322]\n"," ...\n"," [-0.01135254]\n"," [ 0.        ]\n"," [-0.01589966]], shape=(82592, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.1499939   0.1227417   0.10455322 ... -0.01135254  0.\n"," -0.01589966], shape=(82592,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02902222]\n"," [-0.03793335]\n"," [-0.04910278]\n"," ...\n"," [ 0.04910278]\n"," [ 0.05133057]\n"," [ 0.046875  ]], shape=(52514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02902222 -0.03793335 -0.04910278 ...  0.04910278  0.05133057\n","  0.046875  ], shape=(52514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04336548]\n"," [-0.04336548]\n"," [-0.04336548]\n"," ...\n"," [-0.02023315]\n"," [-0.02023315]\n"," [-0.02600098]], shape=(82116, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04336548 -0.04336548 -0.04336548 ... -0.02023315 -0.02023315\n"," -0.02600098], shape=(82116,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01245117]\n"," [-0.01245117]\n"," [-0.00311279]\n"," ...\n"," [-0.05606079]\n"," [-0.05606079]\n"," [-0.06231689]], shape=(23820, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01245117 -0.01245117 -0.00311279 ... -0.05606079 -0.05606079\n"," -0.06231689], shape=(23820,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01422119]\n"," [ 0.01138306]\n"," [ 0.00949097]\n"," ...\n"," [-0.01422119]\n"," [-0.01422119]\n"," [-0.01611328]], shape=(29752, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01422119  0.01138306  0.00949097 ... -0.01422119 -0.01422119\n"," -0.01611328], shape=(29752,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00256348]\n"," [ 0.00064087]\n"," [ 0.00320435]\n"," ...\n"," [-0.00704956]\n"," [-0.00640869]\n"," [-0.00576782]], shape=(20776, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00256348  0.00064087  0.00320435 ... -0.00704956 -0.00640869\n"," -0.00576782], shape=(20776,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03762817]\n"," [-0.03762817]\n"," [-0.05377197]\n"," ...\n"," [-0.03762817]\n"," [-0.03762817]\n"," [-0.02688599]], shape=(45174, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03762817 -0.03762817 -0.05377197 ... -0.03762817 -0.03762817\n"," -0.02688599], shape=(45174,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02139282]\n"," [ 0.02139282]\n"," [ 0.01068115]\n"," ...\n"," [-0.02139282]\n"," [-0.02139282]\n"," [-0.01605225]], shape=(61408, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02139282  0.02139282  0.01068115 ... -0.02139282 -0.02139282\n"," -0.01605225], shape=(61408,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00848389]\n"," [-0.01037598]\n"," [-0.00848389]\n"," ...\n"," [-0.04806519]\n"," [-0.03390503]\n"," [-0.01925659]], shape=(36842, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00848389 -0.01037598 -0.00848389 ... -0.04806519 -0.03390503\n"," -0.01925659], shape=(36842,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00473022]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.01885986]\n"," [ 0.01885986]\n"," [ 0.02359009]], shape=(80302, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00473022  0.          0.         ...  0.01885986  0.01885986\n","  0.02359009], shape=(80302,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.        ]\n"," [-0.01824951]\n"," [-0.01824951]], shape=(32642, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.         -0.01824951\n"," -0.01824951], shape=(32642,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01040649]\n"," [0.02084351]\n"," [0.02084351]\n"," ...\n"," [0.02084351]\n"," [0.02084351]\n"," [0.04165649]], shape=(38588, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01040649 0.02084351 0.02084351 ... 0.02084351 0.02084351 0.04165649], shape=(38588,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.10858154]\n"," [0.10858154]\n"," [0.10858154]\n"," ...\n"," [0.1793518 ]\n"," [0.18157959]\n"," [0.18469238]], shape=(31514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.10858154 0.10858154 0.10858154 ... 0.1793518  0.18157959 0.18469238], shape=(31514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03411865]\n"," [-0.03411865]\n"," [-0.02706909]\n"," ...\n"," [-0.00469971]\n"," [-0.00704956]\n"," [-0.00469971]], shape=(47356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03411865 -0.03411865 -0.02706909 ... -0.00469971 -0.00704956\n"," -0.00469971], shape=(47356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01577759]\n"," [-0.0163269 ]\n"," [-0.01577759]\n"," ...\n"," [ 0.00866699]\n"," [ 0.00790405]\n"," [ 0.00701904]], shape=(42400, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01577759 -0.0163269  -0.01577759 ...  0.00866699  0.00790405\n","  0.00701904], shape=(42400,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1111145 ]\n"," [-0.13070679]\n"," [-0.13070679]\n"," ...\n"," [-0.14379883]\n"," [-0.14379883]\n"," [-0.13726807]], shape=(19830, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1111145  -0.13070679 -0.13070679 ... -0.14379883 -0.14379883\n"," -0.13726807], shape=(19830,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.06790161]\n"," [0.06936646]\n"," [0.06936646]\n"," ...\n"," [0.03567505]\n"," [0.03811646]\n"," [0.04055786]], shape=(42714, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.06790161 0.06936646 0.06936646 ... 0.03567505 0.03811646 0.04055786], shape=(42714,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01651001]\n"," [0.01651001]\n"," [0.01980591]\n"," ...\n"," [0.02310181]\n"," [0.01651001]\n"," [0.01321411]], shape=(35558, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01651001 0.01651001 0.01980591 ... 0.02310181 0.01651001 0.01321411], shape=(35558,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00515747]\n"," [-0.00515747]\n"," [-0.00430298]\n"," ...\n"," [-0.00860596]\n"," [-0.00949097]\n"," [-0.00860596]], shape=(77814, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00515747 -0.00515747 -0.00430298 ... -0.00860596 -0.00949097\n"," -0.00860596], shape=(77814,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02078247]\n"," [-0.01818848]\n"," [-0.01559448]\n"," ...\n"," [ 0.04675293]\n"," [ 0.02597046]\n"," [ 0.00518799]], shape=(89962, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02078247 -0.01818848 -0.01559448 ...  0.04675293  0.02597046\n","  0.00518799], shape=(89962,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.29501343]\n"," [-0.23999023]\n"," [-0.17999268]\n"," ...\n"," [-0.05249023]\n"," [-0.04748535]\n"," [-0.0249939 ]], shape=(101520, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.29501343 -0.23999023 -0.17999268 ... -0.05249023 -0.04748535\n"," -0.0249939 ], shape=(101520,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00817871]\n"," [-0.0105896 ]\n"," [-0.00964355]\n"," ...\n"," [-0.00335693]\n"," [-0.00482178]\n"," [-0.00817871]], shape=(96952, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00817871 -0.0105896  -0.00964355 ... -0.00335693 -0.00482178\n"," -0.00817871], shape=(96952,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05377197]\n"," [-0.02688599]\n"," [-0.03762817]\n"," ...\n"," [-0.12902832]\n"," [-0.1559143 ]\n"," [-0.1720581 ]], shape=(25882, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05377197 -0.02688599 -0.03762817 ... -0.12902832 -0.1559143\n"," -0.1720581 ], shape=(25882,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01126099]\n"," [-0.01126099]\n"," [-0.01376343]\n"," ...\n"," [-0.00125122]\n"," [ 0.        ]\n"," [ 0.00250244]], shape=(76150, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01126099 -0.01126099 -0.01376343 ... -0.00125122  0.\n","  0.00250244], shape=(76150,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07757568]\n"," [-0.07757568]\n"," [-0.08621216]\n"," ...\n"," [-0.04309082]\n"," [-0.04309082]\n"," [-0.06033325]], shape=(28884, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07757568 -0.07757568 -0.08621216 ... -0.04309082 -0.04309082\n"," -0.06033325], shape=(28884,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00161743]\n"," [ 0.00161743]\n"," [ 0.00161743]\n"," ...\n"," [-0.00323486]\n"," [-0.00323486]\n"," [-0.00161743]], shape=(71878, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00161743  0.00161743  0.00161743 ... -0.00323486 -0.00323486\n"," -0.00161743], shape=(71878,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00448608]\n"," [0.00350952]\n"," [0.00350952]\n"," ...\n"," [0.00448608]\n"," [0.00299072]\n"," [0.00100708]], shape=(61530, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00448608 0.00350952 0.00350952 ... 0.00448608 0.00299072 0.00100708], shape=(61530,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01177979]\n"," [-0.01412964]\n"," [-0.01647949]\n"," ...\n"," [ 0.38589478]\n"," [ 0.41412354]\n"," [ 0.4258728 ]], shape=(39092, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01177979 -0.01412964 -0.01647949 ...  0.38589478  0.41412354\n","  0.4258728 ], shape=(39092,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00949097]\n"," [-0.0100708 ]\n"," [-0.00949097]\n"," ...\n"," [-0.0272522 ]\n"," [-0.03198242]\n"," [-0.0402832 ]], shape=(28450, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00949097 -0.0100708  -0.00949097 ... -0.0272522  -0.03198242\n"," -0.0402832 ], shape=(28450,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.08572388]\n"," [ 0.08572388]\n"," [ 0.07144165]\n"," ...\n"," [-0.47143555]\n"," [-0.48571777]\n"," [-0.47143555]], shape=(36498, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.08572388  0.08572388  0.07144165 ... -0.47143555 -0.48571777\n"," -0.47143555], shape=(36498,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00918579]\n"," [-0.00918579]\n"," ...\n"," [ 0.01834106]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(93844, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00918579 -0.00918579 ...  0.01834106  0.\n","  0.        ], shape=(93844,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03808594]\n"," [-0.03237915]\n"," [-0.03808594]\n"," ...\n"," [-0.08380127]\n"," [-0.07427979]\n"," [-0.0609436 ]], shape=(36222, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03808594 -0.03237915 -0.03808594 ... -0.08380127 -0.07427979\n"," -0.0609436 ], shape=(36222,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0038147 ]\n"," [-0.01141357]\n"," [-0.01333618]\n"," ...\n"," [ 0.0038147 ]\n"," [ 0.01141357]\n"," [ 0.01333618]], shape=(33264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0038147  -0.01141357 -0.01333618 ...  0.0038147   0.01141357\n","  0.01333618], shape=(33264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00161743]\n"," [ 0.00161743]\n"," [ 0.00161743]\n"," ...\n"," [-0.0161438 ]\n"," [-0.01776123]\n"," [-0.02099609]], shape=(34718, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00161743  0.00161743  0.00161743 ... -0.0161438  -0.01776123\n"," -0.02099609], shape=(34718,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02047729]\n"," [0.03411865]\n"," [0.02389526]\n"," ...\n"," [0.04437256]\n"," [0.05459595]\n"," [0.0512085 ]], shape=(22458, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02047729 0.03411865 0.02389526 ... 0.04437256 0.05459595 0.0512085 ], shape=(22458,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03265381]\n"," [-0.03057861]\n"," [-0.0291748 ]\n"," ...\n"," [-0.04919434]\n"," [-0.04818726]\n"," [-0.04647827]], shape=(20722, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03265381 -0.03057861 -0.0291748  ... -0.04919434 -0.04818726\n"," -0.04647827], shape=(20722,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00326538]\n"," [ 0.00326538]\n"," [ 0.00326538]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [-0.00326538]], shape=(128458, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00326538  0.00326538  0.00326538 ...  0.          0.\n"," -0.00326538], shape=(128458,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02178955]\n"," [-0.02178955]\n"," [-0.02178955]\n"," ...\n"," [-0.00436401]\n"," [-0.01525879]\n"," [-0.02178955]], shape=(31888, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02178955 -0.02178955 -0.02178955 ... -0.00436401 -0.01525879\n"," -0.02178955], shape=(31888,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03030396]\n"," [-0.01211548]\n"," [-0.02423096]\n"," ...\n"," [-0.03030396]\n"," [-0.06668091]\n"," [-0.10302734]], shape=(53704, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03030396 -0.01211548 -0.02423096 ... -0.03030396 -0.06668091\n"," -0.10302734], shape=(53704,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06723022]\n"," [-0.06091309]\n"," [-0.05673218]\n"," ...\n"," [-0.03570557]\n"," [-0.04202271]\n"," [-0.04202271]], shape=(28086, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06723022 -0.06091309 -0.05673218 ... -0.03570557 -0.04202271\n"," -0.04202271], shape=(28086,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00598145]\n"," [ 0.0149231 ]\n"," [ 0.00598145]\n"," ...\n"," [ 0.        ]\n"," [-0.00598145]\n"," [ 0.        ]], shape=(44174, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00598145  0.0149231   0.00598145 ...  0.         -0.00598145\n","  0.        ], shape=(44174,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11541748]\n"," [-0.10836792]\n"," [-0.11102295]\n"," ...\n"," [-0.0369873 ]\n"," [-0.05725098]\n"," [-0.07666016]], shape=(21790, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11541748 -0.10836792 -0.11102295 ... -0.0369873  -0.05725098\n"," -0.07666016], shape=(21790,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02728271]\n"," [-0.0227356 ]\n"," [-0.01818848]\n"," ...\n"," [-0.00909424]\n"," [-0.00909424]\n"," [-0.01818848]], shape=(53586, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02728271 -0.0227356  -0.01818848 ... -0.00909424 -0.00909424\n"," -0.01818848], shape=(53586,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.8372803 ]\n"," [ 0.65509033]\n"," [ 0.4881897 ]\n"," ...\n"," [-0.0083313 ]\n"," [-0.02087402]\n"," [-0.02780151]], shape=(45618, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.8372803   0.65509033  0.4881897  ... -0.0083313  -0.02087402\n"," -0.02780151], shape=(45618,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [-0.00869751]\n"," ...\n"," [-0.03479004]\n"," [-0.03479004]\n"," [-0.03479004]], shape=(34978, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.         -0.00869751 ... -0.03479004 -0.03479004\n"," -0.03479004], shape=(34978,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0227356 ]\n"," [-0.0227356 ]\n"," [-0.0227356 ]\n"," ...\n"," [-0.01135254]\n"," [-0.00454712]\n"," [-0.00454712]], shape=(128584, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0227356  -0.0227356  -0.0227356  ... -0.01135254 -0.00454712\n"," -0.00454712], shape=(128584,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00860596]\n"," [ 0.00860596]\n"," [ 0.00860596]\n"," ...\n"," [-0.31887817]\n"," [-0.32748413]\n"," [-0.32748413]], shape=(26924, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00860596  0.00860596  0.00860596 ... -0.31887817 -0.32748413\n"," -0.32748413], shape=(26924,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03268433]\n"," [-0.03268433]\n"," [-0.03076172]\n"," ...\n"," [-0.01153564]\n"," [-0.02114868]\n"," [-0.02307129]], shape=(30500, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03268433 -0.03268433 -0.03076172 ... -0.01153564 -0.02114868\n"," -0.02307129], shape=(30500,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01461792]\n"," [ 0.01461792]\n"," [ 0.00585938]\n"," ...\n"," [-0.04385376]\n"," [-0.05847168]\n"," [-0.06433105]], shape=(18320, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01461792  0.01461792  0.00585938 ... -0.04385376 -0.05847168\n"," -0.06433105], shape=(18320,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.29626465]\n"," [0.2953186 ]\n"," [0.29385376]\n"," ...\n"," [0.07684326]\n"," [0.07781982]\n"," [0.08023071]], shape=(39014, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.29626465 0.2953186  0.29385376 ... 0.07684326 0.07781982 0.08023071], shape=(39014,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.03030396]\n"," [ 0.02423096]\n"," [ 0.02423096]\n"," ...\n"," [-0.05453491]\n"," [-0.05453491]\n"," [-0.04849243]], shape=(35150, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.03030396  0.02423096  0.02423096 ... -0.05453491 -0.05453491\n"," -0.04849243], shape=(35150,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07601929]\n"," [-0.07894897]\n"," [-0.07894897]\n"," ...\n"," [-0.2748413 ]\n"," [-0.30410767]\n"," [-0.3333435 ]], shape=(55848, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07601929 -0.07894897 -0.07894897 ... -0.2748413  -0.30410767\n"," -0.3333435 ], shape=(55848,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10733032]\n"," [-0.09268188]\n"," [-0.07562256]\n"," ...\n"," [-0.06829834]\n"," [-0.06585693]\n"," [-0.06829834]], shape=(42220, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10733032 -0.09268188 -0.07562256 ... -0.06829834 -0.06585693\n"," -0.06829834], shape=(42220,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00289917]\n"," [-0.00289917]\n"," [-0.01446533]\n"," ...\n"," [ 0.00289917]\n"," [ 0.01156616]\n"," [ 0.00576782]], shape=(44100, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00289917 -0.00289917 -0.01446533 ...  0.00289917  0.01156616\n","  0.00576782], shape=(44100,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02438354]\n"," [0.01220703]\n"," [0.02438354]\n"," ...\n"," [0.03048706]\n"," [0.03048706]\n"," [0.03659058]], shape=(37324, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02438354 0.01220703 0.02438354 ... 0.03048706 0.03048706 0.03659058], shape=(37324,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01882935]\n"," [ 0.01074219]\n"," [ 0.00537109]\n"," ...\n"," [-0.00805664]\n"," [-0.00537109]\n"," [-0.00537109]], shape=(39874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01882935  0.01074219  0.00537109 ... -0.00805664 -0.00537109\n"," -0.00537109], shape=(39874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00048828]\n"," [ 0.00299072]\n"," [ 0.00448608]\n"," ...\n"," [-0.02151489]\n"," [-0.01901245]\n"," [-0.01550293]], shape=(66888, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00048828  0.00299072  0.00448608 ... -0.02151489 -0.01901245\n"," -0.01550293], shape=(66888,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.16720581]\n"," [ 0.15737915]\n"," [ 0.14099121]\n"," ...\n"," [-0.00656128]\n"," [-0.00656128]\n"," [-0.00656128]], shape=(21142, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.16720581  0.15737915  0.14099121 ... -0.00656128 -0.00656128\n"," -0.00656128], shape=(21142,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02249146]\n"," [-0.02124023]\n"," [-0.02124023]\n"," ...\n"," [-0.00875854]\n"," [-0.00750732]\n"," [-0.0062561 ]], shape=(42904, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02249146 -0.02124023 -0.02124023 ... -0.00875854 -0.00750732\n"," -0.0062561 ], shape=(42904,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08779907]\n"," [-0.08291626]\n"," [-0.10244751]\n"," ...\n"," [-0.10244751]\n"," [-0.10733032]\n"," [-0.0975647 ]], shape=(87576, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08779907 -0.08291626 -0.10244751 ... -0.10244751 -0.10733032\n"," -0.0975647 ], shape=(87576,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.        ]\n"," [-0.00375366]\n"," ...\n"," [-0.01623535]\n"," [-0.01623535]\n"," [-0.01623535]], shape=(84514, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.         -0.00375366 ... -0.01623535 -0.01623535\n"," -0.01623535], shape=(84514,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.34695435]\n"," [-0.3852234 ]\n"," [-0.4208374 ]\n"," ...\n"," [-0.34960938]\n"," [-0.33642578]\n"," [-0.31399536]], shape=(34420, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.34695435 -0.3852234  -0.4208374  ... -0.34960938 -0.33642578\n"," -0.31399536], shape=(34420,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14285278]\n"," [-0.2571411 ]\n"," [-0.32382202]\n"," ...\n"," [-0.15237427]\n"," [-0.16189575]\n"," [-0.16189575]], shape=(37196, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14285278 -0.2571411  -0.32382202 ... -0.15237427 -0.16189575\n"," -0.16189575], shape=(37196,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00973511]\n"," [0.00485229]\n"," [0.00973511]], shape=(29644, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00973511 0.00485229 0.00973511], shape=(29644,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07788086]\n"," [ 0.07788086]\n"," [ 0.08099365]\n"," ...\n"," [-0.01245117]\n"," [-0.00933838]\n"," [-0.00622559]], shape=(65522, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07788086  0.07788086  0.08099365 ... -0.01245117 -0.00933838\n"," -0.00622559], shape=(65522,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04092407]\n"," [-0.05847168]\n"," [-0.02923584]\n"," ...\n"," [-0.07019043]\n"," [-0.04092407]\n"," [-0.04092407]], shape=(33896, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04092407 -0.05847168 -0.02923584 ... -0.07019043 -0.04092407\n"," -0.04092407], shape=(33896,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1494751 ]\n"," [-0.1494751 ]\n"," [-0.1494751 ]\n"," ...\n"," [-0.17526245]\n"," [-0.17526245]\n"," [-0.18041992]], shape=(58172, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1494751  -0.1494751  -0.1494751  ... -0.17526245 -0.17526245\n"," -0.18041992], shape=(58172,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04470825]\n"," [-0.04586792]\n"," [-0.05175781]\n"," ...\n"," [-0.01293945]\n"," [-0.01293945]\n"," [-0.00704956]], shape=(58304, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04470825 -0.04586792 -0.05175781 ... -0.01293945 -0.01293945\n"," -0.00704956], shape=(58304,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0062561 ]\n"," [-0.00250244]\n"," [-0.00125122]\n"," ...\n"," [ 0.01623535]\n"," [ 0.01748657]\n"," [ 0.01998901]], shape=(49884, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0062561  -0.00250244 -0.00125122 ...  0.01623535  0.01748657\n","  0.01998901], shape=(49884,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00598145]\n"," [-0.0149231 ]\n"," [-0.0149231 ]\n"," ...\n"," [-0.02090454]\n"," [-0.02090454]\n"," [-0.0149231 ]], shape=(45816, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00598145 -0.0149231  -0.0149231  ... -0.02090454 -0.02090454\n"," -0.0149231 ], shape=(45816,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00241089]\n"," [ 0.00097656]\n"," [-0.00097656]\n"," ...\n"," [-0.01782227]\n"," [-0.02023315]\n"," [-0.02215576]], shape=(76042, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00241089  0.00097656 -0.00097656 ... -0.01782227 -0.02023315\n"," -0.02215576], shape=(76042,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.48864746]\n"," [-0.4772644 ]\n"," [-0.46136475]\n"," ...\n"," [-0.01589966]\n"," [-0.01135254]\n"," [-0.00454712]], shape=(27020, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.48864746 -0.4772644  -0.46136475 ... -0.01589966 -0.01135254\n"," -0.00454712], shape=(27020,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.01150513]\n"," [0.01724243]\n"," ...\n"," [0.01150513]\n"," [0.01150513]\n"," [0.01150513]], shape=(18334, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.01150513 0.01724243 ... 0.01150513 0.01150513 0.01150513], shape=(18334,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.00820923]\n"," ...\n"," [0.01638794]\n"," [0.03277588]\n"," [0.03277588]], shape=(66356, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.00820923 ... 0.01638794 0.03277588 0.03277588], shape=(66356,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.0007019 ]\n"," [ 0.00262451]\n"," ...\n"," [-0.00198364]\n"," [-0.00262451]\n"," [-0.00015259]], shape=(42790, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.0007019   0.00262451 ... -0.00198364 -0.00262451\n"," -0.00015259], shape=(42790,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.01748657]\n"," [0.01623535]\n"," [0.01623535]\n"," ...\n"," [0.03250122]\n"," [0.03625488]\n"," [0.04000854]], shape=(49010, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.01748657 0.01623535 0.01623535 ... 0.03250122 0.03625488 0.04000854], shape=(49010,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02615356]\n"," [-0.03268433]\n"," [-0.04794312]\n"," ...\n"," [-0.04794312]\n"," [-0.03704834]\n"," [-0.02615356]], shape=(83154, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02615356 -0.03268433 -0.04794312 ... -0.04794312 -0.03704834\n"," -0.02615356], shape=(83154,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0071106 ]\n"," [ 0.0100708 ]\n"," [ 0.01361084]\n"," ...\n"," [-0.00057983]\n"," [ 0.        ]\n"," [ 0.00238037]], shape=(51060, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0071106   0.0100708   0.01361084 ... -0.00057983  0.\n","  0.00238037], shape=(51060,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00375366]\n"," [-0.00250244]\n"," [ 0.        ]\n"," ...\n"," [ 0.00375366]\n"," [ 0.00500488]\n"," [ 0.00500488]], shape=(102426, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00375366 -0.00250244  0.         ...  0.00375366  0.00500488\n","  0.00500488], shape=(102426,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.01306152]\n"," [0.00521851]\n"," ...\n"," [0.11486816]\n"," [0.17233276]\n"," [0.2036438 ]], shape=(22446, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.01306152 0.00521851 ... 0.11486816 0.17233276 0.2036438 ], shape=(22446,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01150513]\n"," [-0.01748657]\n"," [-0.02249146]\n"," ...\n"," [ 0.01748657]\n"," [ 0.01998901]\n"," [ 0.02249146]], shape=(77902, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01150513 -0.01748657 -0.02249146 ...  0.01748657  0.01998901\n","  0.02249146], shape=(77902,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00656128]\n"," [-0.00656128]\n"," [-0.00656128]\n"," ...\n"," [ 0.00326538]\n"," [-0.00326538]\n"," [ 0.        ]], shape=(17640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00656128 -0.00656128 -0.00656128 ...  0.00326538 -0.00326538\n","  0.        ], shape=(17640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00875854]\n"," [0.01998901]\n"," [0.0249939 ]], shape=(63854, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00875854 0.01998901 0.0249939 ], shape=(63854,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.08914185]\n"," [ 0.06686401]\n"," [ 0.04736328]\n"," ...\n"," [-0.0557251 ]\n"," [-0.0557251 ]\n"," [-0.04736328]], shape=(43796, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.08914185  0.06686401  0.04736328 ... -0.0557251  -0.0557251\n"," -0.04736328], shape=(43796,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04623413]\n"," [-0.0491333 ]\n"," [-0.0491333 ]\n"," ...\n"," [-0.01733398]\n"," [-0.01156616]\n"," [-0.01446533]], shape=(41774, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04623413 -0.0491333  -0.0491333  ... -0.01733398 -0.01156616\n"," -0.01446533], shape=(41774,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00213623]\n"," [ 0.        ]\n"," [ 0.00427246]\n"," ...\n"," [-0.01919556]\n"," [-0.02133179]\n"," [-0.02133179]], shape=(42222, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00213623  0.          0.00427246 ... -0.01919556 -0.02133179\n"," -0.02133179], shape=(42222,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01931763]\n"," [-0.00772095]\n"," [-0.02703857]\n"," ...\n"," [-0.05792236]\n"," [-0.04632568]\n"," [-0.04632568]], shape=(43766, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01931763 -0.00772095 -0.02703857 ... -0.05792236 -0.04632568\n"," -0.04632568], shape=(43766,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.17050171]\n"," [-0.17196655]\n"," [-0.17196655]\n"," ...\n"," [ 0.24572754]\n"," [ 0.24816895]\n"," [ 0.25061035]], shape=(77662, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.17050171 -0.17196655 -0.17196655 ...  0.24572754  0.24816895\n","  0.25061035], shape=(77662,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.00250244]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01126099]\n"," [0.00875854]\n"," [0.0062561 ]], shape=(108392, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.00250244 0.         0.         ... 0.01126099 0.00875854 0.0062561 ], shape=(108392,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.02688599]\n"," [0.03494263]\n"," [0.04299927]\n"," ...\n"," [0.02420044]\n"," [0.02151489]\n"," [0.02420044]], shape=(42100, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.02688599 0.03494263 0.04299927 ... 0.02420044 0.02151489 0.02420044], shape=(42100,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00772095]\n"," [ 0.00256348]\n"," [ 0.        ]\n"," ...\n"," [-0.00256348]\n"," [-0.00256348]\n"," [ 0.        ]], shape=(36184, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00772095  0.00256348  0.         ... -0.00256348 -0.00256348\n","  0.        ], shape=(36184,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02401733]\n"," [-0.01702881]\n"," [-0.01501465]\n"," ...\n"," [-0.02203369]\n"," [-0.02001953]\n"," [-0.02203369]], shape=(19308, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02401733 -0.01702881 -0.01501465 ... -0.02203369 -0.02001953\n"," -0.02203369], shape=(19308,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00424194]\n"," [-0.00424194]\n"," [-0.00424194]\n"," ...\n"," [ 0.25424194]\n"," [ 0.27542114]\n"," [ 0.2584839 ]], shape=(49384, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00424194 -0.00424194 -0.00424194 ...  0.25424194  0.27542114\n","  0.2584839 ], shape=(49384,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08413696]\n"," [-0.07388306]\n"," [-0.06344604]\n"," ...\n"," [-0.04412842]\n"," [-0.04388428]\n"," [-0.04241943]], shape=(42982, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08413696 -0.07388306 -0.06344604 ... -0.04412842 -0.04388428\n"," -0.04241943], shape=(42982,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.07879639]\n"," [0.09091187]\n"," [0.09091187]\n"," ...\n"," [0.03030396]\n"," [0.03030396]\n"," [0.03030396]], shape=(29508, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.07879639 0.09091187 0.09091187 ... 0.03030396 0.03030396 0.03030396], shape=(29508,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.2784729 ]\n"," [-0.28442383]\n"," [-0.290802  ]\n"," ...\n"," [-0.19940186]\n"," [-0.19515991]\n"," [-0.19216919]], shape=(29850, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.2784729  -0.28442383 -0.290802   ... -0.19940186 -0.19515991\n"," -0.19216919], shape=(29850,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.1272583 ]\n"," [-0.15756226]\n"," [-0.16970825]\n"," ...\n"," [-0.02423096]\n"," [-0.01211548]\n"," [-0.02423096]], shape=(24948, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.1272583  -0.15756226 -0.16970825 ... -0.02423096 -0.01211548\n"," -0.02423096], shape=(24948,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00973511]\n"," [ 0.        ]\n"," [-0.0083313 ]\n"," ...\n"," [ 0.00140381]\n"," [ 0.        ]\n"," [-0.00140381]], shape=(62882, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00973511  0.         -0.0083313  ...  0.00140381  0.\n"," -0.00140381], shape=(62882,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0375061 ]\n"," [-0.05374146]\n"," [-0.06500244]\n"," ...\n"," [ 0.01501465]\n"," [ 0.01501465]\n"," [ 0.01251221]], shape=(23046, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0375061  -0.05374146 -0.06500244 ...  0.01501465  0.01501465\n","  0.01251221], shape=(23046,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.04092407]\n"," [ 0.05847168]\n"," [ 0.02923584]\n"," ...\n"," [-0.01168823]\n"," [-0.04092407]\n"," [ 0.01168823]], shape=(60840, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.04092407  0.05847168  0.02923584 ... -0.01168823 -0.04092407\n","  0.01168823], shape=(60840,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.14285278]\n"," [-0.24285889]\n"," [-0.32858276]\n"," ...\n"," [ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(29128, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.14285278 -0.24285889 -0.32858276 ...  0.          0.\n","  0.        ], shape=(29128,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01977539]\n"," [-0.01715088]\n"," [-0.02111816]\n"," ...\n"," [-0.02770996]\n"," [-0.01715088]\n"," [-0.00924683]], shape=(43874, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01977539 -0.01715088 -0.02111816 ... -0.02770996 -0.01715088\n"," -0.00924683], shape=(43874,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00961304]\n"," [-0.03845215]\n"," [-0.0730896 ]\n"," ...\n"," [-0.04229736]\n"," [-0.04229736]\n"," [-0.03845215]], shape=(37496, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00961304 -0.03845215 -0.0730896  ... -0.04229736 -0.04229736\n"," -0.03845215], shape=(37496,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.0255127 ]\n"," [-0.0249939 ]\n"," [-0.0249939 ]\n"," ...\n"," [-0.00250244]\n"," [-0.00250244]\n"," [-0.00250244]], shape=(63956, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.0255127  -0.0249939  -0.0249939  ... -0.00250244 -0.00250244\n"," -0.00250244], shape=(63956,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.07144165]\n"," [-0.07144165]\n"," [-0.07144165]\n"," ...\n"," [ 0.04202271]\n"," [ 0.04202271]\n"," [ 0.04620361]], shape=(21976, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07144165 -0.07144165 -0.07144165 ...  0.04202271  0.04202271\n","  0.04620361], shape=(21976,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00048828]\n"," [ 0.00100708]\n"," [ 0.00299072]\n"," ...\n"," [-0.0085144 ]\n"," [-0.01049805]\n"," [-0.01049805]], shape=(50382, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00048828  0.00100708  0.00299072 ... -0.0085144  -0.01049805\n"," -0.01049805], shape=(50382,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.25204468]\n"," [-0.25204468]\n"," [-0.22763062]\n"," ...\n"," [-0.23577881]\n"," [-0.23577881]\n"," [-0.25204468]], shape=(16172, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.25204468 -0.25204468 -0.22763062 ... -0.23577881 -0.23577881\n"," -0.25204468], shape=(16172,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00137329]\n"," [-0.00436401]\n"," [-0.0078125 ]\n"," ...\n"," [-0.06219482]\n"," [-0.05740356]\n"," [-0.05206299]], shape=(75064, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00137329 -0.00436401 -0.0078125  ... -0.06219482 -0.05740356\n"," -0.05206299], shape=(75064,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03845215]\n"," [-0.03460693]\n"," [-0.03076172]\n"," ...\n"," [-0.01730347]\n"," [-0.03076172]\n"," [-0.04614258]], shape=(24716, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03845215 -0.03460693 -0.03076172 ... -0.01730347 -0.03076172\n"," -0.04614258], shape=(24716,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.     ]\n"," [ 0.     ]\n"," [-0.03125]\n"," ...\n"," [ 0.0625 ]\n"," [ 0.03125]\n"," [ 0.03125]], shape=(36300, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.       0.      -0.03125 ...  0.0625   0.03125  0.03125], shape=(36300,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02410889]\n"," [-0.01205444]\n"," [-0.01687622]\n"," ...\n"," [-0.01687622]\n"," [-0.01687622]\n"," [-0.01687622]], shape=(22062, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02410889 -0.01205444 -0.01687622 ... -0.01687622 -0.01687622\n"," -0.01687622], shape=(22062,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01126099]\n"," [ 0.0062561 ]\n"," [ 0.00250244]\n"," ...\n"," [-0.0375061 ]\n"," [-0.03625488]\n"," [-0.02874756]], shape=(39108, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01126099  0.0062561   0.00250244 ... -0.0375061  -0.03625488\n"," -0.02874756], shape=(39108,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01333618]\n"," [-0.01333618]\n"," [-0.03808594]\n"," ...\n"," [-0.04190063]\n"," [-0.05142212]\n"," [-0.05142212]], shape=(60258, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01333618 -0.01333618 -0.03808594 ... -0.04190063 -0.05142212\n"," -0.05142212], shape=(60258,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00204468]\n"," [-0.00204468]\n"," [-0.00253296]\n"," ...\n"," [-0.01068115]\n"," [-0.01373291]\n"," [-0.01678467]], shape=(51140, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00204468 -0.00204468 -0.00253296 ... -0.01068115 -0.01373291\n"," -0.01678467], shape=(51140,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.05575562]\n"," [0.04833984]\n"," [0.04089355]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.00372314]], shape=(75540, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.05575562 0.04833984 0.04089355 ... 0.         0.         0.00372314], shape=(75540,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00427246]\n"," [-0.00213623]\n"," [-0.00427246]\n"," ...\n"," [-0.0149231 ]\n"," [-0.01919556]\n"," [-0.02557373]], shape=(17390, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00427246 -0.00213623 -0.00427246 ... -0.0149231  -0.01919556\n"," -0.02557373], shape=(17390,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01104736]\n"," [ 0.01019287]\n"," [ 0.00680542]\n"," ...\n"," [-0.16766357]\n"," [-0.17184448]\n"," [-0.17092896]], shape=(53146, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01104736  0.01019287  0.00680542 ... -0.16766357 -0.17184448\n"," -0.17092896], shape=(53146,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08572388]\n"," [-0.07858276]\n"," [-0.06430054]\n"," ...\n"," [ 0.        ]\n"," [ 0.00714111]\n"," [ 0.00714111]], shape=(62776, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08572388 -0.07858276 -0.06430054 ...  0.          0.00714111\n","  0.00714111], shape=(62776,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01495361]\n"," [-0.02380371]\n"," [-0.01989746]\n"," ...\n"," [ 0.00268555]\n"," [ 0.0039978 ]\n"," [ 0.00363159]], shape=(31846, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01495361 -0.02380371 -0.01989746 ...  0.00268555  0.0039978\n","  0.00363159], shape=(31846,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0144043 ]\n"," [ 0.02593994]\n"," [ 0.02593994]\n"," ...\n"," [ 0.        ]\n"," [-0.00286865]\n"," [ 0.00576782]], shape=(37972, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0144043   0.02593994  0.02593994 ...  0.         -0.00286865\n","  0.00576782], shape=(37972,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00250244]\n"," [ 0.00375366]\n"," [ 0.00375366]\n"," ...\n"," [-0.04000854]\n"," [-0.04000854]\n"," [-0.0375061 ]], shape=(33222, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00250244  0.00375366  0.00375366 ... -0.04000854 -0.04000854\n"," -0.0375061 ], shape=(33222,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01101685]\n"," [-0.01101685]\n"," [-0.01049805]\n"," ...\n"," [ 0.03601074]\n"," [ 0.03500366]\n"," [ 0.03250122]], shape=(61470, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01101685 -0.01101685 -0.01049805 ...  0.03601074  0.03500366\n","  0.03250122], shape=(61470,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00772095]\n"," [-0.01931763]\n"," [-0.01931763]\n"," ...\n"," [ 0.03860474]\n"," [ 0.00772095]\n"," [-0.02703857]], shape=(41358, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00772095 -0.01931763 -0.01931763 ...  0.03860474  0.00772095\n"," -0.02703857], shape=(41358,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.06411743]\n"," [-0.03845215]\n"," [-0.01281738]\n"," ...\n"," [ 0.04486084]\n"," [ 0.04486084]\n"," [ 0.03204346]], shape=(18454, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.06411743 -0.03845215 -0.01281738 ...  0.04486084  0.04486084\n","  0.03204346], shape=(18454,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02615356]\n"," [-0.02178955]\n"," [-0.02615356]\n"," ...\n"," [-0.02615356]\n"," [-0.02178955]\n"," [-0.02178955]], shape=(37906, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02615356 -0.02178955 -0.02615356 ... -0.02615356 -0.02178955\n"," -0.02178955], shape=(37906,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0062561 ]\n"," [ 0.0062561 ]\n"," [ 0.00500488]\n"," ...\n"," [-0.03500366]\n"," [-0.02749634]\n"," [-0.01748657]], shape=(19174, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0062561   0.0062561   0.00500488 ... -0.03500366 -0.02749634\n"," -0.01748657], shape=(19174,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00875854]\n"," [-0.01000977]\n"," [-0.01251221]\n"," ...\n"," [-0.02374268]\n"," [-0.02374268]\n"," [-0.02374268]], shape=(44720, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00875854 -0.01000977 -0.01251221 ... -0.02374268 -0.02374268\n"," -0.02374268], shape=(44720,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.2869568 ]\n"," [ 0.27557373]\n"," [ 0.26608276]\n"," ...\n"," [-0.09631348]\n"," [-0.09567261]\n"," [-0.09298706]], shape=(57554, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.2869568   0.27557373  0.26608276 ... -0.09631348 -0.09567261\n"," -0.09298706], shape=(57554,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.11383057]\n"," [-0.11923218]\n"," [-0.11923218]\n"," ...\n"," [ 0.05419922]\n"," [ 0.05963135]\n"," [ 0.05419922]], shape=(25782, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.11383057 -0.11923218 -0.11923218 ...  0.05419922  0.05963135\n","  0.05419922], shape=(25782,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01315308]\n"," [-0.01315308]\n"," [-0.01315308]\n"," ...\n"," [ 0.1315918 ]\n"," [ 0.1184082 ]\n"," [ 0.1184082 ]], shape=(32000, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01315308 -0.01315308 -0.01315308 ...  0.1315918   0.1184082\n","  0.1184082 ], shape=(32000,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02600098]\n"," [-0.03805542]\n"," [-0.10800171]\n"," ...\n"," [-0.30337524]\n"," [-0.42199707]\n"," [-0.52557373]], shape=(73126, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02600098 -0.03805542 -0.10800171 ... -0.30337524 -0.42199707\n"," -0.52557373], shape=(73126,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00421143]\n"," [-0.00421143]\n"," [-0.01049805]\n"," ...\n"," [-0.09243774]\n"," [-0.09243774]\n"," [-0.09243774]], shape=(30644, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00421143 -0.00421143 -0.01049805 ... -0.09243774 -0.09243774\n"," -0.09243774], shape=(30644,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00469971]\n"," [-0.00469971]\n"," [ 0.        ]\n"," ...\n"," [-0.07293701]\n"," [-0.07528687]\n"," [-0.07763672]], shape=(34648, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00469971 -0.00469971  0.         ... -0.07293701 -0.07528687\n"," -0.07763672], shape=(34648,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.00524902]\n"," [ 0.00671387]\n"," [ 0.00790405]\n"," ...\n"," [-0.00384521]\n"," [-0.00524902]\n"," [-0.00662231]], shape=(26744, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.00524902  0.00671387  0.00790405 ... -0.00384521 -0.00524902\n"," -0.00662231], shape=(26744,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.1192627 ]\n"," [0.13760376]\n"," [0.14678955]\n"," ...\n"," [0.        ]\n"," [0.        ]\n"," [0.        ]], shape=(62182, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.1192627  0.13760376 0.14678955 ... 0.         0.         0.        ], shape=(62182,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0065918]\n"," [ 0.0065918]\n"," [ 0.0065918]\n"," ...\n"," [-0.0032959]\n"," [-0.0032959]\n"," [-0.0032959]], shape=(24546, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([ 0.0065918  0.0065918  0.0065918 ... -0.0032959 -0.0032959 -0.0032959], shape=(24546,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.03790283]\n"," [0.04141235]\n"," [0.04669189]\n"," ...\n"," [0.02996826]\n"," [0.03436279]\n"," [0.04403687]], shape=(51016, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.03790283 0.04141235 0.04669189 ... 0.02996826 0.03436279 0.04403687], shape=(51016,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04666138]\n"," [-0.03790283]\n"," [-0.03790283]\n"," ...\n"," [-0.06121826]\n"," [-0.04666138]\n"," [-0.03497314]], shape=(31120, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04666138 -0.03790283 -0.03790283 ... -0.06121826 -0.04666138\n"," -0.03497314], shape=(31120,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.05487061]\n"," [ 0.05487061]\n"," [ 0.03659058]\n"," ...\n"," [-0.00610352]\n"," [-0.01220703]\n"," [-0.01220703]], shape=(44176, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.05487061  0.05487061  0.03659058 ... -0.00610352 -0.01220703\n"," -0.01220703], shape=(44176,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.006073  ]\n"," [ 0.006073  ]\n"," [ 0.01211548]\n"," ...\n"," [-0.03637695]\n"," [-0.03637695]\n"," [-0.03637695]], shape=(39188, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.006073    0.006073    0.01211548 ... -0.03637695 -0.03637695\n"," -0.03637695], shape=(39188,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0032959 ]\n"," [-0.0032959 ]\n"," [-0.01321411]\n"," ...\n"," [-0.07260132]\n"," [-0.07589722]\n"," [-0.08911133]], shape=(45750, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0032959  -0.0032959  -0.01321411 ... -0.07260132 -0.07589722\n"," -0.08911133], shape=(45750,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.10986328]\n"," [-0.10986328]\n"," [-0.10986328]\n"," ...\n"," [-0.05682373]\n"," [-0.06439209]\n"," [-0.06439209]], shape=(50572, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.10986328 -0.10986328 -0.10986328 ... -0.05682373 -0.06439209\n"," -0.06439209], shape=(50572,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02856445]\n"," [-0.02856445]\n"," [-0.02856445]\n"," ...\n"," [-0.01715088]\n"," [-0.01715088]\n"," [-0.01715088]], shape=(29042, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02856445 -0.02856445 -0.02856445 ... -0.01715088 -0.01715088\n"," -0.01715088], shape=(29042,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02624512]\n"," [-0.02249146]\n"," [-0.01873779]\n"," ...\n"," [ 0.00750732]\n"," [ 0.        ]\n"," [-0.01126099]], shape=(45318, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02624512 -0.02249146 -0.01873779 ...  0.00750732  0.\n"," -0.01126099], shape=(45318,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00808716]\n"," [-0.02023315]\n"," [ 0.00808716]\n"," ...\n"," [-0.02023315]\n"," [-0.02835083]\n"," [-0.02023315]], shape=(41432, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00808716 -0.02023315  0.00808716 ... -0.02023315 -0.02835083\n"," -0.02023315], shape=(41432,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01739502]\n"," [-0.02609253]\n"," [-0.03479004]\n"," ...\n"," [ 0.00869751]\n"," [ 0.01739502]\n"," [ 0.02609253]], shape=(34908, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01739502 -0.02609253 -0.03479004 ...  0.00869751  0.01739502\n","  0.02609253], shape=(34908,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.01269531]\n"," [ 0.01269531]\n"," [ 0.01522827]\n"," ...\n"," [-0.12689209]\n"," [-0.1802063 ]\n"," [-0.23858643]], shape=(62268, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.01269531  0.01269531  0.01522827 ... -0.12689209 -0.1802063\n"," -0.23858643], shape=(62268,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01470947]\n"," [-0.01837158]\n"," [-0.01837158]\n"," ...\n"," [-0.01470947]\n"," [-0.01837158]\n"," [-0.01470947]], shape=(18160, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01470947 -0.01837158 -0.01837158 ... -0.01470947 -0.01837158\n"," -0.01470947], shape=(18160,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03271484]\n"," [-0.02545166]\n"," [-0.03271484]\n"," ...\n"," [-0.07272339]\n"," [-0.07272339]\n"," [-0.06546021]], shape=(44868, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03271484 -0.02545166 -0.03271484 ... -0.07272339 -0.07272339\n"," -0.06546021], shape=(44868,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0149231 ]\n"," [-0.0085144 ]\n"," [-0.03411865]\n"," ...\n"," [ 0.0085144 ]\n"," [-0.00213623]\n"," [-0.02133179]], shape=(53594, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0149231  -0.0085144  -0.03411865 ...  0.0085144  -0.00213623\n"," -0.02133179], shape=(53594,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01000977]\n"," [-0.01000977]\n"," [-0.00875854]\n"," ...\n"," [-0.00500488]\n"," [-0.00500488]\n"," [-0.00500488]], shape=(42546, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01000977 -0.01000977 -0.00875854 ... -0.00500488 -0.00500488\n"," -0.00500488], shape=(42546,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.03845215]\n"," [-0.03460693]\n"," [-0.03076172]\n"," ...\n"," [ 0.00769043]\n"," [ 0.01153564]\n"," [ 0.01730347]], shape=(22402, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.03845215 -0.03460693 -0.03076172 ...  0.00769043  0.01153564\n","  0.01730347], shape=(22402,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01086426]\n"," [-0.01086426]\n"," [ 0.        ]\n"," ...\n"," [-0.02172852]\n"," [-0.02172852]\n"," [-0.02172852]], shape=(48984, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01086426 -0.01086426  0.         ... -0.02172852 -0.02172852\n"," -0.02172852], shape=(48984,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.02319336]\n"," [-0.02835083]\n"," [-0.02835083]\n"," ...\n"," [-0.00515747]\n"," [ 0.00515747]\n"," [ 0.01803589]], shape=(39742, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.02319336 -0.02835083 -0.02835083 ... -0.00515747  0.00515747\n","  0.01803589], shape=(39742,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01419067]\n"," [-0.01419067]\n"," [-0.00567627]\n"," ...\n"," [-0.01419067]\n"," [-0.00567627]\n"," [-0.00567627]], shape=(34954, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01419067 -0.01419067 -0.00567627 ... -0.01419067 -0.00567627\n"," -0.00567627], shape=(34954,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00961304]\n"," [-0.00961304]\n"," [-0.00769043]\n"," ...\n"," [ 0.00192261]\n"," [-0.00192261]\n"," [-0.00192261]], shape=(17064, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00961304 -0.00961304 -0.00769043 ...  0.00192261 -0.00192261\n"," -0.00192261], shape=(17064,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.08099365]\n"," [-0.15576172]\n"," [-0.23364258]\n"," ...\n"," [ 0.00311279]\n"," [ 0.        ]\n"," [ 0.        ]], shape=(47548, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.08099365 -0.15576172 -0.23364258 ...  0.00311279  0.\n","  0.        ], shape=(47548,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01464844]\n"," [-0.01464844]\n"," [-0.01379395]\n"," ...\n"," [-0.00949097]\n"," [-0.00860596]\n"," [-0.00732422]], shape=(64796, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01464844 -0.01464844 -0.01379395 ... -0.00949097 -0.00860596\n"," -0.00732422], shape=(64796,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.07937622]\n"," [ 0.18252563]\n"," [ 0.29364014]\n"," ...\n"," [-0.03967285]\n"," [-0.03967285]\n"," [-0.01586914]], shape=(44956, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.07937622  0.18252563  0.29364014 ... -0.03967285 -0.03967285\n"," -0.01586914], shape=(44956,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01351929]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.00674438]\n"," [ 0.00674438]\n"," [ 0.03378296]], shape=(32822, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01351929  0.          0.         ...  0.00674438  0.00674438\n","  0.03378296], shape=(32822,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.05453491]\n"," [-0.06060791]\n"," [-0.06668091]\n"," ...\n"," [-0.03030396]\n"," [-0.04241943]\n"," [-0.05453491]], shape=(23884, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.05453491 -0.06060791 -0.06668091 ... -0.03030396 -0.04241943\n"," -0.05453491], shape=(23884,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00161743]\n"," [ 0.00161743]\n"," [-0.00161743]\n"," ...\n"," [ 0.        ]\n"," [ 0.00323486]\n"," [ 0.00808716]], shape=(29804, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00161743  0.00161743 -0.00161743 ...  0.          0.00323486\n","  0.00808716], shape=(29804,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.02603149]\n"," [ 0.00744629]\n"," [-0.00372314]\n"," ...\n"," [ 0.        ]\n"," [ 0.00372314]\n"," [ 0.01486206]], shape=(72630, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.02603149  0.00744629 -0.00372314 ...  0.          0.00372314\n","  0.01486206], shape=(72630,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00714111]\n"," [-0.07144165]\n"," [-0.12857056]\n"," ...\n"," [ 0.02856445]\n"," [ 0.02856445]\n"," [ 0.02856445]], shape=(26152, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00714111 -0.07144165 -0.12857056 ...  0.02856445  0.02856445\n","  0.02856445], shape=(26152,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [-0.00421143]\n"," [ 0.        ]\n"," ...\n"," [ 0.01049805]\n"," [ 0.02520752]\n"," [ 0.04202271]], shape=(44064, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.         -0.00421143  0.         ...  0.01049805  0.02520752\n","  0.04202271], shape=(44064,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01864624]\n"," [-0.02484131]\n"," [-0.02484131]\n"," ...\n"," [-0.03106689]\n"," [-0.02484131]\n"," [-0.01864624]], shape=(47478, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01864624 -0.02484131 -0.02484131 ... -0.03106689 -0.02484131\n"," -0.01864624], shape=(47478,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.0149231 ]\n"," [0.00598145]\n"," [0.00598145]\n"," ...\n"," [0.02090454]\n"," [0.03582764]\n"," [0.05075073]], shape=(24556, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.0149231  0.00598145 0.00598145 ... 0.02090454 0.03582764 0.05075073], shape=(24556,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.04727173]\n"," [-0.04727173]\n"," [-0.05819702]\n"," ...\n"," [-0.07998657]\n"," [-0.07635498]\n"," [-0.07998657]], shape=(54414, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.04727173 -0.04727173 -0.05819702 ... -0.07998657 -0.07635498\n"," -0.07998657], shape=(54414,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.00613403]\n"," [ 0.        ]\n"," [ 0.01226807]\n"," ...\n"," [ 0.00613403]\n"," [ 0.01226807]\n"," [ 0.0184021 ]], shape=(54998, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.00613403  0.          0.01226807 ...  0.00613403  0.01226807\n","  0.0184021 ], shape=(54998,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.03775024]\n"," [0.03329468]\n"," [0.03396606]], shape=(63648, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.03775024 0.03329468 0.03396606], shape=(63648,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01904297]\n"," [0.02719116]\n"," [0.02111816]], shape=(60672, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01904297 0.02719116 0.02111816], shape=(60672,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.02493286]\n"," [0.01766968]\n"," [0.01104736]], shape=(70272, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.02493286 0.01766968 0.01104736], shape=(70272,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.00076294]\n"," [-0.0010376 ]\n"," [ 0.00134277]], shape=(79488, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.00076294 -0.0010376\n","  0.00134277], shape=(79488,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.03115845]\n"," [0.03918457]\n"," [0.05300903]], shape=(64416, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.03115845 0.03918457 0.05300903], shape=(64416,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.00033569]\n"," [-0.00036621]\n"," [-0.00335693]], shape=(60864, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.00033569 -0.00036621\n"," -0.00335693], shape=(60864,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00027466]\n"," [ 0.00222778]\n"," [-0.00015259]], shape=(64896, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00027466  0.00222778\n"," -0.00015259], shape=(64896,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.05386353]\n"," [-0.06921387]\n"," [-0.0920105 ]], shape=(119232, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.05386353 -0.06921387\n"," -0.0920105 ], shape=(119232,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00033569]\n"," [-0.00604248]\n"," [-0.00314331]], shape=(68544, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00033569 -0.00604248\n"," -0.00314331], shape=(68544,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01065063]\n"," [-0.00860596]\n"," [-0.00177002]], shape=(86208, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.01065063 -0.00860596\n"," -0.00177002], shape=(86208,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.02612305]\n"," [-0.01785278]\n"," [-0.01174927]], shape=(63168, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.02612305 -0.01785278\n"," -0.01174927], shape=(63168,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01425171]\n"," [-0.01184082]\n"," [-0.01126099]], shape=(63264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.01425171 -0.01184082\n"," -0.01126099], shape=(63264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00689697]\n"," [0.0090332 ]\n"," [0.00686646]], shape=(63648, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00689697 0.0090332  0.00686646], shape=(63648,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01055908]\n"," [0.0168457 ]\n"," [0.03900146]], shape=(61344, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01055908 0.0168457  0.03900146], shape=(61344,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00195312]\n"," [-0.00268555]\n"," [-0.00372314]], shape=(64704, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00195312 -0.00268555\n"," -0.00372314], shape=(64704,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01580811]\n"," [-0.03036499]\n"," [-0.04751587]], shape=(60960, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.01580811 -0.03036499\n"," -0.04751587], shape=(60960,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.02023315]\n"," [-0.02050781]\n"," [-0.02401733]], shape=(61152, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.02023315 -0.02050781\n"," -0.02401733], shape=(61152,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00814819]\n"," [-0.01055908]\n"," [-0.02716064]], shape=(64320, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00814819 -0.01055908\n"," -0.02716064], shape=(64320,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01541138]\n"," [0.02822876]\n"," [0.02416992]], shape=(69024, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01541138 0.02822876 0.02416992], shape=(69024,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.03103638]\n"," [0.04156494]\n"," [0.03262329]], shape=(63264, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.03103638 0.04156494 0.03262329], shape=(63264,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.]\n"," [0.]\n"," [0.]\n"," ...\n"," [0.]\n"," [0.]\n"," [0.]], shape=(59904, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(59904,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00537109]\n"," [0.00830078]\n"," [0.0111084 ]], shape=(68256, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00537109 0.00830078 0.0111084 ], shape=(68256,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00445557]\n"," [-0.00247192]\n"," [-0.00210571]], shape=(67104, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00445557 -0.00247192\n"," -0.00210571], shape=(67104,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00241089]\n"," [-0.00286865]\n"," [-0.00186157]], shape=(63072, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00241089 -0.00286865\n"," -0.00186157], shape=(63072,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.03286743]\n"," [0.6308594 ]\n"," [0.3734131 ]], shape=(61632, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.03286743 0.6308594  0.3734131 ], shape=(61632,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00588989]\n"," [0.00448608]\n"," [0.00521851]], shape=(63456, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00588989 0.00448608 0.00521851], shape=(63456,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.0043335 ]\n"," [-0.00454712]\n"," [-0.00457764]], shape=(60960, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.0043335  -0.00454712\n"," -0.00457764], shape=(60960,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.00088501]\n"," [-0.00024414]\n"," [ 0.00048828]], shape=(65536, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.00088501 -0.00024414\n","  0.00048828], shape=(65536,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.0039978 ]\n"," [ 0.00198364]\n"," [-0.00054932]], shape=(65856, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.0039978   0.00198364\n"," -0.00054932], shape=(65856,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.02954102]\n"," [ 0.02050781]\n"," [-0.03659058]], shape=(70080, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.02954102  0.02050781\n"," -0.03659058], shape=(70080,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.0043335 ]\n"," [-0.00137329]\n"," [-0.00054932]], shape=(62976, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.0043335  -0.00137329\n"," -0.00054932], shape=(62976,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00567627]\n"," [-0.0057373 ]\n"," [-0.00646973]], shape=(64800, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00567627 -0.0057373\n"," -0.00646973], shape=(64800,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.00115967]\n"," [-0.01602173]\n"," [-0.03146362]], shape=(70368, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.00115967 -0.01602173\n"," -0.03146362], shape=(70368,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.03417969]\n"," [-0.01617432]\n"," [-0.00839233]], shape=(60192, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.03417969 -0.01617432\n"," -0.00839233], shape=(60192,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00396729]\n"," [-0.00720215]\n"," [-0.01296997]], shape=(79296, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00396729 -0.00720215\n"," -0.01296997], shape=(79296,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00280762]\n"," [0.00494385]\n"," [0.04360962]], shape=(64608, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00280762 0.00494385 0.04360962], shape=(64608,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.00195312]\n"," [-0.00793457]\n"," [-0.01446533]], shape=(66432, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.00195312 -0.00793457\n"," -0.01446533], shape=(66432,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00741577]\n"," [-0.00839233]\n"," [-0.0083313 ]], shape=(62496, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00741577 -0.00839233\n"," -0.0083313 ], shape=(62496,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.34729004]\n"," [0.3611145 ]\n"," [0.41082764]], shape=(65184, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.34729004 0.3611145  0.41082764], shape=(65184,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.03820801]\n"," [0.03985596]\n"," [0.04837036]], shape=(61920, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.03820801 0.03985596 0.04837036], shape=(61920,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.0000000e+00]\n"," [ 0.0000000e+00]\n"," [ 0.0000000e+00]\n"," ...\n"," [ 6.7749023e-03]\n"," [-3.0517578e-05]\n"," [-4.3029785e-03]], shape=(69024, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  6.7749023e-03\n"," -3.0517578e-05 -4.3029785e-03], shape=(69024,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.15429688]\n"," [-0.14672852]\n"," [-0.15988159]], shape=(81216, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.15429688 -0.14672852\n"," -0.15988159], shape=(81216,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.04040527]\n"," [-0.03726196]\n"," [-0.18066406]], shape=(104640, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.04040527 -0.03726196\n"," -0.18066406], shape=(104640,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00134277]\n"," [0.00775146]\n"," [0.01144409]], shape=(61536, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00134277 0.00775146 0.01144409], shape=(61536,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00363159]\n"," [-0.00473022]\n"," [-0.00564575]], shape=(62496, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00363159 -0.00473022\n"," -0.00564575], shape=(62496,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01876831]\n"," [-0.01324463]\n"," [-0.01013184]], shape=(59328, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.01876831 -0.01324463\n"," -0.01013184], shape=(59328,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.08200073]\n"," [-0.07946777]\n"," [-0.09890747]], shape=(60576, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.08200073 -0.07946777\n"," -0.09890747], shape=(60576,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00146484]\n"," [-0.00079346]\n"," [ 0.00094604]], shape=(62688, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00146484 -0.00079346\n","  0.00094604], shape=(62688,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.02865601]\n"," [0.02398682]\n"," [0.03439331]], shape=(61824, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.02865601 0.02398682 0.03439331], shape=(61824,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.41619873]\n"," [-0.380188  ]\n"," [-0.21603394]], shape=(67776, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.41619873 -0.380188\n"," -0.21603394], shape=(67776,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.03717041]\n"," [0.03479004]\n"," [0.03933716]], shape=(61920, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.03717041 0.03479004 0.03933716], shape=(61920,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.01358032]\n"," [0.00863647]\n"," [0.02081299]], shape=(65568, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.01358032 0.00863647 0.02081299], shape=(65568,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00686646]\n"," [-0.00552368]\n"," [-0.00735474]], shape=(67776, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00686646 -0.00552368\n"," -0.00735474], shape=(67776,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00259399]\n"," [-0.00308228]\n"," [-0.00210571]], shape=(65568, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00259399 -0.00308228\n"," -0.00210571], shape=(65568,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.0005188 ]\n"," [-0.00289917]\n"," [-0.00869751]], shape=(61144, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.0005188  -0.00289917\n"," -0.00869751], shape=(61144,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.06079102]\n"," [-0.04815674]\n"," [-0.02923584]], shape=(62208, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.06079102 -0.04815674\n"," -0.02923584], shape=(62208,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00021362]\n"," [0.00167847]\n"," [0.00454712]], shape=(68448, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00021362 0.00167847 0.00454712], shape=(68448,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.06738281]\n"," [0.07528687]\n"," [0.0881958 ]], shape=(63360, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.06738281 0.07528687 0.0881958 ], shape=(63360,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00430298]\n"," [-0.00830078]\n"," [-0.0015564 ]], shape=(63552, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00430298 -0.00830078\n"," -0.0015564 ], shape=(63552,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.04663086]\n"," [-0.0300293 ]\n"," [-0.00476074]], shape=(62496, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.04663086 -0.0300293\n"," -0.00476074], shape=(62496,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00747681]\n"," [0.0093689 ]\n"," [0.00592041]], shape=(74688, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00747681 0.0093689  0.00592041], shape=(74688,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.25250244]\n"," [-0.36798096]\n"," [-0.49804688]], shape=(63648, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.25250244 -0.36798096\n"," -0.49804688], shape=(63648,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.006073  ]\n"," [0.00061035]\n"," [0.00311279]], shape=(60672, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.006073   0.00061035 0.00311279], shape=(60672,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.0475769 ]\n"," [-0.01483154]\n"," [-0.05783081]], shape=(82176, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.0475769  -0.01483154\n"," -0.05783081], shape=(82176,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00195312]\n"," [-0.00366211]\n"," [-0.00161743]], shape=(113376, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00195312 -0.00366211\n"," -0.00161743], shape=(113376,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.07714844]\n"," [-0.07351685]\n"," [-0.07824707]], shape=(59240, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.07714844 -0.07351685\n"," -0.07824707], shape=(59240,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.05447388]\n"," [ 0.01821899]\n"," [-0.02590942]], shape=(62688, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.05447388  0.01821899\n"," -0.02590942], shape=(62688,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.4458313 ]\n"," [-0.25393677]\n"," [-0.140625  ]], shape=(61920, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.4458313  -0.25393677\n"," -0.140625  ], shape=(61920,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.16073608]\n"," [-0.14938354]\n"," [-0.16085815]], shape=(62304, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.16073608 -0.14938354\n"," -0.16085815], shape=(62304,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.08740234]\n"," [0.09899902]\n"," [0.10131836]], shape=(61728, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.08740234 0.09899902 0.10131836], shape=(61728,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.00967407]\n"," [-0.01266479]\n"," [-0.03173828]], shape=(60672, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.00967407 -0.01266479\n"," -0.03173828], shape=(60672,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[-0.01156616]\n"," [-0.02633667]\n"," [-0.04406738]\n"," ...\n"," [-0.00500488]\n"," [-0.00085449]\n"," [-0.00012207]], shape=(64636, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.01156616 -0.02633667 -0.04406738 ... -0.00500488 -0.00085449\n"," -0.00012207], shape=(64636,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00180054]\n"," [0.00564575]\n"," [0.00543213]], shape=(61152, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00180054 0.00564575 0.00543213], shape=(61152,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.02044678]\n"," [ 0.00421143]\n"," [ 0.02224731]], shape=(61056, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.02044678  0.00421143\n","  0.02224731], shape=(61056,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.00860596]\n"," [0.00836182]\n"," [0.00906372]], shape=(61536, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.00860596 0.00836182 0.00906372], shape=(61536,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.12658691]\n"," [-0.13467407]\n"," [-0.15979004]], shape=(61344, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.12658691 -0.13467407\n"," -0.15979004], shape=(61344,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01834106]\n"," [-0.00665283]\n"," [ 0.00158691]], shape=(58752, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.01834106 -0.00665283\n","  0.00158691], shape=(58752,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [-0.01953125]\n"," [-0.00991821]\n"," [ 0.02334595]], shape=(60864, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ... -0.01953125 -0.00991821\n","  0.02334595], shape=(60864,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[0.        ]\n"," [0.        ]\n"," [0.        ]\n"," ...\n"," [0.0085144 ]\n"," [0.00897217]\n"," [0.0178833 ]], shape=(65952, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor([0.         0.         0.         ... 0.0085144  0.00897217 0.0178833 ], shape=(65952,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[ 0.        ]\n"," [ 0.        ]\n"," [ 0.        ]\n"," ...\n"," [ 0.00030518]\n"," [-0.00180054]\n"," [-0.00515747]], shape=(62784, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[ 0.          0.          0.         ...  0.00030518 -0.00180054\n"," -0.00515747], shape=(62784,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n"]}],"source":["#train_data = train_data.concatenate(valid_data)\n","lengths = []\n","for f in os.listdir(os.path.join(train_dir_path, 'healthy')):\n","    tensor_wave = load_wav_16k_mono(os.path.join(train_dir_path, 'healthy', f))\n","    lengths.append(len(tensor_wave))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of train_data: 3240\n"]}],"source":["# Calculate the lengths\n","train_length = tf.data.experimental.cardinality(train_data).numpy()\n","#valid_length = tf.data.experimental.cardinality(valid_data).numpy()\n","\n","# Print the lengths\n","print(\"Length of train_data:\", train_length)\n","#print(\"Length of valid_data:\", valid_length)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import librosa\n","J = 6\n","Q = 1\n","T = 30000\n","scatt = Scattering1D(J, T, Q)\n","def extract(file_path, label, wav_length=30000):\n","    def mfccs(wav):\n","        # Ensure wav is a numpy array\n","        wav = wav.numpy()\n","        \n","        mfcc = librosa.feature.mfcc(y=wav, sr=2000, n_mfcc=7)\n","        return mfcc\n","\n","    \n","    \n","    def scattering_transform(wav):\n","        # Ensure wav is a numpy array\n","        wav = wav.numpy()\n","        \n","        meta = scatt.meta()\n","        order0 = np.where(meta['order'] == 0)\n","        order1 = np.where(meta['order'] == 1)\n","        order2 = np.where(meta['order'] == 2)\n","\n","        Sx = scatt(wav) \n","        return Sx[order1]\n","    \n","    wav = load_wav_16k_mono(file_path)\n","    wav = tf.cast(wav, dtype=tf.float32)  # Ensure wav is float32\n","    wav = wav / tf.reduce_max(tf.abs(wav))\n","    wav = wav[:wav_length] if tf.shape(wav)[0] > wav_length else tf.pad(wav, [(0, wav_length - tf.shape(wav)[0])], \"CONSTANT\")\n","    \n","    # Using tf.py_function to wrap the scattering transform\n","    mfcc = tf.py_function(mfccs, [wav], tf.float32)\n","    mfcc = tf.abs(mfcc)\n","\n","    # Using tf.py_function to wrap the scattering transform\n","    scattering_transform = tf.py_function(scattering_transform, [wav], tf.float32)\n","    scattering_transform = tf.abs(scattering_transform)\n","    # You might need to set the shape of the output manually if required\n","    scattering_transform.set_shape((7, 469)) \n","    \n","    concatenated_feature = tf.concat([scattering_transform, mfcc] , axis = 1)\n","    concatenated_feature = tf.expand_dims(concatenated_feature, axis = 2)\n","    \n","    return concatenated_feature, label"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:37.389949Z","iopub.status.busy":"2024-03-23T17:00:37.389564Z","iopub.status.idle":"2024-03-23T17:00:37.409052Z","shell.execute_reply":"2024-03-23T17:00:37.408118Z","shell.execute_reply.started":"2024-03-23T17:00:37.389918Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["b'D:\\\\MIET_HeartSound\\\\Dataset\\\\Dataset2\\\\heart_sound\\\\train\\\\healthy\\\\e00511.wav' 1.0\n"]}],"source":["iterator = hhl_train.shuffle(buffer_size=10000).as_numpy_iterator()\n","iterator.next()\n","filepath, label = next(iterator)\n","print(filepath, label)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:40.307339Z","iopub.status.busy":"2024-03-23T17:00:40.306396Z","iopub.status.idle":"2024-03-23T17:00:40.327641Z","shell.execute_reply":"2024-03-23T17:00:40.326773Z","shell.execute_reply.started":"2024-03-23T17:00:40.307294Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[-0.07125854]\n"," [-0.0687561 ]\n"," [-0.06500244]\n"," ...\n"," [-0.01126099]\n"," [-0.00875854]\n"," [-0.01126099]], shape=(68736, 1), dtype=float32) tf.Tensor(2000, shape=(), dtype=int32)\n","tf.Tensor(\n","[-0.07125854 -0.0687561  -0.06500244 ... -0.01126099 -0.00875854\n"," -0.01126099], shape=(68736,), dtype=float32) tf.Tensor(2000, shape=(), dtype=int64)\n","tf.Tensor(\n","[[[2.14285357e-03]\n","  [2.02181167e-03]\n","  [1.82538282e-03]\n","  ...\n","  [2.18276230e+02]\n","  [2.17560623e+02]\n","  [1.52267029e+02]]\n","\n"," [[4.83513996e-03]\n","  [4.63685673e-03]\n","  [4.30068979e-03]\n","  ...\n","  [1.19290382e+02]\n","  [1.15875664e+02]\n","  [9.86825867e+01]]\n","\n"," [[1.22641763e-02]\n","  [1.21064670e-02]\n","  [1.16255404e-02]\n","  ...\n","  [9.18457184e+01]\n","  [8.90641937e+01]\n","  [6.42180176e+01]]\n","\n"," ...\n","\n"," [[1.76258329e-02]\n","  [1.50319375e-02]\n","  [1.10651040e-02]\n","  ...\n","  [2.41555309e+01]\n","  [2.12642860e+01]\n","  [2.88164597e+01]]\n","\n"," [[1.02970228e-02]\n","  [8.81613977e-03]\n","  [6.42565871e-03]\n","  ...\n","  [1.51099911e+01]\n","  [1.13040018e+01]\n","  [1.72179260e+01]]\n","\n"," [[1.60011428e-03]\n","  [1.34212000e-03]\n","  [9.45651263e-04]\n","  ...\n","  [8.75690937e+00]\n","  [6.33063459e+00]\n","  [1.03476219e+01]]], shape=(7, 528, 1), dtype=float32)\n"]}],"source":["feature, label = extract(filepath, label)\n","print(feature)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:43.503373Z","iopub.status.busy":"2024-03-23T17:00:43.502676Z","iopub.status.idle":"2024-03-23T17:00:43.652508Z","shell.execute_reply":"2024-03-23T17:00:43.651723Z","shell.execute_reply.started":"2024-03-23T17:00:43.503340Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor(\"DecodeWav:0\", shape=(None, 1), dtype=float32) Tensor(\"DecodeWav:1\", shape=(), dtype=int32)\n","Tensor(\"Squeeze:0\", shape=(None,), dtype=float32) Tensor(\"Cast:0\", shape=(), dtype=int64)\n"]}],"source":["train_data = train_data.map(extract)\n","train_data = train_data.cache()\n","train_data = train_data.shuffle(buffer_size=1000)\n","train_data = train_data.batch(4)\n","train_data = train_data.prefetch(2)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:45.895416Z","iopub.status.busy":"2024-03-23T17:00:45.894979Z","iopub.status.idle":"2024-03-23T17:00:45.901683Z","shell.execute_reply":"2024-03-23T17:00:45.900608Z","shell.execute_reply.started":"2024-03-23T17:00:45.895366Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples in train_data: 810\n"]}],"source":["num_samples = tf.data.experimental.cardinality(train_data).numpy()\n","print(f\"Number of samples in train_data: {num_samples}\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:48.265552Z","iopub.status.busy":"2024-03-23T17:00:48.265187Z","iopub.status.idle":"2024-03-23T17:00:49.977083Z","shell.execute_reply":"2024-03-23T17:00:49.976092Z","shell.execute_reply.started":"2024-03-23T17:00:48.265524Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4, 7, 528, 1)\n","[1. 1. 1. 1.]\n"]}],"source":["train = train_data.take(567)\n","test = train_data.skip(567).take(243)\n","samples, labels = train.as_numpy_iterator().next()\n","print(samples.shape)\n","print(labels)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of train: 567\n","Length of test: 243\n"]}],"source":["# Calculate the lengths\n","train_length = tf.data.experimental.cardinality(train).numpy()\n","test_length = tf.data.experimental.cardinality(test).numpy()\n","\n","# Print the lengths\n","print(\"Length of train:\", train_length)\n","print(\"Length of test:\", test_length)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["# CNN"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:52.926719Z","iopub.status.busy":"2024-03-23T17:00:52.926348Z","iopub.status.idle":"2024-03-23T17:00:52.932647Z","shell.execute_reply":"2024-03-23T17:00:52.931707Z","shell.execute_reply.started":"2024-03-23T17:00:52.926688Z"},"trusted":true},"outputs":[],"source":["def cnn():\n","    model = Sequential()\n","    model.add(Conv2D(16, (2,2), activation='relu', input_shape=(7, 528, 1)))\n","    model.add(Conv2D(32, (2,2), activation='relu'))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    return model"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:00:56.002446Z","iopub.status.busy":"2024-03-23T17:00:56.002110Z","iopub.status.idle":"2024-03-23T17:00:56.078876Z","shell.execute_reply":"2024-03-23T17:00:56.077938Z","shell.execute_reply.started":"2024-03-23T17:00:56.002421Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 6, 527, 16)        80        \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 5, 526, 32)        2080      \n","_________________________________________________________________\n","flatten (Flatten)            (None, 84160)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               10772608  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 10,774,897\n","Trainable params: 10,774,897\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Create an optimizer with the learning rate schedule\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n","model0 = cnn()\n","model0.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","model0.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-23T17:01:02.291482Z","iopub.status.busy":"2024-03-23T17:01:02.290658Z","iopub.status.idle":"2024-03-23T17:07:13.791505Z","shell.execute_reply":"2024-03-23T17:07:13.790529Z","shell.execute_reply.started":"2024-03-23T17:01:02.291450Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1973 - accuracy: 0.9220 - val_loss: 0.6751 - val_accuracy: 0.5154\n","Epoch 2/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1868 - accuracy: 0.9131 - val_loss: 0.6637 - val_accuracy: 0.5165\n","Epoch 3/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1799 - accuracy: 0.9158 - val_loss: 0.6545 - val_accuracy: 0.5134\n","Epoch 4/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1821 - accuracy: 0.9034 - val_loss: 0.6509 - val_accuracy: 0.5000\n","Epoch 5/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1693 - accuracy: 0.9175 - val_loss: 0.6439 - val_accuracy: 0.6430\n","Epoch 6/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1654 - accuracy: 0.9295 - val_loss: 0.6213 - val_accuracy: 0.7191\n","Epoch 7/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1691 - accuracy: 0.9233 - val_loss: 0.6110 - val_accuracy: 0.7058\n","Epoch 8/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1814 - accuracy: 0.9233 - val_loss: 0.6128 - val_accuracy: 0.7109\n","Epoch 9/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1722 - accuracy: 0.9259 - val_loss: 0.6081 - val_accuracy: 0.7418\n","Epoch 10/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1740 - accuracy: 0.9250 - val_loss: 0.5935 - val_accuracy: 0.7798\n","Epoch 11/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1688 - accuracy: 0.9237 - val_loss: 0.6107 - val_accuracy: 0.7202\n","Epoch 12/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1700 - accuracy: 0.9220 - val_loss: 0.5924 - val_accuracy: 0.7263\n","Epoch 13/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.1726 - accuracy: 0.9264 - val_loss: 0.6183 - val_accuracy: 0.6584\n","Epoch 14/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1651 - accuracy: 0.9334 - val_loss: 0.5918 - val_accuracy: 0.7356\n","Epoch 15/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1683 - accuracy: 0.9224 - val_loss: 0.5969 - val_accuracy: 0.7130\n","Epoch 16/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1703 - accuracy: 0.9250 - val_loss: 0.5766 - val_accuracy: 0.7274\n","Epoch 17/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1624 - accuracy: 0.9290 - val_loss: 0.5683 - val_accuracy: 0.7294\n","Epoch 18/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1576 - accuracy: 0.9325 - val_loss: 0.5984 - val_accuracy: 0.6821\n","Epoch 19/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1694 - accuracy: 0.9317 - val_loss: 0.5668 - val_accuracy: 0.7088\n","Epoch 20/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1742 - accuracy: 0.9242 - val_loss: 0.5661 - val_accuracy: 0.7109\n","Epoch 21/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.1605 - accuracy: 0.9299 - val_loss: 0.5595 - val_accuracy: 0.7130\n","Epoch 22/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1509 - accuracy: 0.9347 - val_loss: 0.5745 - val_accuracy: 0.7171\n","Epoch 23/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1684 - accuracy: 0.9259 - val_loss: 0.5410 - val_accuracy: 0.7366\n","Epoch 24/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1548 - accuracy: 0.9369 - val_loss: 0.5028 - val_accuracy: 0.7675\n","Epoch 25/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1433 - accuracy: 0.9378 - val_loss: 0.5423 - val_accuracy: 0.7315\n","Epoch 26/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1580 - accuracy: 0.9277 - val_loss: 0.5338 - val_accuracy: 0.7603\n","Epoch 27/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.1665 - accuracy: 0.9237 - val_loss: 0.5477 - val_accuracy: 0.7058\n","Epoch 28/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1576 - accuracy: 0.9334 - val_loss: 0.5191 - val_accuracy: 0.7222\n","Epoch 29/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1526 - accuracy: 0.9378 - val_loss: 0.5179 - val_accuracy: 0.7418\n","Epoch 30/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1496 - accuracy: 0.9330 - val_loss: 0.5134 - val_accuracy: 0.7469\n","Epoch 31/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1464 - accuracy: 0.9356 - val_loss: 0.5103 - val_accuracy: 0.7438\n","Epoch 32/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1509 - accuracy: 0.9396 - val_loss: 0.5091 - val_accuracy: 0.7572\n","Epoch 33/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1590 - accuracy: 0.9317 - val_loss: 0.4999 - val_accuracy: 0.7654\n","Epoch 34/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1485 - accuracy: 0.9347 - val_loss: 0.4872 - val_accuracy: 0.7634\n","Epoch 35/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1631 - accuracy: 0.9330 - val_loss: 0.4866 - val_accuracy: 0.7788\n","Epoch 36/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1567 - accuracy: 0.9361 - val_loss: 0.4940 - val_accuracy: 0.7459\n","Epoch 37/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1455 - accuracy: 0.9414 - val_loss: 0.5021 - val_accuracy: 0.7500\n","Epoch 38/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.1498 - accuracy: 0.9378 - val_loss: 0.4938 - val_accuracy: 0.7366\n","Epoch 39/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1458 - accuracy: 0.9440 - val_loss: 0.4748 - val_accuracy: 0.7603\n","Epoch 40/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1435 - accuracy: 0.9414 - val_loss: 0.4816 - val_accuracy: 0.7582\n","Epoch 41/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1376 - accuracy: 0.9480 - val_loss: 0.4598 - val_accuracy: 0.7675\n","Epoch 42/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1407 - accuracy: 0.9422 - val_loss: 0.4768 - val_accuracy: 0.7562\n","Epoch 43/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1440 - accuracy: 0.9400 - val_loss: 0.4497 - val_accuracy: 0.7726\n","Epoch 44/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1393 - accuracy: 0.9449 - val_loss: 0.4583 - val_accuracy: 0.7716\n","Epoch 45/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1497 - accuracy: 0.9431 - val_loss: 0.4711 - val_accuracy: 0.7809\n","Epoch 46/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1411 - accuracy: 0.9458 - val_loss: 0.4508 - val_accuracy: 0.7922\n","Epoch 47/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1324 - accuracy: 0.9475 - val_loss: 0.4596 - val_accuracy: 0.7726\n","Epoch 48/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1401 - accuracy: 0.9466 - val_loss: 0.4504 - val_accuracy: 0.7778\n","Epoch 49/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1337 - accuracy: 0.9502 - val_loss: 0.4440 - val_accuracy: 0.7737\n","Epoch 50/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1378 - accuracy: 0.9444 - val_loss: 0.4318 - val_accuracy: 0.8189\n","Epoch 51/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1203 - accuracy: 0.9533 - val_loss: 0.4539 - val_accuracy: 0.7912\n","Epoch 52/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1210 - accuracy: 0.9524 - val_loss: 0.4575 - val_accuracy: 0.7829\n","Epoch 53/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1152 - accuracy: 0.9537 - val_loss: 0.4312 - val_accuracy: 0.7942\n","Epoch 54/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1221 - accuracy: 0.9511 - val_loss: 0.3979 - val_accuracy: 0.8272\n","Epoch 55/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1374 - accuracy: 0.9493 - val_loss: 0.4104 - val_accuracy: 0.8076\n","Epoch 56/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1197 - accuracy: 0.9533 - val_loss: 0.4325 - val_accuracy: 0.7840\n","Epoch 57/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1184 - accuracy: 0.9511 - val_loss: 0.5044 - val_accuracy: 0.7449\n","Epoch 58/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1321 - accuracy: 0.9427 - val_loss: 0.4198 - val_accuracy: 0.7973\n","Epoch 59/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1272 - accuracy: 0.9497 - val_loss: 0.4820 - val_accuracy: 0.7551\n","Epoch 60/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1351 - accuracy: 0.9462 - val_loss: 0.4190 - val_accuracy: 0.8138\n","Epoch 61/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1294 - accuracy: 0.9519 - val_loss: 0.3821 - val_accuracy: 0.8333\n","Epoch 62/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1129 - accuracy: 0.9541 - val_loss: 0.3906 - val_accuracy: 0.8251\n","Epoch 63/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1160 - accuracy: 0.9572 - val_loss: 0.3952 - val_accuracy: 0.8333\n","Epoch 64/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1309 - accuracy: 0.9506 - val_loss: 0.3880 - val_accuracy: 0.8374\n","Epoch 65/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1294 - accuracy: 0.9511 - val_loss: 0.3859 - val_accuracy: 0.8302\n","Epoch 66/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.1243 - accuracy: 0.9466 - val_loss: 0.3984 - val_accuracy: 0.8313\n","Epoch 67/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1293 - accuracy: 0.9515 - val_loss: 0.3964 - val_accuracy: 0.8210\n","Epoch 68/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1234 - accuracy: 0.9537 - val_loss: 0.3678 - val_accuracy: 0.8395\n","Epoch 69/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1376 - accuracy: 0.9462 - val_loss: 0.3827 - val_accuracy: 0.8313\n","Epoch 70/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1191 - accuracy: 0.9550 - val_loss: 0.3857 - val_accuracy: 0.8344\n","Epoch 71/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1104 - accuracy: 0.9546 - val_loss: 0.4118 - val_accuracy: 0.8107\n","Epoch 72/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1238 - accuracy: 0.9484 - val_loss: 0.3874 - val_accuracy: 0.8354\n","Epoch 73/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1148 - accuracy: 0.9590 - val_loss: 0.4020 - val_accuracy: 0.8210\n","Epoch 74/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1139 - accuracy: 0.9603 - val_loss: 0.3899 - val_accuracy: 0.8241\n","Epoch 75/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1174 - accuracy: 0.9590 - val_loss: 0.3745 - val_accuracy: 0.8426\n","Epoch 76/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1125 - accuracy: 0.9528 - val_loss: 0.3679 - val_accuracy: 0.8313\n","Epoch 77/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1114 - accuracy: 0.9581 - val_loss: 0.3960 - val_accuracy: 0.8261\n","Epoch 78/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1045 - accuracy: 0.9572 - val_loss: 0.4315 - val_accuracy: 0.7881\n","Epoch 79/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1131 - accuracy: 0.9528 - val_loss: 0.4087 - val_accuracy: 0.8138\n","Epoch 80/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1031 - accuracy: 0.9630 - val_loss: 0.3455 - val_accuracy: 0.8508\n","Epoch 81/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1160 - accuracy: 0.9590 - val_loss: 0.3698 - val_accuracy: 0.8395\n","Epoch 82/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1148 - accuracy: 0.9603 - val_loss: 0.3776 - val_accuracy: 0.8344\n","Epoch 83/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1243 - accuracy: 0.9546 - val_loss: 0.3636 - val_accuracy: 0.8447\n","Epoch 84/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1095 - accuracy: 0.9524 - val_loss: 0.3564 - val_accuracy: 0.8508\n","Epoch 85/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1062 - accuracy: 0.9599 - val_loss: 0.3959 - val_accuracy: 0.8302\n","Epoch 86/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1016 - accuracy: 0.9643 - val_loss: 0.3535 - val_accuracy: 0.8467\n","Epoch 87/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1055 - accuracy: 0.9599 - val_loss: 0.3579 - val_accuracy: 0.8313\n","Epoch 88/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1118 - accuracy: 0.9581 - val_loss: 0.3524 - val_accuracy: 0.8447\n","Epoch 89/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1100 - accuracy: 0.9612 - val_loss: 0.3788 - val_accuracy: 0.8323\n","Epoch 90/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1109 - accuracy: 0.9572 - val_loss: 0.3594 - val_accuracy: 0.8436\n","Epoch 91/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1144 - accuracy: 0.9528 - val_loss: 0.3503 - val_accuracy: 0.8457\n","Epoch 92/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1014 - accuracy: 0.9638 - val_loss: 0.3624 - val_accuracy: 0.8333\n","Epoch 93/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1036 - accuracy: 0.9586 - val_loss: 0.3565 - val_accuracy: 0.8364\n","Epoch 94/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1096 - accuracy: 0.9599 - val_loss: 0.3826 - val_accuracy: 0.8230\n","Epoch 95/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0902 - accuracy: 0.9660 - val_loss: 0.3490 - val_accuracy: 0.8488\n","Epoch 96/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1053 - accuracy: 0.9581 - val_loss: 0.3908 - val_accuracy: 0.8200\n","Epoch 97/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0944 - accuracy: 0.9625 - val_loss: 0.3446 - val_accuracy: 0.8467\n","Epoch 98/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0928 - accuracy: 0.9621 - val_loss: 0.3520 - val_accuracy: 0.8416\n","Epoch 99/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0976 - accuracy: 0.9630 - val_loss: 0.3356 - val_accuracy: 0.8549\n","Epoch 100/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1020 - accuracy: 0.9634 - val_loss: 0.3228 - val_accuracy: 0.8632\n","Epoch 101/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1002 - accuracy: 0.9643 - val_loss: 0.3867 - val_accuracy: 0.8220\n","Epoch 102/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0935 - accuracy: 0.9683 - val_loss: 0.3458 - val_accuracy: 0.8560\n","Epoch 103/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0920 - accuracy: 0.9616 - val_loss: 0.3274 - val_accuracy: 0.8621\n","Epoch 104/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0943 - accuracy: 0.9665 - val_loss: 0.3612 - val_accuracy: 0.8457\n","Epoch 105/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.1049 - accuracy: 0.9603 - val_loss: 0.3370 - val_accuracy: 0.8611\n","Epoch 106/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0892 - accuracy: 0.9678 - val_loss: 0.3336 - val_accuracy: 0.8508\n","Epoch 107/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0899 - accuracy: 0.9660 - val_loss: 0.3416 - val_accuracy: 0.8591\n","Epoch 108/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0947 - accuracy: 0.9625 - val_loss: 0.3239 - val_accuracy: 0.8601\n","Epoch 109/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1021 - accuracy: 0.9630 - val_loss: 0.3222 - val_accuracy: 0.8560\n","Epoch 110/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0954 - accuracy: 0.9612 - val_loss: 0.3244 - val_accuracy: 0.8621\n","Epoch 111/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0961 - accuracy: 0.9634 - val_loss: 0.3215 - val_accuracy: 0.8621\n","Epoch 112/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0905 - accuracy: 0.9647 - val_loss: 0.3155 - val_accuracy: 0.8632\n","Epoch 113/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.1040 - accuracy: 0.9572 - val_loss: 0.3343 - val_accuracy: 0.8488\n","Epoch 114/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0905 - accuracy: 0.9647 - val_loss: 0.3289 - val_accuracy: 0.8591\n","Epoch 115/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0942 - accuracy: 0.9669 - val_loss: 0.3167 - val_accuracy: 0.8601\n","Epoch 116/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0927 - accuracy: 0.9652 - val_loss: 0.3159 - val_accuracy: 0.8560\n","Epoch 117/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0935 - accuracy: 0.9594 - val_loss: 0.3151 - val_accuracy: 0.8467\n","Epoch 118/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0848 - accuracy: 0.9660 - val_loss: 0.3228 - val_accuracy: 0.8591\n","Epoch 119/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0896 - accuracy: 0.9643 - val_loss: 0.3059 - val_accuracy: 0.8745\n","Epoch 120/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0911 - accuracy: 0.9665 - val_loss: 0.3415 - val_accuracy: 0.8374\n","Epoch 121/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0819 - accuracy: 0.9696 - val_loss: 0.3388 - val_accuracy: 0.8580\n","Epoch 122/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0887 - accuracy: 0.9665 - val_loss: 0.3109 - val_accuracy: 0.8776\n","Epoch 123/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0861 - accuracy: 0.9660 - val_loss: 0.2923 - val_accuracy: 0.8704\n","Epoch 124/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0789 - accuracy: 0.9683 - val_loss: 0.2921 - val_accuracy: 0.8652\n","Epoch 125/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0884 - accuracy: 0.9669 - val_loss: 0.3181 - val_accuracy: 0.8611\n","Epoch 126/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0853 - accuracy: 0.9674 - val_loss: 0.3480 - val_accuracy: 0.8344\n","Epoch 127/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0884 - accuracy: 0.9669 - val_loss: 0.3079 - val_accuracy: 0.8580\n","Epoch 128/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0900 - accuracy: 0.9656 - val_loss: 0.2981 - val_accuracy: 0.8663\n","Epoch 129/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0828 - accuracy: 0.9660 - val_loss: 0.3114 - val_accuracy: 0.8601\n","Epoch 130/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0896 - accuracy: 0.9643 - val_loss: 0.2854 - val_accuracy: 0.8796\n","Epoch 131/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0849 - accuracy: 0.9638 - val_loss: 0.2780 - val_accuracy: 0.8817\n","Epoch 132/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0836 - accuracy: 0.9669 - val_loss: 0.3084 - val_accuracy: 0.8683\n","Epoch 133/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0657 - accuracy: 0.9757 - val_loss: 0.3103 - val_accuracy: 0.8652\n","Epoch 134/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0812 - accuracy: 0.9683 - val_loss: 0.3064 - val_accuracy: 0.8560\n","Epoch 135/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0772 - accuracy: 0.9687 - val_loss: 0.2854 - val_accuracy: 0.8663\n","Epoch 136/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0775 - accuracy: 0.9713 - val_loss: 0.2911 - val_accuracy: 0.8683\n","Epoch 137/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0782 - accuracy: 0.9683 - val_loss: 0.2916 - val_accuracy: 0.8673\n","Epoch 138/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0857 - accuracy: 0.9683 - val_loss: 0.2837 - val_accuracy: 0.8776\n","Epoch 139/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0672 - accuracy: 0.9731 - val_loss: 0.3281 - val_accuracy: 0.8426\n","Epoch 140/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0687 - accuracy: 0.9744 - val_loss: 0.2758 - val_accuracy: 0.8724\n","Epoch 141/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0760 - accuracy: 0.9700 - val_loss: 0.2739 - val_accuracy: 0.8704\n","Epoch 142/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0766 - accuracy: 0.9683 - val_loss: 0.2856 - val_accuracy: 0.8817\n","Epoch 143/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0759 - accuracy: 0.9700 - val_loss: 0.3116 - val_accuracy: 0.8591\n","Epoch 144/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0727 - accuracy: 0.9696 - val_loss: 0.2687 - val_accuracy: 0.8837\n","Epoch 145/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0684 - accuracy: 0.9757 - val_loss: 0.3365 - val_accuracy: 0.8519\n","Epoch 146/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0683 - accuracy: 0.9735 - val_loss: 0.2610 - val_accuracy: 0.8858\n","Epoch 147/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0687 - accuracy: 0.9735 - val_loss: 0.2924 - val_accuracy: 0.8807\n","Epoch 148/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0741 - accuracy: 0.9718 - val_loss: 0.2837 - val_accuracy: 0.8796\n","Epoch 149/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0722 - accuracy: 0.9731 - val_loss: 0.2714 - val_accuracy: 0.8735\n","Epoch 150/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0628 - accuracy: 0.9740 - val_loss: 0.2786 - val_accuracy: 0.8704\n","Epoch 151/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0699 - accuracy: 0.9709 - val_loss: 0.3087 - val_accuracy: 0.8632\n","Epoch 152/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0751 - accuracy: 0.9705 - val_loss: 0.2957 - val_accuracy: 0.8714\n","Epoch 153/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0684 - accuracy: 0.9735 - val_loss: 0.2809 - val_accuracy: 0.8817\n","Epoch 154/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0704 - accuracy: 0.9687 - val_loss: 0.2699 - val_accuracy: 0.8837\n","Epoch 155/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0632 - accuracy: 0.9766 - val_loss: 0.2625 - val_accuracy: 0.8807\n","Epoch 156/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0653 - accuracy: 0.9727 - val_loss: 0.2832 - val_accuracy: 0.8652\n","Epoch 157/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0754 - accuracy: 0.9687 - val_loss: 0.2490 - val_accuracy: 0.9002\n","Epoch 158/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0609 - accuracy: 0.9775 - val_loss: 0.2367 - val_accuracy: 0.9002\n","Epoch 159/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0663 - accuracy: 0.9766 - val_loss: 0.2323 - val_accuracy: 0.9023\n","Epoch 160/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0551 - accuracy: 0.9788 - val_loss: 0.3102 - val_accuracy: 0.8642\n","Epoch 161/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.2465 - val_accuracy: 0.8940\n","Epoch 162/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0640 - accuracy: 0.9766 - val_loss: 0.2411 - val_accuracy: 0.8940\n","Epoch 163/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0559 - accuracy: 0.9788 - val_loss: 0.2675 - val_accuracy: 0.8807\n","Epoch 164/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0625 - accuracy: 0.9793 - val_loss: 0.2806 - val_accuracy: 0.8848\n","Epoch 165/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0543 - accuracy: 0.9780 - val_loss: 0.2378 - val_accuracy: 0.8961\n","Epoch 166/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0603 - accuracy: 0.9757 - val_loss: 0.2302 - val_accuracy: 0.9053\n","Epoch 167/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0575 - accuracy: 0.9788 - val_loss: 0.2309 - val_accuracy: 0.8971\n","Epoch 168/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0670 - accuracy: 0.9722 - val_loss: 0.2357 - val_accuracy: 0.9064\n","Epoch 169/200\n","567/567 [==============================] - 4s 8ms/step - loss: 0.0603 - accuracy: 0.9775 - val_loss: 0.2436 - val_accuracy: 0.8930\n","Epoch 170/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.2156 - val_accuracy: 0.9033\n","Epoch 171/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0548 - accuracy: 0.9797 - val_loss: 0.2156 - val_accuracy: 0.9074\n","Epoch 172/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0550 - accuracy: 0.9797 - val_loss: 0.2249 - val_accuracy: 0.9074\n","Epoch 173/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0515 - accuracy: 0.9797 - val_loss: 0.2657 - val_accuracy: 0.8940\n","Epoch 174/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0548 - accuracy: 0.9797 - val_loss: 0.2314 - val_accuracy: 0.9002\n","Epoch 175/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 0.2251 - val_accuracy: 0.9043\n","Epoch 176/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.2929 - val_accuracy: 0.8683\n","Epoch 177/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0504 - accuracy: 0.9793 - val_loss: 0.2576 - val_accuracy: 0.8848\n","Epoch 178/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 0.2263 - val_accuracy: 0.9095\n","Epoch 179/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.2111 - val_accuracy: 0.9074\n","Epoch 180/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0547 - accuracy: 0.9766 - val_loss: 0.2207 - val_accuracy: 0.9105\n","Epoch 181/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0515 - accuracy: 0.9828 - val_loss: 0.1997 - val_accuracy: 0.9136\n","Epoch 182/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.2141 - val_accuracy: 0.9095\n","Epoch 183/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0488 - accuracy: 0.9797 - val_loss: 0.2435 - val_accuracy: 0.9074\n","Epoch 184/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0485 - accuracy: 0.9806 - val_loss: 0.2023 - val_accuracy: 0.9136\n","Epoch 185/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0421 - accuracy: 0.9828 - val_loss: 0.2137 - val_accuracy: 0.9033\n","Epoch 186/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0549 - accuracy: 0.9802 - val_loss: 0.2269 - val_accuracy: 0.9095\n","Epoch 187/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0445 - accuracy: 0.9832 - val_loss: 0.2076 - val_accuracy: 0.9115\n","Epoch 188/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0485 - accuracy: 0.9824 - val_loss: 0.2055 - val_accuracy: 0.9084\n","Epoch 189/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 0.2274 - val_accuracy: 0.8992\n","Epoch 190/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0465 - accuracy: 0.9819 - val_loss: 0.2278 - val_accuracy: 0.9023\n","Epoch 191/200\n","567/567 [==============================] - 5s 8ms/step - loss: 0.0462 - accuracy: 0.9819 - val_loss: 0.2150 - val_accuracy: 0.9156\n","Epoch 192/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0458 - accuracy: 0.9837 - val_loss: 0.2335 - val_accuracy: 0.9126\n","Epoch 193/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0412 - accuracy: 0.9815 - val_loss: 0.2047 - val_accuracy: 0.9156\n","Epoch 194/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0490 - accuracy: 0.9775 - val_loss: 0.1947 - val_accuracy: 0.9290\n","Epoch 195/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0460 - accuracy: 0.9757 - val_loss: 0.2033 - val_accuracy: 0.9187\n","Epoch 196/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0421 - accuracy: 0.9841 - val_loss: 0.2000 - val_accuracy: 0.9167\n","Epoch 197/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0432 - accuracy: 0.9846 - val_loss: 0.1938 - val_accuracy: 0.9208\n","Epoch 198/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0379 - accuracy: 0.9872 - val_loss: 0.2025 - val_accuracy: 0.9198\n","Epoch 199/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0399 - accuracy: 0.9850 - val_loss: 0.1995 - val_accuracy: 0.9187\n","Epoch 200/200\n","567/567 [==============================] - 5s 9ms/step - loss: 0.0457 - accuracy: 0.9846 - val_loss: 0.2065 - val_accuracy: 0.9136\n"]}],"source":["batch_size = 64\n","\n","history0 = model0.fit(train, \n","                    batch_size=batch_size, \n","                    epochs=200,\n","                    validation_data=test,\n","                    verbose=1,\n","                    )"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","def butterfly_optimization(n, fitness, dimension, lb, ub, max_iter):\n","    # Initialize population\n","    population = np.random.rand(n, dimension) * (ub - lb) + lb\n","    fitness_population = np.array([fitness(ind) for ind in population])\n","    \n","    # BOA parameters\n","    sensory_modality = 0.01  # Sensory modality (perception)\n","    \n","    for _ in range(max_iter):\n","        # Update butterflies\n","        for i in range(n):\n","            if np.random.rand() < sensory_modality:\n","                # Global search\n","                j = np.random.randint(0, n)  # Random butterfly index\n","                step_size = np.random.rand() * (population[j] - population[i])\n","            else:\n","                # Local search\n","                step_size = np.random.normal(0, 1, dimension)\n","            \n","            # Move butterfly\n","            population[i] += step_size\n","            population[i] = np.clip(population[i], lb, ub)  # Keep within bounds\n","            print(\"Calculating\")\n","            # Evaluate new solution\n","            new_fitness = fitness(population[i])\n","            if new_fitness < fitness_population[i]:\n","                fitness_population[i] = new_fitness\n","                print('Found new fitness: ', new_fitness)\n","    \n","    # Return the best solution\n","    best_idx = np.argmin(fitness_population)\n","    return population[best_idx]\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def model_fitness(hyperparams):\n","    learning_rate, batch_size = hyperparams\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    model = cnn()  # Your CNN model function\n","    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","    \n","    # Assuming `train` and `test` are predefined datasets\n","    history = model.fit(train, batch_size=int(batch_size), epochs=10, validation_data=test, verbose=0)\n","    val_accuracy = np.max(history.history['val_accuracy'])  # Max validation accuracy\n","    \n","    return -val_accuracy  # Negative because BOA minimizes the fitness function\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Calculating\n","Calculating\n","Found new fitness:  -0.8847736716270447\n","Calculating\n","Found new fitness:  -0.7644032835960388\n","Calculating\n","Found new fitness:  -0.8487654328346252\n","Calculating\n","Calculating\n","Found new fitness:  -0.8497942090034485\n","Calculating\n","Calculating\n","Found new fitness:  -0.8518518805503845\n","Calculating\n","Found new fitness:  -0.8220164775848389\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.7705761194229126\n","Calculating\n","Found new fitness:  -0.8611111044883728\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8497942090034485\n","Calculating\n","Found new fitness:  -0.8168724179267883\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8528806567192078\n","Calculating\n","Calculating\n","Found new fitness:  -0.8508230447769165\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.854938268661499\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8744856119155884\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8600823283195496\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8641975522041321\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.854938268661499\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8580247163772583\n","Calculating\n","Found new fitness:  -0.8683127760887146\n","Calculating\n","Found new fitness:  -0.8847736716270447\n","Calculating\n","Found new fitness:  -0.8755143880844116\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8611111044883728\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8672839403152466\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8724279999732971\n","Calculating\n","Found new fitness:  -0.8847736716270447\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8734567761421204\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8683127760887146\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8693415522575378\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8734567761421204\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Found new fitness:  -0.8775720000267029\n","Calculating\n","Calculating\n","Calculating\n","Calculating\n","Best Hyperparameters: Learning Rate = 1e-05, Batch Size = 58\n"]}],"source":["best_hyperparams = butterfly_optimization(\n","    n=10, \n","    fitness=model_fitness, \n","    dimension=2, \n","    lb=np.array([1e-5, 8]),  # Lower bounds for learning rate and batch size\n","    ub=np.array([1e-2, 64]),  # Upper bounds\n","    max_iter=20\n",")\n","\n","print(f\"Best Hyperparameters: Learning Rate = {best_hyperparams[0]}, Batch Size = {int(best_hyperparams[1])}\")\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","567/567 [==============================] - 112s 140ms/step - loss: 0.4605 - accuracy: 0.9149 - val_loss: 0.7698 - val_accuracy: 0.7490\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2521 - accuracy: 0.9206 - val_loss: 0.5483 - val_accuracy: 0.7716\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2429 - accuracy: 0.9237 - val_loss: 0.7098 - val_accuracy: 0.7912\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1796 - accuracy: 0.9387 - val_loss: 0.4825 - val_accuracy: 0.7706\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1982 - accuracy: 0.9352 - val_loss: 0.4311 - val_accuracy: 0.7870\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1326 - accuracy: 0.9511 - val_loss: 0.4093 - val_accuracy: 0.8292\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1365 - accuracy: 0.9427 - val_loss: 0.4546 - val_accuracy: 0.7798\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1297 - accuracy: 0.9444 - val_loss: 0.5046 - val_accuracy: 0.7778\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1276 - accuracy: 0.9533 - val_loss: 0.3839 - val_accuracy: 0.8169\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1207 - accuracy: 0.9502 - val_loss: 0.3982 - val_accuracy: 0.8148\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1201 - accuracy: 0.9533 - val_loss: 0.3918 - val_accuracy: 0.8416\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1343 - accuracy: 0.9559 - val_loss: 0.3251 - val_accuracy: 0.8549\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0952 - accuracy: 0.9634 - val_loss: 0.4019 - val_accuracy: 0.8056\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1206 - accuracy: 0.9555 - val_loss: 0.3248 - val_accuracy: 0.8498\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1167 - accuracy: 0.9546 - val_loss: 0.3468 - val_accuracy: 0.8519\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0951 - accuracy: 0.9599 - val_loss: 0.2737 - val_accuracy: 0.8827\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0999 - accuracy: 0.9638 - val_loss: 0.3359 - val_accuracy: 0.8374\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 0.3861 - val_accuracy: 0.8251\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0878 - accuracy: 0.9630 - val_loss: 0.3405 - val_accuracy: 0.8611\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0832 - accuracy: 0.9647 - val_loss: 0.3328 - val_accuracy: 0.8364\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0848 - accuracy: 0.9634 - val_loss: 0.3779 - val_accuracy: 0.8570\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0930 - accuracy: 0.9665 - val_loss: 0.3785 - val_accuracy: 0.8488\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0928 - accuracy: 0.9634 - val_loss: 0.2802 - val_accuracy: 0.8817\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0785 - accuracy: 0.9709 - val_loss: 0.3077 - val_accuracy: 0.8580\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0875 - accuracy: 0.9634 - val_loss: 0.2768 - val_accuracy: 0.8786\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0783 - accuracy: 0.9660 - val_loss: 0.2300 - val_accuracy: 0.8981\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0821 - accuracy: 0.9687 - val_loss: 0.2557 - val_accuracy: 0.8858\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0727 - accuracy: 0.9735 - val_loss: 0.2462 - val_accuracy: 0.8889\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0722 - accuracy: 0.9749 - val_loss: 0.2480 - val_accuracy: 0.8796\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0600 - accuracy: 0.9753 - val_loss: 0.2888 - val_accuracy: 0.8704\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0718 - accuracy: 0.9740 - val_loss: 0.2143 - val_accuracy: 0.9074\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0736 - accuracy: 0.9687 - val_loss: 0.2277 - val_accuracy: 0.9043\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9775 - val_loss: 0.2114 - val_accuracy: 0.9115\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0571 - accuracy: 0.9757 - val_loss: 0.2253 - val_accuracy: 0.9043\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0626 - accuracy: 0.9753 - val_loss: 0.1863 - val_accuracy: 0.9208\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0598 - accuracy: 0.9762 - val_loss: 0.1913 - val_accuracy: 0.9095\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.1996 - val_accuracy: 0.9126\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9780 - val_loss: 0.2664 - val_accuracy: 0.8909\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0645 - accuracy: 0.9753 - val_loss: 0.2031 - val_accuracy: 0.9002\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9771 - val_loss: 0.1636 - val_accuracy: 0.9311\n","Epoch 41/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0478 - accuracy: 0.9828 - val_loss: 0.2192 - val_accuracy: 0.9012\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.9740 - val_loss: 0.1739 - val_accuracy: 0.9218\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0411 - accuracy: 0.9841 - val_loss: 0.2343 - val_accuracy: 0.8940\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0417 - accuracy: 0.9824 - val_loss: 0.1522 - val_accuracy: 0.9424\n","Epoch 45/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: 0.1633 - val_accuracy: 0.9270\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0404 - accuracy: 0.9819 - val_loss: 0.2309 - val_accuracy: 0.8879\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 0.1435 - val_accuracy: 0.9311\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0407 - accuracy: 0.9837 - val_loss: 0.1402 - val_accuracy: 0.9372\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0394 - accuracy: 0.9854 - val_loss: 0.1580 - val_accuracy: 0.9280\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0422 - accuracy: 0.9846 - val_loss: 0.1446 - val_accuracy: 0.9424\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 1.9051 - accuracy: 0.9087 - val_loss: 0.7133 - val_accuracy: 0.5051\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3374 - accuracy: 0.9175 - val_loss: 0.6349 - val_accuracy: 0.6636\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2952 - accuracy: 0.9123 - val_loss: 0.6974 - val_accuracy: 0.5123\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2056 - accuracy: 0.9153 - val_loss: 0.6863 - val_accuracy: 0.5401\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1854 - accuracy: 0.9396 - val_loss: 0.5898 - val_accuracy: 0.7109\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1593 - accuracy: 0.9405 - val_loss: 0.5319 - val_accuracy: 0.7551\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1716 - accuracy: 0.9264 - val_loss: 0.5404 - val_accuracy: 0.7346\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1711 - accuracy: 0.9259 - val_loss: 0.5481 - val_accuracy: 0.7284\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1713 - accuracy: 0.9339 - val_loss: 0.5345 - val_accuracy: 0.7490\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1720 - accuracy: 0.9369 - val_loss: 0.5320 - val_accuracy: 0.7449\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7873 - accuracy: 0.9264 - val_loss: 0.4585 - val_accuracy: 0.7695\n","Epoch 12/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.3158 - accuracy: 0.9436 - val_loss: 0.4635 - val_accuracy: 0.7665\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2347 - accuracy: 0.9471 - val_loss: 0.4475 - val_accuracy: 0.8066\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1466 - accuracy: 0.9493 - val_loss: 0.4560 - val_accuracy: 0.7757\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1301 - accuracy: 0.9533 - val_loss: 0.4036 - val_accuracy: 0.8035\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1599 - accuracy: 0.9515 - val_loss: 0.4173 - val_accuracy: 0.8076\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1990 - accuracy: 0.9444 - val_loss: 0.3731 - val_accuracy: 0.8313\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1527 - accuracy: 0.9484 - val_loss: 0.4421 - val_accuracy: 0.7942\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9471 - val_loss: 0.4173 - val_accuracy: 0.8241\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1576 - accuracy: 0.9515 - val_loss: 0.4200 - val_accuracy: 0.8035\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1146 - accuracy: 0.9559 - val_loss: 0.3946 - val_accuracy: 0.8076\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1230 - accuracy: 0.9502 - val_loss: 0.3938 - val_accuracy: 0.8179\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1249 - accuracy: 0.9502 - val_loss: 0.3810 - val_accuracy: 0.8148\n","Epoch 24/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1369 - accuracy: 0.9524 - val_loss: 0.3927 - val_accuracy: 0.8313\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1297 - accuracy: 0.9489 - val_loss: 0.4057 - val_accuracy: 0.7963\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2170 - accuracy: 0.9506 - val_loss: 0.4062 - val_accuracy: 0.8035\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1146 - accuracy: 0.9537 - val_loss: 0.3860 - val_accuracy: 0.8117\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1224 - accuracy: 0.9572 - val_loss: 0.3490 - val_accuracy: 0.8344\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1526 - accuracy: 0.9506 - val_loss: 0.3816 - val_accuracy: 0.8210\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1974 - accuracy: 0.9528 - val_loss: 0.3868 - val_accuracy: 0.8158\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1578 - accuracy: 0.9524 - val_loss: 0.3791 - val_accuracy: 0.8220\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1058 - accuracy: 0.9581 - val_loss: 0.3564 - val_accuracy: 0.8210\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1033 - accuracy: 0.9621 - val_loss: 0.3852 - val_accuracy: 0.8313\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1280 - accuracy: 0.9502 - val_loss: 0.4177 - val_accuracy: 0.8385\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1340 - accuracy: 0.9581 - val_loss: 0.3444 - val_accuracy: 0.8395\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1216 - accuracy: 0.9616 - val_loss: 0.3043 - val_accuracy: 0.8642\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1063 - accuracy: 0.9603 - val_loss: 0.3282 - val_accuracy: 0.8580\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1141 - accuracy: 0.9594 - val_loss: 0.3242 - val_accuracy: 0.8601\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1263 - accuracy: 0.9550 - val_loss: 0.3370 - val_accuracy: 0.8591\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1186 - accuracy: 0.9550 - val_loss: 0.3137 - val_accuracy: 0.8560\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0908 - accuracy: 0.9691 - val_loss: 0.3853 - val_accuracy: 0.8395\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1106 - accuracy: 0.9608 - val_loss: 0.3941 - val_accuracy: 0.8261\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0860 - accuracy: 0.9687 - val_loss: 0.3102 - val_accuracy: 0.8704\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2173 - accuracy: 0.9630 - val_loss: 0.2985 - val_accuracy: 0.8642\n","Epoch 45/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0943 - accuracy: 0.9709 - val_loss: 0.2822 - val_accuracy: 0.8663\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1636 - accuracy: 0.9638 - val_loss: 0.3110 - val_accuracy: 0.8601\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0951 - accuracy: 0.9656 - val_loss: 0.3047 - val_accuracy: 0.8539\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0809 - accuracy: 0.9674 - val_loss: 0.2810 - val_accuracy: 0.8776\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0809 - accuracy: 0.9735 - val_loss: 0.2833 - val_accuracy: 0.8580\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0801 - accuracy: 0.9727 - val_loss: 0.2852 - val_accuracy: 0.8621\n","Score: 0.8621399402618408 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 574991.0000 - accuracy: 0.8946 - val_loss: 0.6967 - val_accuracy: 0.4938\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1879 - accuracy: 0.9030 - val_loss: 0.7181 - val_accuracy: 0.5206\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1928 - accuracy: 0.9078 - val_loss: 0.7547 - val_accuracy: 0.5134\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1835 - accuracy: 0.9105 - val_loss: 0.6930 - val_accuracy: 0.5165\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1879 - accuracy: 0.9136 - val_loss: 0.7326 - val_accuracy: 0.4784\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9149 - val_loss: 0.7968 - val_accuracy: 0.5154\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9087 - val_loss: 0.8214 - val_accuracy: 0.4722\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1911 - accuracy: 0.9052 - val_loss: 0.6986 - val_accuracy: 0.4877\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1941 - accuracy: 0.9061 - val_loss: 0.6973 - val_accuracy: 0.4856\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1920 - accuracy: 0.9087 - val_loss: 0.6944 - val_accuracy: 0.4907\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1866 - accuracy: 0.9070 - val_loss: 0.7043 - val_accuracy: 0.4918\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2035 - accuracy: 0.9008 - val_loss: 0.7362 - val_accuracy: 0.4877\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1972 - accuracy: 0.9017 - val_loss: 0.6924 - val_accuracy: 0.5226\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1866 - accuracy: 0.9153 - val_loss: 0.7317 - val_accuracy: 0.5267\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2007 - accuracy: 0.9056 - val_loss: 0.8419 - val_accuracy: 0.5216\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1870 - accuracy: 0.9056 - val_loss: 0.6943 - val_accuracy: 0.5195\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1878 - accuracy: 0.9127 - val_loss: 0.6949 - val_accuracy: 0.4835\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2019 - accuracy: 0.9065 - val_loss: 0.6916 - val_accuracy: 0.5319\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1968 - accuracy: 0.9004 - val_loss: 0.7009 - val_accuracy: 0.5144\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1888 - accuracy: 0.9149 - val_loss: 0.7208 - val_accuracy: 0.5051\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2035 - accuracy: 0.9030 - val_loss: 0.7369 - val_accuracy: 0.5154\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1910 - accuracy: 0.9034 - val_loss: 0.6975 - val_accuracy: 0.4805\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2069 - accuracy: 0.8968 - val_loss: 0.7648 - val_accuracy: 0.5360\n","Epoch 24/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1989 - accuracy: 0.9114 - val_loss: 0.7201 - val_accuracy: 0.4877\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2006 - accuracy: 0.9096 - val_loss: 0.7121 - val_accuracy: 0.4897\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1935 - accuracy: 0.9061 - val_loss: 0.7304 - val_accuracy: 0.4856\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2033 - accuracy: 0.9004 - val_loss: 0.7171 - val_accuracy: 0.5195\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1947 - accuracy: 0.9145 - val_loss: 0.6927 - val_accuracy: 0.5206\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1996 - accuracy: 0.9056 - val_loss: 0.7405 - val_accuracy: 0.4949\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2139 - accuracy: 0.8924 - val_loss: 0.7291 - val_accuracy: 0.5103\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1982 - accuracy: 0.9180 - val_loss: 0.7098 - val_accuracy: 0.4866\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1947 - accuracy: 0.9043 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1937 - accuracy: 0.9101 - val_loss: 0.7541 - val_accuracy: 0.5154\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1880 - accuracy: 0.9092 - val_loss: 0.7014 - val_accuracy: 0.5185\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1901 - accuracy: 0.9043 - val_loss: 0.6983 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1892 - accuracy: 0.9167 - val_loss: 0.6983 - val_accuracy: 0.4835\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1927 - accuracy: 0.9114 - val_loss: 0.7014 - val_accuracy: 0.4887\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1949 - accuracy: 0.9074 - val_loss: 0.7167 - val_accuracy: 0.5247\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1854 - accuracy: 0.9202 - val_loss: 0.6967 - val_accuracy: 0.5062\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1895 - accuracy: 0.9184 - val_loss: 0.7185 - val_accuracy: 0.4928\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1941 - accuracy: 0.9140 - val_loss: 0.6972 - val_accuracy: 0.4815\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1903 - accuracy: 0.9070 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1984 - accuracy: 0.9078 - val_loss: 0.7066 - val_accuracy: 0.4907\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1964 - accuracy: 0.9109 - val_loss: 0.7008 - val_accuracy: 0.4877\n","Epoch 45/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1971 - accuracy: 0.9034 - val_loss: 0.8120 - val_accuracy: 0.4743\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9065 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1906 - accuracy: 0.9211 - val_loss: 0.7855 - val_accuracy: 0.4825\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1961 - accuracy: 0.9039 - val_loss: 0.6943 - val_accuracy: 0.5144\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1944 - accuracy: 0.9180 - val_loss: 0.7132 - val_accuracy: 0.4887\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1937 - accuracy: 0.9056 - val_loss: 0.6964 - val_accuracy: 0.4969\n","Score: 0.4969135820865631 \n","Parameters:  {'learning_rate': 0.12169711334629683, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.8949 - accuracy: 0.9193 - val_loss: 0.6299 - val_accuracy: 0.6430\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1614 - accuracy: 0.9228 - val_loss: 0.5966 - val_accuracy: 0.6842\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1775 - accuracy: 0.9259 - val_loss: 0.5495 - val_accuracy: 0.7418\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1551 - accuracy: 0.9308 - val_loss: 0.5415 - val_accuracy: 0.7130\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1586 - accuracy: 0.9325 - val_loss: 0.4930 - val_accuracy: 0.7315\n","Epoch 6/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1921 - accuracy: 0.9228 - val_loss: 0.5421 - val_accuracy: 0.7181\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1562 - accuracy: 0.9352 - val_loss: 0.6771 - val_accuracy: 0.6965\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1427 - accuracy: 0.9418 - val_loss: 0.5131 - val_accuracy: 0.7449\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1703 - accuracy: 0.9392 - val_loss: 0.5409 - val_accuracy: 0.7551\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9281 - val_loss: 0.4641 - val_accuracy: 0.7593\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1382 - accuracy: 0.9418 - val_loss: 0.4480 - val_accuracy: 0.7726\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1736 - accuracy: 0.9396 - val_loss: 0.4855 - val_accuracy: 0.7531\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1500 - accuracy: 0.9392 - val_loss: 0.4572 - val_accuracy: 0.7623\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9489 - val_loss: 0.4752 - val_accuracy: 0.7819\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.3784 - accuracy: 0.9440 - val_loss: 0.4878 - val_accuracy: 0.7500\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3094 - accuracy: 0.9475 - val_loss: 0.4691 - val_accuracy: 0.7819\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1687 - accuracy: 0.9462 - val_loss: 0.4459 - val_accuracy: 0.7726\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2024 - accuracy: 0.9484 - val_loss: 0.4315 - val_accuracy: 0.7881\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1311 - accuracy: 0.9466 - val_loss: 0.4186 - val_accuracy: 0.8056\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1415 - accuracy: 0.9458 - val_loss: 0.4116 - val_accuracy: 0.8200\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1491 - accuracy: 0.9475 - val_loss: 0.4408 - val_accuracy: 0.7726\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1402 - accuracy: 0.9475 - val_loss: 0.3941 - val_accuracy: 0.8158\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1596 - accuracy: 0.9484 - val_loss: 0.4145 - val_accuracy: 0.8045\n","Epoch 24/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1804 - accuracy: 0.9484 - val_loss: 0.4165 - val_accuracy: 0.8056\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1464 - accuracy: 0.9506 - val_loss: 0.4248 - val_accuracy: 0.8035\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1915 - accuracy: 0.9422 - val_loss: 0.4575 - val_accuracy: 0.7809\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2616 - accuracy: 0.9405 - val_loss: 0.4179 - val_accuracy: 0.8200\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1259 - accuracy: 0.9550 - val_loss: 0.4082 - val_accuracy: 0.8076\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1152 - accuracy: 0.9541 - val_loss: 0.3462 - val_accuracy: 0.8333\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1252 - accuracy: 0.9506 - val_loss: 0.3653 - val_accuracy: 0.8261\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1046 - accuracy: 0.9577 - val_loss: 0.3769 - val_accuracy: 0.8158\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1062 - accuracy: 0.9660 - val_loss: 0.3528 - val_accuracy: 0.8477\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1294 - accuracy: 0.9489 - val_loss: 0.3694 - val_accuracy: 0.8374\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1208 - accuracy: 0.9537 - val_loss: 0.3465 - val_accuracy: 0.8436\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1445 - accuracy: 0.9533 - val_loss: 0.3581 - val_accuracy: 0.8272\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1173 - accuracy: 0.9603 - val_loss: 0.3524 - val_accuracy: 0.8292\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3039 - accuracy: 0.9506 - val_loss: 0.3751 - val_accuracy: 0.8323\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1282 - accuracy: 0.9524 - val_loss: 0.3739 - val_accuracy: 0.8128\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1172 - accuracy: 0.9572 - val_loss: 0.3829 - val_accuracy: 0.8323\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1174 - accuracy: 0.9537 - val_loss: 0.3995 - val_accuracy: 0.8056\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1013 - accuracy: 0.9621 - val_loss: 0.3451 - val_accuracy: 0.8344\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1178 - accuracy: 0.9581 - val_loss: 0.3116 - val_accuracy: 0.8539\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1062 - accuracy: 0.9616 - val_loss: 0.3639 - val_accuracy: 0.8426\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0809 - accuracy: 0.9665 - val_loss: 0.3363 - val_accuracy: 0.8447\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0958 - accuracy: 0.9621 - val_loss: 0.3081 - val_accuracy: 0.8549\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1006 - accuracy: 0.9612 - val_loss: 0.3078 - val_accuracy: 0.8580\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1131 - accuracy: 0.9541 - val_loss: 0.3278 - val_accuracy: 0.8426\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1085 - accuracy: 0.9577 - val_loss: 0.3607 - val_accuracy: 0.8261\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1132 - accuracy: 0.9528 - val_loss: 0.3577 - val_accuracy: 0.8395\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1151 - accuracy: 0.9586 - val_loss: 0.3068 - val_accuracy: 0.8632\n","Score: 0.8631687164306641 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 63214.4688 - accuracy: 0.8836 - val_loss: 1.1269 - val_accuracy: 0.4887\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2067 - accuracy: 0.9136 - val_loss: 0.7139 - val_accuracy: 0.5103\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2068 - accuracy: 0.9131 - val_loss: 0.7275 - val_accuracy: 0.4784\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1991 - accuracy: 0.9056 - val_loss: 0.6947 - val_accuracy: 0.4774\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2009 - accuracy: 0.9070 - val_loss: 0.6998 - val_accuracy: 0.5123\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1919 - accuracy: 0.9101 - val_loss: 0.7157 - val_accuracy: 0.4753\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2068 - accuracy: 0.9118 - val_loss: 0.7218 - val_accuracy: 0.4846\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2106 - accuracy: 0.8986 - val_loss: 0.7034 - val_accuracy: 0.4835\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2076 - accuracy: 0.9070 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1991 - accuracy: 0.9180 - val_loss: 0.6974 - val_accuracy: 0.5062\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2014 - accuracy: 0.9171 - val_loss: 0.7004 - val_accuracy: 0.5226\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9162 - val_loss: 0.7346 - val_accuracy: 0.4897\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2106 - accuracy: 0.9017 - val_loss: 0.7000 - val_accuracy: 0.4918\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1925 - accuracy: 0.9105 - val_loss: 0.6954 - val_accuracy: 0.4938\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1961 - accuracy: 0.9074 - val_loss: 0.6924 - val_accuracy: 0.5206\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2060 - accuracy: 0.9092 - val_loss: 0.6924 - val_accuracy: 0.5257\n","Epoch 17/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2033 - accuracy: 0.9034 - val_loss: 0.6935 - val_accuracy: 0.4990\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2058 - accuracy: 0.9109 - val_loss: 0.6974 - val_accuracy: 0.5041\n","Epoch 19/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2172 - accuracy: 0.9039 - val_loss: 0.6943 - val_accuracy: 0.5144\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2056 - accuracy: 0.9092 - val_loss: 0.7105 - val_accuracy: 0.4877\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1986 - accuracy: 0.9061 - val_loss: 0.6976 - val_accuracy: 0.4959\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2041 - accuracy: 0.9052 - val_loss: 0.7730 - val_accuracy: 0.5113\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2005 - accuracy: 0.9180 - val_loss: 0.6961 - val_accuracy: 0.5154\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1932 - accuracy: 0.9167 - val_loss: 0.7255 - val_accuracy: 0.5175\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1950 - accuracy: 0.9162 - val_loss: 0.6937 - val_accuracy: 0.5154\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2027 - accuracy: 0.9158 - val_loss: 0.7202 - val_accuracy: 0.4897\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2022 - accuracy: 0.8981 - val_loss: 0.6920 - val_accuracy: 0.5237\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1954 - accuracy: 0.9140 - val_loss: 0.7053 - val_accuracy: 0.4949\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2077 - accuracy: 0.9078 - val_loss: 0.6957 - val_accuracy: 0.5113\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1984 - accuracy: 0.9153 - val_loss: 0.6932 - val_accuracy: 0.5165\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9070 - val_loss: 0.6957 - val_accuracy: 0.4815\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9171 - val_loss: 0.6946 - val_accuracy: 0.5206\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2062 - accuracy: 0.9153 - val_loss: 0.6948 - val_accuracy: 0.5021\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9078 - val_loss: 0.7122 - val_accuracy: 0.4805\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2055 - accuracy: 0.9012 - val_loss: 0.6930 - val_accuracy: 0.5247\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2090 - accuracy: 0.9087 - val_loss: 0.7215 - val_accuracy: 0.4815\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2097 - accuracy: 0.8981 - val_loss: 0.6943 - val_accuracy: 0.5195\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2037 - accuracy: 0.9153 - val_loss: 0.7180 - val_accuracy: 0.4846\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1995 - accuracy: 0.9109 - val_loss: 0.7009 - val_accuracy: 0.5072\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1939 - accuracy: 0.9180 - val_loss: 0.6980 - val_accuracy: 0.4774\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2048 - accuracy: 0.9043 - val_loss: 0.6916 - val_accuracy: 0.5278\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1931 - accuracy: 0.9136 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9189 - val_loss: 0.6945 - val_accuracy: 0.5113\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1974 - accuracy: 0.9118 - val_loss: 0.7160 - val_accuracy: 0.5175\n","Epoch 45/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1915 - accuracy: 0.9034 - val_loss: 0.6973 - val_accuracy: 0.5267\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1952 - accuracy: 0.9109 - val_loss: 0.7104 - val_accuracy: 0.5195\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2066 - accuracy: 0.9056 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2066 - accuracy: 0.9109 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1990 - accuracy: 0.9105 - val_loss: 0.6921 - val_accuracy: 0.5278\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2075 - accuracy: 0.9008 - val_loss: 0.6958 - val_accuracy: 0.4969\n","Score: 0.4969135820865631 \n","Parameters:  {'learning_rate': 0.09377323666747836, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 1089360.3750 - accuracy: 0.8876 - val_loss: 0.7798 - val_accuracy: 0.4959\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3478 - accuracy: 0.9056 - val_loss: 0.7374 - val_accuracy: 0.4938\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2020 - accuracy: 0.9004 - val_loss: 0.6917 - val_accuracy: 0.5195\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1906 - accuracy: 0.9118 - val_loss: 0.7025 - val_accuracy: 0.5123\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9189 - val_loss: 0.7198 - val_accuracy: 0.5134\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1915 - accuracy: 0.9109 - val_loss: 0.6983 - val_accuracy: 0.5195\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1951 - accuracy: 0.9118 - val_loss: 0.6975 - val_accuracy: 0.4805\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1910 - accuracy: 0.9030 - val_loss: 0.7078 - val_accuracy: 0.4866\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1894 - accuracy: 0.9052 - val_loss: 0.7058 - val_accuracy: 0.4949\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2007 - accuracy: 0.8986 - val_loss: 0.7222 - val_accuracy: 0.4825\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1945 - accuracy: 0.9105 - val_loss: 0.6931 - val_accuracy: 0.5113\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1971 - accuracy: 0.9105 - val_loss: 0.6980 - val_accuracy: 0.5165\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1920 - accuracy: 0.9087 - val_loss: 0.7064 - val_accuracy: 0.4866\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9021 - val_loss: 0.6930 - val_accuracy: 0.5216\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1873 - accuracy: 0.9136 - val_loss: 0.7077 - val_accuracy: 0.4918\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1928 - accuracy: 0.9056 - val_loss: 0.6943 - val_accuracy: 0.4733\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1906 - accuracy: 0.9087 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1902 - accuracy: 0.9149 - val_loss: 0.6933 - val_accuracy: 0.5237\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1838 - accuracy: 0.9153 - val_loss: 0.7000 - val_accuracy: 0.4897\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2008 - accuracy: 0.9061 - val_loss: 0.6944 - val_accuracy: 0.5134\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1911 - accuracy: 0.9145 - val_loss: 0.6978 - val_accuracy: 0.4784\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 0.6927 - val_accuracy: 0.5195\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2004 - accuracy: 0.9087 - val_loss: 0.7017 - val_accuracy: 0.4990\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1974 - accuracy: 0.9070 - val_loss: 0.6968 - val_accuracy: 0.5319\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1971 - accuracy: 0.9153 - val_loss: 0.7036 - val_accuracy: 0.5144\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1881 - accuracy: 0.9162 - val_loss: 0.7133 - val_accuracy: 0.4928\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1932 - accuracy: 0.9114 - val_loss: 0.6963 - val_accuracy: 0.5175\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9092 - val_loss: 0.6934 - val_accuracy: 0.4949\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1951 - accuracy: 0.9083 - val_loss: 0.7129 - val_accuracy: 0.4907\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1974 - accuracy: 0.9017 - val_loss: 0.6920 - val_accuracy: 0.5257\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9202 - val_loss: 0.7015 - val_accuracy: 0.5041\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1878 - accuracy: 0.9096 - val_loss: 0.6935 - val_accuracy: 0.5206\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 0.7031 - val_accuracy: 0.5093\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1928 - accuracy: 0.9202 - val_loss: 0.6930 - val_accuracy: 0.5154\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1888 - accuracy: 0.9184 - val_loss: 0.6932 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1895 - accuracy: 0.9224 - val_loss: 0.6995 - val_accuracy: 0.5206\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1838 - accuracy: 0.9140 - val_loss: 0.7088 - val_accuracy: 0.4815\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1930 - accuracy: 0.9056 - val_loss: 0.6963 - val_accuracy: 0.4835\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9136 - val_loss: 0.7090 - val_accuracy: 0.4794\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9087 - val_loss: 0.7091 - val_accuracy: 0.4774\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2051 - accuracy: 0.8955 - val_loss: 0.7003 - val_accuracy: 0.5093\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1870 - accuracy: 0.9087 - val_loss: 0.6924 - val_accuracy: 0.4959\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2016 - accuracy: 0.9145 - val_loss: 0.7415 - val_accuracy: 0.4979\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1978 - accuracy: 0.9092 - val_loss: 0.7806 - val_accuracy: 0.4949\n","Epoch 45/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2023 - accuracy: 0.9021 - val_loss: 0.7211 - val_accuracy: 0.4835\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1982 - accuracy: 0.9030 - val_loss: 0.6934 - val_accuracy: 0.4794\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1909 - accuracy: 0.9078 - val_loss: 0.7960 - val_accuracy: 0.4969\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1896 - accuracy: 0.9092 - val_loss: 0.7102 - val_accuracy: 0.4990\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1946 - accuracy: 0.9118 - val_loss: 0.6957 - val_accuracy: 0.4897\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1956 - accuracy: 0.9048 - val_loss: 0.6958 - val_accuracy: 0.5000\n","Score: 0.5 \n","Parameters:  {'learning_rate': 0.14842176072427857, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 5443.8521 - accuracy: 0.9070 - val_loss: 0.7130 - val_accuracy: 0.5113\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1860 - accuracy: 0.9149 - val_loss: 0.6933 - val_accuracy: 0.5154\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2156 - accuracy: 0.9206 - val_loss: 0.6960 - val_accuracy: 0.5257\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2313 - accuracy: 0.9158 - val_loss: 0.6985 - val_accuracy: 0.5237\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2296 - accuracy: 0.9140 - val_loss: 0.6942 - val_accuracy: 0.5123\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2284 - accuracy: 0.9167 - val_loss: 0.6929 - val_accuracy: 0.5206\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2219 - accuracy: 0.9233 - val_loss: 0.6986 - val_accuracy: 0.5093\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2304 - accuracy: 0.9127 - val_loss: 0.7045 - val_accuracy: 0.5093\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2232 - accuracy: 0.9184 - val_loss: 0.6922 - val_accuracy: 0.5257\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2381 - accuracy: 0.9131 - val_loss: 0.7072 - val_accuracy: 0.4959\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2348 - accuracy: 0.9083 - val_loss: 0.6975 - val_accuracy: 0.4753\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2388 - accuracy: 0.9074 - val_loss: 0.6999 - val_accuracy: 0.5175\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2315 - accuracy: 0.9109 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2342 - accuracy: 0.9131 - val_loss: 0.6941 - val_accuracy: 0.4825\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2407 - accuracy: 0.9061 - val_loss: 0.6959 - val_accuracy: 0.5165\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2351 - accuracy: 0.9136 - val_loss: 0.6932 - val_accuracy: 0.5051\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2373 - accuracy: 0.9158 - val_loss: 0.7174 - val_accuracy: 0.5010\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2387 - accuracy: 0.9065 - val_loss: 0.6932 - val_accuracy: 0.4907\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2329 - accuracy: 0.9105 - val_loss: 0.6936 - val_accuracy: 0.4887\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2389 - accuracy: 0.9101 - val_loss: 0.6941 - val_accuracy: 0.5010\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2414 - accuracy: 0.9101 - val_loss: 0.6967 - val_accuracy: 0.5000\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2267 - accuracy: 0.9123 - val_loss: 0.6949 - val_accuracy: 0.5010\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2412 - accuracy: 0.9114 - val_loss: 0.6944 - val_accuracy: 0.5206\n","Epoch 24/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2300 - accuracy: 0.9109 - val_loss: 0.6983 - val_accuracy: 0.4918\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2335 - accuracy: 0.9078 - val_loss: 0.7042 - val_accuracy: 0.4743\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2396 - accuracy: 0.9048 - val_loss: 0.7062 - val_accuracy: 0.5144\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2287 - accuracy: 0.9153 - val_loss: 0.6922 - val_accuracy: 0.5216\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2274 - accuracy: 0.9162 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2321 - accuracy: 0.9131 - val_loss: 0.6931 - val_accuracy: 0.5031\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2350 - accuracy: 0.9131 - val_loss: 0.6937 - val_accuracy: 0.5113\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2317 - accuracy: 0.9193 - val_loss: 0.7067 - val_accuracy: 0.5206\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2268 - accuracy: 0.9153 - val_loss: 0.6920 - val_accuracy: 0.5247\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2372 - accuracy: 0.9026 - val_loss: 0.6923 - val_accuracy: 0.5247\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2303 - accuracy: 0.9198 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2264 - accuracy: 0.9198 - val_loss: 0.6927 - val_accuracy: 0.5237\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2338 - accuracy: 0.9123 - val_loss: 0.6957 - val_accuracy: 0.5216\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2368 - accuracy: 0.9114 - val_loss: 0.7037 - val_accuracy: 0.5103\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2236 - accuracy: 0.9153 - val_loss: 0.6924 - val_accuracy: 0.5247\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2310 - accuracy: 0.9131 - val_loss: 0.6946 - val_accuracy: 0.5103\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2394 - accuracy: 0.9118 - val_loss: 0.6924 - val_accuracy: 0.5216\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2270 - accuracy: 0.9193 - val_loss: 0.6944 - val_accuracy: 0.5216\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2362 - accuracy: 0.9118 - val_loss: 0.6910 - val_accuracy: 0.5329\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2333 - accuracy: 0.9162 - val_loss: 0.7075 - val_accuracy: 0.4979\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2260 - accuracy: 0.9145 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2302 - accuracy: 0.9123 - val_loss: 0.6988 - val_accuracy: 0.4866\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2327 - accuracy: 0.8964 - val_loss: 0.6948 - val_accuracy: 0.4938\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2291 - accuracy: 0.9206 - val_loss: 0.7056 - val_accuracy: 0.5278\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2248 - accuracy: 0.9105 - val_loss: 0.6966 - val_accuracy: 0.4835\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2387 - accuracy: 0.9074 - val_loss: 0.7080 - val_accuracy: 0.5021\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2383 - accuracy: 0.9127 - val_loss: 0.6940 - val_accuracy: 0.5247\n","Score: 0.5246913433074951 \n","Parameters:  {'learning_rate': 0.03925203469760291, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6312 - accuracy: 0.9233 - val_loss: 0.6363 - val_accuracy: 0.6595\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3095 - accuracy: 0.9295 - val_loss: 0.5225 - val_accuracy: 0.7593\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1689 - accuracy: 0.9356 - val_loss: 0.4622 - val_accuracy: 0.7809\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.9387 - val_loss: 0.5461 - val_accuracy: 0.7068\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9405 - val_loss: 0.4284 - val_accuracy: 0.7922\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9405 - val_loss: 0.4527 - val_accuracy: 0.7912\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1994 - accuracy: 0.9400 - val_loss: 0.4602 - val_accuracy: 0.7840\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2141 - accuracy: 0.9537 - val_loss: 0.3456 - val_accuracy: 0.8395\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1532 - accuracy: 0.9519 - val_loss: 0.3638 - val_accuracy: 0.8210\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1323 - accuracy: 0.9493 - val_loss: 0.4436 - val_accuracy: 0.8230\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1352 - accuracy: 0.9475 - val_loss: 0.3643 - val_accuracy: 0.8302\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1133 - accuracy: 0.9599 - val_loss: 0.3511 - val_accuracy: 0.8642\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1101 - accuracy: 0.9572 - val_loss: 0.3086 - val_accuracy: 0.8632\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1505 - accuracy: 0.9603 - val_loss: 0.3302 - val_accuracy: 0.8488\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9652 - val_loss: 0.2932 - val_accuracy: 0.8683\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1235 - accuracy: 0.9528 - val_loss: 0.3657 - val_accuracy: 0.8354\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9471 - val_loss: 0.3837 - val_accuracy: 0.8158\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9621 - val_loss: 0.3763 - val_accuracy: 0.8395\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1239 - accuracy: 0.9541 - val_loss: 0.3951 - val_accuracy: 0.8107\n","Epoch 20/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1099 - accuracy: 0.9630 - val_loss: 0.5458 - val_accuracy: 0.8200\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1025 - accuracy: 0.9652 - val_loss: 0.2760 - val_accuracy: 0.8663\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1283 - accuracy: 0.9713 - val_loss: 0.3716 - val_accuracy: 0.8416\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0992 - accuracy: 0.9608 - val_loss: 0.2905 - val_accuracy: 0.8642\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9524 - val_loss: 0.3796 - val_accuracy: 0.8117\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0853 - accuracy: 0.9718 - val_loss: 0.3177 - val_accuracy: 0.8570\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1023 - accuracy: 0.9608 - val_loss: 0.3214 - val_accuracy: 0.8611\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0795 - accuracy: 0.9683 - val_loss: 0.2675 - val_accuracy: 0.8961\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0880 - accuracy: 0.9678 - val_loss: 0.3195 - val_accuracy: 0.8364\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9735 - val_loss: 0.2826 - val_accuracy: 0.8807\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9713 - val_loss: 0.2634 - val_accuracy: 0.8889\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0887 - accuracy: 0.9674 - val_loss: 0.2621 - val_accuracy: 0.8961\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0968 - accuracy: 0.9665 - val_loss: 0.2001 - val_accuracy: 0.9156\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0713 - accuracy: 0.9727 - val_loss: 0.3125 - val_accuracy: 0.8560\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9771 - val_loss: 0.2087 - val_accuracy: 0.9136\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0923 - accuracy: 0.9713 - val_loss: 0.1956 - val_accuracy: 0.9105\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9744 - val_loss: 0.2367 - val_accuracy: 0.9064\n","Epoch 37/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0663 - accuracy: 0.9802 - val_loss: 0.2660 - val_accuracy: 0.8889\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.1766 - val_accuracy: 0.9331\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0691 - accuracy: 0.9757 - val_loss: 0.1713 - val_accuracy: 0.9249\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0513 - accuracy: 0.9828 - val_loss: 0.1691 - val_accuracy: 0.9372\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0544 - accuracy: 0.9775 - val_loss: 0.2231 - val_accuracy: 0.9105\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 0.1670 - val_accuracy: 0.9342\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0392 - accuracy: 0.9841 - val_loss: 0.2038 - val_accuracy: 0.9208\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0558 - accuracy: 0.9832 - val_loss: 0.1991 - val_accuracy: 0.9146\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0475 - accuracy: 0.9872 - val_loss: 0.1604 - val_accuracy: 0.9352\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.2507 - val_accuracy: 0.9105\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.2690 - val_accuracy: 0.9167\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 0.1159 - val_accuracy: 0.9578\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.1758 - val_accuracy: 0.9403\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0512 - accuracy: 0.9863 - val_loss: 0.2245 - val_accuracy: 0.9228\n","Score: 0.9228395223617554 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.3268 - accuracy: 0.9131 - val_loss: 0.6859 - val_accuracy: 0.5226\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1982 - accuracy: 0.9131 - val_loss: 0.6786 - val_accuracy: 0.5103\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1725 - accuracy: 0.9206 - val_loss: 0.6181 - val_accuracy: 0.6903\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1742 - accuracy: 0.9237 - val_loss: 0.5927 - val_accuracy: 0.6883\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1915 - accuracy: 0.9127 - val_loss: 0.6240 - val_accuracy: 0.5484\n","Epoch 6/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1920 - accuracy: 0.9290 - val_loss: 0.5999 - val_accuracy: 0.6626\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2123 - accuracy: 0.9383 - val_loss: 0.5537 - val_accuracy: 0.7274\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2130 - accuracy: 0.9250 - val_loss: 0.5325 - val_accuracy: 0.7119\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1599 - accuracy: 0.9374 - val_loss: 0.5056 - val_accuracy: 0.7315\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.5000 - accuracy: 0.9312 - val_loss: 0.5116 - val_accuracy: 0.7428\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1665 - accuracy: 0.9343 - val_loss: 0.5430 - val_accuracy: 0.7222\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1497 - accuracy: 0.9466 - val_loss: 0.5293 - val_accuracy: 0.7274\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1520 - accuracy: 0.9422 - val_loss: 0.5281 - val_accuracy: 0.7171\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1430 - accuracy: 0.9449 - val_loss: 0.4701 - val_accuracy: 0.7510\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1345 - accuracy: 0.9453 - val_loss: 0.4821 - val_accuracy: 0.7706\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2101 - accuracy: 0.9449 - val_loss: 0.5102 - val_accuracy: 0.7428\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2814 - accuracy: 0.9369 - val_loss: 0.4464 - val_accuracy: 0.7901\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1474 - accuracy: 0.9418 - val_loss: 0.4695 - val_accuracy: 0.7726\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1398 - accuracy: 0.9497 - val_loss: 0.5400 - val_accuracy: 0.7130\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1371 - accuracy: 0.9493 - val_loss: 0.4551 - val_accuracy: 0.7850\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1247 - accuracy: 0.9502 - val_loss: 0.4879 - val_accuracy: 0.7778\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2074 - accuracy: 0.9352 - val_loss: 0.4301 - val_accuracy: 0.7973\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1392 - accuracy: 0.9449 - val_loss: 0.4086 - val_accuracy: 0.8086\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1296 - accuracy: 0.9502 - val_loss: 0.4093 - val_accuracy: 0.8025\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1417 - accuracy: 0.9453 - val_loss: 0.4384 - val_accuracy: 0.8056\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1410 - accuracy: 0.9541 - val_loss: 0.4513 - val_accuracy: 0.7942\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9537 - val_loss: 0.4257 - val_accuracy: 0.7922\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1311 - accuracy: 0.9484 - val_loss: 0.4123 - val_accuracy: 0.8014\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1305 - accuracy: 0.9506 - val_loss: 0.4296 - val_accuracy: 0.7757\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1465 - accuracy: 0.9497 - val_loss: 0.4008 - val_accuracy: 0.8169\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1258 - accuracy: 0.9493 - val_loss: 0.4085 - val_accuracy: 0.8066\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1212 - accuracy: 0.9519 - val_loss: 0.4002 - val_accuracy: 0.8097\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1229 - accuracy: 0.9475 - val_loss: 0.4334 - val_accuracy: 0.7994\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1265 - accuracy: 0.9502 - val_loss: 0.4247 - val_accuracy: 0.7984\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2150 - accuracy: 0.9422 - val_loss: 0.4051 - val_accuracy: 0.8128\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1274 - accuracy: 0.9444 - val_loss: 0.4022 - val_accuracy: 0.8179\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1298 - accuracy: 0.9493 - val_loss: 0.3932 - val_accuracy: 0.8230\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1213 - accuracy: 0.9546 - val_loss: 0.4030 - val_accuracy: 0.8241\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1287 - accuracy: 0.9541 - val_loss: 0.4192 - val_accuracy: 0.8035\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1599 - accuracy: 0.9515 - val_loss: 0.3908 - val_accuracy: 0.8158\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1074 - accuracy: 0.9577 - val_loss: 0.3990 - val_accuracy: 0.8220\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1382 - accuracy: 0.9533 - val_loss: 0.4024 - val_accuracy: 0.8138\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1336 - accuracy: 0.9466 - val_loss: 0.4401 - val_accuracy: 0.7901\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1100 - accuracy: 0.9563 - val_loss: 0.3650 - val_accuracy: 0.8210\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1907 - accuracy: 0.9440 - val_loss: 0.3869 - val_accuracy: 0.8220\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1301 - accuracy: 0.9568 - val_loss: 0.3732 - val_accuracy: 0.8210\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1229 - accuracy: 0.9528 - val_loss: 0.3852 - val_accuracy: 0.8086\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1277 - accuracy: 0.9519 - val_loss: 0.3996 - val_accuracy: 0.7973\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1148 - accuracy: 0.9550 - val_loss: 0.3948 - val_accuracy: 0.8179\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1166 - accuracy: 0.9537 - val_loss: 0.4210 - val_accuracy: 0.7870\n","Score: 0.7870370149612427 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 2273776.5000 - accuracy: 0.8871 - val_loss: 0.8531 - val_accuracy: 0.4887\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2290 - accuracy: 0.8902 - val_loss: 0.9366 - val_accuracy: 0.5123\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8893 - val_loss: 1.5523 - val_accuracy: 0.4866\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3237 - accuracy: 0.8959 - val_loss: 0.7739 - val_accuracy: 0.5031\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2629 - accuracy: 0.8959 - val_loss: 0.6950 - val_accuracy: 0.4897\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2479 - accuracy: 0.8955 - val_loss: 1.0379 - val_accuracy: 0.4938\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2728 - accuracy: 0.8920 - val_loss: 0.7233 - val_accuracy: 0.4794\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2697 - accuracy: 0.8937 - val_loss: 0.7229 - val_accuracy: 0.4897\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2810 - accuracy: 0.8990 - val_loss: 0.6935 - val_accuracy: 0.5329\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2428 - accuracy: 0.9012 - val_loss: 1.3722 - val_accuracy: 0.5031\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2150 - accuracy: 0.9056 - val_loss: 0.9505 - val_accuracy: 0.5144\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2132 - accuracy: 0.9026 - val_loss: 0.8146 - val_accuracy: 0.4856\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2369 - accuracy: 0.8946 - val_loss: 0.7498 - val_accuracy: 0.5247\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2334 - accuracy: 0.8898 - val_loss: 0.7259 - val_accuracy: 0.5237\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2107 - accuracy: 0.9048 - val_loss: 0.9239 - val_accuracy: 0.4856\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2391 - accuracy: 0.8915 - val_loss: 0.9283 - val_accuracy: 0.4897\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2570 - accuracy: 0.8977 - val_loss: 0.8066 - val_accuracy: 0.4877\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2326 - accuracy: 0.9043 - val_loss: 0.7979 - val_accuracy: 0.5062\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2134 - accuracy: 0.9087 - val_loss: 1.2347 - val_accuracy: 0.4969\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2037 - accuracy: 0.8973 - val_loss: 0.7008 - val_accuracy: 0.5144\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2465 - accuracy: 0.8933 - val_loss: 0.7318 - val_accuracy: 0.4856\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2074 - accuracy: 0.8981 - val_loss: 0.7021 - val_accuracy: 0.5226\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1999 - accuracy: 0.9043 - val_loss: 0.7648 - val_accuracy: 0.5062\n","Epoch 24/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2015 - accuracy: 0.9105 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2280 - accuracy: 0.9004 - val_loss: 1.0496 - val_accuracy: 0.4856\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2049 - accuracy: 0.9105 - val_loss: 0.7061 - val_accuracy: 0.4887\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1928 - accuracy: 0.8995 - val_loss: 0.6964 - val_accuracy: 0.5051\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1931 - accuracy: 0.9043 - val_loss: 0.7292 - val_accuracy: 0.4918\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1880 - accuracy: 0.9171 - val_loss: 0.6943 - val_accuracy: 0.5113\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1847 - accuracy: 0.9101 - val_loss: 0.7016 - val_accuracy: 0.4856\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1937 - accuracy: 0.9123 - val_loss: 0.7177 - val_accuracy: 0.5267\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1851 - accuracy: 0.9145 - val_loss: 0.7419 - val_accuracy: 0.4866\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2031 - accuracy: 0.9021 - val_loss: 0.6943 - val_accuracy: 0.4928\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1914 - accuracy: 0.9109 - val_loss: 0.7061 - val_accuracy: 0.4949\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1930 - accuracy: 0.9052 - val_loss: 0.6970 - val_accuracy: 0.5247\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1903 - accuracy: 0.9162 - val_loss: 0.7673 - val_accuracy: 0.4815\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9056 - val_loss: 0.7003 - val_accuracy: 0.4907\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2030 - accuracy: 0.9043 - val_loss: 0.7015 - val_accuracy: 0.5123\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1930 - accuracy: 0.9127 - val_loss: 0.6958 - val_accuracy: 0.4918\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1836 - accuracy: 0.9118 - val_loss: 0.7010 - val_accuracy: 0.5175\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1799 - accuracy: 0.9162 - val_loss: 0.7054 - val_accuracy: 0.5185\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1800 - accuracy: 0.9149 - val_loss: 0.6956 - val_accuracy: 0.5123\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1850 - accuracy: 0.9175 - val_loss: 0.7208 - val_accuracy: 0.5329\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1856 - accuracy: 0.9149 - val_loss: 0.6927 - val_accuracy: 0.5206\n","Epoch 45/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1830 - accuracy: 0.9171 - val_loss: 0.6959 - val_accuracy: 0.5072\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1903 - accuracy: 0.9198 - val_loss: 0.7119 - val_accuracy: 0.4774\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1883 - accuracy: 0.8977 - val_loss: 0.6936 - val_accuracy: 0.4887\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1898 - accuracy: 0.9070 - val_loss: 0.7144 - val_accuracy: 0.4907\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2017 - accuracy: 0.8995 - val_loss: 0.7964 - val_accuracy: 0.5216\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1948 - accuracy: 0.9026 - val_loss: 0.6921 - val_accuracy: 0.5237\n","Score: 0.5236625671386719 \n","Parameters:  {'learning_rate': 0.21355750403297283, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7120 - accuracy: 0.9277 - val_loss: 0.7624 - val_accuracy: 0.6214\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1839 - accuracy: 0.9299 - val_loss: 0.5649 - val_accuracy: 0.7037\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1628 - accuracy: 0.9277 - val_loss: 0.5424 - val_accuracy: 0.7181\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1814 - accuracy: 0.9383 - val_loss: 0.5263 - val_accuracy: 0.7438\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1807 - accuracy: 0.9418 - val_loss: 0.5010 - val_accuracy: 0.7449\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1552 - accuracy: 0.9339 - val_loss: 0.4732 - val_accuracy: 0.7562\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1396 - accuracy: 0.9444 - val_loss: 0.6436 - val_accuracy: 0.7130\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1540 - accuracy: 0.9369 - val_loss: 0.5210 - val_accuracy: 0.7222\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9383 - val_loss: 0.4988 - val_accuracy: 0.7634\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1494 - accuracy: 0.9392 - val_loss: 0.5117 - val_accuracy: 0.7263\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9405 - val_loss: 0.4830 - val_accuracy: 0.7582\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1458 - accuracy: 0.9414 - val_loss: 0.4941 - val_accuracy: 0.7562\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1683 - accuracy: 0.9453 - val_loss: 0.4652 - val_accuracy: 0.7901\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1406 - accuracy: 0.9484 - val_loss: 0.4613 - val_accuracy: 0.7788\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1961 - accuracy: 0.9431 - val_loss: 0.4781 - val_accuracy: 0.7726\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.4397 - accuracy: 0.9431 - val_loss: 0.5105 - val_accuracy: 0.7623\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1477 - accuracy: 0.9497 - val_loss: 0.4104 - val_accuracy: 0.8158\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1319 - accuracy: 0.9515 - val_loss: 0.4589 - val_accuracy: 0.7850\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1321 - accuracy: 0.9493 - val_loss: 0.4493 - val_accuracy: 0.7850\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1512 - accuracy: 0.9440 - val_loss: 0.4332 - val_accuracy: 0.7809\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2056 - accuracy: 0.9515 - val_loss: 0.4170 - val_accuracy: 0.8107\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1419 - accuracy: 0.9466 - val_loss: 0.4300 - val_accuracy: 0.7963\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9541 - val_loss: 0.4246 - val_accuracy: 0.8179\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1367 - accuracy: 0.9533 - val_loss: 0.4444 - val_accuracy: 0.7870\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1360 - accuracy: 0.9568 - val_loss: 0.4644 - val_accuracy: 0.7737\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1697 - accuracy: 0.9555 - val_loss: 0.3866 - val_accuracy: 0.8251\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1402 - accuracy: 0.9506 - val_loss: 0.4441 - val_accuracy: 0.8128\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1308 - accuracy: 0.9524 - val_loss: 0.3945 - val_accuracy: 0.8128\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1235 - accuracy: 0.9489 - val_loss: 0.4164 - val_accuracy: 0.8128\n","Epoch 30/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2286 - accuracy: 0.9581 - val_loss: 0.3762 - val_accuracy: 0.8302\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1824 - accuracy: 0.9497 - val_loss: 0.4251 - val_accuracy: 0.7881\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1297 - accuracy: 0.9493 - val_loss: 0.4187 - val_accuracy: 0.8035\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1571 - accuracy: 0.9511 - val_loss: 0.3613 - val_accuracy: 0.8313\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1104 - accuracy: 0.9563 - val_loss: 0.4020 - val_accuracy: 0.8097\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1324 - accuracy: 0.9528 - val_loss: 0.4236 - val_accuracy: 0.8107\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9537 - val_loss: 0.3618 - val_accuracy: 0.8457\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1546 - accuracy: 0.9493 - val_loss: 0.4056 - val_accuracy: 0.8158\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9572 - val_loss: 0.3953 - val_accuracy: 0.8241\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9541 - val_loss: 0.3931 - val_accuracy: 0.8323\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1287 - accuracy: 0.9541 - val_loss: 0.3531 - val_accuracy: 0.8313\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.3637 - val_accuracy: 0.8230\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1331 - accuracy: 0.9515 - val_loss: 0.3523 - val_accuracy: 0.8354\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1040 - accuracy: 0.9621 - val_loss: 0.3753 - val_accuracy: 0.8354\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1082 - accuracy: 0.9546 - val_loss: 0.3549 - val_accuracy: 0.8272\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1210 - accuracy: 0.9559 - val_loss: 0.3683 - val_accuracy: 0.8261\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1071 - accuracy: 0.9616 - val_loss: 0.3506 - val_accuracy: 0.8457\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9586 - val_loss: 0.3491 - val_accuracy: 0.8519\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1239 - accuracy: 0.9572 - val_loss: 0.3440 - val_accuracy: 0.8374\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1239 - accuracy: 0.9502 - val_loss: 0.3411 - val_accuracy: 0.8323\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1200 - accuracy: 0.9594 - val_loss: 0.3990 - val_accuracy: 0.8230\n","Score: 0.8230452537536621 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 788.8761 - accuracy: 0.9083 - val_loss: 0.6940 - val_accuracy: 0.5154\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1855 - accuracy: 0.9092 - val_loss: 0.6926 - val_accuracy: 0.5237\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1992 - accuracy: 0.9167 - val_loss: 0.6972 - val_accuracy: 0.4969\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2123 - accuracy: 0.9101 - val_loss: 0.7157 - val_accuracy: 0.5031\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2279 - accuracy: 0.9127 - val_loss: 0.7114 - val_accuracy: 0.4959\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2416 - accuracy: 0.9131 - val_loss: 0.7082 - val_accuracy: 0.5082\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2179 - accuracy: 0.9162 - val_loss: 0.7008 - val_accuracy: 0.4877\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2313 - accuracy: 0.9078 - val_loss: 0.6995 - val_accuracy: 0.5237\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2448 - accuracy: 0.9158 - val_loss: 0.6923 - val_accuracy: 0.5309\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2538 - accuracy: 0.9127 - val_loss: 0.6972 - val_accuracy: 0.5267\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2464 - accuracy: 0.9149 - val_loss: 0.6957 - val_accuracy: 0.5237\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.9123 - val_loss: 0.7118 - val_accuracy: 0.5000\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2771 - accuracy: 0.9092 - val_loss: 0.7080 - val_accuracy: 0.5072\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2723 - accuracy: 0.9127 - val_loss: 0.7175 - val_accuracy: 0.5051\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2745 - accuracy: 0.9140 - val_loss: 0.7213 - val_accuracy: 0.5237\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2698 - accuracy: 0.9109 - val_loss: 0.7020 - val_accuracy: 0.5185\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2727 - accuracy: 0.9162 - val_loss: 0.7344 - val_accuracy: 0.5103\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2640 - accuracy: 0.9215 - val_loss: 0.7688 - val_accuracy: 0.5031\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2638 - accuracy: 0.9158 - val_loss: 0.7188 - val_accuracy: 0.5206\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2668 - accuracy: 0.9171 - val_loss: 0.7276 - val_accuracy: 0.5123\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2743 - accuracy: 0.9096 - val_loss: 0.7033 - val_accuracy: 0.5165\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2722 - accuracy: 0.9127 - val_loss: 0.7066 - val_accuracy: 0.5195\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2736 - accuracy: 0.9175 - val_loss: 0.7382 - val_accuracy: 0.5123\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2701 - accuracy: 0.9114 - val_loss: 0.7156 - val_accuracy: 0.5082\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2694 - accuracy: 0.9189 - val_loss: 0.7429 - val_accuracy: 0.5154\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2715 - accuracy: 0.9096 - val_loss: 0.7060 - val_accuracy: 0.5278\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2739 - accuracy: 0.9153 - val_loss: 0.7368 - val_accuracy: 0.5093\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2662 - accuracy: 0.9171 - val_loss: 0.7241 - val_accuracy: 0.5185\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2713 - accuracy: 0.9131 - val_loss: 0.7127 - val_accuracy: 0.5247\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2749 - accuracy: 0.9118 - val_loss: 0.7158 - val_accuracy: 0.5062\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2698 - accuracy: 0.9162 - val_loss: 0.7157 - val_accuracy: 0.5185\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2634 - accuracy: 0.9211 - val_loss: 0.7488 - val_accuracy: 0.5185\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2566 - accuracy: 0.9224 - val_loss: 0.7368 - val_accuracy: 0.4990\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2687 - accuracy: 0.9136 - val_loss: 0.7142 - val_accuracy: 0.5195\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2710 - accuracy: 0.9140 - val_loss: 0.7221 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2734 - accuracy: 0.9136 - val_loss: 0.7222 - val_accuracy: 0.5329\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2650 - accuracy: 0.9193 - val_loss: 0.7362 - val_accuracy: 0.5206\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2706 - accuracy: 0.9123 - val_loss: 0.7074 - val_accuracy: 0.5340\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2657 - accuracy: 0.9175 - val_loss: 0.7282 - val_accuracy: 0.5165\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2552 - accuracy: 0.9255 - val_loss: 0.7570 - val_accuracy: 0.5206\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2609 - accuracy: 0.9184 - val_loss: 0.7394 - val_accuracy: 0.5175\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2745 - accuracy: 0.9092 - val_loss: 0.7176 - val_accuracy: 0.5010\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2770 - accuracy: 0.9118 - val_loss: 0.7187 - val_accuracy: 0.5051\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2766 - accuracy: 0.9087 - val_loss: 0.7053 - val_accuracy: 0.5185\n","Epoch 45/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2766 - accuracy: 0.9140 - val_loss: 0.7288 - val_accuracy: 0.5165\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2833 - accuracy: 0.9056 - val_loss: 0.7151 - val_accuracy: 0.4969\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2660 - accuracy: 0.9215 - val_loss: 0.7489 - val_accuracy: 0.5247\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2559 - accuracy: 0.9228 - val_loss: 0.7719 - val_accuracy: 0.4990\n","Epoch 49/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2668 - accuracy: 0.9158 - val_loss: 0.7376 - val_accuracy: 0.5134\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2605 - accuracy: 0.9162 - val_loss: 0.7153 - val_accuracy: 0.5123\n","Score: 0.5123456716537476 \n","Parameters:  {'learning_rate': 0.020852361605963897, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.6189 - accuracy: 0.9211 - val_loss: 0.6605 - val_accuracy: 0.5926\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1867 - accuracy: 0.9255 - val_loss: 0.6132 - val_accuracy: 0.6872\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1986 - accuracy: 0.9224 - val_loss: 0.6374 - val_accuracy: 0.6728\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1745 - accuracy: 0.9211 - val_loss: 0.5840 - val_accuracy: 0.7263\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1626 - accuracy: 0.9339 - val_loss: 0.5698 - val_accuracy: 0.6975\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2087 - accuracy: 0.9343 - val_loss: 0.5374 - val_accuracy: 0.7418\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1464 - accuracy: 0.9352 - val_loss: 0.5090 - val_accuracy: 0.7253\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1456 - accuracy: 0.9356 - val_loss: 0.5187 - val_accuracy: 0.7253\n","Epoch 9/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1625 - accuracy: 0.9339 - val_loss: 0.5442 - val_accuracy: 0.6893\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2011 - accuracy: 0.9387 - val_loss: 0.4877 - val_accuracy: 0.7551\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1465 - accuracy: 0.9392 - val_loss: 0.5102 - val_accuracy: 0.7418\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1362 - accuracy: 0.9471 - val_loss: 0.4593 - val_accuracy: 0.7737\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1595 - accuracy: 0.9449 - val_loss: 0.4329 - val_accuracy: 0.7778\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1522 - accuracy: 0.9405 - val_loss: 0.4613 - val_accuracy: 0.7695\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2329 - accuracy: 0.9440 - val_loss: 0.4404 - val_accuracy: 0.7767\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1485 - accuracy: 0.9440 - val_loss: 0.6692 - val_accuracy: 0.7479\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1803 - accuracy: 0.9453 - val_loss: 0.4421 - val_accuracy: 0.7767\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1425 - accuracy: 0.9409 - val_loss: 0.4771 - val_accuracy: 0.7881\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1517 - accuracy: 0.9462 - val_loss: 0.4313 - val_accuracy: 0.7912\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2900 - accuracy: 0.9400 - val_loss: 0.4537 - val_accuracy: 0.8025\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1603 - accuracy: 0.9511 - val_loss: 0.5208 - val_accuracy: 0.7767\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1376 - accuracy: 0.9563 - val_loss: 0.5166 - val_accuracy: 0.7747\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1006 - accuracy: 0.9586 - val_loss: 0.3098 - val_accuracy: 0.8745\n","Epoch 24/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2076 - accuracy: 0.9462 - val_loss: 0.4836 - val_accuracy: 0.7521\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1385 - accuracy: 0.9471 - val_loss: 0.4463 - val_accuracy: 0.7932\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1440 - accuracy: 0.9506 - val_loss: 1.1137 - val_accuracy: 0.7068\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1219 - accuracy: 0.9546 - val_loss: 0.4700 - val_accuracy: 0.7994\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1442 - accuracy: 0.9484 - val_loss: 0.3854 - val_accuracy: 0.8169\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1151 - accuracy: 0.9506 - val_loss: 0.3752 - val_accuracy: 0.8251\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1167 - accuracy: 0.9563 - val_loss: 0.3813 - val_accuracy: 0.8138\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1389 - accuracy: 0.9480 - val_loss: 0.4270 - val_accuracy: 0.8076\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1280 - accuracy: 0.9524 - val_loss: 0.3951 - val_accuracy: 0.8117\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1193 - accuracy: 0.9563 - val_loss: 0.3787 - val_accuracy: 0.8333\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1319 - accuracy: 0.9533 - val_loss: 0.4273 - val_accuracy: 0.8107\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1454 - accuracy: 0.9528 - val_loss: 0.4086 - val_accuracy: 0.8117\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1382 - accuracy: 0.9515 - val_loss: 0.4307 - val_accuracy: 0.7891\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1358 - accuracy: 0.9599 - val_loss: 0.4020 - val_accuracy: 0.7984\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1401 - accuracy: 0.9546 - val_loss: 0.3399 - val_accuracy: 0.8477\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1148 - accuracy: 0.9559 - val_loss: 0.3379 - val_accuracy: 0.8436\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0806 - accuracy: 0.9691 - val_loss: 0.3631 - val_accuracy: 0.8385\n","Epoch 41/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1110 - accuracy: 0.9594 - val_loss: 0.5549 - val_accuracy: 0.8241\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1335 - accuracy: 0.9586 - val_loss: 0.3536 - val_accuracy: 0.8344\n","Epoch 43/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1076 - accuracy: 0.9608 - val_loss: 0.3311 - val_accuracy: 0.8447\n","Epoch 44/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1088 - accuracy: 0.9630 - val_loss: 0.3094 - val_accuracy: 0.8560\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1069 - accuracy: 0.9586 - val_loss: 0.3437 - val_accuracy: 0.8447\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1070 - accuracy: 0.9674 - val_loss: 0.3257 - val_accuracy: 0.8549\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1189 - accuracy: 0.9586 - val_loss: 0.3165 - val_accuracy: 0.8560\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0860 - accuracy: 0.9634 - val_loss: 0.3298 - val_accuracy: 0.8313\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0926 - accuracy: 0.9709 - val_loss: 0.3309 - val_accuracy: 0.8416\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1068 - accuracy: 0.9594 - val_loss: 0.2988 - val_accuracy: 0.8673\n","Score: 0.8672839403152466 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6385 - accuracy: 0.9193 - val_loss: 0.6313 - val_accuracy: 0.6842\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3000 - accuracy: 0.9127 - val_loss: 0.5874 - val_accuracy: 0.6996\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2368 - accuracy: 0.9228 - val_loss: 0.5926 - val_accuracy: 0.6934\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1921 - accuracy: 0.9220 - val_loss: 0.5746 - val_accuracy: 0.7058\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1527 - accuracy: 0.9343 - val_loss: 0.5250 - val_accuracy: 0.7459\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9405 - val_loss: 0.5125 - val_accuracy: 0.7356\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2600 - accuracy: 0.9392 - val_loss: 0.4768 - val_accuracy: 0.7510\n","Epoch 8/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1517 - accuracy: 0.9422 - val_loss: 0.4665 - val_accuracy: 0.7654\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1482 - accuracy: 0.9480 - val_loss: 0.4462 - val_accuracy: 0.7881\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1891 - accuracy: 0.9392 - val_loss: 0.6118 - val_accuracy: 0.6852\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1463 - accuracy: 0.9396 - val_loss: 0.4592 - val_accuracy: 0.7788\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1276 - accuracy: 0.9524 - val_loss: 0.4537 - val_accuracy: 0.7881\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1499 - accuracy: 0.9409 - val_loss: 0.4572 - val_accuracy: 0.7695\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1538 - accuracy: 0.9409 - val_loss: 0.4874 - val_accuracy: 0.7459\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1786 - accuracy: 0.9528 - val_loss: 0.4367 - val_accuracy: 0.7870\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2089 - accuracy: 0.9378 - val_loss: 0.4914 - val_accuracy: 0.7706\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1446 - accuracy: 0.9462 - val_loss: 0.4579 - val_accuracy: 0.7850\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9506 - val_loss: 0.4293 - val_accuracy: 0.7881\n","Epoch 19/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1614 - accuracy: 0.9493 - val_loss: 0.4745 - val_accuracy: 0.7891\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1349 - accuracy: 0.9568 - val_loss: 0.4390 - val_accuracy: 0.7963\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9409 - val_loss: 0.4581 - val_accuracy: 0.7942\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9511 - val_loss: 0.4562 - val_accuracy: 0.7994\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1458 - accuracy: 0.9493 - val_loss: 0.4609 - val_accuracy: 0.7922\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1265 - accuracy: 0.9559 - val_loss: 0.4395 - val_accuracy: 0.7922\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1481 - accuracy: 0.9524 - val_loss: 0.4488 - val_accuracy: 0.8014\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2189 - accuracy: 0.9475 - val_loss: 0.4277 - val_accuracy: 0.8014\n","Epoch 27/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1792 - accuracy: 0.9343 - val_loss: 0.4406 - val_accuracy: 0.7798\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1414 - accuracy: 0.9475 - val_loss: 0.4471 - val_accuracy: 0.7870\n","Epoch 29/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1503 - accuracy: 0.9444 - val_loss: 0.4593 - val_accuracy: 0.7932\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1265 - accuracy: 0.9484 - val_loss: 0.4485 - val_accuracy: 0.7942\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1369 - accuracy: 0.9506 - val_loss: 0.4486 - val_accuracy: 0.7922\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1261 - accuracy: 0.9537 - val_loss: 0.4172 - val_accuracy: 0.8158\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1426 - accuracy: 0.9387 - val_loss: 0.3947 - val_accuracy: 0.8230\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1316 - accuracy: 0.9546 - val_loss: 0.3992 - val_accuracy: 0.8189\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.9533 - val_loss: 0.3827 - val_accuracy: 0.8220\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1468 - accuracy: 0.9550 - val_loss: 0.4432 - val_accuracy: 0.7994\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1394 - accuracy: 0.9502 - val_loss: 0.3904 - val_accuracy: 0.8148\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1362 - accuracy: 0.9519 - val_loss: 0.3960 - val_accuracy: 0.8179\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1726 - accuracy: 0.9502 - val_loss: 0.3887 - val_accuracy: 0.8045\n","Epoch 40/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1267 - accuracy: 0.9559 - val_loss: 0.3642 - val_accuracy: 0.8261\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1193 - accuracy: 0.9546 - val_loss: 0.4259 - val_accuracy: 0.8025\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1323 - accuracy: 0.9489 - val_loss: 0.3956 - val_accuracy: 0.8004\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1043 - accuracy: 0.9572 - val_loss: 0.3693 - val_accuracy: 0.8364\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2976 - accuracy: 0.9506 - val_loss: 0.3689 - val_accuracy: 0.8189\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9581 - val_loss: 0.3637 - val_accuracy: 0.8313\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1287 - accuracy: 0.9572 - val_loss: 0.3759 - val_accuracy: 0.8200\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9493 - val_loss: 0.3641 - val_accuracy: 0.8086\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1126 - accuracy: 0.9603 - val_loss: 0.3518 - val_accuracy: 0.8447\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1351 - accuracy: 0.9577 - val_loss: 0.4088 - val_accuracy: 0.8344\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.9581 - val_loss: 0.3933 - val_accuracy: 0.8272\n","Score: 0.8271604776382446 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9574 - accuracy: 0.9272 - val_loss: 0.6237 - val_accuracy: 0.7058\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1834 - accuracy: 0.9202 - val_loss: 0.6629 - val_accuracy: 0.5926\n","Epoch 3/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1672 - accuracy: 0.9369 - val_loss: 0.5844 - val_accuracy: 0.7088\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1934 - accuracy: 0.9317 - val_loss: 0.5804 - val_accuracy: 0.7047\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3874 - accuracy: 0.9259 - val_loss: 0.5323 - val_accuracy: 0.7233\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2856 - accuracy: 0.9422 - val_loss: 0.4038 - val_accuracy: 0.8292\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1382 - accuracy: 0.9462 - val_loss: 0.4118 - val_accuracy: 0.7994\n","Epoch 8/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1270 - accuracy: 0.9555 - val_loss: 0.3067 - val_accuracy: 0.8560\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0972 - accuracy: 0.9603 - val_loss: 0.3494 - val_accuracy: 0.8385\n","Epoch 10/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3100 - accuracy: 0.9303 - val_loss: 0.4678 - val_accuracy: 0.7716\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1369 - accuracy: 0.9466 - val_loss: 0.4158 - val_accuracy: 0.7922\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1376 - accuracy: 0.9475 - val_loss: 0.3747 - val_accuracy: 0.8302\n","Epoch 13/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1454 - accuracy: 0.9511 - val_loss: 0.4237 - val_accuracy: 0.7901\n","Epoch 14/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1650 - accuracy: 0.9409 - val_loss: 0.3901 - val_accuracy: 0.8086\n","Epoch 15/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1061 - accuracy: 0.9515 - val_loss: 0.3880 - val_accuracy: 0.8354\n","Epoch 16/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1261 - accuracy: 0.9581 - val_loss: 0.3475 - val_accuracy: 0.8426\n","Epoch 17/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1176 - accuracy: 0.9616 - val_loss: 0.3853 - val_accuracy: 0.8107\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1850 - accuracy: 0.9405 - val_loss: 0.4822 - val_accuracy: 0.7377\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1441 - accuracy: 0.9480 - val_loss: 0.4753 - val_accuracy: 0.7788\n","Epoch 20/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1684 - accuracy: 0.9383 - val_loss: 0.4368 - val_accuracy: 0.7819\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1496 - accuracy: 0.9436 - val_loss: 0.4499 - val_accuracy: 0.7767\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1410 - accuracy: 0.9458 - val_loss: 0.4010 - val_accuracy: 0.8014\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1359 - accuracy: 0.9493 - val_loss: 0.4169 - val_accuracy: 0.8004\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1271 - accuracy: 0.9480 - val_loss: 0.3939 - val_accuracy: 0.8035\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2682 - accuracy: 0.9475 - val_loss: 0.4358 - val_accuracy: 0.7994\n","Epoch 26/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1326 - accuracy: 0.9497 - val_loss: 0.4295 - val_accuracy: 0.7984\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1133 - accuracy: 0.9519 - val_loss: 0.4462 - val_accuracy: 0.7819\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9519 - val_loss: 0.3852 - val_accuracy: 0.8086\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1217 - accuracy: 0.9528 - val_loss: 0.3996 - val_accuracy: 0.8189\n","Epoch 30/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1159 - accuracy: 0.9546 - val_loss: 0.4497 - val_accuracy: 0.7860\n","Epoch 31/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1623 - accuracy: 0.9418 - val_loss: 0.4590 - val_accuracy: 0.8025\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1186 - accuracy: 0.9581 - val_loss: 0.4209 - val_accuracy: 0.8025\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1209 - accuracy: 0.9590 - val_loss: 0.4273 - val_accuracy: 0.8169\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1603 - accuracy: 0.9418 - val_loss: 0.5186 - val_accuracy: 0.7695\n","Epoch 35/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1993 - accuracy: 0.9347 - val_loss: 0.4077 - val_accuracy: 0.8302\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1212 - accuracy: 0.9502 - val_loss: 0.3800 - val_accuracy: 0.8292\n","Epoch 37/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1111 - accuracy: 0.9546 - val_loss: 0.4383 - val_accuracy: 0.8138\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1194 - accuracy: 0.9555 - val_loss: 0.4244 - val_accuracy: 0.8210\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9546 - val_loss: 0.3716 - val_accuracy: 0.8405\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1131 - accuracy: 0.9572 - val_loss: 0.3551 - val_accuracy: 0.8539\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1039 - accuracy: 0.9537 - val_loss: 0.3485 - val_accuracy: 0.8436\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0998 - accuracy: 0.9621 - val_loss: 0.2992 - val_accuracy: 0.8693\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1080 - accuracy: 0.9572 - val_loss: 0.3328 - val_accuracy: 0.8344\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1127 - accuracy: 0.9555 - val_loss: 0.3321 - val_accuracy: 0.8508\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1142 - accuracy: 0.9581 - val_loss: 0.2779 - val_accuracy: 0.8786\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1058 - accuracy: 0.9608 - val_loss: 0.3104 - val_accuracy: 0.8498\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.9559 - val_loss: 0.2888 - val_accuracy: 0.8786\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0943 - accuracy: 0.9705 - val_loss: 0.2954 - val_accuracy: 0.8693\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0868 - accuracy: 0.9696 - val_loss: 0.3007 - val_accuracy: 0.8673\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9687 - val_loss: 0.4287 - val_accuracy: 0.8539\n","Score: 0.8539094924926758 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4274 - accuracy: 0.9167 - val_loss: 0.6114 - val_accuracy: 0.6944\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1775 - accuracy: 0.9290 - val_loss: 0.5266 - val_accuracy: 0.7315\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1595 - accuracy: 0.9352 - val_loss: 0.4914 - val_accuracy: 0.7572\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1657 - accuracy: 0.9400 - val_loss: 0.5110 - val_accuracy: 0.7623\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2269 - accuracy: 0.9343 - val_loss: 0.5829 - val_accuracy: 0.6852\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1467 - accuracy: 0.9444 - val_loss: 0.4897 - val_accuracy: 0.7757\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1561 - accuracy: 0.9365 - val_loss: 0.5068 - val_accuracy: 0.7603\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9436 - val_loss: 0.4533 - val_accuracy: 0.7860\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9489 - val_loss: 0.4513 - val_accuracy: 0.7963\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1412 - accuracy: 0.9493 - val_loss: 0.4409 - val_accuracy: 0.7901\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1459 - accuracy: 0.9378 - val_loss: 0.4335 - val_accuracy: 0.7891\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9475 - val_loss: 0.7898 - val_accuracy: 0.5916\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1252 - accuracy: 0.9537 - val_loss: 0.5334 - val_accuracy: 0.7521\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1348 - accuracy: 0.9506 - val_loss: 0.4614 - val_accuracy: 0.7891\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1813 - accuracy: 0.9466 - val_loss: 0.4195 - val_accuracy: 0.8056\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1728 - accuracy: 0.9440 - val_loss: 0.4240 - val_accuracy: 0.7922\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1379 - accuracy: 0.9436 - val_loss: 0.4565 - val_accuracy: 0.7737\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1289 - accuracy: 0.9524 - val_loss: 0.4482 - val_accuracy: 0.7963\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1538 - accuracy: 0.9519 - val_loss: 0.4121 - val_accuracy: 0.7860\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9568 - val_loss: 0.4119 - val_accuracy: 0.8251\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1230 - accuracy: 0.9533 - val_loss: 0.4063 - val_accuracy: 0.8261\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1533 - accuracy: 0.9489 - val_loss: 0.4053 - val_accuracy: 0.7963\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1235 - accuracy: 0.9541 - val_loss: 0.4485 - val_accuracy: 0.8169\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1181 - accuracy: 0.9502 - val_loss: 0.4003 - val_accuracy: 0.8189\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.9528 - val_loss: 0.3517 - val_accuracy: 0.8385\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1532 - accuracy: 0.9484 - val_loss: 0.3742 - val_accuracy: 0.8230\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9541 - val_loss: 0.3649 - val_accuracy: 0.8333\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9563 - val_loss: 0.3803 - val_accuracy: 0.8313\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1397 - accuracy: 0.9466 - val_loss: 0.3943 - val_accuracy: 0.8117\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1395 - accuracy: 0.9537 - val_loss: 0.3684 - val_accuracy: 0.8395\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1182 - accuracy: 0.9528 - val_loss: 0.4226 - val_accuracy: 0.8128\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1096 - accuracy: 0.9594 - val_loss: 0.3518 - val_accuracy: 0.8405\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1055 - accuracy: 0.9621 - val_loss: 0.3604 - val_accuracy: 0.8426\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9466 - val_loss: 0.3786 - val_accuracy: 0.8220\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1325 - accuracy: 0.9506 - val_loss: 0.3789 - val_accuracy: 0.8251\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1133 - accuracy: 0.9608 - val_loss: 0.3773 - val_accuracy: 0.8179\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1054 - accuracy: 0.9674 - val_loss: 0.3930 - val_accuracy: 0.8539\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1505 - accuracy: 0.9555 - val_loss: 0.3831 - val_accuracy: 0.8292\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2621 - accuracy: 0.9537 - val_loss: 0.4021 - val_accuracy: 0.8056\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9546 - val_loss: 0.3384 - val_accuracy: 0.8467\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1147 - accuracy: 0.9555 - val_loss: 0.3530 - val_accuracy: 0.8447\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1271 - accuracy: 0.9612 - val_loss: 0.3354 - val_accuracy: 0.8591\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1109 - accuracy: 0.9608 - val_loss: 0.3649 - val_accuracy: 0.8436\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1025 - accuracy: 0.9590 - val_loss: 0.3326 - val_accuracy: 0.8457\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1283 - accuracy: 0.9660 - val_loss: 0.3540 - val_accuracy: 0.8457\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9581 - val_loss: 0.3499 - val_accuracy: 0.8426\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1617 - accuracy: 0.9643 - val_loss: 0.3492 - val_accuracy: 0.8426\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2307 - accuracy: 0.9537 - val_loss: 0.4000 - val_accuracy: 0.8436\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0841 - accuracy: 0.9683 - val_loss: 0.3166 - val_accuracy: 0.8663\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0987 - accuracy: 0.9625 - val_loss: 0.3016 - val_accuracy: 0.8642\n","Score: 0.8641975522041321 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1118110.8750 - accuracy: 0.8805 - val_loss: 1.5028 - val_accuracy: 0.4588\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3760 - accuracy: 0.9153 - val_loss: 0.7791 - val_accuracy: 0.5237\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9074 - val_loss: 0.7357 - val_accuracy: 0.4825\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2102 - accuracy: 0.8959 - val_loss: 0.7685 - val_accuracy: 0.5185\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1866 - accuracy: 0.9131 - val_loss: 0.8161 - val_accuracy: 0.4959\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2065 - accuracy: 0.9092 - val_loss: 0.7648 - val_accuracy: 0.4959\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.8995 - val_loss: 0.7907 - val_accuracy: 0.4866\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2042 - accuracy: 0.8902 - val_loss: 0.7091 - val_accuracy: 0.4825\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1973 - accuracy: 0.9070 - val_loss: 0.7062 - val_accuracy: 0.5298\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9109 - val_loss: 0.6951 - val_accuracy: 0.5206\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1762 - accuracy: 0.9206 - val_loss: 0.7021 - val_accuracy: 0.5206\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1822 - accuracy: 0.9206 - val_loss: 0.6945 - val_accuracy: 0.5267\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1871 - accuracy: 0.9180 - val_loss: 0.6963 - val_accuracy: 0.4969\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9074 - val_loss: 0.6929 - val_accuracy: 0.4928\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9114 - val_loss: 0.7041 - val_accuracy: 0.5154\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9140 - val_loss: 0.6904 - val_accuracy: 0.4897\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.8968 - val_loss: 0.6920 - val_accuracy: 0.5154\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1723 - accuracy: 0.9255 - val_loss: 0.6982 - val_accuracy: 0.5237\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9039 - val_loss: 0.6944 - val_accuracy: 0.5082\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9140 - val_loss: 0.6934 - val_accuracy: 0.5144\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9123 - val_loss: 0.7015 - val_accuracy: 0.4907\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2022 - accuracy: 0.9034 - val_loss: 0.6977 - val_accuracy: 0.5216\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9114 - val_loss: 0.7020 - val_accuracy: 0.5123\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9127 - val_loss: 0.6914 - val_accuracy: 0.5309\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1930 - accuracy: 0.9171 - val_loss: 0.7280 - val_accuracy: 0.4866\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1958 - accuracy: 0.9105 - val_loss: 0.7418 - val_accuracy: 0.4691\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1972 - accuracy: 0.9056 - val_loss: 0.7227 - val_accuracy: 0.4846\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9078 - val_loss: 0.6977 - val_accuracy: 0.4938\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9136 - val_loss: 0.6947 - val_accuracy: 0.5216\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9123 - val_loss: 0.7006 - val_accuracy: 0.5031\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9175 - val_loss: 0.7090 - val_accuracy: 0.4722\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9030 - val_loss: 0.7004 - val_accuracy: 0.5134\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9158 - val_loss: 0.6953 - val_accuracy: 0.5082\n","Epoch 34/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2043 - accuracy: 0.9061 - val_loss: 0.6935 - val_accuracy: 0.5144\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1953 - accuracy: 0.9061 - val_loss: 0.6991 - val_accuracy: 0.4979\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9114 - val_loss: 0.6937 - val_accuracy: 0.4794\n","Epoch 37/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1980 - accuracy: 0.9114 - val_loss: 0.6935 - val_accuracy: 0.5288\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1997 - accuracy: 0.9101 - val_loss: 0.6981 - val_accuracy: 0.4949\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1948 - accuracy: 0.9056 - val_loss: 0.7229 - val_accuracy: 0.4743\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1991 - accuracy: 0.9048 - val_loss: 0.6944 - val_accuracy: 0.5082\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1952 - accuracy: 0.9096 - val_loss: 0.6939 - val_accuracy: 0.5175\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9105 - val_loss: 0.7140 - val_accuracy: 0.4887\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.8968 - val_loss: 0.6951 - val_accuracy: 0.5123\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9184 - val_loss: 0.7016 - val_accuracy: 0.5021\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9175 - val_loss: 0.6971 - val_accuracy: 0.5216\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9162 - val_loss: 0.7026 - val_accuracy: 0.5072\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9162 - val_loss: 0.7024 - val_accuracy: 0.5082\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9078 - val_loss: 0.7028 - val_accuracy: 0.4784\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1915 - accuracy: 0.9074 - val_loss: 0.7778 - val_accuracy: 0.4959\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9012 - val_loss: 0.6957 - val_accuracy: 0.5206\n","Score: 0.5205761194229126 \n","Parameters:  {'learning_rate': 0.13826288974489487, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7594 - accuracy: 0.9264 - val_loss: 0.6103 - val_accuracy: 0.6564\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1714 - accuracy: 0.9264 - val_loss: 0.5624 - val_accuracy: 0.7243\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2079 - accuracy: 0.9277 - val_loss: 0.5511 - val_accuracy: 0.7068\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1775 - accuracy: 0.9330 - val_loss: 0.5315 - val_accuracy: 0.7387\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1659 - accuracy: 0.9308 - val_loss: 0.5127 - val_accuracy: 0.7500\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3022 - accuracy: 0.9303 - val_loss: 0.5391 - val_accuracy: 0.7191\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1686 - accuracy: 0.9378 - val_loss: 0.5208 - val_accuracy: 0.7346\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1592 - accuracy: 0.9396 - val_loss: 0.4839 - val_accuracy: 0.7490\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1497 - accuracy: 0.9418 - val_loss: 0.4964 - val_accuracy: 0.7387\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1349 - accuracy: 0.9462 - val_loss: 0.4520 - val_accuracy: 0.7706\n","Epoch 11/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1377 - accuracy: 0.9493 - val_loss: 0.4984 - val_accuracy: 0.7613\n","Epoch 12/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1247 - accuracy: 0.9497 - val_loss: 0.4556 - val_accuracy: 0.7840\n","Epoch 13/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1472 - accuracy: 0.9493 - val_loss: 0.4686 - val_accuracy: 0.7726\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1449 - accuracy: 0.9396 - val_loss: 0.4273 - val_accuracy: 0.7963\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1497 - accuracy: 0.9422 - val_loss: 0.4724 - val_accuracy: 0.7932\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9378 - val_loss: 0.4441 - val_accuracy: 0.7685\n","Epoch 17/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1418 - accuracy: 0.9436 - val_loss: 0.4433 - val_accuracy: 0.7819\n","Epoch 18/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.4160 - accuracy: 0.9409 - val_loss: 0.4437 - val_accuracy: 0.7953\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.9502 - val_loss: 0.4215 - val_accuracy: 0.8086\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1199 - accuracy: 0.9563 - val_loss: 0.4082 - val_accuracy: 0.8045\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1108 - accuracy: 0.9594 - val_loss: 0.3991 - val_accuracy: 0.8138\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1197 - accuracy: 0.9541 - val_loss: 0.4290 - val_accuracy: 0.7973\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1484 - accuracy: 0.9427 - val_loss: 0.3774 - val_accuracy: 0.8230\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1747 - accuracy: 0.9506 - val_loss: 0.3939 - val_accuracy: 0.8241\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1275 - accuracy: 0.9515 - val_loss: 0.4275 - val_accuracy: 0.7984\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9392 - val_loss: 0.3890 - val_accuracy: 0.8076\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9506 - val_loss: 0.4119 - val_accuracy: 0.8045\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2242 - accuracy: 0.9440 - val_loss: 0.3946 - val_accuracy: 0.8344\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1296 - accuracy: 0.9528 - val_loss: 0.3780 - val_accuracy: 0.8364\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9541 - val_loss: 0.3731 - val_accuracy: 0.8302\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1213 - accuracy: 0.9550 - val_loss: 0.4123 - val_accuracy: 0.8107\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1347 - accuracy: 0.9546 - val_loss: 0.3439 - val_accuracy: 0.8467\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9511 - val_loss: 0.4564 - val_accuracy: 0.8333\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1117 - accuracy: 0.9594 - val_loss: 0.3640 - val_accuracy: 0.8210\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9559 - val_loss: 0.3345 - val_accuracy: 0.8632\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1313 - accuracy: 0.9555 - val_loss: 0.3440 - val_accuracy: 0.8457\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.9581 - val_loss: 0.3744 - val_accuracy: 0.8385\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1997 - accuracy: 0.9511 - val_loss: 0.3633 - val_accuracy: 0.8333\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1289 - accuracy: 0.9599 - val_loss: 0.3488 - val_accuracy: 0.8467\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1028 - accuracy: 0.9608 - val_loss: 0.3672 - val_accuracy: 0.8395\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1018 - accuracy: 0.9581 - val_loss: 0.3256 - val_accuracy: 0.8477\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9599 - val_loss: 0.3239 - val_accuracy: 0.8467\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0914 - accuracy: 0.9634 - val_loss: 0.3062 - val_accuracy: 0.8632\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1100 - accuracy: 0.9594 - val_loss: 0.3606 - val_accuracy: 0.8354\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1225 - accuracy: 0.9572 - val_loss: 0.2962 - val_accuracy: 0.8621\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0922 - accuracy: 0.9669 - val_loss: 0.3168 - val_accuracy: 0.8580\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1194 - accuracy: 0.9546 - val_loss: 0.3243 - val_accuracy: 0.8539\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0906 - accuracy: 0.9674 - val_loss: 0.2849 - val_accuracy: 0.8724\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0971 - accuracy: 0.9638 - val_loss: 0.3066 - val_accuracy: 0.8601\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1003 - accuracy: 0.9634 - val_loss: 0.2908 - val_accuracy: 0.8611\n","Score: 0.8611111044883728 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.9536 - accuracy: 0.9250 - val_loss: 0.6404 - val_accuracy: 0.6296\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9092 - val_loss: 0.6128 - val_accuracy: 0.6687\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1666 - accuracy: 0.9140 - val_loss: 0.5821 - val_accuracy: 0.6914\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1858 - accuracy: 0.9312 - val_loss: 0.5074 - val_accuracy: 0.7469\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1671 - accuracy: 0.9277 - val_loss: 0.8478 - val_accuracy: 0.6975\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9321 - val_loss: 0.5404 - val_accuracy: 0.7006\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1660 - accuracy: 0.9365 - val_loss: 0.5321 - val_accuracy: 0.7479\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2344 - accuracy: 0.9356 - val_loss: 0.5043 - val_accuracy: 0.7263\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2701 - accuracy: 0.9347 - val_loss: 0.5285 - val_accuracy: 0.7181\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1653 - accuracy: 0.9369 - val_loss: 0.5046 - val_accuracy: 0.7315\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1587 - accuracy: 0.9409 - val_loss: 0.4789 - val_accuracy: 0.7644\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1604 - accuracy: 0.9400 - val_loss: 0.4934 - val_accuracy: 0.7541\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1653 - accuracy: 0.9418 - val_loss: 0.4557 - val_accuracy: 0.7932\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1668 - accuracy: 0.9462 - val_loss: 0.5264 - val_accuracy: 0.7377\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9466 - val_loss: 0.4859 - val_accuracy: 0.7428\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1416 - accuracy: 0.9458 - val_loss: 0.4497 - val_accuracy: 0.7932\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7974 - accuracy: 0.9325 - val_loss: 0.4484 - val_accuracy: 0.7881\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1732 - accuracy: 0.9361 - val_loss: 0.4270 - val_accuracy: 0.8014\n","Epoch 19/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1363 - accuracy: 0.9422 - val_loss: 0.4390 - val_accuracy: 0.7963\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9480 - val_loss: 0.3299 - val_accuracy: 0.8395\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9546 - val_loss: 0.3724 - val_accuracy: 0.8261\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0938 - accuracy: 0.9660 - val_loss: 0.3563 - val_accuracy: 0.8416\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2984 - accuracy: 0.9528 - val_loss: 0.3556 - val_accuracy: 0.8354\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1099 - accuracy: 0.9674 - val_loss: 0.3985 - val_accuracy: 0.8251\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1509 - accuracy: 0.9458 - val_loss: 0.4189 - val_accuracy: 0.8025\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1203 - accuracy: 0.9515 - val_loss: 0.4568 - val_accuracy: 0.7767\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1225 - accuracy: 0.9502 - val_loss: 0.4537 - val_accuracy: 0.7984\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1541 - accuracy: 0.9572 - val_loss: 0.3598 - val_accuracy: 0.8385\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1202 - accuracy: 0.9555 - val_loss: 0.3292 - val_accuracy: 0.8488\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0978 - accuracy: 0.9612 - val_loss: 0.3355 - val_accuracy: 0.8519\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1198 - accuracy: 0.9541 - val_loss: 0.3447 - val_accuracy: 0.8580\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1225 - accuracy: 0.9630 - val_loss: 0.2716 - val_accuracy: 0.8663\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0946 - accuracy: 0.9647 - val_loss: 0.2881 - val_accuracy: 0.8621\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0868 - accuracy: 0.9652 - val_loss: 0.2757 - val_accuracy: 0.8693\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0880 - accuracy: 0.9705 - val_loss: 0.3150 - val_accuracy: 0.8570\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1018 - accuracy: 0.9621 - val_loss: 0.2830 - val_accuracy: 0.8549\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0973 - accuracy: 0.9643 - val_loss: 0.2603 - val_accuracy: 0.8858\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0823 - accuracy: 0.9683 - val_loss: 0.2563 - val_accuracy: 0.8837\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0720 - accuracy: 0.9735 - val_loss: 0.2416 - val_accuracy: 0.9084\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0835 - accuracy: 0.9647 - val_loss: 0.2507 - val_accuracy: 0.8951\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0938 - accuracy: 0.9638 - val_loss: 0.2286 - val_accuracy: 0.9012\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0592 - accuracy: 0.9771 - val_loss: 0.1977 - val_accuracy: 0.9105\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0795 - accuracy: 0.9749 - val_loss: 0.2049 - val_accuracy: 0.9074\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0593 - accuracy: 0.9788 - val_loss: 0.2627 - val_accuracy: 0.9012\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.2715 - val_accuracy: 0.8961\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0882 - accuracy: 0.9727 - val_loss: 0.2851 - val_accuracy: 0.8817\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0647 - accuracy: 0.9744 - val_loss: 0.1949 - val_accuracy: 0.9218\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0670 - accuracy: 0.9744 - val_loss: 0.1808 - val_accuracy: 0.9187\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0533 - accuracy: 0.9788 - val_loss: 0.1657 - val_accuracy: 0.9383\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 0.2136 - val_accuracy: 0.9259\n","Score: 0.9259259104728699 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 5909.3442 - accuracy: 0.9008 - val_loss: 0.7194 - val_accuracy: 0.4897\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9039 - val_loss: 0.7166 - val_accuracy: 0.4794\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.8999 - val_loss: 0.7307 - val_accuracy: 0.4938\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 484.1595 - accuracy: 0.9043 - val_loss: 0.8130 - val_accuracy: 0.5103\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1789 - accuracy: 0.9171 - val_loss: 0.6945 - val_accuracy: 0.4856\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9184 - val_loss: 0.6942 - val_accuracy: 0.5072\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2195 - accuracy: 0.9145 - val_loss: 0.6976 - val_accuracy: 0.4918\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2268 - accuracy: 0.9034 - val_loss: 0.7127 - val_accuracy: 0.5154\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2207 - accuracy: 0.9087 - val_loss: 0.6922 - val_accuracy: 0.5298\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2216 - accuracy: 0.9202 - val_loss: 0.7133 - val_accuracy: 0.5103\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2253 - accuracy: 0.9118 - val_loss: 0.6986 - val_accuracy: 0.5031\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2187 - accuracy: 0.9215 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2165 - accuracy: 0.9198 - val_loss: 0.6939 - val_accuracy: 0.5144\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2288 - accuracy: 0.9105 - val_loss: 0.6967 - val_accuracy: 0.5247\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2187 - accuracy: 0.9193 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.9180 - val_loss: 0.6925 - val_accuracy: 0.5267\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2234 - accuracy: 0.9123 - val_loss: 0.6920 - val_accuracy: 0.5267\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2283 - accuracy: 0.9087 - val_loss: 0.6931 - val_accuracy: 0.5093\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2249 - accuracy: 0.9167 - val_loss: 0.7030 - val_accuracy: 0.5175\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2162 - accuracy: 0.9189 - val_loss: 0.6945 - val_accuracy: 0.4949\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9189 - val_loss: 0.6971 - val_accuracy: 0.4907\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2260 - accuracy: 0.9101 - val_loss: 0.7043 - val_accuracy: 0.4753\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2178 - accuracy: 0.9153 - val_loss: 0.7452 - val_accuracy: 0.4969\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2141 - accuracy: 0.9167 - val_loss: 0.6933 - val_accuracy: 0.4763\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2286 - accuracy: 0.9105 - val_loss: 0.7040 - val_accuracy: 0.5237\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2205 - accuracy: 0.9158 - val_loss: 0.6966 - val_accuracy: 0.5165\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2246 - accuracy: 0.9136 - val_loss: 0.6937 - val_accuracy: 0.4918\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2217 - accuracy: 0.9118 - val_loss: 0.6973 - val_accuracy: 0.4825\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2233 - accuracy: 0.9096 - val_loss: 0.6984 - val_accuracy: 0.5412\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2166 - accuracy: 0.9180 - val_loss: 0.7042 - val_accuracy: 0.5103\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2287 - accuracy: 0.9056 - val_loss: 0.6944 - val_accuracy: 0.4877\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2224 - accuracy: 0.9061 - val_loss: 0.6932 - val_accuracy: 0.4907\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2235 - accuracy: 0.9118 - val_loss: 0.7035 - val_accuracy: 0.4990\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2428 - accuracy: 0.8955 - val_loss: 0.6938 - val_accuracy: 0.5154\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2218 - accuracy: 0.9140 - val_loss: 0.7031 - val_accuracy: 0.5021\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2247 - accuracy: 0.9145 - val_loss: 0.6924 - val_accuracy: 0.5216\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2280 - accuracy: 0.9096 - val_loss: 0.7024 - val_accuracy: 0.5031\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2254 - accuracy: 0.9056 - val_loss: 0.6952 - val_accuracy: 0.5041\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2254 - accuracy: 0.9123 - val_loss: 0.6927 - val_accuracy: 0.5185\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9175 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2248 - accuracy: 0.9056 - val_loss: 0.6922 - val_accuracy: 0.5216\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9215 - val_loss: 0.6954 - val_accuracy: 0.5165\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2223 - accuracy: 0.9149 - val_loss: 0.6984 - val_accuracy: 0.4887\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.8893 - val_loss: 0.6936 - val_accuracy: 0.4959\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2225 - accuracy: 0.9145 - val_loss: 0.6965 - val_accuracy: 0.5144\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2110 - accuracy: 0.9206 - val_loss: 0.6930 - val_accuracy: 0.5072\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9180 - val_loss: 0.6936 - val_accuracy: 0.4959\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.9127 - val_loss: 0.7485 - val_accuracy: 0.5113\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2232 - accuracy: 0.9140 - val_loss: 0.7046 - val_accuracy: 0.5134\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2248 - accuracy: 0.9092 - val_loss: 0.6956 - val_accuracy: 0.5010\n","Score: 0.501028835773468 \n","Parameters:  {'learning_rate': 0.046800470824223776, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 45348.2695 - accuracy: 0.9012 - val_loss: 0.7209 - val_accuracy: 0.5123\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9008 - val_loss: 0.7040 - val_accuracy: 0.5113\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1837 - accuracy: 0.9131 - val_loss: 0.6931 - val_accuracy: 0.5051\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9109 - val_loss: 0.7253 - val_accuracy: 0.4938\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.8995 - val_loss: 0.7904 - val_accuracy: 0.4856\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.9008 - val_loss: 0.7004 - val_accuracy: 0.5093\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1868 - accuracy: 0.9123 - val_loss: 0.7523 - val_accuracy: 0.4712\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9070 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1881 - accuracy: 0.9061 - val_loss: 0.8748 - val_accuracy: 0.5051\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.9074 - val_loss: 0.7897 - val_accuracy: 0.5031\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9101 - val_loss: 0.8665 - val_accuracy: 0.4774\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9039 - val_loss: 0.7353 - val_accuracy: 0.5216\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.8981 - val_loss: 1.0507 - val_accuracy: 0.4774\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9021 - val_loss: 0.7103 - val_accuracy: 0.5082\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9078 - val_loss: 0.7877 - val_accuracy: 0.5247\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1795 - accuracy: 0.9065 - val_loss: 1.0499 - val_accuracy: 0.4866\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2284 - accuracy: 0.8986 - val_loss: 0.6959 - val_accuracy: 0.5237\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9012 - val_loss: 0.6987 - val_accuracy: 0.5082\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9070 - val_loss: 0.6968 - val_accuracy: 0.4928\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.8981 - val_loss: 0.6952 - val_accuracy: 0.4846\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9026 - val_loss: 0.7001 - val_accuracy: 0.4866\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9065 - val_loss: 0.7906 - val_accuracy: 0.4877\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9145 - val_loss: 0.6937 - val_accuracy: 0.4753\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9030 - val_loss: 0.7015 - val_accuracy: 0.5093\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9083 - val_loss: 0.6993 - val_accuracy: 0.5134\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.9105 - val_loss: 0.6951 - val_accuracy: 0.5154\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2005 - accuracy: 0.9118 - val_loss: 0.6967 - val_accuracy: 0.5206\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9180 - val_loss: 0.6916 - val_accuracy: 0.5370\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9206 - val_loss: 0.6925 - val_accuracy: 0.5226\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.8990 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2144 - accuracy: 0.9105 - val_loss: 0.6995 - val_accuracy: 0.5175\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9149 - val_loss: 0.6980 - val_accuracy: 0.5000\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9074 - val_loss: 0.6947 - val_accuracy: 0.4918\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9074 - val_loss: 0.6934 - val_accuracy: 0.5031\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2091 - accuracy: 0.9123 - val_loss: 0.6955 - val_accuracy: 0.5041\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9167 - val_loss: 0.7065 - val_accuracy: 0.4866\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9026 - val_loss: 0.7010 - val_accuracy: 0.5082\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9215 - val_loss: 0.7287 - val_accuracy: 0.5123\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9255 - val_loss: 0.7368 - val_accuracy: 0.5278\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9158 - val_loss: 0.6952 - val_accuracy: 0.5031\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.8990 - val_loss: 0.7047 - val_accuracy: 0.5103\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9136 - val_loss: 0.6941 - val_accuracy: 0.5216\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2093 - accuracy: 0.9136 - val_loss: 0.6982 - val_accuracy: 0.4825\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2116 - accuracy: 0.9039 - val_loss: 0.6950 - val_accuracy: 0.5113\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2108 - accuracy: 0.9118 - val_loss: 0.6914 - val_accuracy: 0.5298\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1999 - accuracy: 0.9202 - val_loss: 0.6987 - val_accuracy: 0.4805\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2211 - accuracy: 0.8986 - val_loss: 0.7003 - val_accuracy: 0.4856\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2152 - accuracy: 0.9056 - val_loss: 0.6918 - val_accuracy: 0.5309\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9215 - val_loss: 0.7091 - val_accuracy: 0.5000\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2130 - accuracy: 0.9021 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Score: 0.5195473432540894 \n","Parameters:  {'learning_rate': 0.07517496675768283, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 30477.0410 - accuracy: 0.8770 - val_loss: 0.6972 - val_accuracy: 0.5257\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2215 - accuracy: 0.9034 - val_loss: 0.7196 - val_accuracy: 0.4897\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2183 - accuracy: 0.8876 - val_loss: 0.6928 - val_accuracy: 0.5195\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2150 - accuracy: 0.9070 - val_loss: 0.8864 - val_accuracy: 0.5031\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9083 - val_loss: 0.7049 - val_accuracy: 0.5134\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.8924 - val_loss: 0.8190 - val_accuracy: 0.4969\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2295 - accuracy: 0.8884 - val_loss: 0.7504 - val_accuracy: 0.5195\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9039 - val_loss: 0.7271 - val_accuracy: 0.5082\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9039 - val_loss: 0.7172 - val_accuracy: 0.5082\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9153 - val_loss: 0.6987 - val_accuracy: 0.5195\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2117 - accuracy: 0.9189 - val_loss: 0.7038 - val_accuracy: 0.4866\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9255 - val_loss: 0.7169 - val_accuracy: 0.5072\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9136 - val_loss: 0.7035 - val_accuracy: 0.4907\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2091 - accuracy: 0.9052 - val_loss: 0.6955 - val_accuracy: 0.4959\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9017 - val_loss: 0.6938 - val_accuracy: 0.4835\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9171 - val_loss: 0.6938 - val_accuracy: 0.5195\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9043 - val_loss: 0.6945 - val_accuracy: 0.4887\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.9123 - val_loss: 0.7003 - val_accuracy: 0.5134\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9092 - val_loss: 0.7192 - val_accuracy: 0.5206\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9198 - val_loss: 0.7121 - val_accuracy: 0.5093\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2092 - accuracy: 0.9136 - val_loss: 0.6979 - val_accuracy: 0.5062\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2092 - accuracy: 0.9114 - val_loss: 0.7275 - val_accuracy: 0.4887\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2100 - accuracy: 0.8990 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2120 - accuracy: 0.9175 - val_loss: 0.7013 - val_accuracy: 0.5082\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9224 - val_loss: 0.6967 - val_accuracy: 0.5123\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9123 - val_loss: 0.7100 - val_accuracy: 0.4815\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9021 - val_loss: 0.7048 - val_accuracy: 0.4784\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2122 - accuracy: 0.9074 - val_loss: 0.6987 - val_accuracy: 0.4887\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2165 - accuracy: 0.9048 - val_loss: 0.6942 - val_accuracy: 0.5247\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2112 - accuracy: 0.9074 - val_loss: 0.6958 - val_accuracy: 0.4794\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2066 - accuracy: 0.9153 - val_loss: 0.7101 - val_accuracy: 0.5051\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1839 - accuracy: 0.9250 - val_loss: 0.6972 - val_accuracy: 0.4784\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2072 - accuracy: 0.9105 - val_loss: 0.6934 - val_accuracy: 0.4918\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2108 - accuracy: 0.9153 - val_loss: 0.6921 - val_accuracy: 0.5237\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2084 - accuracy: 0.9206 - val_loss: 0.7207 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9180 - val_loss: 0.6931 - val_accuracy: 0.5093\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.9131 - val_loss: 0.6937 - val_accuracy: 0.5051\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9167 - val_loss: 0.6964 - val_accuracy: 0.5185\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2120 - accuracy: 0.9078 - val_loss: 0.6933 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.9140 - val_loss: 0.7189 - val_accuracy: 0.5123\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.9087 - val_loss: 0.6938 - val_accuracy: 0.5123\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9140 - val_loss: 0.6929 - val_accuracy: 0.5206\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2077 - accuracy: 0.9056 - val_loss: 0.6951 - val_accuracy: 0.5175\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9153 - val_loss: 0.6929 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2109 - accuracy: 0.9087 - val_loss: 0.7123 - val_accuracy: 0.4681\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2152 - accuracy: 0.8986 - val_loss: 0.7051 - val_accuracy: 0.5093\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9206 - val_loss: 0.6952 - val_accuracy: 0.4907\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2155 - accuracy: 0.9048 - val_loss: 0.7151 - val_accuracy: 0.4969\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9004 - val_loss: 0.7034 - val_accuracy: 0.5051\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2023 - accuracy: 0.9114 - val_loss: 0.6929 - val_accuracy: 0.5257\n","Score: 0.5257201790809631 \n","Parameters:  {'learning_rate': 0.07473973964869712, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0291 - accuracy: 0.9206 - val_loss: 0.6212 - val_accuracy: 0.7047\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2059 - accuracy: 0.9281 - val_loss: 0.6003 - val_accuracy: 0.6780\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4384 - accuracy: 0.9383 - val_loss: 0.5249 - val_accuracy: 0.7284\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2276 - accuracy: 0.9343 - val_loss: 0.5404 - val_accuracy: 0.7130\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2762 - accuracy: 0.9352 - val_loss: 0.5309 - val_accuracy: 0.7418\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1342 - accuracy: 0.9511 - val_loss: 0.4509 - val_accuracy: 0.7850\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1772 - accuracy: 0.9387 - val_loss: 0.4577 - val_accuracy: 0.7829\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1692 - accuracy: 0.9418 - val_loss: 0.4559 - val_accuracy: 0.7850\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1744 - accuracy: 0.9497 - val_loss: 0.4745 - val_accuracy: 0.7737\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9414 - val_loss: 0.4446 - val_accuracy: 0.7788\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9466 - val_loss: 0.4231 - val_accuracy: 0.7984\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9458 - val_loss: 0.4270 - val_accuracy: 0.7953\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2368 - accuracy: 0.9458 - val_loss: 0.4246 - val_accuracy: 0.8035\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9431 - val_loss: 0.4286 - val_accuracy: 0.7870\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.9484 - val_loss: 0.4281 - val_accuracy: 0.7953\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1263 - accuracy: 0.9537 - val_loss: 0.4366 - val_accuracy: 0.7984\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9563 - val_loss: 0.5355 - val_accuracy: 0.7747\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9489 - val_loss: 0.4057 - val_accuracy: 0.8179\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1521 - accuracy: 0.9422 - val_loss: 0.4650 - val_accuracy: 0.7737\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9462 - val_loss: 0.3882 - val_accuracy: 0.8179\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1622 - accuracy: 0.9616 - val_loss: 0.5202 - val_accuracy: 0.7819\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1250 - accuracy: 0.9519 - val_loss: 0.3714 - val_accuracy: 0.8200\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9546 - val_loss: 0.3816 - val_accuracy: 0.8117\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1385 - accuracy: 0.9466 - val_loss: 0.4161 - val_accuracy: 0.7942\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1086 - accuracy: 0.9524 - val_loss: 0.3794 - val_accuracy: 0.8179\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9431 - val_loss: 0.3922 - val_accuracy: 0.8313\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1222 - accuracy: 0.9572 - val_loss: 0.4075 - val_accuracy: 0.8014\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1402 - accuracy: 0.9572 - val_loss: 0.3894 - val_accuracy: 0.8128\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1109 - accuracy: 0.9537 - val_loss: 0.3691 - val_accuracy: 0.8230\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9568 - val_loss: 0.3787 - val_accuracy: 0.8117\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9572 - val_loss: 0.3460 - val_accuracy: 0.8220\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0957 - accuracy: 0.9621 - val_loss: 0.3310 - val_accuracy: 0.8498\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1009 - accuracy: 0.9665 - val_loss: 0.3444 - val_accuracy: 0.8374\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1512 - accuracy: 0.9546 - val_loss: 0.3520 - val_accuracy: 0.8374\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0937 - accuracy: 0.9665 - val_loss: 0.3495 - val_accuracy: 0.8447\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1044 - accuracy: 0.9621 - val_loss: 0.3027 - val_accuracy: 0.8467\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.9590 - val_loss: 0.3290 - val_accuracy: 0.8601\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0944 - accuracy: 0.9643 - val_loss: 0.3126 - val_accuracy: 0.8570\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1006 - accuracy: 0.9603 - val_loss: 0.3114 - val_accuracy: 0.8632\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1030 - accuracy: 0.9581 - val_loss: 0.3066 - val_accuracy: 0.8714\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0921 - accuracy: 0.9669 - val_loss: 0.3038 - val_accuracy: 0.8601\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0939 - accuracy: 0.9665 - val_loss: 0.3373 - val_accuracy: 0.8539\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0819 - accuracy: 0.9691 - val_loss: 0.2962 - val_accuracy: 0.8735\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0801 - accuracy: 0.9691 - val_loss: 0.2559 - val_accuracy: 0.8889\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.3933 - val_accuracy: 0.8488\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9586 - val_loss: 0.2903 - val_accuracy: 0.8642\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1183 - accuracy: 0.9709 - val_loss: 0.2761 - val_accuracy: 0.8858\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0783 - accuracy: 0.9687 - val_loss: 0.2724 - val_accuracy: 0.8776\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0888 - accuracy: 0.9700 - val_loss: 0.2960 - val_accuracy: 0.8663\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9683 - val_loss: 0.2699 - val_accuracy: 0.8909\n","Score: 0.8909465074539185 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5356 - accuracy: 0.9175 - val_loss: 0.6383 - val_accuracy: 0.6440\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9299 - val_loss: 0.5757 - val_accuracy: 0.7490\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1709 - accuracy: 0.9409 - val_loss: 0.5542 - val_accuracy: 0.7500\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1497 - accuracy: 0.9444 - val_loss: 0.5349 - val_accuracy: 0.7438\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9440 - val_loss: 0.5012 - val_accuracy: 0.7500\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1540 - accuracy: 0.9378 - val_loss: 0.5689 - val_accuracy: 0.7510\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9361 - val_loss: 0.5302 - val_accuracy: 0.7346\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.9405 - val_loss: 0.4832 - val_accuracy: 0.7819\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9444 - val_loss: 0.4913 - val_accuracy: 0.7757\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2809 - accuracy: 0.9369 - val_loss: 0.4403 - val_accuracy: 0.7942\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2661 - accuracy: 0.9427 - val_loss: 0.4768 - val_accuracy: 0.7870\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1534 - accuracy: 0.9414 - val_loss: 0.4644 - val_accuracy: 0.7953\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9528 - val_loss: 0.4624 - val_accuracy: 0.8004\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1424 - accuracy: 0.9519 - val_loss: 0.4426 - val_accuracy: 0.7922\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9515 - val_loss: 0.5165 - val_accuracy: 0.7695\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9493 - val_loss: 0.4546 - val_accuracy: 0.8035\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1404 - accuracy: 0.9440 - val_loss: 0.4670 - val_accuracy: 0.7809\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9422 - val_loss: 0.4593 - val_accuracy: 0.7778\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1403 - accuracy: 0.9444 - val_loss: 0.4245 - val_accuracy: 0.7984\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2284 - accuracy: 0.9458 - val_loss: 0.4224 - val_accuracy: 0.8097\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1674 - accuracy: 0.9458 - val_loss: 0.4434 - val_accuracy: 0.7767\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2326 - accuracy: 0.9493 - val_loss: 0.4488 - val_accuracy: 0.8035\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9519 - val_loss: 0.4451 - val_accuracy: 0.7881\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1304 - accuracy: 0.9537 - val_loss: 0.4228 - val_accuracy: 0.8086\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1558 - accuracy: 0.9493 - val_loss: 0.4272 - val_accuracy: 0.8025\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1260 - accuracy: 0.9533 - val_loss: 0.4122 - val_accuracy: 0.7963\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1174 - accuracy: 0.9541 - val_loss: 0.4232 - val_accuracy: 0.8138\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9511 - val_loss: 0.4106 - val_accuracy: 0.8117\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1237 - accuracy: 0.9537 - val_loss: 0.3878 - val_accuracy: 0.8086\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1518 - accuracy: 0.9458 - val_loss: 0.6126 - val_accuracy: 0.8179\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9462 - val_loss: 0.4377 - val_accuracy: 0.7953\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1549 - accuracy: 0.9356 - val_loss: 0.4586 - val_accuracy: 0.7603\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1179 - accuracy: 0.9511 - val_loss: 0.4060 - val_accuracy: 0.8128\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1389 - accuracy: 0.9480 - val_loss: 0.3966 - val_accuracy: 0.8066\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1228 - accuracy: 0.9555 - val_loss: 0.4647 - val_accuracy: 0.7942\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9599 - val_loss: 0.3595 - val_accuracy: 0.8447\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1096 - accuracy: 0.9638 - val_loss: 0.3602 - val_accuracy: 0.8447\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9453 - val_loss: 0.4659 - val_accuracy: 0.7798\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1102 - accuracy: 0.9541 - val_loss: 0.4177 - val_accuracy: 0.8066\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1098 - accuracy: 0.9550 - val_loss: 0.3701 - val_accuracy: 0.8467\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9586 - val_loss: 0.3451 - val_accuracy: 0.8477\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.4248 - val_accuracy: 0.8107\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1001 - accuracy: 0.9616 - val_loss: 0.3715 - val_accuracy: 0.8364\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1005 - accuracy: 0.9603 - val_loss: 0.3695 - val_accuracy: 0.8447\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9550 - val_loss: 0.3640 - val_accuracy: 0.8488\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1012 - accuracy: 0.9586 - val_loss: 0.3386 - val_accuracy: 0.8570\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9550 - val_loss: 0.3462 - val_accuracy: 0.8560\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1430 - accuracy: 0.9559 - val_loss: 0.9978 - val_accuracy: 0.7294\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0982 - accuracy: 0.9638 - val_loss: 0.3299 - val_accuracy: 0.8539\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1194 - accuracy: 0.9572 - val_loss: 0.3679 - val_accuracy: 0.8374\n","Score: 0.8374485373497009 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 21.5403 - accuracy: 0.9131 - val_loss: 0.7189 - val_accuracy: 0.5082\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2440 - accuracy: 0.9153 - val_loss: 0.6950 - val_accuracy: 0.5237\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2222 - accuracy: 0.9242 - val_loss: 0.7022 - val_accuracy: 0.5278\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9083 - val_loss: 0.6934 - val_accuracy: 0.4959\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2223 - accuracy: 0.9056 - val_loss: 0.7039 - val_accuracy: 0.5134\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9145 - val_loss: 0.7089 - val_accuracy: 0.5000\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2032 - accuracy: 0.8981 - val_loss: 0.7004 - val_accuracy: 0.5206\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9114 - val_loss: 0.6906 - val_accuracy: 0.5453\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2369 - accuracy: 0.9101 - val_loss: 0.6959 - val_accuracy: 0.5391\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1821 - accuracy: 0.9224 - val_loss: 0.7021 - val_accuracy: 0.4774\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2098 - accuracy: 0.9039 - val_loss: 0.6924 - val_accuracy: 0.4825\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2181 - accuracy: 0.9048 - val_loss: 0.7229 - val_accuracy: 0.4774\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2136 - accuracy: 0.9061 - val_loss: 0.6976 - val_accuracy: 0.4856\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2271 - accuracy: 0.9092 - val_loss: 0.7119 - val_accuracy: 0.5103\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2248 - accuracy: 0.9131 - val_loss: 0.7008 - val_accuracy: 0.4763\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2075 - accuracy: 0.9008 - val_loss: 0.6953 - val_accuracy: 0.4990\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9101 - val_loss: 0.7091 - val_accuracy: 0.4866\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.8959 - val_loss: 0.6965 - val_accuracy: 0.5206\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9065 - val_loss: 0.7230 - val_accuracy: 0.4856\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2071 - accuracy: 0.9105 - val_loss: 0.7485 - val_accuracy: 0.5123\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9109 - val_loss: 0.6966 - val_accuracy: 0.4846\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9048 - val_loss: 0.7041 - val_accuracy: 0.4918\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9087 - val_loss: 0.8186 - val_accuracy: 0.4774\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9021 - val_loss: 0.6963 - val_accuracy: 0.4794\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9061 - val_loss: 0.7436 - val_accuracy: 0.4763\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9034 - val_loss: 0.6930 - val_accuracy: 0.5093\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9070 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9153 - val_loss: 0.6927 - val_accuracy: 0.5144\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9131 - val_loss: 0.6937 - val_accuracy: 0.5206\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2189 - accuracy: 0.9171 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2307 - accuracy: 0.9131 - val_loss: 0.6933 - val_accuracy: 0.5093\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2471 - accuracy: 0.9140 - val_loss: 0.6949 - val_accuracy: 0.5165\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2599 - accuracy: 0.9136 - val_loss: 0.7027 - val_accuracy: 0.5288\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2739 - accuracy: 0.9193 - val_loss: 0.7939 - val_accuracy: 0.5247\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2832 - accuracy: 0.9153 - val_loss: 0.8472 - val_accuracy: 0.5216\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2983 - accuracy: 0.9127 - val_loss: 0.9303 - val_accuracy: 0.5144\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2981 - accuracy: 0.9136 - val_loss: 0.9790 - val_accuracy: 0.5154\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2859 - accuracy: 0.9193 - val_loss: 1.0396 - val_accuracy: 0.5062\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2787 - accuracy: 0.9211 - val_loss: 1.0542 - val_accuracy: 0.5072\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3026 - accuracy: 0.9083 - val_loss: 0.9820 - val_accuracy: 0.5195\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3026 - accuracy: 0.9109 - val_loss: 1.0041 - val_accuracy: 0.5051\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3021 - accuracy: 0.9109 - val_loss: 0.9982 - val_accuracy: 0.5072\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2909 - accuracy: 0.9171 - val_loss: 1.0287 - val_accuracy: 0.5062\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3015 - accuracy: 0.9096 - val_loss: 0.9960 - val_accuracy: 0.5062\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2980 - accuracy: 0.9131 - val_loss: 0.9946 - val_accuracy: 0.5165\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2879 - accuracy: 0.9180 - val_loss: 1.0203 - val_accuracy: 0.5144\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2843 - accuracy: 0.9189 - val_loss: 1.0157 - val_accuracy: 0.5206\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2918 - accuracy: 0.9145 - val_loss: 1.0054 - val_accuracy: 0.5175\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2895 - accuracy: 0.9167 - val_loss: 1.0347 - val_accuracy: 0.5082\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2849 - accuracy: 0.9184 - val_loss: 1.0003 - val_accuracy: 0.5309\n","Score: 0.5308641791343689 \n","Parameters:  {'learning_rate': 0.007097562450077077, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7237 - accuracy: 0.9162 - val_loss: 0.6475 - val_accuracy: 0.6533\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1841 - accuracy: 0.9149 - val_loss: 0.6211 - val_accuracy: 0.6296\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9149 - val_loss: 0.6068 - val_accuracy: 0.6379\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1748 - accuracy: 0.9215 - val_loss: 0.5991 - val_accuracy: 0.6831\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1522 - accuracy: 0.9356 - val_loss: 0.5408 - val_accuracy: 0.7428\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1686 - accuracy: 0.9361 - val_loss: 0.4625 - val_accuracy: 0.7901\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9317 - val_loss: 0.4805 - val_accuracy: 0.7613\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1426 - accuracy: 0.9466 - val_loss: 0.4691 - val_accuracy: 0.7603\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9369 - val_loss: 0.4725 - val_accuracy: 0.7891\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1529 - accuracy: 0.9383 - val_loss: 0.4465 - val_accuracy: 0.7737\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1410 - accuracy: 0.9405 - val_loss: 0.4321 - val_accuracy: 0.7767\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1593 - accuracy: 0.9458 - val_loss: 0.3742 - val_accuracy: 0.8179\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1379 - accuracy: 0.9374 - val_loss: 0.4198 - val_accuracy: 0.8086\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1216 - accuracy: 0.9502 - val_loss: 0.4325 - val_accuracy: 0.7850\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9436 - val_loss: 0.3932 - val_accuracy: 0.8292\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9528 - val_loss: 0.8359 - val_accuracy: 0.7521\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.9559 - val_loss: 0.3745 - val_accuracy: 0.8272\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1176 - accuracy: 0.9519 - val_loss: 0.4148 - val_accuracy: 0.8158\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1132 - accuracy: 0.9528 - val_loss: 0.3718 - val_accuracy: 0.8282\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1235 - accuracy: 0.9594 - val_loss: 0.2811 - val_accuracy: 0.8776\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9555 - val_loss: 0.3261 - val_accuracy: 0.8642\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1095 - accuracy: 0.9616 - val_loss: 0.3216 - val_accuracy: 0.8570\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1022 - accuracy: 0.9647 - val_loss: 0.3933 - val_accuracy: 0.8220\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0886 - accuracy: 0.9691 - val_loss: 0.3171 - val_accuracy: 0.8796\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0952 - accuracy: 0.9669 - val_loss: 0.3065 - val_accuracy: 0.8663\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1023 - accuracy: 0.9691 - val_loss: 0.2636 - val_accuracy: 0.8796\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0985 - accuracy: 0.9660 - val_loss: 0.3355 - val_accuracy: 0.8230\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1449 - accuracy: 0.9674 - val_loss: 0.3514 - val_accuracy: 0.8313\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0810 - accuracy: 0.9665 - val_loss: 0.2604 - val_accuracy: 0.8735\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1043 - accuracy: 0.9665 - val_loss: 0.2533 - val_accuracy: 0.8940\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0654 - accuracy: 0.9757 - val_loss: 0.2430 - val_accuracy: 0.8899\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0725 - accuracy: 0.9727 - val_loss: 0.2593 - val_accuracy: 0.9064\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0648 - accuracy: 0.9762 - val_loss: 0.2252 - val_accuracy: 0.8940\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0725 - accuracy: 0.9757 - val_loss: 0.3725 - val_accuracy: 0.8128\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9740 - val_loss: 0.2590 - val_accuracy: 0.8971\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0983 - accuracy: 0.9735 - val_loss: 0.3412 - val_accuracy: 0.8313\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0724 - accuracy: 0.9744 - val_loss: 0.1976 - val_accuracy: 0.9064\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9784 - val_loss: 0.2367 - val_accuracy: 0.8909\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0623 - accuracy: 0.9788 - val_loss: 0.1848 - val_accuracy: 0.9177\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0677 - accuracy: 0.9784 - val_loss: 0.2807 - val_accuracy: 0.8817\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0563 - accuracy: 0.9771 - val_loss: 0.3494 - val_accuracy: 0.8930\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9771 - val_loss: 0.2092 - val_accuracy: 0.9043\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0796 - accuracy: 0.9828 - val_loss: 0.2108 - val_accuracy: 0.9115\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0507 - accuracy: 0.9810 - val_loss: 0.2004 - val_accuracy: 0.9095\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0680 - accuracy: 0.9850 - val_loss: 0.1815 - val_accuracy: 0.9228\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0625 - accuracy: 0.9784 - val_loss: 0.1820 - val_accuracy: 0.9270\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0682 - accuracy: 0.9775 - val_loss: 0.3004 - val_accuracy: 0.8889\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0544 - accuracy: 0.9819 - val_loss: 0.1912 - val_accuracy: 0.9146\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0475 - accuracy: 0.9810 - val_loss: 0.1485 - val_accuracy: 0.9444\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0382 - accuracy: 0.9854 - val_loss: 0.1369 - val_accuracy: 0.9444\n","Score: 0.9444444179534912 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Global:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 49.3564 - accuracy: 0.8929 - val_loss: 0.6969 - val_accuracy: 0.5288\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9105 - val_loss: 0.7060 - val_accuracy: 0.5062\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2293 - accuracy: 0.9153 - val_loss: 0.7023 - val_accuracy: 0.4784\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9105 - val_loss: 0.6910 - val_accuracy: 0.5267\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9136 - val_loss: 0.6943 - val_accuracy: 0.5134\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2089 - accuracy: 0.9171 - val_loss: 0.7021 - val_accuracy: 0.4856\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2113 - accuracy: 0.9065 - val_loss: 0.6938 - val_accuracy: 0.5041\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2227 - accuracy: 0.9127 - val_loss: 0.7042 - val_accuracy: 0.5185\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2331 - accuracy: 0.9220 - val_loss: 0.7032 - val_accuracy: 0.5051\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2594 - accuracy: 0.9211 - val_loss: 0.7482 - val_accuracy: 0.5072\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2859 - accuracy: 0.9114 - val_loss: 0.7526 - val_accuracy: 0.5288\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2897 - accuracy: 0.9162 - val_loss: 0.8690 - val_accuracy: 0.5154\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2838 - accuracy: 0.9171 - val_loss: 0.8923 - val_accuracy: 0.5165\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2771 - accuracy: 0.9215 - val_loss: 0.9203 - val_accuracy: 0.5175\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2867 - accuracy: 0.9136 - val_loss: 0.8769 - val_accuracy: 0.5113\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2868 - accuracy: 0.9162 - val_loss: 0.9025 - val_accuracy: 0.5062\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2800 - accuracy: 0.9189 - val_loss: 0.9146 - val_accuracy: 0.5123\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2816 - accuracy: 0.9180 - val_loss: 0.8705 - val_accuracy: 0.5340\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2866 - accuracy: 0.9145 - val_loss: 0.8754 - val_accuracy: 0.5144\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2933 - accuracy: 0.9118 - val_loss: 0.8636 - val_accuracy: 0.5154\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2911 - accuracy: 0.9140 - val_loss: 0.8782 - val_accuracy: 0.5144\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2947 - accuracy: 0.9109 - val_loss: 0.8566 - val_accuracy: 0.5144\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2796 - accuracy: 0.9215 - val_loss: 0.8752 - val_accuracy: 0.5360\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2957 - accuracy: 0.9070 - val_loss: 0.8464 - val_accuracy: 0.5031\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2968 - accuracy: 0.9136 - val_loss: 0.8493 - val_accuracy: 0.5267\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2912 - accuracy: 0.9149 - val_loss: 0.9027 - val_accuracy: 0.5082\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2865 - accuracy: 0.9153 - val_loss: 0.8935 - val_accuracy: 0.5103\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2873 - accuracy: 0.9158 - val_loss: 0.8759 - val_accuracy: 0.5175\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2934 - accuracy: 0.9114 - val_loss: 0.8395 - val_accuracy: 0.5298\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2852 - accuracy: 0.9180 - val_loss: 0.9045 - val_accuracy: 0.5134\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2867 - accuracy: 0.9136 - val_loss: 0.8856 - val_accuracy: 0.5082\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2889 - accuracy: 0.9158 - val_loss: 0.8972 - val_accuracy: 0.5093\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3002 - accuracy: 0.9074 - val_loss: 0.8354 - val_accuracy: 0.5195\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2874 - accuracy: 0.9184 - val_loss: 0.9016 - val_accuracy: 0.5123\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2862 - accuracy: 0.9158 - val_loss: 0.8901 - val_accuracy: 0.5123\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2871 - accuracy: 0.9153 - val_loss: 0.9041 - val_accuracy: 0.5051\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2822 - accuracy: 0.9193 - val_loss: 0.9381 - val_accuracy: 0.5000\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2794 - accuracy: 0.9184 - val_loss: 0.9231 - val_accuracy: 0.5000\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2817 - accuracy: 0.9180 - val_loss: 0.9144 - val_accuracy: 0.5041\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2886 - accuracy: 0.9127 - val_loss: 0.8750 - val_accuracy: 0.5062\n","Epoch 41/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2799 - accuracy: 0.9206 - val_loss: 0.9136 - val_accuracy: 0.5144\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2784 - accuracy: 0.9193 - val_loss: 0.8961 - val_accuracy: 0.5195\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2829 - accuracy: 0.9171 - val_loss: 0.9083 - val_accuracy: 0.5113\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2870 - accuracy: 0.9149 - val_loss: 0.8767 - val_accuracy: 0.5093\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2910 - accuracy: 0.9127 - val_loss: 0.8621 - val_accuracy: 0.5216\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.3033 - accuracy: 0.9070 - val_loss: 0.8296 - val_accuracy: 0.5267\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3020 - accuracy: 0.9092 - val_loss: 0.8471 - val_accuracy: 0.5144\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2914 - accuracy: 0.9153 - val_loss: 0.9037 - val_accuracy: 0.5031\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2895 - accuracy: 0.9145 - val_loss: 0.8949 - val_accuracy: 0.5103\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3023 - accuracy: 0.9070 - val_loss: 0.8382 - val_accuracy: 0.5226\n","Score: 0.5226337313652039 \n","Parameters:  {'learning_rate': 0.011440334711688645, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 12952.5781 - accuracy: 0.8955 - val_loss: 0.6976 - val_accuracy: 0.5082\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1848 - accuracy: 0.9043 - val_loss: 0.7108 - val_accuracy: 0.4733\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.9043 - val_loss: 0.6947 - val_accuracy: 0.5123\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2330 - accuracy: 0.9109 - val_loss: 0.6933 - val_accuracy: 0.4835\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2416 - accuracy: 0.8981 - val_loss: 0.6936 - val_accuracy: 0.5062\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2302 - accuracy: 0.9136 - val_loss: 0.6953 - val_accuracy: 0.4949\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2388 - accuracy: 0.8951 - val_loss: 0.6918 - val_accuracy: 0.5319\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2259 - accuracy: 0.9206 - val_loss: 0.7221 - val_accuracy: 0.5041\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2249 - accuracy: 0.9136 - val_loss: 0.6943 - val_accuracy: 0.5123\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2332 - accuracy: 0.9131 - val_loss: 0.6928 - val_accuracy: 0.5381\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2303 - accuracy: 0.9056 - val_loss: 0.6932 - val_accuracy: 0.4763\n","Epoch 12/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2247 - accuracy: 0.9105 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2310 - accuracy: 0.9078 - val_loss: 0.6964 - val_accuracy: 0.4815\n","Epoch 14/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2292 - accuracy: 0.9048 - val_loss: 0.6948 - val_accuracy: 0.4969\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2304 - accuracy: 0.9083 - val_loss: 0.6947 - val_accuracy: 0.5216\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2258 - accuracy: 0.9149 - val_loss: 0.6966 - val_accuracy: 0.4979\n","Epoch 17/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2266 - accuracy: 0.9145 - val_loss: 0.7046 - val_accuracy: 0.4743\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2297 - accuracy: 0.9087 - val_loss: 0.6984 - val_accuracy: 0.4918\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2269 - accuracy: 0.9136 - val_loss: 0.6956 - val_accuracy: 0.4979\n","Epoch 20/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2363 - accuracy: 0.9123 - val_loss: 0.7018 - val_accuracy: 0.5041\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2244 - accuracy: 0.9171 - val_loss: 0.7039 - val_accuracy: 0.5093\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2266 - accuracy: 0.9171 - val_loss: 0.7009 - val_accuracy: 0.5103\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2340 - accuracy: 0.9092 - val_loss: 0.6922 - val_accuracy: 0.5278\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9198 - val_loss: 0.6950 - val_accuracy: 0.5123\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2269 - accuracy: 0.9109 - val_loss: 0.6927 - val_accuracy: 0.5206\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2271 - accuracy: 0.9162 - val_loss: 0.7027 - val_accuracy: 0.5113\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2236 - accuracy: 0.9145 - val_loss: 0.6945 - val_accuracy: 0.4835\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2299 - accuracy: 0.9096 - val_loss: 0.6937 - val_accuracy: 0.5082\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2353 - accuracy: 0.9105 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2333 - accuracy: 0.9083 - val_loss: 0.6956 - val_accuracy: 0.4897\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2319 - accuracy: 0.9078 - val_loss: 0.6932 - val_accuracy: 0.5103\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2241 - accuracy: 0.9220 - val_loss: 0.6990 - val_accuracy: 0.5113\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2254 - accuracy: 0.9158 - val_loss: 0.6956 - val_accuracy: 0.5206\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2348 - accuracy: 0.9136 - val_loss: 0.7028 - val_accuracy: 0.5175\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2267 - accuracy: 0.9123 - val_loss: 0.6917 - val_accuracy: 0.5288\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2244 - accuracy: 0.9193 - val_loss: 0.6976 - val_accuracy: 0.5103\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2327 - accuracy: 0.9149 - val_loss: 0.6932 - val_accuracy: 0.5134\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2280 - accuracy: 0.9145 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 39/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2307 - accuracy: 0.9109 - val_loss: 0.6929 - val_accuracy: 0.5103\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2339 - accuracy: 0.9153 - val_loss: 0.6940 - val_accuracy: 0.5144\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2250 - accuracy: 0.9171 - val_loss: 0.6918 - val_accuracy: 0.5257\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2418 - accuracy: 0.9061 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2326 - accuracy: 0.9105 - val_loss: 0.7023 - val_accuracy: 0.5144\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2300 - accuracy: 0.9105 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2348 - accuracy: 0.9083 - val_loss: 0.7031 - val_accuracy: 0.4774\n","Epoch 46/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2254 - accuracy: 0.9065 - val_loss: 0.6977 - val_accuracy: 0.4619\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2328 - accuracy: 0.8977 - val_loss: 0.6934 - val_accuracy: 0.4784\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2319 - accuracy: 0.9131 - val_loss: 0.6957 - val_accuracy: 0.5185\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2314 - accuracy: 0.9193 - val_loss: 0.7079 - val_accuracy: 0.5298\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2232 - accuracy: 0.9158 - val_loss: 0.6944 - val_accuracy: 0.5021\n","Score: 0.5020576119422913 \n","Parameters:  {'learning_rate': 0.042004963052064075, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.4446 - accuracy: 0.9242 - val_loss: 0.5398 - val_accuracy: 0.7469\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2569 - accuracy: 0.9321 - val_loss: 0.5290 - val_accuracy: 0.7335\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2652 - accuracy: 0.9339 - val_loss: 0.5029 - val_accuracy: 0.7572\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1765 - accuracy: 0.9365 - val_loss: 0.4665 - val_accuracy: 0.7860\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2359 - accuracy: 0.9361 - val_loss: 0.4761 - val_accuracy: 0.7665\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1401 - accuracy: 0.9453 - val_loss: 0.4521 - val_accuracy: 0.7809\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1247 - accuracy: 0.9506 - val_loss: 0.4386 - val_accuracy: 0.7819\n","Epoch 8/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1347 - accuracy: 0.9489 - val_loss: 0.3829 - val_accuracy: 0.8344\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1252 - accuracy: 0.9533 - val_loss: 0.5365 - val_accuracy: 0.7654\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1420 - accuracy: 0.9497 - val_loss: 0.4492 - val_accuracy: 0.7767\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9497 - val_loss: 0.4671 - val_accuracy: 0.7572\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1277 - accuracy: 0.9528 - val_loss: 0.3865 - val_accuracy: 0.8035\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1548 - accuracy: 0.9396 - val_loss: 0.4606 - val_accuracy: 0.8066\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9462 - val_loss: 0.4144 - val_accuracy: 0.8035\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1379 - accuracy: 0.9422 - val_loss: 0.4184 - val_accuracy: 0.8138\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1256 - accuracy: 0.9537 - val_loss: 0.4345 - val_accuracy: 0.7737\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.9519 - val_loss: 0.5039 - val_accuracy: 0.8014\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.9568 - val_loss: 0.4239 - val_accuracy: 0.7942\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5620 - accuracy: 0.9343 - val_loss: 0.4854 - val_accuracy: 0.7521\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2592 - accuracy: 0.9506 - val_loss: 0.3810 - val_accuracy: 0.8230\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9511 - val_loss: 0.4011 - val_accuracy: 0.8117\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1636 - accuracy: 0.9563 - val_loss: 0.3833 - val_accuracy: 0.8210\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1274 - accuracy: 0.9506 - val_loss: 0.3838 - val_accuracy: 0.8169\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9515 - val_loss: 0.4008 - val_accuracy: 0.8086\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1192 - accuracy: 0.9537 - val_loss: 0.3537 - val_accuracy: 0.8272\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9489 - val_loss: 0.3964 - val_accuracy: 0.8210\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1949 - accuracy: 0.9458 - val_loss: 0.4536 - val_accuracy: 0.8066\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1192 - accuracy: 0.9581 - val_loss: 0.3729 - val_accuracy: 0.8364\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9568 - val_loss: 0.3630 - val_accuracy: 0.8251\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1493 - accuracy: 0.9506 - val_loss: 0.3555 - val_accuracy: 0.8467\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1229 - accuracy: 0.9568 - val_loss: 0.3605 - val_accuracy: 0.8395\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1253 - accuracy: 0.9533 - val_loss: 0.4055 - val_accuracy: 0.8107\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1444 - accuracy: 0.9511 - val_loss: 0.4092 - val_accuracy: 0.8107\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9484 - val_loss: 0.3331 - val_accuracy: 0.8416\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1168 - accuracy: 0.9577 - val_loss: 0.3564 - val_accuracy: 0.8200\n","Epoch 36/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0972 - accuracy: 0.9581 - val_loss: 0.3302 - val_accuracy: 0.8560\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2708 - accuracy: 0.9524 - val_loss: 0.3177 - val_accuracy: 0.8539\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1559 - accuracy: 0.9524 - val_loss: 0.3433 - val_accuracy: 0.8519\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1208 - accuracy: 0.9568 - val_loss: 0.3162 - val_accuracy: 0.8416\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9652 - val_loss: 0.3524 - val_accuracy: 0.8385\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1041 - accuracy: 0.9643 - val_loss: 0.3111 - val_accuracy: 0.8704\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1085 - accuracy: 0.9630 - val_loss: 0.3468 - val_accuracy: 0.8457\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1337 - accuracy: 0.9519 - val_loss: 0.2928 - val_accuracy: 0.8549\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0863 - accuracy: 0.9612 - val_loss: 0.3395 - val_accuracy: 0.8591\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1175 - accuracy: 0.9537 - val_loss: 0.3491 - val_accuracy: 0.8364\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9603 - val_loss: 0.3479 - val_accuracy: 0.8642\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9555 - val_loss: 0.3873 - val_accuracy: 0.8313\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1027 - accuracy: 0.9612 - val_loss: 0.2870 - val_accuracy: 0.8745\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0895 - accuracy: 0.9630 - val_loss: 0.3153 - val_accuracy: 0.8539\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1149 - accuracy: 0.9586 - val_loss: 0.3172 - val_accuracy: 0.8529\n","Score: 0.8528806567192078 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 27616.2871 - accuracy: 0.8889 - val_loss: 0.7896 - val_accuracy: 0.5165\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1904 - accuracy: 0.9114 - val_loss: 1.1909 - val_accuracy: 0.5082\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9039 - val_loss: 1.2541 - val_accuracy: 0.4825\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2259 - accuracy: 0.8951 - val_loss: 0.7395 - val_accuracy: 0.4835\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2050 - accuracy: 0.9078 - val_loss: 0.6937 - val_accuracy: 0.4907\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9105 - val_loss: 0.6999 - val_accuracy: 0.4846\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9118 - val_loss: 0.7195 - val_accuracy: 0.4722\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2246 - accuracy: 0.9030 - val_loss: 0.7157 - val_accuracy: 0.5103\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2046 - accuracy: 0.9105 - val_loss: 0.7050 - val_accuracy: 0.4784\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2146 - accuracy: 0.9061 - val_loss: 0.6932 - val_accuracy: 0.5134\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2141 - accuracy: 0.9140 - val_loss: 0.6920 - val_accuracy: 0.5237\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2157 - accuracy: 0.9123 - val_loss: 0.6933 - val_accuracy: 0.5051\n","Epoch 13/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2204 - accuracy: 0.9153 - val_loss: 0.7267 - val_accuracy: 0.5113\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2091 - accuracy: 0.9096 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9096 - val_loss: 0.7067 - val_accuracy: 0.4835\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2170 - accuracy: 0.9008 - val_loss: 0.6934 - val_accuracy: 0.5051\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2187 - accuracy: 0.9118 - val_loss: 0.6928 - val_accuracy: 0.5123\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2122 - accuracy: 0.9109 - val_loss: 0.6943 - val_accuracy: 0.4938\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2125 - accuracy: 0.9105 - val_loss: 0.6982 - val_accuracy: 0.4856\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2146 - accuracy: 0.9101 - val_loss: 0.6971 - val_accuracy: 0.5442\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2174 - accuracy: 0.9092 - val_loss: 0.6927 - val_accuracy: 0.5206\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2109 - accuracy: 0.9167 - val_loss: 0.6932 - val_accuracy: 0.5123\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2072 - accuracy: 0.9175 - val_loss: 0.6922 - val_accuracy: 0.5298\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9078 - val_loss: 0.6933 - val_accuracy: 0.4825\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2110 - accuracy: 0.9153 - val_loss: 0.7079 - val_accuracy: 0.4949\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2104 - accuracy: 0.9101 - val_loss: 0.7290 - val_accuracy: 0.5134\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2147 - accuracy: 0.9131 - val_loss: 0.6957 - val_accuracy: 0.4928\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2090 - accuracy: 0.9070 - val_loss: 0.6944 - val_accuracy: 0.5144\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9180 - val_loss: 0.6987 - val_accuracy: 0.5021\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9105 - val_loss: 0.6932 - val_accuracy: 0.4918\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2207 - accuracy: 0.9052 - val_loss: 0.6975 - val_accuracy: 0.4856\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2216 - accuracy: 0.9021 - val_loss: 0.6994 - val_accuracy: 0.4825\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2200 - accuracy: 0.8999 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9043 - val_loss: 0.7044 - val_accuracy: 0.5021\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9153 - val_loss: 0.6986 - val_accuracy: 0.4856\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2182 - accuracy: 0.9078 - val_loss: 0.7196 - val_accuracy: 0.5267\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9145 - val_loss: 0.7064 - val_accuracy: 0.4918\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2138 - accuracy: 0.9105 - val_loss: 0.6955 - val_accuracy: 0.5195\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9140 - val_loss: 0.6944 - val_accuracy: 0.5381\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9131 - val_loss: 0.6988 - val_accuracy: 0.5051\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9136 - val_loss: 0.6951 - val_accuracy: 0.5093\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9127 - val_loss: 0.6925 - val_accuracy: 0.5226\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9123 - val_loss: 0.6959 - val_accuracy: 0.4897\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2212 - accuracy: 0.8986 - val_loss: 0.6941 - val_accuracy: 0.4815\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2185 - accuracy: 0.9048 - val_loss: 0.6941 - val_accuracy: 0.4825\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2005 - accuracy: 0.9202 - val_loss: 0.7034 - val_accuracy: 0.4959\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9083 - val_loss: 0.7099 - val_accuracy: 0.4774\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9008 - val_loss: 0.7017 - val_accuracy: 0.5165\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2126 - accuracy: 0.9184 - val_loss: 0.7192 - val_accuracy: 0.5216\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1989 - accuracy: 0.9189 - val_loss: 0.6940 - val_accuracy: 0.5093\n","Score: 0.5092592835426331 \n","Parameters:  {'learning_rate': 0.061051643797337456, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8957 - accuracy: 0.9206 - val_loss: 0.6164 - val_accuracy: 0.7037\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1518 - accuracy: 0.9356 - val_loss: 0.6253 - val_accuracy: 0.6523\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1715 - accuracy: 0.9334 - val_loss: 0.7910 - val_accuracy: 0.5967\n","Epoch 4/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1801 - accuracy: 0.9158 - val_loss: 0.5521 - val_accuracy: 0.7181\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1454 - accuracy: 0.9418 - val_loss: 0.5386 - val_accuracy: 0.7325\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1709 - accuracy: 0.9330 - val_loss: 0.4995 - val_accuracy: 0.7634\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1595 - accuracy: 0.9356 - val_loss: 0.5221 - val_accuracy: 0.7551\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1556 - accuracy: 0.9471 - val_loss: 0.4789 - val_accuracy: 0.7798\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.3427 - accuracy: 0.9369 - val_loss: 0.4667 - val_accuracy: 0.7716\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9449 - val_loss: 0.4148 - val_accuracy: 0.8035\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1350 - accuracy: 0.9475 - val_loss: 0.4969 - val_accuracy: 0.7397\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1573 - accuracy: 0.9347 - val_loss: 0.4617 - val_accuracy: 0.7757\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1477 - accuracy: 0.9400 - val_loss: 0.4449 - val_accuracy: 0.7932\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3618 - accuracy: 0.9396 - val_loss: 0.4909 - val_accuracy: 0.7654\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1347 - accuracy: 0.9546 - val_loss: 0.4273 - val_accuracy: 0.7973\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1849 - accuracy: 0.9502 - val_loss: 0.7859 - val_accuracy: 0.7233\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1713 - accuracy: 0.9511 - val_loss: 0.4288 - val_accuracy: 0.7891\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9577 - val_loss: 0.3975 - val_accuracy: 0.8230\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9493 - val_loss: 0.4889 - val_accuracy: 0.7788\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1403 - accuracy: 0.9506 - val_loss: 0.4094 - val_accuracy: 0.8076\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1547 - accuracy: 0.9511 - val_loss: 0.3978 - val_accuracy: 0.8025\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1289 - accuracy: 0.9484 - val_loss: 0.3955 - val_accuracy: 0.8220\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9537 - val_loss: 0.4073 - val_accuracy: 0.8158\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1313 - accuracy: 0.9475 - val_loss: 0.4951 - val_accuracy: 0.8230\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1208 - accuracy: 0.9515 - val_loss: 0.3791 - val_accuracy: 0.8261\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1495 - accuracy: 0.9466 - val_loss: 0.4181 - val_accuracy: 0.7984\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1273 - accuracy: 0.9506 - val_loss: 0.3914 - val_accuracy: 0.8148\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.9462 - val_loss: 0.3863 - val_accuracy: 0.8220\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9493 - val_loss: 0.4007 - val_accuracy: 0.8107\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1205 - accuracy: 0.9546 - val_loss: 0.3719 - val_accuracy: 0.8313\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1039 - accuracy: 0.9630 - val_loss: 0.4025 - val_accuracy: 0.8056\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9431 - val_loss: 0.3775 - val_accuracy: 0.8282\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1168 - accuracy: 0.9546 - val_loss: 0.3840 - val_accuracy: 0.8251\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1146 - accuracy: 0.9511 - val_loss: 0.4226 - val_accuracy: 0.7984\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3849 - accuracy: 0.9502 - val_loss: 0.4198 - val_accuracy: 0.8025\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.9528 - val_loss: 0.3939 - val_accuracy: 0.8241\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1167 - accuracy: 0.9586 - val_loss: 0.3744 - val_accuracy: 0.8405\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9546 - val_loss: 0.3853 - val_accuracy: 0.8261\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.9506 - val_loss: 0.3922 - val_accuracy: 0.8261\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1034 - accuracy: 0.9621 - val_loss: 0.4105 - val_accuracy: 0.8076\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1227 - accuracy: 0.9563 - val_loss: 0.3438 - val_accuracy: 0.8426\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1448 - accuracy: 0.9594 - val_loss: 0.3840 - val_accuracy: 0.8385\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1076 - accuracy: 0.9541 - val_loss: 0.3499 - val_accuracy: 0.8416\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9541 - val_loss: 0.3572 - val_accuracy: 0.8374\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1547 - accuracy: 0.9559 - val_loss: 0.3741 - val_accuracy: 0.8354\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1244 - accuracy: 0.9537 - val_loss: 0.3226 - val_accuracy: 0.8529\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1310 - accuracy: 0.9541 - val_loss: 0.3604 - val_accuracy: 0.8529\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1340 - accuracy: 0.9555 - val_loss: 0.3668 - val_accuracy: 0.8220\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1121 - accuracy: 0.9608 - val_loss: 0.3273 - val_accuracy: 0.8519\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0994 - accuracy: 0.9559 - val_loss: 0.3466 - val_accuracy: 0.8313\n","Score: 0.8312757015228271 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1233567.8750 - accuracy: 0.9056 - val_loss: 0.6986 - val_accuracy: 0.5175\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1906 - accuracy: 0.9180 - val_loss: 0.6975 - val_accuracy: 0.5000\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9153 - val_loss: 0.7981 - val_accuracy: 0.4856\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9034 - val_loss: 0.7189 - val_accuracy: 0.5175\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9074 - val_loss: 0.7226 - val_accuracy: 0.5134\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9206 - val_loss: 0.8315 - val_accuracy: 0.5010\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9039 - val_loss: 0.6931 - val_accuracy: 0.5082\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9065 - val_loss: 0.7284 - val_accuracy: 0.4825\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9048 - val_loss: 0.6937 - val_accuracy: 0.4846\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9123 - val_loss: 0.7233 - val_accuracy: 0.5247\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9101 - val_loss: 0.7621 - val_accuracy: 0.4743\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9026 - val_loss: 0.6961 - val_accuracy: 0.4887\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9008 - val_loss: 0.6921 - val_accuracy: 0.5267\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9242 - val_loss: 0.8071 - val_accuracy: 0.4897\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9052 - val_loss: 0.6912 - val_accuracy: 0.5329\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1875 - accuracy: 0.9153 - val_loss: 0.7542 - val_accuracy: 0.4825\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9039 - val_loss: 0.6937 - val_accuracy: 0.4866\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9043 - val_loss: 0.6935 - val_accuracy: 0.5021\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9162 - val_loss: 0.7015 - val_accuracy: 0.5113\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1900 - accuracy: 0.9092 - val_loss: 0.6967 - val_accuracy: 0.5062\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9127 - val_loss: 0.6924 - val_accuracy: 0.5226\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9131 - val_loss: 0.7491 - val_accuracy: 0.5226\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1880 - accuracy: 0.9030 - val_loss: 0.6954 - val_accuracy: 0.4794\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9105 - val_loss: 0.6940 - val_accuracy: 0.4949\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1861 - accuracy: 0.9140 - val_loss: 0.6953 - val_accuracy: 0.4846\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9105 - val_loss: 0.7465 - val_accuracy: 0.4969\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1855 - accuracy: 0.9092 - val_loss: 0.6931 - val_accuracy: 0.5154\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9092 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9158 - val_loss: 0.7100 - val_accuracy: 0.5123\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9167 - val_loss: 0.7070 - val_accuracy: 0.5041\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9074 - val_loss: 0.7430 - val_accuracy: 0.4774\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9017 - val_loss: 0.7613 - val_accuracy: 0.4866\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9061 - val_loss: 0.7179 - val_accuracy: 0.4918\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1868 - accuracy: 0.9123 - val_loss: 0.7253 - val_accuracy: 0.5031\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1818 - accuracy: 0.9162 - val_loss: 0.6971 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9026 - val_loss: 0.6932 - val_accuracy: 0.4959\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.7005 - val_accuracy: 0.5082\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9167 - val_loss: 0.7484 - val_accuracy: 0.5051\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1975 - accuracy: 0.9109 - val_loss: 0.7079 - val_accuracy: 0.5021\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9021 - val_loss: 0.7281 - val_accuracy: 0.5010\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1822 - accuracy: 0.9140 - val_loss: 0.7059 - val_accuracy: 0.4733\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9175 - val_loss: 0.7466 - val_accuracy: 0.4825\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9052 - val_loss: 0.6932 - val_accuracy: 0.4959\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9039 - val_loss: 0.7004 - val_accuracy: 0.4928\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1945 - accuracy: 0.9083 - val_loss: 0.8005 - val_accuracy: 0.4774\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9030 - val_loss: 0.7278 - val_accuracy: 0.5226\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1864 - accuracy: 0.9105 - val_loss: 0.6931 - val_accuracy: 0.5237\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1912 - accuracy: 0.9162 - val_loss: 0.7235 - val_accuracy: 0.4907\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9004 - val_loss: 0.7012 - val_accuracy: 0.5093\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9101 - val_loss: 0.7212 - val_accuracy: 0.4784\n","Score: 0.4783950746059418 \n","Parameters:  {'learning_rate': 0.17285337857778438, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 49598.3203 - accuracy: 0.8862 - val_loss: 0.6959 - val_accuracy: 0.4877\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2185 - accuracy: 0.9092 - val_loss: 0.6931 - val_accuracy: 0.5257\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2129 - accuracy: 0.9105 - val_loss: 0.6995 - val_accuracy: 0.5216\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9228 - val_loss: 0.6964 - val_accuracy: 0.5226\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9193 - val_loss: 0.6950 - val_accuracy: 0.5093\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9167 - val_loss: 0.6933 - val_accuracy: 0.4979\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2198 - accuracy: 0.9101 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2208 - accuracy: 0.9101 - val_loss: 0.6976 - val_accuracy: 0.5123\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9127 - val_loss: 0.6931 - val_accuracy: 0.5051\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9140 - val_loss: 0.7094 - val_accuracy: 0.4846\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.9105 - val_loss: 0.6929 - val_accuracy: 0.5154\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9101 - val_loss: 0.6908 - val_accuracy: 0.5360\n","Epoch 13/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2184 - accuracy: 0.9096 - val_loss: 0.7133 - val_accuracy: 0.5237\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9171 - val_loss: 0.7185 - val_accuracy: 0.4949\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2123 - accuracy: 0.8986 - val_loss: 0.6951 - val_accuracy: 0.5082\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2117 - accuracy: 0.9017 - val_loss: 0.7089 - val_accuracy: 0.4990\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9008 - val_loss: 0.7000 - val_accuracy: 0.5021\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9184 - val_loss: 0.6960 - val_accuracy: 0.4928\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9043 - val_loss: 0.6945 - val_accuracy: 0.5154\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9131 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9109 - val_loss: 0.7018 - val_accuracy: 0.4856\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9101 - val_loss: 0.6934 - val_accuracy: 0.4887\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9136 - val_loss: 0.7007 - val_accuracy: 0.4866\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.9070 - val_loss: 0.6929 - val_accuracy: 0.5226\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2085 - accuracy: 0.9149 - val_loss: 0.7297 - val_accuracy: 0.4835\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9078 - val_loss: 0.6986 - val_accuracy: 0.5185\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9153 - val_loss: 0.7153 - val_accuracy: 0.4712\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2039 - accuracy: 0.9101 - val_loss: 0.7400 - val_accuracy: 0.5216\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9114 - val_loss: 0.7053 - val_accuracy: 0.4877\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2031 - accuracy: 0.9175 - val_loss: 0.7101 - val_accuracy: 0.5082\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2101 - accuracy: 0.9070 - val_loss: 0.6938 - val_accuracy: 0.5216\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9211 - val_loss: 0.6996 - val_accuracy: 0.5185\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9123 - val_loss: 0.7161 - val_accuracy: 0.4856\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.9048 - val_loss: 0.6991 - val_accuracy: 0.4846\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2035 - accuracy: 0.9070 - val_loss: 0.6929 - val_accuracy: 0.5144\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2069 - accuracy: 0.9131 - val_loss: 0.6988 - val_accuracy: 0.5103\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9158 - val_loss: 0.7104 - val_accuracy: 0.4763\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2074 - accuracy: 0.9123 - val_loss: 0.6983 - val_accuracy: 0.5103\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2087 - accuracy: 0.9052 - val_loss: 0.6927 - val_accuracy: 0.5175\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2147 - accuracy: 0.9123 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2106 - accuracy: 0.9123 - val_loss: 0.6947 - val_accuracy: 0.4702\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1979 - accuracy: 0.9096 - val_loss: 0.6934 - val_accuracy: 0.4949\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2066 - accuracy: 0.9056 - val_loss: 0.6966 - val_accuracy: 0.4743\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2109 - accuracy: 0.9145 - val_loss: 0.6927 - val_accuracy: 0.5175\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2113 - accuracy: 0.9158 - val_loss: 0.7138 - val_accuracy: 0.5144\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2017 - accuracy: 0.9127 - val_loss: 0.7013 - val_accuracy: 0.4877\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1972 - accuracy: 0.9140 - val_loss: 0.6992 - val_accuracy: 0.4969\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2075 - accuracy: 0.9074 - val_loss: 0.6952 - val_accuracy: 0.5000\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9065 - val_loss: 0.7105 - val_accuracy: 0.4969\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2054 - accuracy: 0.9034 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Score: 0.5288065671920776 \n","Parameters:  {'learning_rate': 0.07533264688859784, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7594 - accuracy: 0.9242 - val_loss: 0.6045 - val_accuracy: 0.7212\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1811 - accuracy: 0.9250 - val_loss: 0.5301 - val_accuracy: 0.7377\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1633 - accuracy: 0.9281 - val_loss: 0.5044 - val_accuracy: 0.7428\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1417 - accuracy: 0.9444 - val_loss: 0.5208 - val_accuracy: 0.7685\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1431 - accuracy: 0.9427 - val_loss: 0.4773 - val_accuracy: 0.7695\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1460 - accuracy: 0.9396 - val_loss: 0.4345 - val_accuracy: 0.7798\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1573 - accuracy: 0.9489 - val_loss: 0.4714 - val_accuracy: 0.7757\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1588 - accuracy: 0.9365 - val_loss: 0.4408 - val_accuracy: 0.7953\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1482 - accuracy: 0.9365 - val_loss: 0.4877 - val_accuracy: 0.7438\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1524 - accuracy: 0.9405 - val_loss: 0.4764 - val_accuracy: 0.7850\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1489 - accuracy: 0.9444 - val_loss: 0.4551 - val_accuracy: 0.7747\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1346 - accuracy: 0.9493 - val_loss: 0.4152 - val_accuracy: 0.7994\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1413 - accuracy: 0.9444 - val_loss: 0.4254 - val_accuracy: 0.7891\n","Epoch 14/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1357 - accuracy: 0.9444 - val_loss: 0.4024 - val_accuracy: 0.8158\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1795 - accuracy: 0.9550 - val_loss: 0.4105 - val_accuracy: 0.8066\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1430 - accuracy: 0.9493 - val_loss: 0.4414 - val_accuracy: 0.8086\n","Epoch 17/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1498 - accuracy: 0.9387 - val_loss: 0.4326 - val_accuracy: 0.8097\n","Epoch 18/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1402 - accuracy: 0.9453 - val_loss: 0.4216 - val_accuracy: 0.8014\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.9519 - val_loss: 0.4355 - val_accuracy: 0.7901\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1176 - accuracy: 0.9550 - val_loss: 0.4541 - val_accuracy: 0.7901\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1409 - accuracy: 0.9528 - val_loss: 0.4115 - val_accuracy: 0.8148\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1800 - accuracy: 0.9444 - val_loss: 0.4551 - val_accuracy: 0.8035\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1342 - accuracy: 0.9506 - val_loss: 0.4203 - val_accuracy: 0.7881\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1279 - accuracy: 0.9519 - val_loss: 0.4185 - val_accuracy: 0.8117\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1434 - accuracy: 0.9559 - val_loss: 0.3914 - val_accuracy: 0.8200\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1421 - accuracy: 0.9449 - val_loss: 0.4302 - val_accuracy: 0.8138\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1406 - accuracy: 0.9484 - val_loss: 0.3840 - val_accuracy: 0.8189\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9528 - val_loss: 0.4126 - val_accuracy: 0.8261\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1199 - accuracy: 0.9586 - val_loss: 0.3804 - val_accuracy: 0.8220\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9497 - val_loss: 0.4359 - val_accuracy: 0.7953\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9444 - val_loss: 0.4308 - val_accuracy: 0.8056\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1690 - accuracy: 0.9471 - val_loss: 0.4378 - val_accuracy: 0.8035\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9497 - val_loss: 0.4203 - val_accuracy: 0.8025\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1326 - accuracy: 0.9493 - val_loss: 0.4128 - val_accuracy: 0.8138\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1377 - accuracy: 0.9480 - val_loss: 0.4051 - val_accuracy: 0.8210\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9515 - val_loss: 0.4214 - val_accuracy: 0.7912\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4088 - accuracy: 0.9458 - val_loss: 0.4407 - val_accuracy: 0.7891\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1229 - accuracy: 0.9537 - val_loss: 0.4144 - val_accuracy: 0.8148\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9515 - val_loss: 0.3974 - val_accuracy: 0.7963\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1335 - accuracy: 0.9480 - val_loss: 0.3937 - val_accuracy: 0.8086\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1174 - accuracy: 0.9559 - val_loss: 0.3777 - val_accuracy: 0.8241\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2414 - accuracy: 0.9511 - val_loss: 0.3849 - val_accuracy: 0.8179\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1253 - accuracy: 0.9559 - val_loss: 0.3873 - val_accuracy: 0.8158\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1326 - accuracy: 0.9515 - val_loss: 0.4002 - val_accuracy: 0.8169\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.9550 - val_loss: 0.3927 - val_accuracy: 0.8200\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1638 - accuracy: 0.9475 - val_loss: 0.3568 - val_accuracy: 0.8272\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1147 - accuracy: 0.9586 - val_loss: 0.3594 - val_accuracy: 0.8364\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1044 - accuracy: 0.9568 - val_loss: 0.3890 - val_accuracy: 0.8056\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1241 - accuracy: 0.9466 - val_loss: 0.5543 - val_accuracy: 0.8189\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1157 - accuracy: 0.9603 - val_loss: 0.3634 - val_accuracy: 0.8282\n","Score: 0.8281893134117126 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.2864 - accuracy: 0.9123 - val_loss: 0.6362 - val_accuracy: 0.6728\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1754 - accuracy: 0.9264 - val_loss: 0.5702 - val_accuracy: 0.7202\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1633 - accuracy: 0.9330 - val_loss: 0.5524 - val_accuracy: 0.7212\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1689 - accuracy: 0.9330 - val_loss: 0.4949 - val_accuracy: 0.7613\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9502 - val_loss: 0.4903 - val_accuracy: 0.7644\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1622 - accuracy: 0.9405 - val_loss: 0.4962 - val_accuracy: 0.7644\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1467 - accuracy: 0.9480 - val_loss: 0.4477 - val_accuracy: 0.7706\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9471 - val_loss: 0.4564 - val_accuracy: 0.7912\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1392 - accuracy: 0.9475 - val_loss: 0.4293 - val_accuracy: 0.7860\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2063 - accuracy: 0.9405 - val_loss: 0.4035 - val_accuracy: 0.8158\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1444 - accuracy: 0.9431 - val_loss: 0.4309 - val_accuracy: 0.7829\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6235 - accuracy: 0.9361 - val_loss: 0.4670 - val_accuracy: 0.7757\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9471 - val_loss: 0.4495 - val_accuracy: 0.7860\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9524 - val_loss: 0.4358 - val_accuracy: 0.7819\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9511 - val_loss: 0.4558 - val_accuracy: 0.7860\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1698 - accuracy: 0.9414 - val_loss: 0.4166 - val_accuracy: 0.7973\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1239 - accuracy: 0.9524 - val_loss: 0.4378 - val_accuracy: 0.7932\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1378 - accuracy: 0.9484 - val_loss: 0.4234 - val_accuracy: 0.7963\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2898 - accuracy: 0.9418 - val_loss: 0.4262 - val_accuracy: 0.8035\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1269 - accuracy: 0.9555 - val_loss: 0.4259 - val_accuracy: 0.7840\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1261 - accuracy: 0.9489 - val_loss: 0.4165 - val_accuracy: 0.7953\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1456 - accuracy: 0.9453 - val_loss: 0.4615 - val_accuracy: 0.7593\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1269 - accuracy: 0.9537 - val_loss: 0.4231 - val_accuracy: 0.8066\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9515 - val_loss: 0.3948 - val_accuracy: 0.8148\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1360 - accuracy: 0.9484 - val_loss: 0.4028 - val_accuracy: 0.8107\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1355 - accuracy: 0.9453 - val_loss: 0.4272 - val_accuracy: 0.7984\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9502 - val_loss: 0.4541 - val_accuracy: 0.7788\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1255 - accuracy: 0.9612 - val_loss: 0.4578 - val_accuracy: 0.8004\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9462 - val_loss: 0.3742 - val_accuracy: 0.8292\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1420 - accuracy: 0.9489 - val_loss: 0.4288 - val_accuracy: 0.7994\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1175 - accuracy: 0.9581 - val_loss: 0.3691 - val_accuracy: 0.8344\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1277 - accuracy: 0.9484 - val_loss: 0.3535 - val_accuracy: 0.8519\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1146 - accuracy: 0.9612 - val_loss: 0.3614 - val_accuracy: 0.8241\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1356 - accuracy: 0.9506 - val_loss: 0.3602 - val_accuracy: 0.8282\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1360 - accuracy: 0.9550 - val_loss: 0.3849 - val_accuracy: 0.8148\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9563 - val_loss: 0.3451 - val_accuracy: 0.8416\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1232 - accuracy: 0.9612 - val_loss: 0.5760 - val_accuracy: 0.8210\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1253 - accuracy: 0.9511 - val_loss: 0.3631 - val_accuracy: 0.8611\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.9577 - val_loss: 0.3565 - val_accuracy: 0.8447\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1248 - accuracy: 0.9612 - val_loss: 0.3568 - val_accuracy: 0.8426\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1692 - accuracy: 0.9497 - val_loss: 0.3903 - val_accuracy: 0.8097\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1081 - accuracy: 0.9647 - val_loss: 0.4741 - val_accuracy: 0.8014\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1204 - accuracy: 0.9541 - val_loss: 0.3731 - val_accuracy: 0.8457\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1097 - accuracy: 0.9594 - val_loss: 0.3855 - val_accuracy: 0.8416\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1075 - accuracy: 0.9612 - val_loss: 0.3659 - val_accuracy: 0.8374\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1165 - accuracy: 0.9581 - val_loss: 0.4084 - val_accuracy: 0.8210\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1244 - accuracy: 0.9581 - val_loss: 0.3912 - val_accuracy: 0.8230\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2144 - accuracy: 0.9586 - val_loss: 0.3602 - val_accuracy: 0.8457\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9519 - val_loss: 0.3717 - val_accuracy: 0.8447\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2897 - accuracy: 0.9533 - val_loss: 0.3649 - val_accuracy: 0.8477\n","Score: 0.8477365970611572 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8576 - accuracy: 0.9242 - val_loss: 0.5633 - val_accuracy: 0.7191\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2085 - accuracy: 0.9264 - val_loss: 0.5067 - val_accuracy: 0.7788\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3087 - accuracy: 0.9242 - val_loss: 0.5886 - val_accuracy: 0.7130\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1488 - accuracy: 0.9365 - val_loss: 0.5153 - val_accuracy: 0.7366\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9396 - val_loss: 0.4854 - val_accuracy: 0.7860\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3247 - accuracy: 0.9418 - val_loss: 0.4105 - val_accuracy: 0.8354\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1280 - accuracy: 0.9480 - val_loss: 0.4331 - val_accuracy: 0.8272\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1280 - accuracy: 0.9537 - val_loss: 0.4045 - val_accuracy: 0.8220\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1072 - accuracy: 0.9608 - val_loss: 0.3226 - val_accuracy: 0.8652\n","Epoch 10/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1566 - accuracy: 0.9471 - val_loss: 0.5360 - val_accuracy: 0.7284\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1403 - accuracy: 0.9519 - val_loss: 0.4254 - val_accuracy: 0.7665\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9471 - val_loss: 0.3349 - val_accuracy: 0.8405\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1203 - accuracy: 0.9519 - val_loss: 0.3492 - val_accuracy: 0.8364\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1093 - accuracy: 0.9603 - val_loss: 0.3187 - val_accuracy: 0.8570\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2106 - accuracy: 0.9387 - val_loss: 0.3753 - val_accuracy: 0.8354\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1780 - accuracy: 0.9550 - val_loss: 0.4509 - val_accuracy: 0.7809\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1205 - accuracy: 0.9563 - val_loss: 0.4628 - val_accuracy: 0.7778\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1224 - accuracy: 0.9537 - val_loss: 0.3424 - val_accuracy: 0.8344\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1328 - accuracy: 0.9612 - val_loss: 0.2989 - val_accuracy: 0.8591\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1014 - accuracy: 0.9572 - val_loss: 0.3887 - val_accuracy: 0.8333\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1222 - accuracy: 0.9572 - val_loss: 0.2923 - val_accuracy: 0.8724\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0892 - accuracy: 0.9616 - val_loss: 0.2830 - val_accuracy: 0.8724\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1303 - accuracy: 0.9608 - val_loss: 0.3250 - val_accuracy: 0.8364\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1088 - accuracy: 0.9669 - val_loss: 0.3347 - val_accuracy: 0.8673\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1011 - accuracy: 0.9669 - val_loss: 0.2963 - val_accuracy: 0.8745\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1001 - accuracy: 0.9660 - val_loss: 0.2881 - val_accuracy: 0.8796\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1055 - accuracy: 0.9656 - val_loss: 0.2985 - val_accuracy: 0.8796\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0864 - accuracy: 0.9665 - val_loss: 0.2144 - val_accuracy: 0.9064\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0726 - accuracy: 0.9718 - val_loss: 0.2596 - val_accuracy: 0.8889\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0805 - accuracy: 0.9700 - val_loss: 0.2524 - val_accuracy: 0.8868\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0691 - accuracy: 0.9757 - val_loss: 0.2341 - val_accuracy: 0.9064\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0643 - accuracy: 0.9775 - val_loss: 0.2010 - val_accuracy: 0.9136\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.1974 - val_accuracy: 0.9177\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.2320 - val_accuracy: 0.9167\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1085 - accuracy: 0.9713 - val_loss: 0.1771 - val_accuracy: 0.9290\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0470 - accuracy: 0.9828 - val_loss: 0.1750 - val_accuracy: 0.9414\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 0.2023 - val_accuracy: 0.9187\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0648 - accuracy: 0.9832 - val_loss: 0.3485 - val_accuracy: 0.8858\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.1501 - val_accuracy: 0.9434\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.1654 - val_accuracy: 0.9383\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0642 - accuracy: 0.9863 - val_loss: 0.2355 - val_accuracy: 0.9342\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1146 - accuracy: 0.9775 - val_loss: 0.1761 - val_accuracy: 0.9434\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0351 - accuracy: 0.9872 - val_loss: 0.1885 - val_accuracy: 0.9465\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 0.1772 - val_accuracy: 0.9455\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0501 - accuracy: 0.9841 - val_loss: 0.1686 - val_accuracy: 0.9475\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.1593 - val_accuracy: 0.9568\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0386 - accuracy: 0.9872 - val_loss: 0.1875 - val_accuracy: 0.9311\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0475 - accuracy: 0.9863 - val_loss: 0.1519 - val_accuracy: 0.9558\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.1947 - val_accuracy: 0.9218\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0391 - accuracy: 0.9885 - val_loss: 0.1970 - val_accuracy: 0.9259\n","Score: 0.9259259104728699 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1073.3904 - accuracy: 0.9048 - val_loss: 0.6931 - val_accuracy: 0.5051\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2488 - accuracy: 0.9180 - val_loss: 0.6960 - val_accuracy: 0.5144\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2581 - accuracy: 0.9101 - val_loss: 0.6944 - val_accuracy: 0.5216\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2567 - accuracy: 0.9105 - val_loss: 0.6936 - val_accuracy: 0.5185\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2597 - accuracy: 0.9078 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2642 - accuracy: 0.9114 - val_loss: 0.7033 - val_accuracy: 0.5154\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2501 - accuracy: 0.9149 - val_loss: 0.6990 - val_accuracy: 0.5093\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2535 - accuracy: 0.9175 - val_loss: 0.7109 - val_accuracy: 0.5247\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2537 - accuracy: 0.9158 - val_loss: 0.6986 - val_accuracy: 0.5154\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2568 - accuracy: 0.9136 - val_loss: 0.6918 - val_accuracy: 0.5329\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2457 - accuracy: 0.9206 - val_loss: 0.7086 - val_accuracy: 0.5010\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2455 - accuracy: 0.9198 - val_loss: 0.6940 - val_accuracy: 0.5309\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2514 - accuracy: 0.9206 - val_loss: 0.7413 - val_accuracy: 0.5000\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2320 - accuracy: 0.9233 - val_loss: 0.7075 - val_accuracy: 0.5041\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2481 - accuracy: 0.9198 - val_loss: 0.7024 - val_accuracy: 0.5319\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2487 - accuracy: 0.9153 - val_loss: 0.7038 - val_accuracy: 0.5165\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2443 - accuracy: 0.9184 - val_loss: 0.6985 - val_accuracy: 0.5144\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2553 - accuracy: 0.9140 - val_loss: 0.6967 - val_accuracy: 0.5175\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2510 - accuracy: 0.9184 - val_loss: 0.7040 - val_accuracy: 0.5134\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2550 - accuracy: 0.9140 - val_loss: 0.6956 - val_accuracy: 0.5237\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2566 - accuracy: 0.9127 - val_loss: 0.6961 - val_accuracy: 0.5185\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2439 - accuracy: 0.9233 - val_loss: 0.7092 - val_accuracy: 0.5278\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2458 - accuracy: 0.9167 - val_loss: 0.7040 - val_accuracy: 0.5072\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2442 - accuracy: 0.9211 - val_loss: 0.7030 - val_accuracy: 0.5165\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2533 - accuracy: 0.9101 - val_loss: 0.6936 - val_accuracy: 0.5123\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2603 - accuracy: 0.9158 - val_loss: 0.7080 - val_accuracy: 0.5123\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2606 - accuracy: 0.9070 - val_loss: 0.6943 - val_accuracy: 0.5093\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.9162 - val_loss: 0.7040 - val_accuracy: 0.5319\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2591 - accuracy: 0.9127 - val_loss: 0.7056 - val_accuracy: 0.5103\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2424 - accuracy: 0.9211 - val_loss: 0.7012 - val_accuracy: 0.5175\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2498 - accuracy: 0.9167 - val_loss: 0.6981 - val_accuracy: 0.5123\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2551 - accuracy: 0.9123 - val_loss: 0.6935 - val_accuracy: 0.5247\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2531 - accuracy: 0.9162 - val_loss: 0.7030 - val_accuracy: 0.5072\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2561 - accuracy: 0.9105 - val_loss: 0.6935 - val_accuracy: 0.5154\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2673 - accuracy: 0.9061 - val_loss: 0.6943 - val_accuracy: 0.5041\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2518 - accuracy: 0.9193 - val_loss: 0.6964 - val_accuracy: 0.5144\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2546 - accuracy: 0.9175 - val_loss: 0.7028 - val_accuracy: 0.5206\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2496 - accuracy: 0.9198 - val_loss: 0.7100 - val_accuracy: 0.5134\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2563 - accuracy: 0.9136 - val_loss: 0.7012 - val_accuracy: 0.5206\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2462 - accuracy: 0.9193 - val_loss: 0.7004 - val_accuracy: 0.5154\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2568 - accuracy: 0.9131 - val_loss: 0.6992 - val_accuracy: 0.5093\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2596 - accuracy: 0.9114 - val_loss: 0.6939 - val_accuracy: 0.5144\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2629 - accuracy: 0.9065 - val_loss: 0.6932 - val_accuracy: 0.5072\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2617 - accuracy: 0.9131 - val_loss: 0.6942 - val_accuracy: 0.5113\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2581 - accuracy: 0.9167 - val_loss: 0.7043 - val_accuracy: 0.5154\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2507 - accuracy: 0.9189 - val_loss: 0.7168 - val_accuracy: 0.5051\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2599 - accuracy: 0.9061 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2606 - accuracy: 0.9153 - val_loss: 0.7029 - val_accuracy: 0.5021\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2516 - accuracy: 0.9149 - val_loss: 0.6934 - val_accuracy: 0.5072\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2534 - accuracy: 0.9180 - val_loss: 0.6979 - val_accuracy: 0.5175\n","Score: 0.5174897313117981 \n","Parameters:  {'learning_rate': 0.0276701460590651, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 1.7064 - accuracy: 0.9048 - val_loss: 0.6355 - val_accuracy: 0.6461\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1791 - accuracy: 0.9198 - val_loss: 0.6197 - val_accuracy: 0.6862\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9167 - val_loss: 0.6246 - val_accuracy: 0.5350\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3629 - accuracy: 0.9202 - val_loss: 0.6126 - val_accuracy: 0.6852\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1673 - accuracy: 0.9317 - val_loss: 0.5452 - val_accuracy: 0.7058\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1781 - accuracy: 0.9268 - val_loss: 0.5579 - val_accuracy: 0.7037\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1516 - accuracy: 0.9400 - val_loss: 0.5487 - val_accuracy: 0.7109\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.9347 - val_loss: 0.5817 - val_accuracy: 0.7068\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1394 - accuracy: 0.9462 - val_loss: 0.4486 - val_accuracy: 0.7860\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1452 - accuracy: 0.9418 - val_loss: 0.4478 - val_accuracy: 0.7788\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9418 - val_loss: 0.4589 - val_accuracy: 0.7675\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1225 - accuracy: 0.9511 - val_loss: 0.4440 - val_accuracy: 0.7737\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1555 - accuracy: 0.9422 - val_loss: 0.4167 - val_accuracy: 0.7973\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1874 - accuracy: 0.9418 - val_loss: 0.4267 - val_accuracy: 0.7870\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1831 - accuracy: 0.9374 - val_loss: 0.4476 - val_accuracy: 0.7891\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1487 - accuracy: 0.9449 - val_loss: 0.4217 - val_accuracy: 0.7747\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9361 - val_loss: 0.4411 - val_accuracy: 0.7778\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9528 - val_loss: 0.4505 - val_accuracy: 0.7737\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9444 - val_loss: 0.4242 - val_accuracy: 0.7881\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1184 - accuracy: 0.9480 - val_loss: 0.5265 - val_accuracy: 0.7860\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3633 - accuracy: 0.9524 - val_loss: 0.4355 - val_accuracy: 0.7860\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1254 - accuracy: 0.9524 - val_loss: 0.4023 - val_accuracy: 0.8210\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1690 - accuracy: 0.9528 - val_loss: 0.5030 - val_accuracy: 0.8025\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9528 - val_loss: 0.4120 - val_accuracy: 0.8066\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1472 - accuracy: 0.9541 - val_loss: 0.4028 - val_accuracy: 0.8210\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1489 - accuracy: 0.9484 - val_loss: 0.3904 - val_accuracy: 0.8128\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1296 - accuracy: 0.9511 - val_loss: 0.4009 - val_accuracy: 0.8097\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9462 - val_loss: 0.4058 - val_accuracy: 0.8025\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1470 - accuracy: 0.9471 - val_loss: 0.4561 - val_accuracy: 0.7819\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1416 - accuracy: 0.9524 - val_loss: 0.3977 - val_accuracy: 0.8097\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1112 - accuracy: 0.9559 - val_loss: 0.4061 - val_accuracy: 0.8097\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9568 - val_loss: 0.3751 - val_accuracy: 0.8189\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9533 - val_loss: 0.4381 - val_accuracy: 0.8076\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9568 - val_loss: 0.4391 - val_accuracy: 0.7891\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1174 - accuracy: 0.9586 - val_loss: 0.3839 - val_accuracy: 0.8261\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1161 - accuracy: 0.9466 - val_loss: 0.3532 - val_accuracy: 0.8457\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1219 - accuracy: 0.9590 - val_loss: 0.3609 - val_accuracy: 0.8189\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9524 - val_loss: 0.3228 - val_accuracy: 0.8539\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1224 - accuracy: 0.9524 - val_loss: 0.3500 - val_accuracy: 0.8344\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1635 - accuracy: 0.9519 - val_loss: 0.3653 - val_accuracy: 0.8210\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1188 - accuracy: 0.9524 - val_loss: 0.3409 - val_accuracy: 0.8385\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1079 - accuracy: 0.9656 - val_loss: 0.3913 - val_accuracy: 0.8025\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9506 - val_loss: 0.3433 - val_accuracy: 0.8457\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1087 - accuracy: 0.9577 - val_loss: 0.3253 - val_accuracy: 0.8560\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9577 - val_loss: 0.3390 - val_accuracy: 0.8374\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1060 - accuracy: 0.9621 - val_loss: 0.3208 - val_accuracy: 0.8549\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1010 - accuracy: 0.9643 - val_loss: 0.2960 - val_accuracy: 0.8807\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1089 - accuracy: 0.9546 - val_loss: 0.3472 - val_accuracy: 0.8519\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.9572 - val_loss: 0.2927 - val_accuracy: 0.8704\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0968 - accuracy: 0.9687 - val_loss: 0.2870 - val_accuracy: 0.8693\n","Score: 0.8693415522575378 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 4660854.5000 - accuracy: 0.8898 - val_loss: 8.6028 - val_accuracy: 0.5123\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9061 - val_loss: 4.3474 - val_accuracy: 0.4918\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9043 - val_loss: 4.3745 - val_accuracy: 0.5185\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 175.2658 - accuracy: 0.9087 - val_loss: 0.7102 - val_accuracy: 0.4774\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9061 - val_loss: 0.7080 - val_accuracy: 0.5195\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9101 - val_loss: 0.6985 - val_accuracy: 0.5072\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9136 - val_loss: 0.7378 - val_accuracy: 0.4743\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9004 - val_loss: 0.6968 - val_accuracy: 0.4846\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9109 - val_loss: 0.6942 - val_accuracy: 0.4846\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9136 - val_loss: 0.6955 - val_accuracy: 0.4722\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1851 - accuracy: 0.9136 - val_loss: 0.8125 - val_accuracy: 0.5113\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1797 - accuracy: 0.9131 - val_loss: 0.7178 - val_accuracy: 0.5319\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1871 - accuracy: 0.9114 - val_loss: 0.7399 - val_accuracy: 0.4825\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9043 - val_loss: 0.7562 - val_accuracy: 0.4743\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2000 - accuracy: 0.8995 - val_loss: 0.6967 - val_accuracy: 0.5185\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9109 - val_loss: 0.6950 - val_accuracy: 0.4794\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9096 - val_loss: 0.6934 - val_accuracy: 0.5175\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9123 - val_loss: 0.6959 - val_accuracy: 0.5226\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9070 - val_loss: 0.7064 - val_accuracy: 0.4774\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9061 - val_loss: 0.6964 - val_accuracy: 0.4990\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2108 - accuracy: 0.9017 - val_loss: 0.7055 - val_accuracy: 0.5216\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1804 - accuracy: 0.9224 - val_loss: 0.6941 - val_accuracy: 0.5113\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9092 - val_loss: 0.8775 - val_accuracy: 0.4825\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1994 - accuracy: 0.9004 - val_loss: 0.7525 - val_accuracy: 0.4784\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9052 - val_loss: 0.7010 - val_accuracy: 0.4907\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9131 - val_loss: 0.6948 - val_accuracy: 0.4887\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9070 - val_loss: 0.6984 - val_accuracy: 0.4907\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9078 - val_loss: 0.7401 - val_accuracy: 0.5082\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9149 - val_loss: 0.6931 - val_accuracy: 0.5031\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9153 - val_loss: 0.7909 - val_accuracy: 0.4928\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9109 - val_loss: 0.6964 - val_accuracy: 0.5031\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.9012 - val_loss: 0.6949 - val_accuracy: 0.4784\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9078 - val_loss: 0.7106 - val_accuracy: 0.5031\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9030 - val_loss: 0.7823 - val_accuracy: 0.4897\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9065 - val_loss: 0.7000 - val_accuracy: 0.4835\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1835 - accuracy: 0.9092 - val_loss: 0.7136 - val_accuracy: 0.4671\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9114 - val_loss: 0.6933 - val_accuracy: 0.4774\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9056 - val_loss: 0.6944 - val_accuracy: 0.4835\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.8977 - val_loss: 0.7643 - val_accuracy: 0.4907\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9043 - val_loss: 0.7060 - val_accuracy: 0.4866\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9061 - val_loss: 0.6988 - val_accuracy: 0.5010\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.9092 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1838 - accuracy: 0.9175 - val_loss: 0.6941 - val_accuracy: 0.5031\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9008 - val_loss: 0.6940 - val_accuracy: 0.4846\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1855 - accuracy: 0.9105 - val_loss: 0.6953 - val_accuracy: 0.4979\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9078 - val_loss: 0.7022 - val_accuracy: 0.4671\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9109 - val_loss: 0.7113 - val_accuracy: 0.4805\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9056 - val_loss: 0.6963 - val_accuracy: 0.4918\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9048 - val_loss: 0.7039 - val_accuracy: 0.4897\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9065 - val_loss: 0.7025 - val_accuracy: 0.4918\n","Score: 0.49176955223083496 \n","Parameters:  {'learning_rate': 0.20818967201081087, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4692 - accuracy: 0.9325 - val_loss: 0.4859 - val_accuracy: 0.7819\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1413 - accuracy: 0.9427 - val_loss: 0.4051 - val_accuracy: 0.8333\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1644 - accuracy: 0.9352 - val_loss: 0.4486 - val_accuracy: 0.7850\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9374 - val_loss: 0.4897 - val_accuracy: 0.7521\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9511 - val_loss: 0.3397 - val_accuracy: 0.8498\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9506 - val_loss: 0.3542 - val_accuracy: 0.8374\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1057 - accuracy: 0.9599 - val_loss: 0.3969 - val_accuracy: 0.8323\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1368 - accuracy: 0.9502 - val_loss: 0.4388 - val_accuracy: 0.8128\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1133 - accuracy: 0.9515 - val_loss: 0.3587 - val_accuracy: 0.8230\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1212 - accuracy: 0.9524 - val_loss: 0.4071 - val_accuracy: 0.7942\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1341 - accuracy: 0.9502 - val_loss: 0.3529 - val_accuracy: 0.8323\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1211 - accuracy: 0.9458 - val_loss: 0.4464 - val_accuracy: 0.7994\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1418 - accuracy: 0.9374 - val_loss: 0.4012 - val_accuracy: 0.7716\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1044 - accuracy: 0.9581 - val_loss: 0.5042 - val_accuracy: 0.8272\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1137 - accuracy: 0.9586 - val_loss: 0.3255 - val_accuracy: 0.8426\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1025 - accuracy: 0.9594 - val_loss: 0.3476 - val_accuracy: 0.8241\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1073 - accuracy: 0.9630 - val_loss: 0.2920 - val_accuracy: 0.8467\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0956 - accuracy: 0.9586 - val_loss: 0.3262 - val_accuracy: 0.8519\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1051 - accuracy: 0.9586 - val_loss: 0.2893 - val_accuracy: 0.8673\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0979 - accuracy: 0.9572 - val_loss: 0.3129 - val_accuracy: 0.8632\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1086 - accuracy: 0.9612 - val_loss: 0.3736 - val_accuracy: 0.8313\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1003 - accuracy: 0.9594 - val_loss: 0.3090 - val_accuracy: 0.8591\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1150 - accuracy: 0.9563 - val_loss: 0.3309 - val_accuracy: 0.8580\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1727 - accuracy: 0.9502 - val_loss: 0.3614 - val_accuracy: 0.8323\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0988 - accuracy: 0.9594 - val_loss: 0.2730 - val_accuracy: 0.8683\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1733 - accuracy: 0.9515 - val_loss: 0.3978 - val_accuracy: 0.8097\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1255 - accuracy: 0.9528 - val_loss: 0.3047 - val_accuracy: 0.8611\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1294 - accuracy: 0.9568 - val_loss: 0.3407 - val_accuracy: 0.8467\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9550 - val_loss: 0.4073 - val_accuracy: 0.8261\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9599 - val_loss: 0.3590 - val_accuracy: 0.8282\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9599 - val_loss: 0.3458 - val_accuracy: 0.8498\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0993 - accuracy: 0.9616 - val_loss: 0.3667 - val_accuracy: 0.7994\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0991 - accuracy: 0.9603 - val_loss: 0.3833 - val_accuracy: 0.8004\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1068 - accuracy: 0.9559 - val_loss: 0.3253 - val_accuracy: 0.8601\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1010 - accuracy: 0.9638 - val_loss: 0.2465 - val_accuracy: 0.8837\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1569 - accuracy: 0.9647 - val_loss: 0.3269 - val_accuracy: 0.8447\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0915 - accuracy: 0.9678 - val_loss: 0.2797 - val_accuracy: 0.8591\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0892 - accuracy: 0.9660 - val_loss: 0.2898 - val_accuracy: 0.8570\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1216 - accuracy: 0.9647 - val_loss: 0.2636 - val_accuracy: 0.8632\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9696 - val_loss: 0.2417 - val_accuracy: 0.8765\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1041 - accuracy: 0.9705 - val_loss: 0.2589 - val_accuracy: 0.8807\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9709 - val_loss: 0.2894 - val_accuracy: 0.8765\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0658 - accuracy: 0.9722 - val_loss: 0.2597 - val_accuracy: 0.9043\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0642 - accuracy: 0.9757 - val_loss: 0.2590 - val_accuracy: 0.8909\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0585 - accuracy: 0.9749 - val_loss: 0.2251 - val_accuracy: 0.8971\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9718 - val_loss: 0.2387 - val_accuracy: 0.8992\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0747 - accuracy: 0.9735 - val_loss: 0.2362 - val_accuracy: 0.8971\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0651 - accuracy: 0.9771 - val_loss: 0.2736 - val_accuracy: 0.8642\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0662 - accuracy: 0.9753 - val_loss: 0.2403 - val_accuracy: 0.8961\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9735 - val_loss: 0.3258 - val_accuracy: 0.8611\n","Score: 0.8611111044883728 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8817 - accuracy: 0.9162 - val_loss: 0.6694 - val_accuracy: 0.5545\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9189 - val_loss: 0.6488 - val_accuracy: 0.5720\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1798 - accuracy: 0.9308 - val_loss: 0.6338 - val_accuracy: 0.7027\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1759 - accuracy: 0.9352 - val_loss: 0.5625 - val_accuracy: 0.7006\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1485 - accuracy: 0.9356 - val_loss: 0.5511 - val_accuracy: 0.7294\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1656 - accuracy: 0.9383 - val_loss: 0.5287 - val_accuracy: 0.7263\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1670 - accuracy: 0.9427 - val_loss: 0.5358 - val_accuracy: 0.7510\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1815 - accuracy: 0.9312 - val_loss: 0.4736 - val_accuracy: 0.7726\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1738 - accuracy: 0.9356 - val_loss: 0.4869 - val_accuracy: 0.7767\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1801 - accuracy: 0.9374 - val_loss: 0.5269 - val_accuracy: 0.7644\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1547 - accuracy: 0.9343 - val_loss: 0.5064 - val_accuracy: 0.7840\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1861 - accuracy: 0.9268 - val_loss: 0.4786 - val_accuracy: 0.7798\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1542 - accuracy: 0.9409 - val_loss: 0.5202 - val_accuracy: 0.7644\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1655 - accuracy: 0.9405 - val_loss: 0.4889 - val_accuracy: 0.7613\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4214 - accuracy: 0.9343 - val_loss: 0.5796 - val_accuracy: 0.7088\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5194 - accuracy: 0.9414 - val_loss: 0.4638 - val_accuracy: 0.7582\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3068 - accuracy: 0.9325 - val_loss: 0.4739 - val_accuracy: 0.7706\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1453 - accuracy: 0.9462 - val_loss: 0.4627 - val_accuracy: 0.7870\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1494 - accuracy: 0.9431 - val_loss: 0.4244 - val_accuracy: 0.7953\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2764 - accuracy: 0.9493 - val_loss: 0.4431 - val_accuracy: 0.7870\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1167 - accuracy: 0.9537 - val_loss: 0.4708 - val_accuracy: 0.7984\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1272 - accuracy: 0.9519 - val_loss: 0.4260 - val_accuracy: 0.8097\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1784 - accuracy: 0.9528 - val_loss: 0.4281 - val_accuracy: 0.7963\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9572 - val_loss: 0.4263 - val_accuracy: 0.8128\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.9466 - val_loss: 0.4305 - val_accuracy: 0.7922\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9563 - val_loss: 0.4343 - val_accuracy: 0.7870\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1181 - accuracy: 0.9497 - val_loss: 0.3980 - val_accuracy: 0.8056\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9515 - val_loss: 0.4551 - val_accuracy: 0.7922\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9497 - val_loss: 0.4508 - val_accuracy: 0.7840\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1108 - accuracy: 0.9603 - val_loss: 0.4444 - val_accuracy: 0.8035\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1200 - accuracy: 0.9550 - val_loss: 0.4337 - val_accuracy: 0.7984\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9586 - val_loss: 0.3456 - val_accuracy: 0.8323\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1455 - accuracy: 0.9555 - val_loss: 0.4087 - val_accuracy: 0.8066\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9541 - val_loss: 0.3785 - val_accuracy: 0.8272\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1173 - accuracy: 0.9568 - val_loss: 0.3854 - val_accuracy: 0.8220\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9489 - val_loss: 0.4348 - val_accuracy: 0.7912\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1263 - accuracy: 0.9519 - val_loss: 0.3464 - val_accuracy: 0.8467\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1141 - accuracy: 0.9572 - val_loss: 0.3867 - val_accuracy: 0.8220\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1134 - accuracy: 0.9612 - val_loss: 0.3344 - val_accuracy: 0.8477\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1063 - accuracy: 0.9683 - val_loss: 0.3313 - val_accuracy: 0.8395\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1099 - accuracy: 0.9625 - val_loss: 0.3610 - val_accuracy: 0.8333\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1079 - accuracy: 0.9599 - val_loss: 0.3392 - val_accuracy: 0.8364\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0987 - accuracy: 0.9586 - val_loss: 0.3898 - val_accuracy: 0.8179\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1123 - accuracy: 0.9590 - val_loss: 0.3841 - val_accuracy: 0.8138\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0884 - accuracy: 0.9621 - val_loss: 0.2969 - val_accuracy: 0.8673\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1819 - accuracy: 0.9608 - val_loss: 0.3239 - val_accuracy: 0.8529\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1126 - accuracy: 0.9665 - val_loss: 0.3149 - val_accuracy: 0.8632\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9603 - val_loss: 0.3752 - val_accuracy: 0.8210\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0949 - accuracy: 0.9652 - val_loss: 0.3116 - val_accuracy: 0.8498\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1083 - accuracy: 0.9625 - val_loss: 0.3010 - val_accuracy: 0.8621\n","Score: 0.8621399402618408 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5393 - accuracy: 0.9220 - val_loss: 0.5657 - val_accuracy: 0.7212\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9158 - val_loss: 0.5539 - val_accuracy: 0.7346\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1571 - accuracy: 0.9321 - val_loss: 0.5400 - val_accuracy: 0.7449\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1493 - accuracy: 0.9330 - val_loss: 0.4906 - val_accuracy: 0.7510\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2717 - accuracy: 0.9422 - val_loss: 0.4872 - val_accuracy: 0.7706\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9458 - val_loss: 0.4790 - val_accuracy: 0.7726\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9427 - val_loss: 0.4299 - val_accuracy: 0.7942\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1563 - accuracy: 0.9458 - val_loss: 0.5315 - val_accuracy: 0.7654\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9475 - val_loss: 0.5740 - val_accuracy: 0.7006\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1796 - accuracy: 0.9418 - val_loss: 0.4385 - val_accuracy: 0.8056\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9502 - val_loss: 0.4535 - val_accuracy: 0.7819\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1401 - accuracy: 0.9480 - val_loss: 0.4227 - val_accuracy: 0.8045\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1439 - accuracy: 0.9533 - val_loss: 0.4398 - val_accuracy: 0.7840\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9594 - val_loss: 0.3903 - val_accuracy: 0.8158\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1195 - accuracy: 0.9563 - val_loss: 0.4074 - val_accuracy: 0.8302\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1221 - accuracy: 0.9568 - val_loss: 0.3751 - val_accuracy: 0.8302\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9586 - val_loss: 0.4087 - val_accuracy: 0.8097\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9453 - val_loss: 0.3935 - val_accuracy: 0.8272\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9546 - val_loss: 0.3790 - val_accuracy: 0.8179\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1106 - accuracy: 0.9555 - val_loss: 0.3693 - val_accuracy: 0.8313\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1063 - accuracy: 0.9630 - val_loss: 0.3478 - val_accuracy: 0.8426\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9572 - val_loss: 0.3476 - val_accuracy: 0.8447\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1099 - accuracy: 0.9586 - val_loss: 0.3527 - val_accuracy: 0.8426\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0986 - accuracy: 0.9647 - val_loss: 0.3281 - val_accuracy: 0.8508\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0962 - accuracy: 0.9647 - val_loss: 0.3066 - val_accuracy: 0.8601\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1088 - accuracy: 0.9577 - val_loss: 0.3730 - val_accuracy: 0.8292\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1428 - accuracy: 0.9599 - val_loss: 0.3337 - val_accuracy: 0.8529\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9599 - val_loss: 0.3594 - val_accuracy: 0.8436\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1147 - accuracy: 0.9590 - val_loss: 0.3456 - val_accuracy: 0.8477\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1161 - accuracy: 0.9647 - val_loss: 0.3298 - val_accuracy: 0.8426\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0924 - accuracy: 0.9656 - val_loss: 0.3315 - val_accuracy: 0.8467\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1110 - accuracy: 0.9612 - val_loss: 0.3781 - val_accuracy: 0.8467\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.9581 - val_loss: 0.3273 - val_accuracy: 0.8621\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0936 - accuracy: 0.9687 - val_loss: 0.3375 - val_accuracy: 0.8570\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0960 - accuracy: 0.9660 - val_loss: 0.3323 - val_accuracy: 0.8395\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0903 - accuracy: 0.9674 - val_loss: 0.3119 - val_accuracy: 0.8570\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0917 - accuracy: 0.9647 - val_loss: 0.3128 - val_accuracy: 0.8467\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1004 - accuracy: 0.9656 - val_loss: 0.3075 - val_accuracy: 0.8693\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1032 - accuracy: 0.9616 - val_loss: 0.3228 - val_accuracy: 0.8642\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1517 - accuracy: 0.9687 - val_loss: 0.4721 - val_accuracy: 0.8436\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0929 - accuracy: 0.9683 - val_loss: 0.2482 - val_accuracy: 0.9023\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.2837 - val_accuracy: 0.8735\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0817 - accuracy: 0.9722 - val_loss: 0.2560 - val_accuracy: 0.8858\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0985 - accuracy: 0.9757 - val_loss: 0.3016 - val_accuracy: 0.8827\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0738 - accuracy: 0.9722 - val_loss: 0.2276 - val_accuracy: 0.9105\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9780 - val_loss: 0.2492 - val_accuracy: 0.8920\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9735 - val_loss: 0.3017 - val_accuracy: 0.8807\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0781 - accuracy: 0.9793 - val_loss: 0.2553 - val_accuracy: 0.8920\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1208 - accuracy: 0.9647 - val_loss: 0.2596 - val_accuracy: 0.8909\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0900 - accuracy: 0.9665 - val_loss: 0.2548 - val_accuracy: 0.8879\n","Score: 0.8878600597381592 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1496.5570 - accuracy: 0.9021 - val_loss: 0.6954 - val_accuracy: 0.4805\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1870 - accuracy: 0.9149 - val_loss: 0.7010 - val_accuracy: 0.5072\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9167 - val_loss: 0.6933 - val_accuracy: 0.5031\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2227 - accuracy: 0.9175 - val_loss: 0.6958 - val_accuracy: 0.5154\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2344 - accuracy: 0.9145 - val_loss: 0.6926 - val_accuracy: 0.5257\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2506 - accuracy: 0.9118 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9109 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2512 - accuracy: 0.9149 - val_loss: 0.6931 - val_accuracy: 0.5185\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2448 - accuracy: 0.9189 - val_loss: 0.7034 - val_accuracy: 0.5154\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2448 - accuracy: 0.9162 - val_loss: 0.6984 - val_accuracy: 0.5010\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2481 - accuracy: 0.9175 - val_loss: 0.7048 - val_accuracy: 0.5113\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2445 - accuracy: 0.9118 - val_loss: 0.6923 - val_accuracy: 0.5226\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2551 - accuracy: 0.9158 - val_loss: 0.6984 - val_accuracy: 0.5237\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2439 - accuracy: 0.9145 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2408 - accuracy: 0.9215 - val_loss: 0.6942 - val_accuracy: 0.5103\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2453 - accuracy: 0.9167 - val_loss: 0.6941 - val_accuracy: 0.5062\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2583 - accuracy: 0.9101 - val_loss: 0.6971 - val_accuracy: 0.4949\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2426 - accuracy: 0.9193 - val_loss: 0.6975 - val_accuracy: 0.5185\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9131 - val_loss: 0.7066 - val_accuracy: 0.5082\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2508 - accuracy: 0.9136 - val_loss: 0.6973 - val_accuracy: 0.5226\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2467 - accuracy: 0.9149 - val_loss: 0.7043 - val_accuracy: 0.5041\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2575 - accuracy: 0.9092 - val_loss: 0.6939 - val_accuracy: 0.5206\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2509 - accuracy: 0.9140 - val_loss: 0.6946 - val_accuracy: 0.5010\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2421 - accuracy: 0.9215 - val_loss: 0.6983 - val_accuracy: 0.5206\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2457 - accuracy: 0.9162 - val_loss: 0.6974 - val_accuracy: 0.5144\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2484 - accuracy: 0.9149 - val_loss: 0.6949 - val_accuracy: 0.5062\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2519 - accuracy: 0.9136 - val_loss: 0.6939 - val_accuracy: 0.5226\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2517 - accuracy: 0.9105 - val_loss: 0.6917 - val_accuracy: 0.5288\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2519 - accuracy: 0.9149 - val_loss: 0.6976 - val_accuracy: 0.5206\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2523 - accuracy: 0.9105 - val_loss: 0.6935 - val_accuracy: 0.5062\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2525 - accuracy: 0.9175 - val_loss: 0.7015 - val_accuracy: 0.5175\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2497 - accuracy: 0.9153 - val_loss: 0.6959 - val_accuracy: 0.5154\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2489 - accuracy: 0.9131 - val_loss: 0.6943 - val_accuracy: 0.5062\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2477 - accuracy: 0.9149 - val_loss: 0.6947 - val_accuracy: 0.5041\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2551 - accuracy: 0.9140 - val_loss: 0.7105 - val_accuracy: 0.5041\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2438 - accuracy: 0.9140 - val_loss: 0.6939 - val_accuracy: 0.5154\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2434 - accuracy: 0.9202 - val_loss: 0.7056 - val_accuracy: 0.5165\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2504 - accuracy: 0.9123 - val_loss: 0.6964 - val_accuracy: 0.5237\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2505 - accuracy: 0.9167 - val_loss: 0.7058 - val_accuracy: 0.5144\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2348 - accuracy: 0.9193 - val_loss: 0.6971 - val_accuracy: 0.5051\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2442 - accuracy: 0.9180 - val_loss: 0.6958 - val_accuracy: 0.5113\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2514 - accuracy: 0.9131 - val_loss: 0.6948 - val_accuracy: 0.5113\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2558 - accuracy: 0.9123 - val_loss: 0.6932 - val_accuracy: 0.5144\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2473 - accuracy: 0.9149 - val_loss: 0.6928 - val_accuracy: 0.5175\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2531 - accuracy: 0.9140 - val_loss: 0.6982 - val_accuracy: 0.5195\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2482 - accuracy: 0.9171 - val_loss: 0.6902 - val_accuracy: 0.5412\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2393 - accuracy: 0.9189 - val_loss: 0.6939 - val_accuracy: 0.5041\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2591 - accuracy: 0.9083 - val_loss: 0.6911 - val_accuracy: 0.5329\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.9105 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2563 - accuracy: 0.9123 - val_loss: 0.6959 - val_accuracy: 0.5195\n","Score: 0.5195473432540894 \n","Parameters:  {'learning_rate': 0.02990917003017012, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1426461.0000 - accuracy: 0.8686 - val_loss: 0.6937 - val_accuracy: 0.5123\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9123 - val_loss: 0.7458 - val_accuracy: 0.4805\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2010 - accuracy: 0.9017 - val_loss: 0.7317 - val_accuracy: 0.4928\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9012 - val_loss: 0.6961 - val_accuracy: 0.4835\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1877 - accuracy: 0.9039 - val_loss: 0.7022 - val_accuracy: 0.4805\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9039 - val_loss: 0.7034 - val_accuracy: 0.4712\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9048 - val_loss: 0.6930 - val_accuracy: 0.5093\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1838 - accuracy: 0.9180 - val_loss: 0.7110 - val_accuracy: 0.5195\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1839 - accuracy: 0.9145 - val_loss: 0.7052 - val_accuracy: 0.5113\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1871 - accuracy: 0.9078 - val_loss: 0.6957 - val_accuracy: 0.4938\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9052 - val_loss: 0.6976 - val_accuracy: 0.4959\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1881 - accuracy: 0.9021 - val_loss: 0.7942 - val_accuracy: 0.5237\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1818 - accuracy: 0.9153 - val_loss: 0.7142 - val_accuracy: 0.5237\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1825 - accuracy: 0.9162 - val_loss: 0.7488 - val_accuracy: 0.5000\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9065 - val_loss: 0.7205 - val_accuracy: 0.5051\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9105 - val_loss: 0.7118 - val_accuracy: 0.5093\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9017 - val_loss: 0.7497 - val_accuracy: 0.4815\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9039 - val_loss: 0.7488 - val_accuracy: 0.5216\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1787 - accuracy: 0.9105 - val_loss: 0.7031 - val_accuracy: 0.5082\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9065 - val_loss: 0.6922 - val_accuracy: 0.5216\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1793 - accuracy: 0.9153 - val_loss: 0.6975 - val_accuracy: 0.5154\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1842 - accuracy: 0.9083 - val_loss: 0.6915 - val_accuracy: 0.5298\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9096 - val_loss: 0.7514 - val_accuracy: 0.5134\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1893 - accuracy: 0.9065 - val_loss: 0.6941 - val_accuracy: 0.4938\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.8977 - val_loss: 0.7661 - val_accuracy: 0.4866\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9105 - val_loss: 0.7094 - val_accuracy: 0.4887\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9083 - val_loss: 0.7172 - val_accuracy: 0.5010\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1863 - accuracy: 0.9087 - val_loss: 0.8005 - val_accuracy: 0.5216\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9012 - val_loss: 0.7149 - val_accuracy: 0.4959\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9087 - val_loss: 0.7276 - val_accuracy: 0.5412\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9061 - val_loss: 0.7146 - val_accuracy: 0.4979\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9083 - val_loss: 0.9044 - val_accuracy: 0.4979\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1817 - accuracy: 0.9131 - val_loss: 0.7096 - val_accuracy: 0.5093\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2029 - accuracy: 0.9078 - val_loss: 0.7925 - val_accuracy: 0.5000\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9127 - val_loss: 0.7778 - val_accuracy: 0.5134\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9043 - val_loss: 0.8372 - val_accuracy: 0.4805\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9061 - val_loss: 0.6943 - val_accuracy: 0.5144\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9193 - val_loss: 0.7161 - val_accuracy: 0.4877\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9052 - val_loss: 0.7646 - val_accuracy: 0.5051\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9118 - val_loss: 0.7359 - val_accuracy: 0.4877\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.8986 - val_loss: 0.6928 - val_accuracy: 0.5165\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9162 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2052 - accuracy: 0.9087 - val_loss: 0.6929 - val_accuracy: 0.5165\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9127 - val_loss: 0.6972 - val_accuracy: 0.5041\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9153 - val_loss: 0.6973 - val_accuracy: 0.4691\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9149 - val_loss: 0.6945 - val_accuracy: 0.5216\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9087 - val_loss: 0.6949 - val_accuracy: 0.4928\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9056 - val_loss: 0.6966 - val_accuracy: 0.4784\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9074 - val_loss: 0.6931 - val_accuracy: 0.5103\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2027 - accuracy: 0.9127 - val_loss: 0.6937 - val_accuracy: 0.5113\n","Score: 0.5113168954849243 \n","Parameters:  {'learning_rate': 0.11081439977116969, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1599683.8750 - accuracy: 0.8823 - val_loss: 0.9207 - val_accuracy: 0.5072\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2335 - accuracy: 0.8990 - val_loss: 1.0068 - val_accuracy: 0.4805\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2213 - accuracy: 0.8995 - val_loss: 0.6992 - val_accuracy: 0.4743\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2170 - accuracy: 0.8942 - val_loss: 0.7618 - val_accuracy: 0.5021\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9017 - val_loss: 0.7237 - val_accuracy: 0.4835\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2273 - accuracy: 0.8977 - val_loss: 0.6982 - val_accuracy: 0.4825\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2352 - accuracy: 0.8893 - val_loss: 0.7636 - val_accuracy: 0.4969\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.8955 - val_loss: 0.6969 - val_accuracy: 0.5113\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.8920 - val_loss: 0.7192 - val_accuracy: 0.5062\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9114 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9136 - val_loss: 0.6994 - val_accuracy: 0.4866\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1907 - accuracy: 0.9158 - val_loss: 0.7539 - val_accuracy: 0.4928\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.8986 - val_loss: 0.6943 - val_accuracy: 0.4825\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9048 - val_loss: 0.6984 - val_accuracy: 0.5185\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1978 - accuracy: 0.9039 - val_loss: 0.6933 - val_accuracy: 0.4866\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9026 - val_loss: 0.6939 - val_accuracy: 0.4887\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9123 - val_loss: 0.7010 - val_accuracy: 0.5072\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9162 - val_loss: 0.6942 - val_accuracy: 0.5309\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9167 - val_loss: 0.7290 - val_accuracy: 0.4969\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9056 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9140 - val_loss: 0.7014 - val_accuracy: 0.4979\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9158 - val_loss: 0.6957 - val_accuracy: 0.5072\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9061 - val_loss: 0.7591 - val_accuracy: 0.5010\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9061 - val_loss: 0.6987 - val_accuracy: 0.5175\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9171 - val_loss: 0.7303 - val_accuracy: 0.5041\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1801 - accuracy: 0.9242 - val_loss: 0.7115 - val_accuracy: 0.5062\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9114 - val_loss: 0.7068 - val_accuracy: 0.4979\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1904 - accuracy: 0.9105 - val_loss: 0.6939 - val_accuracy: 0.4959\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1932 - accuracy: 0.9114 - val_loss: 0.6995 - val_accuracy: 0.4815\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2031 - accuracy: 0.9105 - val_loss: 0.7037 - val_accuracy: 0.4918\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1879 - accuracy: 0.9136 - val_loss: 0.6977 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.6923 - val_accuracy: 0.5237\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9048 - val_loss: 0.6950 - val_accuracy: 0.5041\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9092 - val_loss: 0.6947 - val_accuracy: 0.4938\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.9101 - val_loss: 0.7064 - val_accuracy: 0.4949\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9030 - val_loss: 0.6957 - val_accuracy: 0.4918\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9145 - val_loss: 0.6941 - val_accuracy: 0.4722\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.8951 - val_loss: 0.7191 - val_accuracy: 0.5422\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1870 - accuracy: 0.9180 - val_loss: 0.7281 - val_accuracy: 0.5134\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1810 - accuracy: 0.9175 - val_loss: 0.7052 - val_accuracy: 0.5113\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9140 - val_loss: 0.6965 - val_accuracy: 0.4753\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2002 - accuracy: 0.9039 - val_loss: 0.6987 - val_accuracy: 0.5185\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9145 - val_loss: 0.7193 - val_accuracy: 0.4835\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2020 - accuracy: 0.8964 - val_loss: 0.6938 - val_accuracy: 0.4846\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9074 - val_loss: 0.6918 - val_accuracy: 0.5257\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9070 - val_loss: 0.7163 - val_accuracy: 0.5206\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9220 - val_loss: 0.7015 - val_accuracy: 0.5082\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9189 - val_loss: 0.7264 - val_accuracy: 0.5206\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9180 - val_loss: 0.7102 - val_accuracy: 0.4794\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1994 - accuracy: 0.9114 - val_loss: 0.7086 - val_accuracy: 0.4660\n","Score: 0.4660493731498718 \n","Parameters:  {'learning_rate': 0.12198309267544409, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5300 - accuracy: 0.9198 - val_loss: 0.6643 - val_accuracy: 0.6492\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2874 - accuracy: 0.9180 - val_loss: 0.5907 - val_accuracy: 0.6595\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1753 - accuracy: 0.9303 - val_loss: 0.5328 - val_accuracy: 0.7325\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1629 - accuracy: 0.9356 - val_loss: 0.5052 - val_accuracy: 0.7479\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1760 - accuracy: 0.9330 - val_loss: 0.5373 - val_accuracy: 0.7068\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1656 - accuracy: 0.9444 - val_loss: 0.4981 - val_accuracy: 0.7510\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9369 - val_loss: 0.4854 - val_accuracy: 0.7521\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1462 - accuracy: 0.9383 - val_loss: 0.4663 - val_accuracy: 0.7788\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1695 - accuracy: 0.9462 - val_loss: 0.4624 - val_accuracy: 0.7798\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1320 - accuracy: 0.9515 - val_loss: 0.4868 - val_accuracy: 0.7685\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1431 - accuracy: 0.9396 - val_loss: 0.4236 - val_accuracy: 0.8076\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1435 - accuracy: 0.9449 - val_loss: 0.4986 - val_accuracy: 0.7634\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.9440 - val_loss: 0.4277 - val_accuracy: 0.8035\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1414 - accuracy: 0.9480 - val_loss: 0.4490 - val_accuracy: 0.7809\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1332 - accuracy: 0.9502 - val_loss: 0.4585 - val_accuracy: 0.7912\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1490 - accuracy: 0.9484 - val_loss: 0.4619 - val_accuracy: 0.7695\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1368 - accuracy: 0.9502 - val_loss: 0.4078 - val_accuracy: 0.8169\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3146 - accuracy: 0.9453 - val_loss: 0.4281 - val_accuracy: 0.8076\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.9497 - val_loss: 0.3739 - val_accuracy: 0.8230\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9480 - val_loss: 0.4027 - val_accuracy: 0.8035\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1230 - accuracy: 0.9546 - val_loss: 0.3946 - val_accuracy: 0.8189\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1239 - accuracy: 0.9533 - val_loss: 0.4111 - val_accuracy: 0.8158\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9577 - val_loss: 0.4246 - val_accuracy: 0.8076\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9506 - val_loss: 0.4396 - val_accuracy: 0.8066\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1411 - accuracy: 0.9440 - val_loss: 0.3970 - val_accuracy: 0.8169\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1198 - accuracy: 0.9506 - val_loss: 0.3693 - val_accuracy: 0.8282\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1338 - accuracy: 0.9489 - val_loss: 0.3827 - val_accuracy: 0.8364\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9524 - val_loss: 0.4486 - val_accuracy: 0.7891\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1636 - accuracy: 0.9502 - val_loss: 0.3684 - val_accuracy: 0.8076\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1527 - accuracy: 0.9621 - val_loss: 0.3711 - val_accuracy: 0.8272\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1290 - accuracy: 0.9586 - val_loss: 0.3274 - val_accuracy: 0.8508\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9515 - val_loss: 0.3596 - val_accuracy: 0.8251\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1172 - accuracy: 0.9537 - val_loss: 0.3267 - val_accuracy: 0.8333\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1126 - accuracy: 0.9572 - val_loss: 0.3457 - val_accuracy: 0.8354\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1134 - accuracy: 0.9559 - val_loss: 0.3378 - val_accuracy: 0.8385\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1066 - accuracy: 0.9603 - val_loss: 0.3523 - val_accuracy: 0.8436\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1025 - accuracy: 0.9608 - val_loss: 0.3624 - val_accuracy: 0.8416\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1590 - accuracy: 0.9568 - val_loss: 0.3635 - val_accuracy: 0.8436\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1062 - accuracy: 0.9612 - val_loss: 0.4070 - val_accuracy: 0.8261\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1174 - accuracy: 0.9528 - val_loss: 0.5332 - val_accuracy: 0.7850\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9577 - val_loss: 0.3115 - val_accuracy: 0.8580\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1100 - accuracy: 0.9559 - val_loss: 0.3278 - val_accuracy: 0.8467\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1093 - accuracy: 0.9603 - val_loss: 0.3167 - val_accuracy: 0.8457\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1202 - accuracy: 0.9630 - val_loss: 0.3101 - val_accuracy: 0.8601\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1044 - accuracy: 0.9581 - val_loss: 0.3439 - val_accuracy: 0.8261\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.9590 - val_loss: 0.3048 - val_accuracy: 0.8652\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1697 - accuracy: 0.9612 - val_loss: 0.3846 - val_accuracy: 0.8498\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0871 - accuracy: 0.9678 - val_loss: 0.2816 - val_accuracy: 0.8724\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9603 - val_loss: 0.3103 - val_accuracy: 0.8704\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0952 - accuracy: 0.9687 - val_loss: 0.2790 - val_accuracy: 0.8765\n","Score: 0.8765432238578796 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 870866.9375 - accuracy: 0.8990 - val_loss: 0.7019 - val_accuracy: 0.5123\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9056 - val_loss: 0.7132 - val_accuracy: 0.5113\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9162 - val_loss: 0.7151 - val_accuracy: 0.4712\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9083 - val_loss: 0.6935 - val_accuracy: 0.4938\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2104 - accuracy: 0.9008 - val_loss: 0.6924 - val_accuracy: 0.5257\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9145 - val_loss: 0.7479 - val_accuracy: 0.5206\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9136 - val_loss: 0.6943 - val_accuracy: 0.5206\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1843 - accuracy: 0.9171 - val_loss: 0.7524 - val_accuracy: 0.5072\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9162 - val_loss: 0.6932 - val_accuracy: 0.5257\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9052 - val_loss: 0.7104 - val_accuracy: 0.4949\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9021 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9140 - val_loss: 0.7238 - val_accuracy: 0.4877\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1852 - accuracy: 0.9109 - val_loss: 0.7167 - val_accuracy: 0.5206\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9171 - val_loss: 0.7259 - val_accuracy: 0.4815\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9030 - val_loss: 0.7025 - val_accuracy: 0.5072\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9162 - val_loss: 0.6947 - val_accuracy: 0.4969\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9140 - val_loss: 0.6960 - val_accuracy: 0.4825\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9127 - val_loss: 0.6990 - val_accuracy: 0.5144\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.9215 - val_loss: 0.7041 - val_accuracy: 0.5257\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9171 - val_loss: 0.7127 - val_accuracy: 0.4979\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9078 - val_loss: 0.7757 - val_accuracy: 0.5216\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9096 - val_loss: 0.7040 - val_accuracy: 0.4763\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.8981 - val_loss: 0.6937 - val_accuracy: 0.5165\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9140 - val_loss: 0.6960 - val_accuracy: 0.5257\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9175 - val_loss: 0.7085 - val_accuracy: 0.4835\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9070 - val_loss: 0.6927 - val_accuracy: 0.5216\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9167 - val_loss: 0.7084 - val_accuracy: 0.5000\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1805 - accuracy: 0.9175 - val_loss: 0.7411 - val_accuracy: 0.5021\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1989 - accuracy: 0.9114 - val_loss: 0.6938 - val_accuracy: 0.4794\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9017 - val_loss: 0.7212 - val_accuracy: 0.5257\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9087 - val_loss: 0.7094 - val_accuracy: 0.4897\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9026 - val_loss: 0.7110 - val_accuracy: 0.5247\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1816 - accuracy: 0.9092 - val_loss: 0.6934 - val_accuracy: 0.5021\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9065 - val_loss: 0.6948 - val_accuracy: 0.4887\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9092 - val_loss: 0.7438 - val_accuracy: 0.4835\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9078 - val_loss: 0.7207 - val_accuracy: 0.5195\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9153 - val_loss: 0.7218 - val_accuracy: 0.5319\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1807 - accuracy: 0.9237 - val_loss: 0.6922 - val_accuracy: 0.5237\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9074 - val_loss: 0.6944 - val_accuracy: 0.5062\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9083 - val_loss: 0.7127 - val_accuracy: 0.4722\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9127 - val_loss: 0.7377 - val_accuracy: 0.4763\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1976 - accuracy: 0.9021 - val_loss: 0.7173 - val_accuracy: 0.4753\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9083 - val_loss: 0.6936 - val_accuracy: 0.5051\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9149 - val_loss: 0.7132 - val_accuracy: 0.4969\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9211 - val_loss: 0.7573 - val_accuracy: 0.5000\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9127 - val_loss: 0.7979 - val_accuracy: 0.5103\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9114 - val_loss: 0.7058 - val_accuracy: 0.4897\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9039 - val_loss: 0.6935 - val_accuracy: 0.4907\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9109 - val_loss: 0.7000 - val_accuracy: 0.4979\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9211 - val_loss: 0.6926 - val_accuracy: 0.5267\n","Score: 0.5267489552497864 \n","Parameters:  {'learning_rate': 0.13009606090760553, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7368 - accuracy: 0.9043 - val_loss: 0.6943 - val_accuracy: 0.5093\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4567 - accuracy: 0.9127 - val_loss: 0.6938 - val_accuracy: 0.5072\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9250 - val_loss: 0.6762 - val_accuracy: 0.6049\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9347 - val_loss: 0.5370 - val_accuracy: 0.7346\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1565 - accuracy: 0.9356 - val_loss: 0.5651 - val_accuracy: 0.7212\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9378 - val_loss: 0.4889 - val_accuracy: 0.7582\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1779 - accuracy: 0.9422 - val_loss: 0.4942 - val_accuracy: 0.7562\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1425 - accuracy: 0.9409 - val_loss: 0.4724 - val_accuracy: 0.7613\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1424 - accuracy: 0.9436 - val_loss: 0.4526 - val_accuracy: 0.7747\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1619 - accuracy: 0.9334 - val_loss: 0.4736 - val_accuracy: 0.7932\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9400 - val_loss: 0.4766 - val_accuracy: 0.7850\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1428 - accuracy: 0.9462 - val_loss: 0.4565 - val_accuracy: 0.7891\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1449 - accuracy: 0.9453 - val_loss: 0.4838 - val_accuracy: 0.7634\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9396 - val_loss: 0.4870 - val_accuracy: 0.7891\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1482 - accuracy: 0.9431 - val_loss: 0.4592 - val_accuracy: 0.7891\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1428 - accuracy: 0.9471 - val_loss: 0.4642 - val_accuracy: 0.7850\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1517 - accuracy: 0.9484 - val_loss: 0.4200 - val_accuracy: 0.8138\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1408 - accuracy: 0.9475 - val_loss: 0.4445 - val_accuracy: 0.8097\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9480 - val_loss: 0.4310 - val_accuracy: 0.8086\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1272 - accuracy: 0.9497 - val_loss: 0.4423 - val_accuracy: 0.7984\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1209 - accuracy: 0.9528 - val_loss: 0.4046 - val_accuracy: 0.8189\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1551 - accuracy: 0.9440 - val_loss: 0.4254 - val_accuracy: 0.8056\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1669 - accuracy: 0.9484 - val_loss: 0.4338 - val_accuracy: 0.8117\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1487 - accuracy: 0.9436 - val_loss: 0.4238 - val_accuracy: 0.8086\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2146 - accuracy: 0.9506 - val_loss: 0.4151 - val_accuracy: 0.8056\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1319 - accuracy: 0.9427 - val_loss: 0.4400 - val_accuracy: 0.7973\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9524 - val_loss: 0.4195 - val_accuracy: 0.8128\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2031 - accuracy: 0.9550 - val_loss: 0.4186 - val_accuracy: 0.8045\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1467 - accuracy: 0.9511 - val_loss: 0.4137 - val_accuracy: 0.8117\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1194 - accuracy: 0.9541 - val_loss: 0.3921 - val_accuracy: 0.8117\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9511 - val_loss: 0.3818 - val_accuracy: 0.8241\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1470 - accuracy: 0.9427 - val_loss: 0.5209 - val_accuracy: 0.7572\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1263 - accuracy: 0.9541 - val_loss: 0.3907 - val_accuracy: 0.8251\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9550 - val_loss: 0.4042 - val_accuracy: 0.8128\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1232 - accuracy: 0.9546 - val_loss: 0.3911 - val_accuracy: 0.8210\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9528 - val_loss: 0.3978 - val_accuracy: 0.8261\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1267 - accuracy: 0.9519 - val_loss: 0.3805 - val_accuracy: 0.8282\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1095 - accuracy: 0.9563 - val_loss: 0.3918 - val_accuracy: 0.8426\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1419 - accuracy: 0.9453 - val_loss: 0.3828 - val_accuracy: 0.8364\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1331 - accuracy: 0.9541 - val_loss: 0.4076 - val_accuracy: 0.8220\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1331 - accuracy: 0.9484 - val_loss: 0.3838 - val_accuracy: 0.8282\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1234 - accuracy: 0.9502 - val_loss: 0.3500 - val_accuracy: 0.8405\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1043 - accuracy: 0.9572 - val_loss: 0.3657 - val_accuracy: 0.8323\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1337 - accuracy: 0.9590 - val_loss: 0.4065 - val_accuracy: 0.8117\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9541 - val_loss: 0.3701 - val_accuracy: 0.8374\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1125 - accuracy: 0.9541 - val_loss: 0.5516 - val_accuracy: 0.7623\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1208 - accuracy: 0.9533 - val_loss: 0.3755 - val_accuracy: 0.8251\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1066 - accuracy: 0.9546 - val_loss: 0.3588 - val_accuracy: 0.8395\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0873 - accuracy: 0.9652 - val_loss: 0.3422 - val_accuracy: 0.8488\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1106 - accuracy: 0.9634 - val_loss: 0.3487 - val_accuracy: 0.8488\n","Score: 0.8487654328346252 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 255674.2500 - accuracy: 0.8862 - val_loss: 0.8341 - val_accuracy: 0.4990\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 4.6879 - accuracy: 0.8955 - val_loss: 2.5524 - val_accuracy: 0.4753\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3577 - accuracy: 0.8959 - val_loss: 0.8211 - val_accuracy: 0.5010\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2652 - accuracy: 0.8946 - val_loss: 0.7138 - val_accuracy: 0.4877\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3394 - accuracy: 0.8880 - val_loss: 0.7779 - val_accuracy: 0.4846\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2711 - accuracy: 0.8942 - val_loss: 0.9430 - val_accuracy: 0.4866\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3071 - accuracy: 0.8920 - val_loss: 0.7626 - val_accuracy: 0.4794\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2656 - accuracy: 0.8933 - val_loss: 1.7054 - val_accuracy: 0.5010\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2823 - accuracy: 0.8924 - val_loss: 1.0010 - val_accuracy: 0.4712\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2905 - accuracy: 0.8995 - val_loss: 1.1194 - val_accuracy: 0.5000\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2891 - accuracy: 0.8880 - val_loss: 0.6982 - val_accuracy: 0.4846\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2785 - accuracy: 0.8876 - val_loss: 1.0666 - val_accuracy: 0.4969\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2366 - accuracy: 0.9065 - val_loss: 0.8932 - val_accuracy: 0.4990\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2471 - accuracy: 0.8955 - val_loss: 2.0464 - val_accuracy: 0.5031\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2573 - accuracy: 0.8973 - val_loss: 0.6946 - val_accuracy: 0.5165\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9039 - val_loss: 0.8512 - val_accuracy: 0.4856\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2503 - accuracy: 0.8929 - val_loss: 0.7902 - val_accuracy: 0.5113\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2716 - accuracy: 0.8964 - val_loss: 1.3165 - val_accuracy: 0.4938\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2803 - accuracy: 0.8884 - val_loss: 0.7741 - val_accuracy: 0.5134\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2500 - accuracy: 0.9021 - val_loss: 0.6990 - val_accuracy: 0.4918\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2411 - accuracy: 0.8946 - val_loss: 0.9235 - val_accuracy: 0.5103\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2383 - accuracy: 0.8990 - val_loss: 1.2622 - val_accuracy: 0.4733\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2893 - accuracy: 0.8876 - val_loss: 0.7823 - val_accuracy: 0.5216\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9043 - val_loss: 0.7009 - val_accuracy: 0.5237\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2156 - accuracy: 0.8981 - val_loss: 0.8705 - val_accuracy: 0.4671\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2354 - accuracy: 0.8981 - val_loss: 0.7779 - val_accuracy: 0.4815\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2398 - accuracy: 0.8929 - val_loss: 0.8365 - val_accuracy: 0.4938\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2425 - accuracy: 0.9074 - val_loss: 1.0736 - val_accuracy: 0.5175\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.8999 - val_loss: 0.6947 - val_accuracy: 0.4825\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2362 - accuracy: 0.8937 - val_loss: 0.8630 - val_accuracy: 0.4733\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9039 - val_loss: 0.6971 - val_accuracy: 0.4815\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9149 - val_loss: 0.6946 - val_accuracy: 0.5000\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9118 - val_loss: 0.6948 - val_accuracy: 0.4887\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9061 - val_loss: 0.6925 - val_accuracy: 0.5247\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9145 - val_loss: 0.7360 - val_accuracy: 0.5062\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9092 - val_loss: 0.7044 - val_accuracy: 0.5072\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9052 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.9149 - val_loss: 0.6941 - val_accuracy: 0.4805\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9123 - val_loss: 0.6987 - val_accuracy: 0.5113\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2020 - accuracy: 0.9145 - val_loss: 0.6933 - val_accuracy: 0.4743\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9140 - val_loss: 0.6935 - val_accuracy: 0.5021\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9105 - val_loss: 0.6952 - val_accuracy: 0.4897\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9096 - val_loss: 0.7061 - val_accuracy: 0.5226\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9061 - val_loss: 0.7219 - val_accuracy: 0.5010\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9149 - val_loss: 0.7057 - val_accuracy: 0.4784\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9123 - val_loss: 0.6960 - val_accuracy: 0.4907\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9114 - val_loss: 0.7094 - val_accuracy: 0.4979\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9039 - val_loss: 0.6933 - val_accuracy: 0.5113\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9198 - val_loss: 0.7352 - val_accuracy: 0.4753\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9048 - val_loss: 0.6951 - val_accuracy: 0.4856\n","Score: 0.4855967164039612 \n","Parameters:  {'learning_rate': 0.10340344895865863, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 21865.2266 - accuracy: 0.9048 - val_loss: 0.6960 - val_accuracy: 0.4784\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2077 - accuracy: 0.9118 - val_loss: 0.6949 - val_accuracy: 0.4897\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9118 - val_loss: 0.6914 - val_accuracy: 0.5298\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2186 - accuracy: 0.9149 - val_loss: 0.6957 - val_accuracy: 0.5093\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9145 - val_loss: 0.6933 - val_accuracy: 0.4990\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9131 - val_loss: 0.7055 - val_accuracy: 0.4866\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2238 - accuracy: 0.9021 - val_loss: 0.6945 - val_accuracy: 0.5113\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9193 - val_loss: 0.7056 - val_accuracy: 0.4969\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2289 - accuracy: 0.8951 - val_loss: 0.6941 - val_accuracy: 0.4866\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2302 - accuracy: 0.8951 - val_loss: 0.6932 - val_accuracy: 0.5062\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2158 - accuracy: 0.9145 - val_loss: 0.7027 - val_accuracy: 0.4763\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2230 - accuracy: 0.9114 - val_loss: 0.7172 - val_accuracy: 0.5072\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9228 - val_loss: 0.6907 - val_accuracy: 0.5350\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9043 - val_loss: 0.6980 - val_accuracy: 0.5103\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9127 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2193 - accuracy: 0.9145 - val_loss: 0.6932 - val_accuracy: 0.5144\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2197 - accuracy: 0.9131 - val_loss: 0.6947 - val_accuracy: 0.4969\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2267 - accuracy: 0.9048 - val_loss: 0.6973 - val_accuracy: 0.5093\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2167 - accuracy: 0.9127 - val_loss: 0.6952 - val_accuracy: 0.5051\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2189 - accuracy: 0.9074 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2180 - accuracy: 0.9162 - val_loss: 0.6958 - val_accuracy: 0.5113\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2166 - accuracy: 0.9153 - val_loss: 0.7004 - val_accuracy: 0.5103\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9198 - val_loss: 0.7080 - val_accuracy: 0.5134\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2222 - accuracy: 0.9114 - val_loss: 0.6944 - val_accuracy: 0.4784\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9123 - val_loss: 0.7106 - val_accuracy: 0.4691\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2116 - accuracy: 0.9123 - val_loss: 0.6942 - val_accuracy: 0.4969\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2166 - accuracy: 0.9153 - val_loss: 0.7083 - val_accuracy: 0.5298\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2117 - accuracy: 0.9206 - val_loss: 0.6967 - val_accuracy: 0.5185\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2147 - accuracy: 0.9118 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.9127 - val_loss: 0.6926 - val_accuracy: 0.5216\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2268 - accuracy: 0.9153 - val_loss: 0.7037 - val_accuracy: 0.5134\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2146 - accuracy: 0.9206 - val_loss: 0.6942 - val_accuracy: 0.5165\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2252 - accuracy: 0.9105 - val_loss: 0.6970 - val_accuracy: 0.4805\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2235 - accuracy: 0.9048 - val_loss: 0.6932 - val_accuracy: 0.5226\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2238 - accuracy: 0.9105 - val_loss: 0.6932 - val_accuracy: 0.4907\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2247 - accuracy: 0.9083 - val_loss: 0.6937 - val_accuracy: 0.4907\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2231 - accuracy: 0.9140 - val_loss: 0.7335 - val_accuracy: 0.4928\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9242 - val_loss: 0.7016 - val_accuracy: 0.5031\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.9065 - val_loss: 0.6941 - val_accuracy: 0.4835\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.9074 - val_loss: 0.6946 - val_accuracy: 0.5257\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.9087 - val_loss: 0.7062 - val_accuracy: 0.5247\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2130 - accuracy: 0.9153 - val_loss: 0.6964 - val_accuracy: 0.4877\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2303 - accuracy: 0.9026 - val_loss: 0.6956 - val_accuracy: 0.5093\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2218 - accuracy: 0.9114 - val_loss: 0.7112 - val_accuracy: 0.5113\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2125 - accuracy: 0.9167 - val_loss: 0.6979 - val_accuracy: 0.5010\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2164 - accuracy: 0.9114 - val_loss: 0.6932 - val_accuracy: 0.4990\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2145 - accuracy: 0.9171 - val_loss: 0.7547 - val_accuracy: 0.5154\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2092 - accuracy: 0.9167 - val_loss: 0.6941 - val_accuracy: 0.5041\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9101 - val_loss: 0.6935 - val_accuracy: 0.5113\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2193 - accuracy: 0.9140 - val_loss: 0.6997 - val_accuracy: 0.5195\n","Score: 0.5195473432540894 \n","Parameters:  {'learning_rate': 0.05465161806379751, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1335.7970 - accuracy: 0.9127 - val_loss: 0.7132 - val_accuracy: 0.4712\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9092 - val_loss: 0.6958 - val_accuracy: 0.5031\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2600 - accuracy: 0.9145 - val_loss: 0.7054 - val_accuracy: 0.5031\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2565 - accuracy: 0.9158 - val_loss: 0.6978 - val_accuracy: 0.5103\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2642 - accuracy: 0.9140 - val_loss: 0.6990 - val_accuracy: 0.5144\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2641 - accuracy: 0.9184 - val_loss: 0.7208 - val_accuracy: 0.5165\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2660 - accuracy: 0.9109 - val_loss: 0.7022 - val_accuracy: 0.5175\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2650 - accuracy: 0.9136 - val_loss: 0.7004 - val_accuracy: 0.5247\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2610 - accuracy: 0.9162 - val_loss: 0.7003 - val_accuracy: 0.5257\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2708 - accuracy: 0.9105 - val_loss: 0.7054 - val_accuracy: 0.5051\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2709 - accuracy: 0.9131 - val_loss: 0.7053 - val_accuracy: 0.5247\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2616 - accuracy: 0.9175 - val_loss: 0.7253 - val_accuracy: 0.5041\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2626 - accuracy: 0.9131 - val_loss: 0.7077 - val_accuracy: 0.5123\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2710 - accuracy: 0.9136 - val_loss: 0.7133 - val_accuracy: 0.5226\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2644 - accuracy: 0.9153 - val_loss: 0.7234 - val_accuracy: 0.5206\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2552 - accuracy: 0.9193 - val_loss: 0.7320 - val_accuracy: 0.5072\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2579 - accuracy: 0.9131 - val_loss: 0.6940 - val_accuracy: 0.5319\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2653 - accuracy: 0.9175 - val_loss: 0.7159 - val_accuracy: 0.4979\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2683 - accuracy: 0.9083 - val_loss: 0.6985 - val_accuracy: 0.5123\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2634 - accuracy: 0.9184 - val_loss: 0.7090 - val_accuracy: 0.5123\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2671 - accuracy: 0.9123 - val_loss: 0.7035 - val_accuracy: 0.5123\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2757 - accuracy: 0.9074 - val_loss: 0.6974 - val_accuracy: 0.5185\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2743 - accuracy: 0.9127 - val_loss: 0.7164 - val_accuracy: 0.5021\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2647 - accuracy: 0.9175 - val_loss: 0.7203 - val_accuracy: 0.5195\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2522 - accuracy: 0.9220 - val_loss: 0.7290 - val_accuracy: 0.5134\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2604 - accuracy: 0.9136 - val_loss: 0.6987 - val_accuracy: 0.5165\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.9220 - val_loss: 0.7335 - val_accuracy: 0.5185\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2573 - accuracy: 0.9206 - val_loss: 0.7202 - val_accuracy: 0.5247\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2613 - accuracy: 0.9127 - val_loss: 0.7069 - val_accuracy: 0.5206\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2643 - accuracy: 0.9171 - val_loss: 0.7328 - val_accuracy: 0.5010\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2521 - accuracy: 0.9228 - val_loss: 0.7478 - val_accuracy: 0.5041\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2608 - accuracy: 0.9149 - val_loss: 0.7154 - val_accuracy: 0.5216\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2592 - accuracy: 0.9114 - val_loss: 0.6942 - val_accuracy: 0.5185\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2763 - accuracy: 0.9114 - val_loss: 0.6998 - val_accuracy: 0.5165\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2746 - accuracy: 0.9109 - val_loss: 0.7100 - val_accuracy: 0.5237\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2684 - accuracy: 0.9118 - val_loss: 0.7044 - val_accuracy: 0.5267\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2629 - accuracy: 0.9167 - val_loss: 0.7169 - val_accuracy: 0.5134\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2662 - accuracy: 0.9131 - val_loss: 0.7122 - val_accuracy: 0.5134\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2586 - accuracy: 0.9189 - val_loss: 0.7292 - val_accuracy: 0.4979\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2618 - accuracy: 0.9158 - val_loss: 0.7113 - val_accuracy: 0.5216\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2621 - accuracy: 0.9158 - val_loss: 0.7080 - val_accuracy: 0.5226\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2669 - accuracy: 0.9061 - val_loss: 0.6977 - val_accuracy: 0.4959\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2624 - accuracy: 0.9220 - val_loss: 0.7365 - val_accuracy: 0.5113\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2609 - accuracy: 0.9149 - val_loss: 0.7141 - val_accuracy: 0.5154\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2595 - accuracy: 0.9145 - val_loss: 0.7041 - val_accuracy: 0.5165\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2678 - accuracy: 0.9092 - val_loss: 0.6973 - val_accuracy: 0.5134\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2646 - accuracy: 0.9175 - val_loss: 0.7171 - val_accuracy: 0.5185\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2607 - accuracy: 0.9175 - val_loss: 0.7150 - val_accuracy: 0.5123\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2616 - accuracy: 0.9145 - val_loss: 0.7101 - val_accuracy: 0.5031\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2719 - accuracy: 0.9127 - val_loss: 0.7099 - val_accuracy: 0.5144\n","Score: 0.5144032835960388 \n","Parameters:  {'learning_rate': 0.023395793695231776, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9725 - accuracy: 0.9198 - val_loss: 0.5902 - val_accuracy: 0.6831\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1690 - accuracy: 0.9290 - val_loss: 0.5688 - val_accuracy: 0.7263\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9281 - val_loss: 0.5544 - val_accuracy: 0.7016\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1609 - accuracy: 0.9246 - val_loss: 0.5249 - val_accuracy: 0.7171\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9361 - val_loss: 0.5634 - val_accuracy: 0.7078\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1622 - accuracy: 0.9308 - val_loss: 0.5314 - val_accuracy: 0.7377\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5963 - accuracy: 0.9343 - val_loss: 0.5451 - val_accuracy: 0.7356\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1653 - accuracy: 0.9281 - val_loss: 0.5286 - val_accuracy: 0.7243\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1611 - accuracy: 0.9378 - val_loss: 0.5816 - val_accuracy: 0.7037\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1421 - accuracy: 0.9471 - val_loss: 0.4751 - val_accuracy: 0.7798\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1562 - accuracy: 0.9387 - val_loss: 0.4854 - val_accuracy: 0.7634\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9436 - val_loss: 0.4802 - val_accuracy: 0.7716\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1713 - accuracy: 0.9405 - val_loss: 0.4611 - val_accuracy: 0.7675\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1629 - accuracy: 0.9462 - val_loss: 0.5007 - val_accuracy: 0.7623\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5203 - accuracy: 0.9414 - val_loss: 0.5389 - val_accuracy: 0.7757\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9533 - val_loss: 0.3492 - val_accuracy: 0.8467\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1019 - accuracy: 0.9590 - val_loss: 0.5100 - val_accuracy: 0.8148\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9616 - val_loss: 0.2822 - val_accuracy: 0.8735\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1165 - accuracy: 0.9590 - val_loss: 0.3732 - val_accuracy: 0.8261\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9497 - val_loss: 0.3628 - val_accuracy: 0.8539\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.9511 - val_loss: 0.3327 - val_accuracy: 0.8498\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9625 - val_loss: 0.3289 - val_accuracy: 0.8755\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9563 - val_loss: 0.2709 - val_accuracy: 0.8796\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1030 - accuracy: 0.9634 - val_loss: 0.2849 - val_accuracy: 0.8714\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0885 - accuracy: 0.9674 - val_loss: 0.3667 - val_accuracy: 0.8704\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1465 - accuracy: 0.9563 - val_loss: 0.3966 - val_accuracy: 0.8302\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1209 - accuracy: 0.9590 - val_loss: 0.3612 - val_accuracy: 0.8323\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0912 - accuracy: 0.9634 - val_loss: 0.3473 - val_accuracy: 0.8364\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0959 - accuracy: 0.9660 - val_loss: 0.2734 - val_accuracy: 0.8961\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9771 - val_loss: 0.2633 - val_accuracy: 0.8889\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0760 - accuracy: 0.9727 - val_loss: 0.2295 - val_accuracy: 0.8971\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0659 - accuracy: 0.9757 - val_loss: 0.2306 - val_accuracy: 0.9053\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0549 - accuracy: 0.9806 - val_loss: 0.3323 - val_accuracy: 0.8992\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0737 - accuracy: 0.9744 - val_loss: 0.2194 - val_accuracy: 0.9115\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0604 - accuracy: 0.9762 - val_loss: 0.3757 - val_accuracy: 0.8796\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0723 - accuracy: 0.9797 - val_loss: 0.1638 - val_accuracy: 0.9311\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0696 - accuracy: 0.9771 - val_loss: 0.2691 - val_accuracy: 0.8868\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0630 - accuracy: 0.9784 - val_loss: 0.2543 - val_accuracy: 0.9126\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0480 - accuracy: 0.9859 - val_loss: 0.1580 - val_accuracy: 0.9352\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0468 - accuracy: 0.9824 - val_loss: 0.1812 - val_accuracy: 0.9300\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0439 - accuracy: 0.9810 - val_loss: 0.1577 - val_accuracy: 0.9362\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0402 - accuracy: 0.9863 - val_loss: 0.1545 - val_accuracy: 0.9475\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0465 - accuracy: 0.9828 - val_loss: 0.1572 - val_accuracy: 0.9321\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0678 - accuracy: 0.9832 - val_loss: 0.2242 - val_accuracy: 0.9177\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0387 - accuracy: 0.9863 - val_loss: 0.2238 - val_accuracy: 0.9198\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.0874 - val_accuracy: 0.9640\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.2165 - val_accuracy: 0.9424\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.0794 - val_accuracy: 0.9712\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0939 - val_accuracy: 0.9671\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0251 - accuracy: 0.9890 - val_loss: 0.1741 - val_accuracy: 0.9414\n","Score: 0.9413580298423767 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 2383.1133 - accuracy: 0.8986 - val_loss: 0.6932 - val_accuracy: 0.5113\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2448 - accuracy: 0.9048 - val_loss: 0.6957 - val_accuracy: 0.4835\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2288 - accuracy: 0.9140 - val_loss: 0.6950 - val_accuracy: 0.5144\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2436 - accuracy: 0.9136 - val_loss: 0.7130 - val_accuracy: 0.5113\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2336 - accuracy: 0.9162 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2364 - accuracy: 0.9136 - val_loss: 0.6962 - val_accuracy: 0.4969\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2394 - accuracy: 0.9118 - val_loss: 0.6910 - val_accuracy: 0.5370\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2298 - accuracy: 0.9198 - val_loss: 0.6928 - val_accuracy: 0.5247\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2436 - accuracy: 0.9127 - val_loss: 0.6935 - val_accuracy: 0.5072\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2353 - accuracy: 0.9136 - val_loss: 0.6929 - val_accuracy: 0.5226\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2346 - accuracy: 0.9175 - val_loss: 0.6982 - val_accuracy: 0.5051\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2260 - accuracy: 0.9206 - val_loss: 0.6932 - val_accuracy: 0.5165\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2327 - accuracy: 0.9202 - val_loss: 0.6973 - val_accuracy: 0.5267\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2241 - accuracy: 0.9206 - val_loss: 0.6972 - val_accuracy: 0.5175\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2235 - accuracy: 0.9211 - val_loss: 0.6937 - val_accuracy: 0.5031\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2438 - accuracy: 0.9123 - val_loss: 0.6975 - val_accuracy: 0.5134\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2261 - accuracy: 0.9220 - val_loss: 0.7116 - val_accuracy: 0.5051\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2314 - accuracy: 0.9092 - val_loss: 0.7065 - val_accuracy: 0.4897\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2374 - accuracy: 0.9061 - val_loss: 0.6987 - val_accuracy: 0.5195\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2336 - accuracy: 0.9114 - val_loss: 0.6932 - val_accuracy: 0.5041\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2401 - accuracy: 0.9061 - val_loss: 0.6957 - val_accuracy: 0.5072\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2381 - accuracy: 0.9158 - val_loss: 0.6977 - val_accuracy: 0.5062\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2316 - accuracy: 0.9171 - val_loss: 0.6934 - val_accuracy: 0.5175\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2399 - accuracy: 0.9131 - val_loss: 0.6956 - val_accuracy: 0.5154\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2342 - accuracy: 0.9171 - val_loss: 0.6941 - val_accuracy: 0.5072\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2310 - accuracy: 0.9175 - val_loss: 0.7067 - val_accuracy: 0.4805\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2503 - accuracy: 0.8959 - val_loss: 0.6941 - val_accuracy: 0.5113\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2338 - accuracy: 0.9162 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2333 - accuracy: 0.9171 - val_loss: 0.6940 - val_accuracy: 0.5206\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2476 - accuracy: 0.9083 - val_loss: 0.6921 - val_accuracy: 0.5247\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2376 - accuracy: 0.9149 - val_loss: 0.6984 - val_accuracy: 0.5175\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2295 - accuracy: 0.9206 - val_loss: 0.7029 - val_accuracy: 0.5134\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2304 - accuracy: 0.9145 - val_loss: 0.6977 - val_accuracy: 0.5278\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2215 - accuracy: 0.9228 - val_loss: 0.6963 - val_accuracy: 0.5216\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2325 - accuracy: 0.9140 - val_loss: 0.6953 - val_accuracy: 0.5010\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2300 - accuracy: 0.9184 - val_loss: 0.6943 - val_accuracy: 0.5154\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2336 - accuracy: 0.9153 - val_loss: 0.6933 - val_accuracy: 0.5082\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2363 - accuracy: 0.9180 - val_loss: 0.6924 - val_accuracy: 0.5237\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2340 - accuracy: 0.9206 - val_loss: 0.7033 - val_accuracy: 0.5123\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2315 - accuracy: 0.9167 - val_loss: 0.6981 - val_accuracy: 0.5021\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.9206 - val_loss: 0.6944 - val_accuracy: 0.5422\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2330 - accuracy: 0.9140 - val_loss: 0.6943 - val_accuracy: 0.4887\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2404 - accuracy: 0.9026 - val_loss: 0.6933 - val_accuracy: 0.4969\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2432 - accuracy: 0.9043 - val_loss: 0.6973 - val_accuracy: 0.5041\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2253 - accuracy: 0.9220 - val_loss: 0.6929 - val_accuracy: 0.5175\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2518 - accuracy: 0.9061 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2486 - accuracy: 0.9109 - val_loss: 0.6944 - val_accuracy: 0.5216\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2459 - accuracy: 0.9083 - val_loss: 0.6970 - val_accuracy: 0.4928\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2470 - accuracy: 0.9030 - val_loss: 0.6929 - val_accuracy: 0.5267\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2372 - accuracy: 0.9030 - val_loss: 0.6936 - val_accuracy: 0.4949\n","Score: 0.49485597014427185 \n","Parameters:  {'learning_rate': 0.03700566714325421, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4221 - accuracy: 0.9224 - val_loss: 0.6027 - val_accuracy: 0.7377\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1509 - accuracy: 0.9290 - val_loss: 0.5799 - val_accuracy: 0.7181\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1661 - accuracy: 0.9405 - val_loss: 0.5374 - val_accuracy: 0.7572\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2234 - accuracy: 0.9021 - val_loss: 0.6226 - val_accuracy: 0.6646\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1810 - accuracy: 0.9202 - val_loss: 0.6041 - val_accuracy: 0.6800\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1750 - accuracy: 0.9198 - val_loss: 0.5506 - val_accuracy: 0.7335\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1495 - accuracy: 0.9365 - val_loss: 0.5089 - val_accuracy: 0.7593\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2181 - accuracy: 0.9396 - val_loss: 0.4979 - val_accuracy: 0.7531\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3413 - accuracy: 0.9427 - val_loss: 0.5619 - val_accuracy: 0.7253\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1659 - accuracy: 0.9387 - val_loss: 0.4577 - val_accuracy: 0.7778\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9431 - val_loss: 0.4214 - val_accuracy: 0.8128\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1438 - accuracy: 0.9511 - val_loss: 0.4345 - val_accuracy: 0.7973\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1495 - accuracy: 0.9431 - val_loss: 0.4380 - val_accuracy: 0.7901\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1347 - accuracy: 0.9550 - val_loss: 0.4205 - val_accuracy: 0.8045\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9471 - val_loss: 0.5487 - val_accuracy: 0.7407\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9541 - val_loss: 0.4233 - val_accuracy: 0.7994\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9484 - val_loss: 0.3909 - val_accuracy: 0.7994\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9475 - val_loss: 0.4331 - val_accuracy: 0.7994\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9537 - val_loss: 0.3943 - val_accuracy: 0.8230\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9453 - val_loss: 0.4022 - val_accuracy: 0.8066\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1713 - accuracy: 0.9515 - val_loss: 0.4013 - val_accuracy: 0.8097\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9524 - val_loss: 0.4303 - val_accuracy: 0.8086\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1189 - accuracy: 0.9559 - val_loss: 0.3882 - val_accuracy: 0.8210\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1260 - accuracy: 0.9511 - val_loss: 0.3805 - val_accuracy: 0.8302\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1112 - accuracy: 0.9524 - val_loss: 0.4121 - val_accuracy: 0.8138\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9471 - val_loss: 0.3946 - val_accuracy: 0.7953\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1063 - accuracy: 0.9581 - val_loss: 0.3894 - val_accuracy: 0.8158\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1271 - accuracy: 0.9546 - val_loss: 0.3618 - val_accuracy: 0.8354\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1242 - accuracy: 0.9550 - val_loss: 0.3823 - val_accuracy: 0.8282\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1428 - accuracy: 0.9471 - val_loss: 0.3510 - val_accuracy: 0.8374\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9586 - val_loss: 0.3419 - val_accuracy: 0.8519\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1466 - accuracy: 0.9524 - val_loss: 0.3622 - val_accuracy: 0.8292\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1125 - accuracy: 0.9555 - val_loss: 0.3540 - val_accuracy: 0.8385\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1057 - accuracy: 0.9594 - val_loss: 0.4101 - val_accuracy: 0.8097\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1297 - accuracy: 0.9559 - val_loss: 0.3508 - val_accuracy: 0.8395\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1038 - accuracy: 0.9621 - val_loss: 0.3599 - val_accuracy: 0.8282\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9581 - val_loss: 0.3738 - val_accuracy: 0.8344\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1065 - accuracy: 0.9590 - val_loss: 0.3560 - val_accuracy: 0.8447\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0965 - accuracy: 0.9634 - val_loss: 0.3291 - val_accuracy: 0.8488\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1310 - accuracy: 0.9541 - val_loss: 0.4442 - val_accuracy: 0.8169\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2276 - accuracy: 0.9590 - val_loss: 0.3408 - val_accuracy: 0.8354\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1604 - accuracy: 0.9550 - val_loss: 0.3266 - val_accuracy: 0.8591\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9563 - val_loss: 0.3296 - val_accuracy: 0.8611\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1198 - accuracy: 0.9660 - val_loss: 0.3618 - val_accuracy: 0.8344\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1132 - accuracy: 0.9555 - val_loss: 0.3056 - val_accuracy: 0.8498\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0994 - accuracy: 0.9625 - val_loss: 0.3280 - val_accuracy: 0.8508\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1525 - accuracy: 0.9546 - val_loss: 0.2862 - val_accuracy: 0.8735\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1059 - accuracy: 0.9572 - val_loss: 0.3330 - val_accuracy: 0.8416\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1806 - accuracy: 0.9665 - val_loss: 0.3149 - val_accuracy: 0.8529\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9660 - val_loss: 0.2844 - val_accuracy: 0.8714\n","Score: 0.8713991641998291 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8373 - accuracy: 0.9220 - val_loss: 0.6385 - val_accuracy: 0.7088\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1773 - accuracy: 0.9171 - val_loss: 0.6502 - val_accuracy: 0.6029\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3613 - accuracy: 0.9255 - val_loss: 0.5375 - val_accuracy: 0.7479\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3547 - accuracy: 0.9303 - val_loss: 0.4823 - val_accuracy: 0.7798\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1595 - accuracy: 0.9418 - val_loss: 0.4474 - val_accuracy: 0.7922\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1418 - accuracy: 0.9440 - val_loss: 0.4687 - val_accuracy: 0.7819\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9444 - val_loss: 0.5312 - val_accuracy: 0.7449\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1508 - accuracy: 0.9383 - val_loss: 0.4271 - val_accuracy: 0.8107\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9427 - val_loss: 1.1818 - val_accuracy: 0.7202\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1654 - accuracy: 0.9440 - val_loss: 0.4256 - val_accuracy: 0.8138\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1255 - accuracy: 0.9502 - val_loss: 0.4294 - val_accuracy: 0.8158\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1809 - accuracy: 0.9444 - val_loss: 0.5006 - val_accuracy: 0.7757\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1833 - accuracy: 0.9502 - val_loss: 0.4033 - val_accuracy: 0.8097\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1434 - accuracy: 0.9422 - val_loss: 0.4262 - val_accuracy: 0.8117\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1492 - accuracy: 0.9462 - val_loss: 0.4491 - val_accuracy: 0.7757\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9484 - val_loss: 0.4016 - val_accuracy: 0.8066\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9458 - val_loss: 0.4211 - val_accuracy: 0.7850\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3272 - accuracy: 0.9378 - val_loss: 0.4145 - val_accuracy: 0.7994\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1347 - accuracy: 0.9502 - val_loss: 0.4184 - val_accuracy: 0.8128\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1474 - accuracy: 0.9453 - val_loss: 0.4189 - val_accuracy: 0.8086\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1315 - accuracy: 0.9489 - val_loss: 0.4061 - val_accuracy: 0.8107\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2103 - accuracy: 0.9444 - val_loss: 0.4068 - val_accuracy: 0.8251\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1802 - accuracy: 0.9436 - val_loss: 0.4021 - val_accuracy: 0.8189\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.9436 - val_loss: 0.3672 - val_accuracy: 0.8302\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1202 - accuracy: 0.9541 - val_loss: 0.3618 - val_accuracy: 0.8241\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9599 - val_loss: 0.3725 - val_accuracy: 0.8405\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1287 - accuracy: 0.9546 - val_loss: 0.3974 - val_accuracy: 0.8107\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1150 - accuracy: 0.9559 - val_loss: 0.4228 - val_accuracy: 0.7973\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0995 - accuracy: 0.9616 - val_loss: 0.3602 - val_accuracy: 0.8344\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9528 - val_loss: 0.4025 - val_accuracy: 0.7973\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1774 - accuracy: 0.9431 - val_loss: 0.3569 - val_accuracy: 0.8364\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1156 - accuracy: 0.9581 - val_loss: 0.4017 - val_accuracy: 0.8056\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1102 - accuracy: 0.9599 - val_loss: 0.3744 - val_accuracy: 0.8241\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1281 - accuracy: 0.9506 - val_loss: 0.3970 - val_accuracy: 0.8179\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1154 - accuracy: 0.9563 - val_loss: 0.3398 - val_accuracy: 0.8364\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9541 - val_loss: 0.4033 - val_accuracy: 0.8117\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1915 - accuracy: 0.9572 - val_loss: 0.3732 - val_accuracy: 0.8272\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1464 - accuracy: 0.9515 - val_loss: 0.3320 - val_accuracy: 0.8436\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1109 - accuracy: 0.9599 - val_loss: 0.3655 - val_accuracy: 0.8457\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9621 - val_loss: 0.3278 - val_accuracy: 0.8488\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9608 - val_loss: 0.4080 - val_accuracy: 0.8158\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9563 - val_loss: 0.4107 - val_accuracy: 0.8107\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.9603 - val_loss: 0.3884 - val_accuracy: 0.8354\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1063 - accuracy: 0.9612 - val_loss: 0.3789 - val_accuracy: 0.8374\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0860 - accuracy: 0.9630 - val_loss: 0.3620 - val_accuracy: 0.8447\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1091 - accuracy: 0.9608 - val_loss: 0.4361 - val_accuracy: 0.7901\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0814 - accuracy: 0.9718 - val_loss: 0.3192 - val_accuracy: 0.8591\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0904 - accuracy: 0.9709 - val_loss: 0.4047 - val_accuracy: 0.8467\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0933 - accuracy: 0.9638 - val_loss: 0.3214 - val_accuracy: 0.8570\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1001 - accuracy: 0.9647 - val_loss: 0.2942 - val_accuracy: 0.8735\n","Score: 0.8734567761421204 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0820 - accuracy: 0.9078 - val_loss: 0.7066 - val_accuracy: 0.5093\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2715 - accuracy: 0.9277 - val_loss: 0.6108 - val_accuracy: 0.6965\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9321 - val_loss: 0.5847 - val_accuracy: 0.7222\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2341 - accuracy: 0.9378 - val_loss: 0.5469 - val_accuracy: 0.7335\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9343 - val_loss: 0.4870 - val_accuracy: 0.7644\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9290 - val_loss: 0.5515 - val_accuracy: 0.7222\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1836 - accuracy: 0.9330 - val_loss: 0.5827 - val_accuracy: 0.7027\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1857 - accuracy: 0.9325 - val_loss: 0.5132 - val_accuracy: 0.7469\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1515 - accuracy: 0.9392 - val_loss: 0.5407 - val_accuracy: 0.7315\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1543 - accuracy: 0.9396 - val_loss: 0.5874 - val_accuracy: 0.7016\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7926 - accuracy: 0.9378 - val_loss: 0.4902 - val_accuracy: 0.7603\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3157 - accuracy: 0.9431 - val_loss: 0.5479 - val_accuracy: 0.7140\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1601 - accuracy: 0.9383 - val_loss: 0.5216 - val_accuracy: 0.7387\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1686 - accuracy: 0.9352 - val_loss: 0.4901 - val_accuracy: 0.7675\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1544 - accuracy: 0.9431 - val_loss: 0.5577 - val_accuracy: 0.7634\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9440 - val_loss: 0.4451 - val_accuracy: 0.7942\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1324 - accuracy: 0.9502 - val_loss: 0.4827 - val_accuracy: 0.7593\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.9400 - val_loss: 0.4618 - val_accuracy: 0.7891\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.9449 - val_loss: 0.4748 - val_accuracy: 0.7747\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1753 - accuracy: 0.9462 - val_loss: 0.4592 - val_accuracy: 0.7840\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2726 - accuracy: 0.9409 - val_loss: 0.4525 - val_accuracy: 0.7922\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1344 - accuracy: 0.9475 - val_loss: 0.4430 - val_accuracy: 0.7922\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1419 - accuracy: 0.9400 - val_loss: 0.4188 - val_accuracy: 0.8097\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1703 - accuracy: 0.9400 - val_loss: 0.4285 - val_accuracy: 0.7932\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1437 - accuracy: 0.9484 - val_loss: 0.4038 - val_accuracy: 0.8230\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9462 - val_loss: 0.4180 - val_accuracy: 0.8148\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1401 - accuracy: 0.9475 - val_loss: 0.4163 - val_accuracy: 0.8004\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1343 - accuracy: 0.9497 - val_loss: 0.4227 - val_accuracy: 0.8117\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9515 - val_loss: 0.4085 - val_accuracy: 0.8045\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1278 - accuracy: 0.9471 - val_loss: 0.4140 - val_accuracy: 0.8107\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9475 - val_loss: 0.3885 - val_accuracy: 0.8128\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1338 - accuracy: 0.9489 - val_loss: 0.3855 - val_accuracy: 0.8344\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1736 - accuracy: 0.9480 - val_loss: 0.4126 - val_accuracy: 0.7984\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9559 - val_loss: 0.3871 - val_accuracy: 0.8179\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9541 - val_loss: 0.3852 - val_accuracy: 0.8169\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1161 - accuracy: 0.9581 - val_loss: 0.3996 - val_accuracy: 0.8179\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1228 - accuracy: 0.9533 - val_loss: 0.3937 - val_accuracy: 0.8323\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1539 - accuracy: 0.9515 - val_loss: 0.4169 - val_accuracy: 0.7973\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1210 - accuracy: 0.9519 - val_loss: 0.3797 - val_accuracy: 0.8261\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1384 - accuracy: 0.9471 - val_loss: 0.4339 - val_accuracy: 0.8097\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9550 - val_loss: 0.3996 - val_accuracy: 0.8169\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9608 - val_loss: 0.4202 - val_accuracy: 0.8117\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1177 - accuracy: 0.9572 - val_loss: 0.3888 - val_accuracy: 0.8169\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1197 - accuracy: 0.9550 - val_loss: 0.4915 - val_accuracy: 0.7870\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9537 - val_loss: 0.3931 - val_accuracy: 0.8272\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1315 - accuracy: 0.9422 - val_loss: 0.4423 - val_accuracy: 0.8004\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1243 - accuracy: 0.9502 - val_loss: 0.3756 - val_accuracy: 0.8405\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1196 - accuracy: 0.9581 - val_loss: 0.3822 - val_accuracy: 0.8292\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9475 - val_loss: 0.4261 - val_accuracy: 0.7973\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1480 - accuracy: 0.9524 - val_loss: 0.4043 - val_accuracy: 0.8200\n","Score: 0.8199588656425476 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.7204 - accuracy: 0.9021 - val_loss: 0.6977 - val_accuracy: 0.5072\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8162 - accuracy: 0.9233 - val_loss: 0.6284 - val_accuracy: 0.6543\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2483 - accuracy: 0.9153 - val_loss: 0.9105 - val_accuracy: 0.5792\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1090 - accuracy: 0.9180 - val_loss: 0.5475 - val_accuracy: 0.7150\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1742 - accuracy: 0.9290 - val_loss: 0.6018 - val_accuracy: 0.6903\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9264 - val_loss: 0.5728 - val_accuracy: 0.6996\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9347 - val_loss: 0.5620 - val_accuracy: 0.7387\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1874 - accuracy: 0.9409 - val_loss: 0.5359 - val_accuracy: 0.7294\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1666 - accuracy: 0.9330 - val_loss: 0.5404 - val_accuracy: 0.7366\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2272 - accuracy: 0.9299 - val_loss: 0.5475 - val_accuracy: 0.7212\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1724 - accuracy: 0.9321 - val_loss: 0.5655 - val_accuracy: 0.7078\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1874 - accuracy: 0.9374 - val_loss: 0.5726 - val_accuracy: 0.7284\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9330 - val_loss: 0.5494 - val_accuracy: 0.7140\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.9444 - val_loss: 0.4942 - val_accuracy: 0.7634\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3044 - accuracy: 0.9272 - val_loss: 0.5467 - val_accuracy: 0.7243\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1621 - accuracy: 0.9347 - val_loss: 0.5987 - val_accuracy: 0.6739\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9365 - val_loss: 0.4862 - val_accuracy: 0.7562\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1626 - accuracy: 0.9361 - val_loss: 0.4998 - val_accuracy: 0.7541\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.9383 - val_loss: 0.5123 - val_accuracy: 0.7469\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9409 - val_loss: 0.5251 - val_accuracy: 0.7428\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1391 - accuracy: 0.9427 - val_loss: 0.4901 - val_accuracy: 0.7675\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1563 - accuracy: 0.9475 - val_loss: 0.5898 - val_accuracy: 0.7202\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9383 - val_loss: 0.5109 - val_accuracy: 0.7510\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1745 - accuracy: 0.9400 - val_loss: 0.5023 - val_accuracy: 0.7449\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1532 - accuracy: 0.9400 - val_loss: 0.4967 - val_accuracy: 0.7551\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9475 - val_loss: 0.4761 - val_accuracy: 0.7757\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1432 - accuracy: 0.9528 - val_loss: 0.4661 - val_accuracy: 0.7695\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1439 - accuracy: 0.9422 - val_loss: 0.4798 - val_accuracy: 0.7891\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1538 - accuracy: 0.9374 - val_loss: 0.4492 - val_accuracy: 0.7850\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1477 - accuracy: 0.9475 - val_loss: 0.4603 - val_accuracy: 0.7881\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1496 - accuracy: 0.9405 - val_loss: 0.4662 - val_accuracy: 0.7809\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1463 - accuracy: 0.9436 - val_loss: 0.4436 - val_accuracy: 0.7984\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2195 - accuracy: 0.9427 - val_loss: 0.4463 - val_accuracy: 0.7829\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1475 - accuracy: 0.9440 - val_loss: 0.4461 - val_accuracy: 0.7860\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1775 - accuracy: 0.9436 - val_loss: 0.4582 - val_accuracy: 0.7747\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1320 - accuracy: 0.9484 - val_loss: 0.4353 - val_accuracy: 0.8014\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9466 - val_loss: 0.4392 - val_accuracy: 0.7953\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1416 - accuracy: 0.9453 - val_loss: 0.4623 - val_accuracy: 0.8035\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1297 - accuracy: 0.9475 - val_loss: 0.4417 - val_accuracy: 0.8004\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1211 - accuracy: 0.9537 - val_loss: 0.4181 - val_accuracy: 0.7984\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1632 - accuracy: 0.9515 - val_loss: 0.4395 - val_accuracy: 0.7942\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1317 - accuracy: 0.9515 - val_loss: 0.4187 - val_accuracy: 0.7973\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1256 - accuracy: 0.9515 - val_loss: 0.4531 - val_accuracy: 0.7922\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9524 - val_loss: 0.3854 - val_accuracy: 0.8210\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1207 - accuracy: 0.9497 - val_loss: 0.4189 - val_accuracy: 0.7973\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1252 - accuracy: 0.9506 - val_loss: 0.4162 - val_accuracy: 0.8056\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1217 - accuracy: 0.9541 - val_loss: 0.4222 - val_accuracy: 0.8138\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1210 - accuracy: 0.9533 - val_loss: 0.4987 - val_accuracy: 0.7778\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1453 - accuracy: 0.9418 - val_loss: 0.4539 - val_accuracy: 0.8200\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1375 - accuracy: 0.9466 - val_loss: 0.4174 - val_accuracy: 0.8076\n","Score: 0.8076131939888 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 31308.0430 - accuracy: 0.8902 - val_loss: 0.6935 - val_accuracy: 0.5134\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9039 - val_loss: 0.6942 - val_accuracy: 0.5165\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2060 - accuracy: 0.9012 - val_loss: 0.7439 - val_accuracy: 0.4691\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.9039 - val_loss: 1.0542 - val_accuracy: 0.5195\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1848 - accuracy: 0.9070 - val_loss: 0.7494 - val_accuracy: 0.5072\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2072 - accuracy: 0.9056 - val_loss: 0.7422 - val_accuracy: 0.5041\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1817 - accuracy: 0.9145 - val_loss: 0.7772 - val_accuracy: 0.4887\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9004 - val_loss: 0.7647 - val_accuracy: 0.4990\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1799 - accuracy: 0.9087 - val_loss: 0.7250 - val_accuracy: 0.5051\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.8951 - val_loss: 0.7084 - val_accuracy: 0.5134\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1831 - accuracy: 0.9017 - val_loss: 0.6987 - val_accuracy: 0.5154\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9105 - val_loss: 0.6945 - val_accuracy: 0.4897\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9096 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2250 - accuracy: 0.9030 - val_loss: 0.6976 - val_accuracy: 0.5041\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2135 - accuracy: 0.9206 - val_loss: 0.7018 - val_accuracy: 0.4774\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.8990 - val_loss: 0.6996 - val_accuracy: 0.4877\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2205 - accuracy: 0.9004 - val_loss: 0.6929 - val_accuracy: 0.5134\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9140 - val_loss: 0.6938 - val_accuracy: 0.4784\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9123 - val_loss: 0.6937 - val_accuracy: 0.5072\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2211 - accuracy: 0.9101 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2091 - accuracy: 0.9220 - val_loss: 0.7014 - val_accuracy: 0.5113\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9167 - val_loss: 0.6932 - val_accuracy: 0.5082\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9175 - val_loss: 0.6907 - val_accuracy: 0.5350\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2181 - accuracy: 0.9131 - val_loss: 0.6977 - val_accuracy: 0.4887\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2158 - accuracy: 0.9048 - val_loss: 0.7146 - val_accuracy: 0.4763\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.9078 - val_loss: 0.6931 - val_accuracy: 0.5051\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2289 - accuracy: 0.9083 - val_loss: 0.6980 - val_accuracy: 0.5165\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2210 - accuracy: 0.9118 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2190 - accuracy: 0.9167 - val_loss: 0.7009 - val_accuracy: 0.5103\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9175 - val_loss: 0.6939 - val_accuracy: 0.4897\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2177 - accuracy: 0.9118 - val_loss: 0.7120 - val_accuracy: 0.5041\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2172 - accuracy: 0.9140 - val_loss: 0.6931 - val_accuracy: 0.5134\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2118 - accuracy: 0.9198 - val_loss: 0.6932 - val_accuracy: 0.5010\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2243 - accuracy: 0.9087 - val_loss: 0.6946 - val_accuracy: 0.5175\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2175 - accuracy: 0.9087 - val_loss: 0.6991 - val_accuracy: 0.4825\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2215 - accuracy: 0.9101 - val_loss: 0.6960 - val_accuracy: 0.4887\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2190 - accuracy: 0.9039 - val_loss: 0.7000 - val_accuracy: 0.4784\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2227 - accuracy: 0.9026 - val_loss: 0.6976 - val_accuracy: 0.4928\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9131 - val_loss: 0.6917 - val_accuracy: 0.5278\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2332 - accuracy: 0.9048 - val_loss: 0.6923 - val_accuracy: 0.5226\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2248 - accuracy: 0.9127 - val_loss: 0.6927 - val_accuracy: 0.5185\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2211 - accuracy: 0.9171 - val_loss: 0.6946 - val_accuracy: 0.5072\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2253 - accuracy: 0.9118 - val_loss: 0.7048 - val_accuracy: 0.5051\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2157 - accuracy: 0.9149 - val_loss: 0.6953 - val_accuracy: 0.4938\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2196 - accuracy: 0.9118 - val_loss: 0.6935 - val_accuracy: 0.5216\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2239 - accuracy: 0.9074 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2211 - accuracy: 0.9127 - val_loss: 0.7086 - val_accuracy: 0.4959\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2230 - accuracy: 0.9004 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2101 - accuracy: 0.9175 - val_loss: 0.6934 - val_accuracy: 0.5113\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2266 - accuracy: 0.9131 - val_loss: 0.7086 - val_accuracy: 0.5000\n","Score: 0.5 \n","Parameters:  {'learning_rate': 0.05357639242104769, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9154 - accuracy: 0.9065 - val_loss: 0.6539 - val_accuracy: 0.7233\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1848 - accuracy: 0.9255 - val_loss: 0.5631 - val_accuracy: 0.7181\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3602 - accuracy: 0.9325 - val_loss: 0.5178 - val_accuracy: 0.7613\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3198 - accuracy: 0.9343 - val_loss: 0.4775 - val_accuracy: 0.7685\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1401 - accuracy: 0.9392 - val_loss: 0.5119 - val_accuracy: 0.7459\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1639 - accuracy: 0.9431 - val_loss: 0.4786 - val_accuracy: 0.7994\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9502 - val_loss: 0.3793 - val_accuracy: 0.8395\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1102 - accuracy: 0.9555 - val_loss: 0.3406 - val_accuracy: 0.8508\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1222 - accuracy: 0.9511 - val_loss: 0.3461 - val_accuracy: 0.8621\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1824 - accuracy: 0.9396 - val_loss: 0.4079 - val_accuracy: 0.8097\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1388 - accuracy: 0.9568 - val_loss: 0.3680 - val_accuracy: 0.8292\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1112 - accuracy: 0.9519 - val_loss: 0.3667 - val_accuracy: 0.8117\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1026 - accuracy: 0.9572 - val_loss: 0.3066 - val_accuracy: 0.8498\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1021 - accuracy: 0.9608 - val_loss: 0.4144 - val_accuracy: 0.7870\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1008 - accuracy: 0.9652 - val_loss: 0.4534 - val_accuracy: 0.7572\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0914 - accuracy: 0.9612 - val_loss: 0.2897 - val_accuracy: 0.8776\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1798 - accuracy: 0.9466 - val_loss: 0.3890 - val_accuracy: 0.8241\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1097 - accuracy: 0.9515 - val_loss: 0.4380 - val_accuracy: 0.8344\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9493 - val_loss: 0.3680 - val_accuracy: 0.8426\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1204 - accuracy: 0.9528 - val_loss: 0.3575 - val_accuracy: 0.8364\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1047 - accuracy: 0.9638 - val_loss: 0.2889 - val_accuracy: 0.8663\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0934 - accuracy: 0.9621 - val_loss: 0.3007 - val_accuracy: 0.8591\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1161 - accuracy: 0.9634 - val_loss: 0.2998 - val_accuracy: 0.8673\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0861 - accuracy: 0.9630 - val_loss: 0.3397 - val_accuracy: 0.8405\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1066 - accuracy: 0.9625 - val_loss: 0.3188 - val_accuracy: 0.8621\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0736 - accuracy: 0.9678 - val_loss: 0.2836 - val_accuracy: 0.8837\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9656 - val_loss: 0.2671 - val_accuracy: 0.8714\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0774 - accuracy: 0.9652 - val_loss: 0.2665 - val_accuracy: 0.8776\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9722 - val_loss: 0.2534 - val_accuracy: 0.8899\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0857 - accuracy: 0.9780 - val_loss: 0.2560 - val_accuracy: 0.8961\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0715 - accuracy: 0.9713 - val_loss: 0.2962 - val_accuracy: 0.8765\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2951 - accuracy: 0.9586 - val_loss: 0.3543 - val_accuracy: 0.8323\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9599 - val_loss: 0.2952 - val_accuracy: 0.8632\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0872 - accuracy: 0.9656 - val_loss: 0.2840 - val_accuracy: 0.8683\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0809 - accuracy: 0.9691 - val_loss: 0.2584 - val_accuracy: 0.8837\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0771 - accuracy: 0.9735 - val_loss: 0.2974 - val_accuracy: 0.8848\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0828 - accuracy: 0.9683 - val_loss: 0.2734 - val_accuracy: 0.8837\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0763 - accuracy: 0.9753 - val_loss: 0.2206 - val_accuracy: 0.9023\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0548 - accuracy: 0.9797 - val_loss: 0.1852 - val_accuracy: 0.9198\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0664 - accuracy: 0.9771 - val_loss: 0.2162 - val_accuracy: 0.9033\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0589 - accuracy: 0.9832 - val_loss: 0.2076 - val_accuracy: 0.9095\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1014 - accuracy: 0.9757 - val_loss: 0.2318 - val_accuracy: 0.9033\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0575 - accuracy: 0.9806 - val_loss: 0.2261 - val_accuracy: 0.9136\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0541 - accuracy: 0.9806 - val_loss: 0.1950 - val_accuracy: 0.9280\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 0.1856 - val_accuracy: 0.9321\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0498 - accuracy: 0.9824 - val_loss: 0.1743 - val_accuracy: 0.9228\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0423 - accuracy: 0.9881 - val_loss: 0.1937 - val_accuracy: 0.9383\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9793 - val_loss: 0.3181 - val_accuracy: 0.8848\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0860 - accuracy: 0.9705 - val_loss: 0.2192 - val_accuracy: 0.9033\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0530 - accuracy: 0.9850 - val_loss: 0.1910 - val_accuracy: 0.9321\n","Score: 0.9320987462997437 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 12759.1777 - accuracy: 0.8990 - val_loss: 0.7405 - val_accuracy: 0.5051\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9101 - val_loss: 0.7002 - val_accuracy: 0.5195\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9043 - val_loss: 0.6920 - val_accuracy: 0.5247\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9026 - val_loss: 0.6944 - val_accuracy: 0.4866\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1843 - accuracy: 0.9096 - val_loss: 0.6968 - val_accuracy: 0.4866\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9052 - val_loss: 0.8551 - val_accuracy: 0.5010\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.8981 - val_loss: 0.7037 - val_accuracy: 0.4825\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9008 - val_loss: 0.9244 - val_accuracy: 0.5031\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2027 - accuracy: 0.9012 - val_loss: 0.8944 - val_accuracy: 0.4897\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2242 - accuracy: 0.8871 - val_loss: 0.7327 - val_accuracy: 0.5051\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1779 - accuracy: 0.9087 - val_loss: 0.6934 - val_accuracy: 0.5123\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9131 - val_loss: 0.7239 - val_accuracy: 0.5298\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1837 - accuracy: 0.9114 - val_loss: 0.7051 - val_accuracy: 0.5309\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9070 - val_loss: 0.6982 - val_accuracy: 0.4959\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1863 - accuracy: 0.9043 - val_loss: 0.7256 - val_accuracy: 0.4753\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2010 - accuracy: 0.8959 - val_loss: 0.7477 - val_accuracy: 0.4938\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9026 - val_loss: 0.7090 - val_accuracy: 0.4846\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9021 - val_loss: 0.6979 - val_accuracy: 0.4856\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1832 - accuracy: 0.9158 - val_loss: 0.7234 - val_accuracy: 0.5051\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9056 - val_loss: 0.7337 - val_accuracy: 0.5165\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1778 - accuracy: 0.9175 - val_loss: 0.6957 - val_accuracy: 0.5134\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9118 - val_loss: 0.6950 - val_accuracy: 0.4907\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2225 - accuracy: 0.9078 - val_loss: 0.6994 - val_accuracy: 0.5031\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9092 - val_loss: 0.6920 - val_accuracy: 0.5298\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2139 - accuracy: 0.9074 - val_loss: 0.6968 - val_accuracy: 0.4743\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2255 - accuracy: 0.9021 - val_loss: 0.6920 - val_accuracy: 0.5237\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2177 - accuracy: 0.9145 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2117 - accuracy: 0.9175 - val_loss: 0.6930 - val_accuracy: 0.5154\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2222 - accuracy: 0.9087 - val_loss: 0.6960 - val_accuracy: 0.5175\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9171 - val_loss: 0.6946 - val_accuracy: 0.5000\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.8990 - val_loss: 0.6932 - val_accuracy: 0.4846\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.9065 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2248 - accuracy: 0.9114 - val_loss: 0.6958 - val_accuracy: 0.4928\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2210 - accuracy: 0.9065 - val_loss: 0.6953 - val_accuracy: 0.5103\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2222 - accuracy: 0.9153 - val_loss: 0.6937 - val_accuracy: 0.5134\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2150 - accuracy: 0.9118 - val_loss: 0.6944 - val_accuracy: 0.4938\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9193 - val_loss: 0.6985 - val_accuracy: 0.5103\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9109 - val_loss: 0.6930 - val_accuracy: 0.5175\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2145 - accuracy: 0.9162 - val_loss: 0.6937 - val_accuracy: 0.5175\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2190 - accuracy: 0.9180 - val_loss: 0.7006 - val_accuracy: 0.5185\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.9096 - val_loss: 0.6932 - val_accuracy: 0.4702\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2324 - accuracy: 0.9048 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2178 - accuracy: 0.9149 - val_loss: 0.7004 - val_accuracy: 0.5175\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2200 - accuracy: 0.9180 - val_loss: 0.7085 - val_accuracy: 0.5103\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9153 - val_loss: 0.6938 - val_accuracy: 0.5103\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2182 - accuracy: 0.9118 - val_loss: 0.6981 - val_accuracy: 0.5051\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2089 - accuracy: 0.9149 - val_loss: 0.7047 - val_accuracy: 0.4835\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2241 - accuracy: 0.9017 - val_loss: 0.6965 - val_accuracy: 0.5144\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9206 - val_loss: 0.6975 - val_accuracy: 0.5195\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2167 - accuracy: 0.9184 - val_loss: 0.6935 - val_accuracy: 0.5000\n","Score: 0.5 \n","Parameters:  {'learning_rate': 0.05371634930318744, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 90605.2734 - accuracy: 0.8898 - val_loss: 0.7053 - val_accuracy: 0.4866\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2313 - accuracy: 0.9034 - val_loss: 0.6956 - val_accuracy: 0.4918\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.8920 - val_loss: 0.7424 - val_accuracy: 0.4887\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.8933 - val_loss: 0.9775 - val_accuracy: 0.5175\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1774 - accuracy: 0.9083 - val_loss: 0.6976 - val_accuracy: 0.5134\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.9101 - val_loss: 0.7525 - val_accuracy: 0.5247\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.8973 - val_loss: 0.6952 - val_accuracy: 0.5278\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.9078 - val_loss: 0.9050 - val_accuracy: 0.4928\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2142 - accuracy: 0.9017 - val_loss: 0.8140 - val_accuracy: 0.4630\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2270 - accuracy: 0.8929 - val_loss: 0.8002 - val_accuracy: 0.5134\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9056 - val_loss: 0.8232 - val_accuracy: 0.5093\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2191 - accuracy: 0.8920 - val_loss: 0.9845 - val_accuracy: 0.4897\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9017 - val_loss: 0.7098 - val_accuracy: 0.4897\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.8933 - val_loss: 0.7405 - val_accuracy: 0.4784\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.8986 - val_loss: 0.6929 - val_accuracy: 0.5247\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.8981 - val_loss: 0.9455 - val_accuracy: 0.5185\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9083 - val_loss: 0.7767 - val_accuracy: 0.4835\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9061 - val_loss: 0.6984 - val_accuracy: 0.5175\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9105 - val_loss: 0.7608 - val_accuracy: 0.4805\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2177 - accuracy: 0.9021 - val_loss: 0.7039 - val_accuracy: 0.5257\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9048 - val_loss: 0.7020 - val_accuracy: 0.4907\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9017 - val_loss: 0.7340 - val_accuracy: 0.5185\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9056 - val_loss: 0.6930 - val_accuracy: 0.5093\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9136 - val_loss: 0.7368 - val_accuracy: 0.4846\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9105 - val_loss: 0.6946 - val_accuracy: 0.4979\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9052 - val_loss: 0.6932 - val_accuracy: 0.4990\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9193 - val_loss: 0.6942 - val_accuracy: 0.4938\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9096 - val_loss: 0.6970 - val_accuracy: 0.4753\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9012 - val_loss: 0.6946 - val_accuracy: 0.5154\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.9065 - val_loss: 0.6950 - val_accuracy: 0.5175\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9109 - val_loss: 0.6978 - val_accuracy: 0.4763\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9101 - val_loss: 0.6963 - val_accuracy: 0.4907\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2077 - accuracy: 0.9017 - val_loss: 0.6933 - val_accuracy: 0.5021\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2097 - accuracy: 0.9140 - val_loss: 0.6938 - val_accuracy: 0.5051\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9215 - val_loss: 0.6935 - val_accuracy: 0.5123\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.9140 - val_loss: 0.7195 - val_accuracy: 0.4846\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9056 - val_loss: 0.6979 - val_accuracy: 0.4846\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.9096 - val_loss: 0.7044 - val_accuracy: 0.5031\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2122 - accuracy: 0.8986 - val_loss: 0.7073 - val_accuracy: 0.5010\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9118 - val_loss: 0.6914 - val_accuracy: 0.5298\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9180 - val_loss: 0.6932 - val_accuracy: 0.4979\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9114 - val_loss: 0.6932 - val_accuracy: 0.4805\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9153 - val_loss: 0.7095 - val_accuracy: 0.5000\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9140 - val_loss: 0.6934 - val_accuracy: 0.5247\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9153 - val_loss: 0.7009 - val_accuracy: 0.4887\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9096 - val_loss: 0.7221 - val_accuracy: 0.4918\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9127 - val_loss: 0.7208 - val_accuracy: 0.5041\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9092 - val_loss: 0.6932 - val_accuracy: 0.4979\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.8986 - val_loss: 0.6999 - val_accuracy: 0.4712\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9145 - val_loss: 0.6948 - val_accuracy: 0.5082\n","Score: 0.508230447769165 \n","Parameters:  {'learning_rate': 0.08253720192004879, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9513 - accuracy: 0.9202 - val_loss: 0.7098 - val_accuracy: 0.6739\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2471 - accuracy: 0.9378 - val_loss: 0.5622 - val_accuracy: 0.7222\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2182 - accuracy: 0.9281 - val_loss: 0.5917 - val_accuracy: 0.6821\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9339 - val_loss: 0.5714 - val_accuracy: 0.7047\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1733 - accuracy: 0.9396 - val_loss: 0.5218 - val_accuracy: 0.7397\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1581 - accuracy: 0.9471 - val_loss: 0.4834 - val_accuracy: 0.7479\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9480 - val_loss: 0.5000 - val_accuracy: 0.7531\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1435 - accuracy: 0.9422 - val_loss: 0.4749 - val_accuracy: 0.7654\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9334 - val_loss: 0.5133 - val_accuracy: 0.7305\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9489 - val_loss: 0.4902 - val_accuracy: 0.7479\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1601 - accuracy: 0.9347 - val_loss: 0.5297 - val_accuracy: 0.7397\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1620 - accuracy: 0.9361 - val_loss: 0.4856 - val_accuracy: 0.7582\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1439 - accuracy: 0.9480 - val_loss: 0.5311 - val_accuracy: 0.7449\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1606 - accuracy: 0.9449 - val_loss: 0.4581 - val_accuracy: 0.7850\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1608 - accuracy: 0.9466 - val_loss: 0.5059 - val_accuracy: 0.7459\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2776 - accuracy: 0.9422 - val_loss: 0.5590 - val_accuracy: 0.7305\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1369 - accuracy: 0.9396 - val_loss: 0.4810 - val_accuracy: 0.7644\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1452 - accuracy: 0.9506 - val_loss: 0.4708 - val_accuracy: 0.7829\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1356 - accuracy: 0.9449 - val_loss: 0.4891 - val_accuracy: 0.7901\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1685 - accuracy: 0.9347 - val_loss: 0.5063 - val_accuracy: 0.7716\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1540 - accuracy: 0.9453 - val_loss: 0.4493 - val_accuracy: 0.7963\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1491 - accuracy: 0.9383 - val_loss: 0.4698 - val_accuracy: 0.8035\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2123 - accuracy: 0.9462 - val_loss: 0.4125 - val_accuracy: 0.8148\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9567 - accuracy: 0.9369 - val_loss: 0.5053 - val_accuracy: 0.7788\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9436 - val_loss: 0.4521 - val_accuracy: 0.7984\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9409 - val_loss: 0.4605 - val_accuracy: 0.7973\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1530 - accuracy: 0.9369 - val_loss: 0.4460 - val_accuracy: 0.8014\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1624 - accuracy: 0.9387 - val_loss: 0.4713 - val_accuracy: 0.7922\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1668 - accuracy: 0.9365 - val_loss: 0.5002 - val_accuracy: 0.7778\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1650 - accuracy: 0.9409 - val_loss: 0.4715 - val_accuracy: 0.7654\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1320 - accuracy: 0.9515 - val_loss: 0.4252 - val_accuracy: 0.8004\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9444 - val_loss: 0.4511 - val_accuracy: 0.7922\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1531 - accuracy: 0.9396 - val_loss: 0.4644 - val_accuracy: 0.7901\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9449 - val_loss: 0.4288 - val_accuracy: 0.8035\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1645 - accuracy: 0.9339 - val_loss: 0.5100 - val_accuracy: 0.7623\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1180 - accuracy: 0.9533 - val_loss: 0.4223 - val_accuracy: 0.8097\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1237 - accuracy: 0.9506 - val_loss: 0.4217 - val_accuracy: 0.8230\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9422 - val_loss: 0.4355 - val_accuracy: 0.8117\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1261 - accuracy: 0.9515 - val_loss: 0.4146 - val_accuracy: 0.8158\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1434 - accuracy: 0.9466 - val_loss: 0.4535 - val_accuracy: 0.8107\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1340 - accuracy: 0.9493 - val_loss: 0.4172 - val_accuracy: 0.8076\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1417 - accuracy: 0.9458 - val_loss: 0.4125 - val_accuracy: 0.7932\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3323 - accuracy: 0.9427 - val_loss: 0.3939 - val_accuracy: 0.8148\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9436 - val_loss: 0.4082 - val_accuracy: 0.8200\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9427 - val_loss: 0.4234 - val_accuracy: 0.8148\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1894 - accuracy: 0.9506 - val_loss: 0.4470 - val_accuracy: 0.8158\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1608 - accuracy: 0.9409 - val_loss: 0.4310 - val_accuracy: 0.8261\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9484 - val_loss: 0.5430 - val_accuracy: 0.7593\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2745 - accuracy: 0.9537 - val_loss: 0.3786 - val_accuracy: 0.8169\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1455 - accuracy: 0.9497 - val_loss: 0.4155 - val_accuracy: 0.8014\n","Score: 0.8014403581619263 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9599 - accuracy: 0.9087 - val_loss: 0.6601 - val_accuracy: 0.6348\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9211 - val_loss: 0.6296 - val_accuracy: 0.7068\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2089 - accuracy: 0.9021 - val_loss: 0.6795 - val_accuracy: 0.5206\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9211 - val_loss: 0.6328 - val_accuracy: 0.7006\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9334 - val_loss: 0.6062 - val_accuracy: 0.7150\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.9228 - val_loss: 0.5923 - val_accuracy: 0.7150\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1765 - accuracy: 0.9334 - val_loss: 0.5768 - val_accuracy: 0.7315\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1807 - accuracy: 0.9268 - val_loss: 0.5635 - val_accuracy: 0.7222\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9427 - val_loss: 0.5409 - val_accuracy: 0.7356\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1745 - accuracy: 0.9325 - val_loss: 0.5330 - val_accuracy: 0.7459\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1846 - accuracy: 0.9272 - val_loss: 0.5535 - val_accuracy: 0.7109\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1635 - accuracy: 0.9383 - val_loss: 0.5438 - val_accuracy: 0.7284\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2311 - accuracy: 0.9418 - val_loss: 0.5118 - val_accuracy: 0.7479\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5440 - accuracy: 0.9361 - val_loss: 0.5565 - val_accuracy: 0.7284\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1750 - accuracy: 0.9312 - val_loss: 0.5427 - val_accuracy: 0.7387\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1614 - accuracy: 0.9418 - val_loss: 0.5222 - val_accuracy: 0.7325\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1749 - accuracy: 0.9281 - val_loss: 0.5261 - val_accuracy: 0.7510\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1775 - accuracy: 0.9317 - val_loss: 0.5084 - val_accuracy: 0.7490\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1817 - accuracy: 0.9466 - val_loss: 0.4559 - val_accuracy: 0.7788\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.9418 - val_loss: 0.4973 - val_accuracy: 0.7500\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1837 - accuracy: 0.9396 - val_loss: 0.5094 - val_accuracy: 0.7418\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1577 - accuracy: 0.9400 - val_loss: 0.5014 - val_accuracy: 0.7593\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2088 - accuracy: 0.9369 - val_loss: 0.5506 - val_accuracy: 0.7305\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9409 - val_loss: 0.4940 - val_accuracy: 0.7613\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9383 - val_loss: 0.4766 - val_accuracy: 0.7747\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1600 - accuracy: 0.9392 - val_loss: 0.4876 - val_accuracy: 0.7706\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9444 - val_loss: 0.4678 - val_accuracy: 0.7767\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1533 - accuracy: 0.9436 - val_loss: 0.4794 - val_accuracy: 0.7953\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1488 - accuracy: 0.9436 - val_loss: 0.4715 - val_accuracy: 0.7809\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1475 - accuracy: 0.9418 - val_loss: 0.4528 - val_accuracy: 0.7767\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9475 - val_loss: 0.4436 - val_accuracy: 0.7870\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1343 - accuracy: 0.9475 - val_loss: 0.4425 - val_accuracy: 0.7901\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1561 - accuracy: 0.9453 - val_loss: 0.4546 - val_accuracy: 0.7963\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1162 - accuracy: 0.9546 - val_loss: 0.4488 - val_accuracy: 0.7881\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1634 - accuracy: 0.9339 - val_loss: 0.4482 - val_accuracy: 0.7922\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1370 - accuracy: 0.9515 - val_loss: 0.4384 - val_accuracy: 0.8014\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1315 - accuracy: 0.9511 - val_loss: 0.4586 - val_accuracy: 0.7737\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9422 - val_loss: 0.4586 - val_accuracy: 0.7613\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9396 - val_loss: 0.4731 - val_accuracy: 0.7757\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1489 - accuracy: 0.9440 - val_loss: 0.4597 - val_accuracy: 0.7870\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2136 - accuracy: 0.9405 - val_loss: 0.4898 - val_accuracy: 0.7613\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1289 - accuracy: 0.9489 - val_loss: 0.4704 - val_accuracy: 0.7829\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9414 - val_loss: 0.4411 - val_accuracy: 0.7819\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9462 - val_loss: 0.4467 - val_accuracy: 0.7973\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1281 - accuracy: 0.9466 - val_loss: 0.4051 - val_accuracy: 0.8128\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1599 - accuracy: 0.9493 - val_loss: 0.4289 - val_accuracy: 0.7870\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1647 - accuracy: 0.9519 - val_loss: 0.5018 - val_accuracy: 0.7654\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2530 - accuracy: 0.9480 - val_loss: 0.4328 - val_accuracy: 0.7922\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1626 - accuracy: 0.9436 - val_loss: 0.4630 - val_accuracy: 0.7870\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9489 - val_loss: 0.4154 - val_accuracy: 0.7932\n","Score: 0.7932098507881165 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9526 - accuracy: 0.9246 - val_loss: 0.5908 - val_accuracy: 0.6934\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1588 - accuracy: 0.9211 - val_loss: 0.5872 - val_accuracy: 0.6914\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1635 - accuracy: 0.9224 - val_loss: 0.5484 - val_accuracy: 0.7284\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3524 - accuracy: 0.9321 - val_loss: 0.5284 - val_accuracy: 0.7428\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9295 - val_loss: 0.5384 - val_accuracy: 0.7562\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1755 - accuracy: 0.9339 - val_loss: 0.4921 - val_accuracy: 0.7582\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9361 - val_loss: 0.4599 - val_accuracy: 0.7840\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1578 - accuracy: 0.9369 - val_loss: 0.4483 - val_accuracy: 0.7901\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1557 - accuracy: 0.9405 - val_loss: 0.4603 - val_accuracy: 0.7973\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1334 - accuracy: 0.9489 - val_loss: 0.4401 - val_accuracy: 0.8066\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9444 - val_loss: 0.4555 - val_accuracy: 0.7757\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1347 - accuracy: 0.9409 - val_loss: 0.4563 - val_accuracy: 0.7675\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1475 - accuracy: 0.9480 - val_loss: 0.4414 - val_accuracy: 0.7819\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1517 - accuracy: 0.9471 - val_loss: 0.4561 - val_accuracy: 0.7623\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9471 - val_loss: 0.4146 - val_accuracy: 0.8035\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3031 - accuracy: 0.9409 - val_loss: 0.4045 - val_accuracy: 0.8128\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1774 - accuracy: 0.9519 - val_loss: 0.4162 - val_accuracy: 0.8025\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1604 - accuracy: 0.9449 - val_loss: 0.4130 - val_accuracy: 0.8097\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9493 - val_loss: 0.3984 - val_accuracy: 0.8014\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1335 - accuracy: 0.9493 - val_loss: 0.4144 - val_accuracy: 0.8107\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1320 - accuracy: 0.9471 - val_loss: 0.3785 - val_accuracy: 0.8210\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1120 - accuracy: 0.9524 - val_loss: 0.4453 - val_accuracy: 0.7798\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1056 - accuracy: 0.9621 - val_loss: 0.3804 - val_accuracy: 0.8272\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1216 - accuracy: 0.9497 - val_loss: 0.3562 - val_accuracy: 0.8302\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1194 - accuracy: 0.9555 - val_loss: 0.4236 - val_accuracy: 0.8066\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3148 - accuracy: 0.9475 - val_loss: 0.4486 - val_accuracy: 0.7809\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9511 - val_loss: 0.3663 - val_accuracy: 0.8313\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1904 - accuracy: 0.9563 - val_loss: 0.3945 - val_accuracy: 0.8056\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1639 - accuracy: 0.9502 - val_loss: 0.3125 - val_accuracy: 0.8498\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1005 - accuracy: 0.9572 - val_loss: 0.3481 - val_accuracy: 0.8436\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1092 - accuracy: 0.9608 - val_loss: 0.3365 - val_accuracy: 0.8261\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1295 - accuracy: 0.9458 - val_loss: 0.4537 - val_accuracy: 0.8508\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0997 - accuracy: 0.9616 - val_loss: 0.3579 - val_accuracy: 0.8426\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1210 - accuracy: 0.9625 - val_loss: 0.4377 - val_accuracy: 0.8169\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0907 - accuracy: 0.9643 - val_loss: 0.4458 - val_accuracy: 0.8148\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1430 - accuracy: 0.9563 - val_loss: 0.3430 - val_accuracy: 0.8364\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9555 - val_loss: 0.3181 - val_accuracy: 0.8652\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1099 - accuracy: 0.9550 - val_loss: 0.4066 - val_accuracy: 0.7963\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1006 - accuracy: 0.9634 - val_loss: 0.3809 - val_accuracy: 0.8261\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1104 - accuracy: 0.9577 - val_loss: 0.2840 - val_accuracy: 0.8591\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1012 - accuracy: 0.9669 - val_loss: 0.3237 - val_accuracy: 0.8498\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1088 - accuracy: 0.9621 - val_loss: 0.3246 - val_accuracy: 0.8416\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0934 - accuracy: 0.9687 - val_loss: 0.2746 - val_accuracy: 0.8796\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1056 - accuracy: 0.9665 - val_loss: 0.3477 - val_accuracy: 0.8395\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0980 - accuracy: 0.9586 - val_loss: 0.3037 - val_accuracy: 0.8714\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1183 - accuracy: 0.9643 - val_loss: 0.2655 - val_accuracy: 0.8786\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9678 - val_loss: 0.2780 - val_accuracy: 0.8735\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0730 - accuracy: 0.9718 - val_loss: 0.2455 - val_accuracy: 0.8796\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0873 - accuracy: 0.9696 - val_loss: 0.3044 - val_accuracy: 0.8560\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0931 - accuracy: 0.9674 - val_loss: 0.2778 - val_accuracy: 0.8837\n","Score: 0.8837448358535767 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.2962 - accuracy: 0.9118 - val_loss: 0.6116 - val_accuracy: 0.7058\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1676 - accuracy: 0.9303 - val_loss: 0.6189 - val_accuracy: 0.6667\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1594 - accuracy: 0.9321 - val_loss: 0.6075 - val_accuracy: 0.6677\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1640 - accuracy: 0.9295 - val_loss: 0.5455 - val_accuracy: 0.6986\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2081 - accuracy: 0.9392 - val_loss: 0.5679 - val_accuracy: 0.7109\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9198 - val_loss: 0.6090 - val_accuracy: 0.6193\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1758 - accuracy: 0.9264 - val_loss: 0.5722 - val_accuracy: 0.6955\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1719 - accuracy: 0.9387 - val_loss: 0.6194 - val_accuracy: 0.6842\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1696 - accuracy: 0.9378 - val_loss: 0.5059 - val_accuracy: 0.7438\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1429 - accuracy: 0.9489 - val_loss: 0.4893 - val_accuracy: 0.7531\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1396 - accuracy: 0.9511 - val_loss: 0.4962 - val_accuracy: 0.7726\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1595 - accuracy: 0.9405 - val_loss: 0.5289 - val_accuracy: 0.7377\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9374 - val_loss: 0.4561 - val_accuracy: 0.7840\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3228 - accuracy: 0.9466 - val_loss: 0.4908 - val_accuracy: 0.7582\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1765 - accuracy: 0.9427 - val_loss: 0.7798 - val_accuracy: 0.6574\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1714 - accuracy: 0.9506 - val_loss: 0.4498 - val_accuracy: 0.7788\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1294 - accuracy: 0.9541 - val_loss: 0.5033 - val_accuracy: 0.7613\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1375 - accuracy: 0.9440 - val_loss: 0.4670 - val_accuracy: 0.7665\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1406 - accuracy: 0.9431 - val_loss: 0.4736 - val_accuracy: 0.7840\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2577 - accuracy: 0.9427 - val_loss: 0.4795 - val_accuracy: 0.7860\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2761 - accuracy: 0.9475 - val_loss: 0.4378 - val_accuracy: 0.7984\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1190 - accuracy: 0.9581 - val_loss: 0.4120 - val_accuracy: 0.8045\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1455 - accuracy: 0.9453 - val_loss: 0.4225 - val_accuracy: 0.7973\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.4214 - val_accuracy: 0.8086\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1432 - accuracy: 0.9550 - val_loss: 0.3916 - val_accuracy: 0.8045\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1080 - accuracy: 0.9541 - val_loss: 0.4597 - val_accuracy: 0.7870\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9519 - val_loss: 0.3936 - val_accuracy: 0.8241\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9559 - val_loss: 0.4046 - val_accuracy: 0.8076\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1472 - accuracy: 0.9466 - val_loss: 0.5391 - val_accuracy: 0.7665\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1228 - accuracy: 0.9506 - val_loss: 0.3557 - val_accuracy: 0.8374\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9497 - val_loss: 0.3874 - val_accuracy: 0.8261\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1554 - accuracy: 0.9524 - val_loss: 0.4162 - val_accuracy: 0.8097\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9493 - val_loss: 0.3970 - val_accuracy: 0.8241\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9568 - val_loss: 0.3965 - val_accuracy: 0.8158\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2966 - accuracy: 0.9563 - val_loss: 0.4268 - val_accuracy: 0.8210\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9608 - val_loss: 0.4873 - val_accuracy: 0.7829\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1227 - accuracy: 0.9511 - val_loss: 0.4099 - val_accuracy: 0.8148\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9475 - val_loss: 0.4082 - val_accuracy: 0.8076\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3794 - accuracy: 0.9422 - val_loss: 0.4071 - val_accuracy: 0.8056\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9506 - val_loss: 0.3962 - val_accuracy: 0.8138\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1178 - accuracy: 0.9546 - val_loss: 0.3824 - val_accuracy: 0.8210\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1182 - accuracy: 0.9581 - val_loss: 0.3860 - val_accuracy: 0.8117\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9541 - val_loss: 0.3783 - val_accuracy: 0.8251\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1070 - accuracy: 0.9634 - val_loss: 0.3779 - val_accuracy: 0.8292\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1183 - accuracy: 0.9550 - val_loss: 0.3117 - val_accuracy: 0.8580\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1173 - accuracy: 0.9555 - val_loss: 0.3427 - val_accuracy: 0.8549\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0991 - accuracy: 0.9612 - val_loss: 0.3735 - val_accuracy: 0.8333\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1255 - accuracy: 0.9625 - val_loss: 0.3647 - val_accuracy: 0.8354\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1063 - accuracy: 0.9608 - val_loss: 0.3423 - val_accuracy: 0.8549\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1267 - accuracy: 0.9550 - val_loss: 0.3798 - val_accuracy: 0.8282\n","Score: 0.8281893134117126 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 4852.9238 - accuracy: 0.8959 - val_loss: 0.6920 - val_accuracy: 0.5175\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2237 - accuracy: 0.9149 - val_loss: 0.6942 - val_accuracy: 0.4774\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2393 - accuracy: 0.9127 - val_loss: 0.6928 - val_accuracy: 0.5165\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2308 - accuracy: 0.9215 - val_loss: 0.6961 - val_accuracy: 0.5103\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2283 - accuracy: 0.9193 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2391 - accuracy: 0.9158 - val_loss: 0.6972 - val_accuracy: 0.5165\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2317 - accuracy: 0.9136 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2387 - accuracy: 0.9136 - val_loss: 0.6941 - val_accuracy: 0.5123\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2408 - accuracy: 0.9118 - val_loss: 0.6952 - val_accuracy: 0.5165\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2398 - accuracy: 0.9118 - val_loss: 0.6919 - val_accuracy: 0.5216\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2358 - accuracy: 0.9162 - val_loss: 0.6963 - val_accuracy: 0.5041\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2361 - accuracy: 0.9193 - val_loss: 0.6996 - val_accuracy: 0.5082\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2378 - accuracy: 0.9127 - val_loss: 0.6927 - val_accuracy: 0.5195\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2384 - accuracy: 0.9180 - val_loss: 0.6934 - val_accuracy: 0.5041\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2375 - accuracy: 0.9167 - val_loss: 0.6943 - val_accuracy: 0.5093\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2413 - accuracy: 0.9153 - val_loss: 0.7064 - val_accuracy: 0.5103\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2345 - accuracy: 0.9171 - val_loss: 0.6910 - val_accuracy: 0.5360\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2369 - accuracy: 0.9162 - val_loss: 0.6937 - val_accuracy: 0.5113\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2431 - accuracy: 0.9114 - val_loss: 0.6921 - val_accuracy: 0.5267\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2393 - accuracy: 0.9158 - val_loss: 0.7010 - val_accuracy: 0.5072\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2323 - accuracy: 0.9162 - val_loss: 0.6924 - val_accuracy: 0.5206\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2478 - accuracy: 0.9105 - val_loss: 0.6995 - val_accuracy: 0.5093\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2448 - accuracy: 0.9105 - val_loss: 0.6939 - val_accuracy: 0.5072\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2334 - accuracy: 0.9193 - val_loss: 0.6975 - val_accuracy: 0.5134\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2448 - accuracy: 0.9030 - val_loss: 0.6934 - val_accuracy: 0.4805\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2388 - accuracy: 0.9096 - val_loss: 0.6967 - val_accuracy: 0.4763\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2469 - accuracy: 0.9017 - val_loss: 0.6930 - val_accuracy: 0.5154\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2476 - accuracy: 0.9131 - val_loss: 0.7031 - val_accuracy: 0.5154\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2329 - accuracy: 0.9153 - val_loss: 0.6945 - val_accuracy: 0.4938\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2466 - accuracy: 0.9056 - val_loss: 0.6958 - val_accuracy: 0.5062\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2335 - accuracy: 0.9193 - val_loss: 0.6968 - val_accuracy: 0.5134\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2431 - accuracy: 0.9105 - val_loss: 0.6918 - val_accuracy: 0.5309\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2402 - accuracy: 0.9162 - val_loss: 0.6985 - val_accuracy: 0.5134\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2358 - accuracy: 0.9206 - val_loss: 0.6985 - val_accuracy: 0.5237\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2472 - accuracy: 0.9109 - val_loss: 0.7016 - val_accuracy: 0.5206\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2382 - accuracy: 0.9158 - val_loss: 0.7025 - val_accuracy: 0.5185\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2460 - accuracy: 0.9078 - val_loss: 0.6932 - val_accuracy: 0.5144\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2445 - accuracy: 0.9140 - val_loss: 0.6950 - val_accuracy: 0.4990\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2311 - accuracy: 0.9224 - val_loss: 0.6960 - val_accuracy: 0.5134\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2412 - accuracy: 0.9114 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2435 - accuracy: 0.9149 - val_loss: 0.6960 - val_accuracy: 0.5123\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2418 - accuracy: 0.9149 - val_loss: 0.6971 - val_accuracy: 0.5134\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2312 - accuracy: 0.9224 - val_loss: 0.7053 - val_accuracy: 0.5123\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2348 - accuracy: 0.9167 - val_loss: 0.6952 - val_accuracy: 0.5113\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2382 - accuracy: 0.9127 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2425 - accuracy: 0.9145 - val_loss: 0.6934 - val_accuracy: 0.5123\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2423 - accuracy: 0.9123 - val_loss: 0.6931 - val_accuracy: 0.5165\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2500 - accuracy: 0.9096 - val_loss: 0.7011 - val_accuracy: 0.5072\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2420 - accuracy: 0.9184 - val_loss: 0.7113 - val_accuracy: 0.5123\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2335 - accuracy: 0.9180 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Score: 0.5123456716537476 \n","Parameters:  {'learning_rate': 0.03511468874393753, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6235 - accuracy: 0.9264 - val_loss: 0.6128 - val_accuracy: 0.6903\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1565 - accuracy: 0.9303 - val_loss: 0.5945 - val_accuracy: 0.7140\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1840 - accuracy: 0.9378 - val_loss: 0.5380 - val_accuracy: 0.7449\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1747 - accuracy: 0.9295 - val_loss: 0.5532 - val_accuracy: 0.7294\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1563 - accuracy: 0.9343 - val_loss: 0.5594 - val_accuracy: 0.7202\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1595 - accuracy: 0.9361 - val_loss: 0.5104 - val_accuracy: 0.7757\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9414 - val_loss: 0.4887 - val_accuracy: 0.7767\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9436 - val_loss: 0.5354 - val_accuracy: 0.6986\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9431 - val_loss: 0.4713 - val_accuracy: 0.7891\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1411 - accuracy: 0.9414 - val_loss: 0.4538 - val_accuracy: 0.7860\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1328 - accuracy: 0.9466 - val_loss: 0.5077 - val_accuracy: 0.7459\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9511 - val_loss: 0.4939 - val_accuracy: 0.7644\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1671 - accuracy: 0.9480 - val_loss: 0.4390 - val_accuracy: 0.7840\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1546 - accuracy: 0.9506 - val_loss: 0.4034 - val_accuracy: 0.8086\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9466 - val_loss: 0.4102 - val_accuracy: 0.8251\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1126 - accuracy: 0.9533 - val_loss: 0.4423 - val_accuracy: 0.7932\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1349 - accuracy: 0.9537 - val_loss: 0.3945 - val_accuracy: 0.8302\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1628 - accuracy: 0.9519 - val_loss: 0.4137 - val_accuracy: 0.8179\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9458 - val_loss: 0.3751 - val_accuracy: 0.8333\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3546 - accuracy: 0.9533 - val_loss: 0.4172 - val_accuracy: 0.8097\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9462 - val_loss: 0.4834 - val_accuracy: 0.7603\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1545 - accuracy: 0.9414 - val_loss: 0.5742 - val_accuracy: 0.7284\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1605 - accuracy: 0.9325 - val_loss: 0.4596 - val_accuracy: 0.7757\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3774 - accuracy: 0.9431 - val_loss: 0.4854 - val_accuracy: 0.7994\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.9475 - val_loss: 0.4530 - val_accuracy: 0.7850\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1537 - accuracy: 0.9436 - val_loss: 0.4997 - val_accuracy: 0.7767\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9466 - val_loss: 0.5122 - val_accuracy: 0.7479\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1663 - accuracy: 0.9440 - val_loss: 0.4476 - val_accuracy: 0.7973\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1566 - accuracy: 0.9453 - val_loss: 0.4443 - val_accuracy: 0.7942\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1639 - accuracy: 0.9449 - val_loss: 0.4534 - val_accuracy: 0.7870\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1893 - accuracy: 0.9511 - val_loss: 0.4531 - val_accuracy: 0.7973\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4397 - accuracy: 0.9361 - val_loss: 0.4755 - val_accuracy: 0.7809\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1490 - accuracy: 0.9414 - val_loss: 0.4536 - val_accuracy: 0.7942\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1507 - accuracy: 0.9502 - val_loss: 0.5087 - val_accuracy: 0.7551\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1377 - accuracy: 0.9458 - val_loss: 0.3935 - val_accuracy: 0.8313\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1379 - accuracy: 0.9475 - val_loss: 0.4338 - val_accuracy: 0.8097\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9493 - val_loss: 0.4283 - val_accuracy: 0.7953\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3167 - accuracy: 0.9453 - val_loss: 0.4096 - val_accuracy: 0.8117\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1590 - accuracy: 0.9444 - val_loss: 0.4371 - val_accuracy: 0.8056\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1193 - accuracy: 0.9511 - val_loss: 0.4113 - val_accuracy: 0.8045\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1384 - accuracy: 0.9462 - val_loss: 0.4075 - val_accuracy: 0.8045\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9489 - val_loss: 0.4327 - val_accuracy: 0.8066\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1429 - accuracy: 0.9436 - val_loss: 0.3842 - val_accuracy: 0.8241\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9422 - val_loss: 0.3913 - val_accuracy: 0.8272\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1421 - accuracy: 0.9546 - val_loss: 0.3922 - val_accuracy: 0.8148\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1410 - accuracy: 0.9458 - val_loss: 0.4617 - val_accuracy: 0.7809\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9546 - val_loss: 0.4402 - val_accuracy: 0.8117\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1175 - accuracy: 0.9528 - val_loss: 0.4319 - val_accuracy: 0.8148\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1272 - accuracy: 0.9511 - val_loss: 0.4137 - val_accuracy: 0.8220\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.9572 - val_loss: 0.3595 - val_accuracy: 0.8580\n","Score: 0.8580247163772583 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 3326.0422 - accuracy: 0.9004 - val_loss: 0.7154 - val_accuracy: 0.4763\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2364 - accuracy: 0.9061 - val_loss: 0.6979 - val_accuracy: 0.5206\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2345 - accuracy: 0.9145 - val_loss: 0.6976 - val_accuracy: 0.5062\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2245 - accuracy: 0.9136 - val_loss: 0.6995 - val_accuracy: 0.4815\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2462 - accuracy: 0.8990 - val_loss: 0.7000 - val_accuracy: 0.5062\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2311 - accuracy: 0.9149 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2324 - accuracy: 0.9171 - val_loss: 0.6965 - val_accuracy: 0.5195\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2267 - accuracy: 0.9215 - val_loss: 0.6993 - val_accuracy: 0.5185\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2213 - accuracy: 0.9184 - val_loss: 0.6929 - val_accuracy: 0.5216\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2344 - accuracy: 0.9118 - val_loss: 0.6957 - val_accuracy: 0.5123\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2230 - accuracy: 0.9189 - val_loss: 0.6948 - val_accuracy: 0.5051\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2395 - accuracy: 0.9109 - val_loss: 0.6977 - val_accuracy: 0.5123\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2339 - accuracy: 0.9109 - val_loss: 0.6939 - val_accuracy: 0.5000\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2237 - accuracy: 0.9215 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2291 - accuracy: 0.9167 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2256 - accuracy: 0.9198 - val_loss: 0.6930 - val_accuracy: 0.5134\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2376 - accuracy: 0.9096 - val_loss: 0.6959 - val_accuracy: 0.5082\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.9087 - val_loss: 0.7022 - val_accuracy: 0.5113\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2351 - accuracy: 0.9105 - val_loss: 0.6931 - val_accuracy: 0.5093\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2341 - accuracy: 0.9149 - val_loss: 0.6986 - val_accuracy: 0.4990\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2348 - accuracy: 0.9145 - val_loss: 0.7032 - val_accuracy: 0.5093\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2359 - accuracy: 0.9118 - val_loss: 0.6962 - val_accuracy: 0.5134\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2419 - accuracy: 0.9092 - val_loss: 0.6956 - val_accuracy: 0.5021\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2291 - accuracy: 0.9127 - val_loss: 0.6953 - val_accuracy: 0.5113\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2199 - accuracy: 0.9246 - val_loss: 0.6968 - val_accuracy: 0.5123\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2338 - accuracy: 0.9114 - val_loss: 0.6912 - val_accuracy: 0.5329\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2302 - accuracy: 0.9180 - val_loss: 0.6939 - val_accuracy: 0.5051\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2326 - accuracy: 0.9087 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2341 - accuracy: 0.9162 - val_loss: 0.6948 - val_accuracy: 0.5021\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2380 - accuracy: 0.9140 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2295 - accuracy: 0.9193 - val_loss: 0.6954 - val_accuracy: 0.5082\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2360 - accuracy: 0.9153 - val_loss: 0.6968 - val_accuracy: 0.5309\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2290 - accuracy: 0.9162 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2258 - accuracy: 0.9180 - val_loss: 0.6934 - val_accuracy: 0.5072\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.9180 - val_loss: 0.6965 - val_accuracy: 0.5216\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2331 - accuracy: 0.9153 - val_loss: 0.6956 - val_accuracy: 0.5103\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2345 - accuracy: 0.9114 - val_loss: 0.6929 - val_accuracy: 0.5134\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2407 - accuracy: 0.9127 - val_loss: 0.7035 - val_accuracy: 0.5154\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.9109 - val_loss: 0.6955 - val_accuracy: 0.4815\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2339 - accuracy: 0.9096 - val_loss: 0.7132 - val_accuracy: 0.5185\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2319 - accuracy: 0.9131 - val_loss: 0.6942 - val_accuracy: 0.5226\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2252 - accuracy: 0.9189 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2388 - accuracy: 0.9131 - val_loss: 0.7162 - val_accuracy: 0.4928\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2450 - accuracy: 0.8880 - val_loss: 0.6930 - val_accuracy: 0.5144\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2303 - accuracy: 0.9180 - val_loss: 0.6961 - val_accuracy: 0.5062\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2371 - accuracy: 0.9145 - val_loss: 0.6951 - val_accuracy: 0.5216\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2333 - accuracy: 0.9184 - val_loss: 0.6971 - val_accuracy: 0.5216\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9246 - val_loss: 0.7062 - val_accuracy: 0.5082\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2274 - accuracy: 0.9158 - val_loss: 0.6938 - val_accuracy: 0.4877\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2431 - accuracy: 0.9096 - val_loss: 0.7240 - val_accuracy: 0.5010\n","Score: 0.501028835773468 \n","Parameters:  {'learning_rate': 0.03892487220165136, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6970 - accuracy: 0.9242 - val_loss: 0.5974 - val_accuracy: 0.6924\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1676 - accuracy: 0.9290 - val_loss: 0.5695 - val_accuracy: 0.7099\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1740 - accuracy: 0.9220 - val_loss: 0.5506 - val_accuracy: 0.6862\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9083 - val_loss: 0.6909 - val_accuracy: 0.4794\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1624 - accuracy: 0.9268 - val_loss: 0.4919 - val_accuracy: 0.7767\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1474 - accuracy: 0.9414 - val_loss: 0.5029 - val_accuracy: 0.7397\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1416 - accuracy: 0.9427 - val_loss: 0.4869 - val_accuracy: 0.7757\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1481 - accuracy: 0.9480 - val_loss: 0.4323 - val_accuracy: 0.8025\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4091 - accuracy: 0.9418 - val_loss: 0.4586 - val_accuracy: 0.7901\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1492 - accuracy: 0.9444 - val_loss: 0.4485 - val_accuracy: 0.8025\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9453 - val_loss: 0.4275 - val_accuracy: 0.7850\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1263 - accuracy: 0.9550 - val_loss: 0.4552 - val_accuracy: 0.7829\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.9541 - val_loss: 0.4045 - val_accuracy: 0.8086\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1665 - accuracy: 0.9453 - val_loss: 0.4621 - val_accuracy: 0.7881\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1413 - accuracy: 0.9361 - val_loss: 0.4348 - val_accuracy: 0.8097\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.9550 - val_loss: 0.3976 - val_accuracy: 0.8097\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9577 - val_loss: 0.4284 - val_accuracy: 0.8189\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1603 - accuracy: 0.9440 - val_loss: 0.5208 - val_accuracy: 0.7274\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1338 - accuracy: 0.9444 - val_loss: 0.3775 - val_accuracy: 0.8128\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9519 - val_loss: 0.4483 - val_accuracy: 0.8014\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1183 - accuracy: 0.9524 - val_loss: 0.3851 - val_accuracy: 0.8200\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1195 - accuracy: 0.9546 - val_loss: 0.3970 - val_accuracy: 0.8189\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1188 - accuracy: 0.9568 - val_loss: 0.3831 - val_accuracy: 0.8364\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9453 - val_loss: 0.4159 - val_accuracy: 0.8107\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1090 - accuracy: 0.9586 - val_loss: 0.3798 - val_accuracy: 0.8200\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1454 - accuracy: 0.9511 - val_loss: 0.3701 - val_accuracy: 0.8313\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1147 - accuracy: 0.9524 - val_loss: 0.4358 - val_accuracy: 0.7932\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9515 - val_loss: 0.3995 - val_accuracy: 0.7922\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1157 - accuracy: 0.9590 - val_loss: 0.4489 - val_accuracy: 0.7994\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1130 - accuracy: 0.9502 - val_loss: 0.3531 - val_accuracy: 0.8354\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9577 - val_loss: 0.3611 - val_accuracy: 0.8302\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1162 - accuracy: 0.9546 - val_loss: 0.3443 - val_accuracy: 0.8416\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1127 - accuracy: 0.9590 - val_loss: 0.3657 - val_accuracy: 0.8200\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2766 - accuracy: 0.9559 - val_loss: 0.3468 - val_accuracy: 0.8416\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1156 - accuracy: 0.9572 - val_loss: 0.3359 - val_accuracy: 0.8405\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1414 - accuracy: 0.9572 - val_loss: 0.3251 - val_accuracy: 0.8457\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1036 - accuracy: 0.9563 - val_loss: 0.3391 - val_accuracy: 0.8457\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1069 - accuracy: 0.9537 - val_loss: 0.3313 - val_accuracy: 0.8560\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1162 - accuracy: 0.9537 - val_loss: 0.3272 - val_accuracy: 0.8467\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1423 - accuracy: 0.9621 - val_loss: 0.3339 - val_accuracy: 0.8416\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1083 - accuracy: 0.9594 - val_loss: 0.3100 - val_accuracy: 0.8519\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0981 - accuracy: 0.9630 - val_loss: 0.3527 - val_accuracy: 0.8220\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0971 - accuracy: 0.9608 - val_loss: 0.3260 - val_accuracy: 0.8529\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1022 - accuracy: 0.9612 - val_loss: 0.3337 - val_accuracy: 0.8354\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1406 - accuracy: 0.9608 - val_loss: 0.3288 - val_accuracy: 0.8560\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1041 - accuracy: 0.9594 - val_loss: 0.2660 - val_accuracy: 0.8827\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0972 - accuracy: 0.9638 - val_loss: 0.2868 - val_accuracy: 0.8621\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1422 - accuracy: 0.9621 - val_loss: 0.2963 - val_accuracy: 0.8673\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1721 - accuracy: 0.9594 - val_loss: 0.3351 - val_accuracy: 0.8457\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1256 - accuracy: 0.9669 - val_loss: 0.2895 - val_accuracy: 0.8724\n","Score: 0.8724279999732971 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 177947.3750 - accuracy: 0.9004 - val_loss: 0.6930 - val_accuracy: 0.5113\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9123 - val_loss: 0.6935 - val_accuracy: 0.4815\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9096 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9198 - val_loss: 0.7060 - val_accuracy: 0.4774\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9105 - val_loss: 0.7265 - val_accuracy: 0.4866\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2086 - accuracy: 0.9008 - val_loss: 0.7073 - val_accuracy: 0.5113\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9061 - val_loss: 0.6972 - val_accuracy: 0.4877\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9061 - val_loss: 0.7296 - val_accuracy: 0.5103\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9026 - val_loss: 0.6949 - val_accuracy: 0.4640\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9127 - val_loss: 0.7013 - val_accuracy: 0.4733\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9078 - val_loss: 0.6930 - val_accuracy: 0.5185\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9070 - val_loss: 0.7161 - val_accuracy: 0.5113\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9087 - val_loss: 0.7331 - val_accuracy: 0.4774\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2112 - accuracy: 0.8986 - val_loss: 0.7013 - val_accuracy: 0.5154\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9180 - val_loss: 0.6956 - val_accuracy: 0.4691\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2058 - accuracy: 0.9074 - val_loss: 0.6937 - val_accuracy: 0.5051\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9070 - val_loss: 0.7027 - val_accuracy: 0.5175\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9070 - val_loss: 0.7053 - val_accuracy: 0.4722\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9092 - val_loss: 0.7076 - val_accuracy: 0.5021\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1880 - accuracy: 0.9136 - val_loss: 0.7121 - val_accuracy: 0.4784\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9123 - val_loss: 0.7158 - val_accuracy: 0.4815\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9012 - val_loss: 0.6937 - val_accuracy: 0.4918\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9105 - val_loss: 0.6952 - val_accuracy: 0.4990\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9105 - val_loss: 0.6936 - val_accuracy: 0.4825\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9026 - val_loss: 0.7061 - val_accuracy: 0.5267\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.9114 - val_loss: 0.6951 - val_accuracy: 0.5051\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9008 - val_loss: 0.6998 - val_accuracy: 0.4794\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1997 - accuracy: 0.9026 - val_loss: 0.6989 - val_accuracy: 0.5021\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9224 - val_loss: 0.7554 - val_accuracy: 0.5031\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9162 - val_loss: 0.7082 - val_accuracy: 0.4835\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9101 - val_loss: 0.6952 - val_accuracy: 0.5093\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.9127 - val_loss: 0.6966 - val_accuracy: 0.5113\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.9167 - val_loss: 0.6957 - val_accuracy: 0.5123\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.9017 - val_loss: 0.7342 - val_accuracy: 0.4938\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2093 - accuracy: 0.9140 - val_loss: 0.6948 - val_accuracy: 0.4722\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2100 - accuracy: 0.9056 - val_loss: 0.7572 - val_accuracy: 0.5257\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9140 - val_loss: 0.6978 - val_accuracy: 0.5144\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9184 - val_loss: 0.7399 - val_accuracy: 0.5072\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9078 - val_loss: 0.6907 - val_accuracy: 0.5401\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9158 - val_loss: 0.6930 - val_accuracy: 0.5247\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9228 - val_loss: 0.7094 - val_accuracy: 0.5144\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9145 - val_loss: 0.7097 - val_accuracy: 0.5319\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2005 - accuracy: 0.9180 - val_loss: 0.7397 - val_accuracy: 0.5123\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9149 - val_loss: 0.7240 - val_accuracy: 0.4897\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9123 - val_loss: 0.7102 - val_accuracy: 0.5175\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2091 - accuracy: 0.9070 - val_loss: 0.7017 - val_accuracy: 0.4938\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9078 - val_loss: 0.7315 - val_accuracy: 0.5072\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9074 - val_loss: 0.6928 - val_accuracy: 0.5247\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9149 - val_loss: 0.7032 - val_accuracy: 0.5093\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9167 - val_loss: 0.7454 - val_accuracy: 0.5134\n","Score: 0.5133745074272156 \n","Parameters:  {'learning_rate': 0.10318796120356365, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 254232.0938 - accuracy: 0.8933 - val_loss: 0.9491 - val_accuracy: 0.4979\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5068 - accuracy: 0.8898 - val_loss: 1.7371 - val_accuracy: 0.4815\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3076 - accuracy: 0.8973 - val_loss: 0.9079 - val_accuracy: 0.4918\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2290 - accuracy: 0.9061 - val_loss: 0.6932 - val_accuracy: 0.5113\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2020 - accuracy: 0.9061 - val_loss: 0.9019 - val_accuracy: 0.5000\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2105 - accuracy: 0.8977 - val_loss: 0.7595 - val_accuracy: 0.4949\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2426 - accuracy: 0.8946 - val_loss: 0.8307 - val_accuracy: 0.5041\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2333 - accuracy: 0.8977 - val_loss: 1.0103 - val_accuracy: 0.4825\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2290 - accuracy: 0.8937 - val_loss: 0.8439 - val_accuracy: 0.5062\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9017 - val_loss: 1.2816 - val_accuracy: 0.5175\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1829 - accuracy: 0.9017 - val_loss: 0.9059 - val_accuracy: 0.5247\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9092 - val_loss: 0.7065 - val_accuracy: 0.5103\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2286 - accuracy: 0.8942 - val_loss: 0.6907 - val_accuracy: 0.5360\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.8995 - val_loss: 0.7087 - val_accuracy: 0.4887\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9087 - val_loss: 0.6926 - val_accuracy: 0.5195\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.9026 - val_loss: 0.7096 - val_accuracy: 0.5000\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2175 - accuracy: 0.8986 - val_loss: 0.7678 - val_accuracy: 0.5319\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2097 - accuracy: 0.9048 - val_loss: 0.7188 - val_accuracy: 0.5062\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9109 - val_loss: 0.7473 - val_accuracy: 0.5185\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9061 - val_loss: 0.6992 - val_accuracy: 0.4712\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9140 - val_loss: 0.7374 - val_accuracy: 0.4918\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9048 - val_loss: 0.7213 - val_accuracy: 0.5247\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.8893 - val_loss: 0.7311 - val_accuracy: 0.5185\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.8999 - val_loss: 0.8005 - val_accuracy: 0.4907\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9034 - val_loss: 0.7032 - val_accuracy: 0.5072\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9004 - val_loss: 0.7611 - val_accuracy: 0.4681\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9021 - val_loss: 0.7805 - val_accuracy: 0.4866\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9118 - val_loss: 0.6973 - val_accuracy: 0.5051\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1803 - accuracy: 0.9193 - val_loss: 0.7548 - val_accuracy: 0.4722\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9043 - val_loss: 0.8654 - val_accuracy: 0.5154\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9012 - val_loss: 0.7442 - val_accuracy: 0.4784\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9052 - val_loss: 0.6951 - val_accuracy: 0.5041\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9048 - val_loss: 0.6983 - val_accuracy: 0.5082\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9136 - val_loss: 0.7106 - val_accuracy: 0.4866\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9123 - val_loss: 0.7059 - val_accuracy: 0.4928\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9105 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2059 - accuracy: 0.9083 - val_loss: 0.6977 - val_accuracy: 0.5278\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9193 - val_loss: 0.6994 - val_accuracy: 0.5062\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9118 - val_loss: 0.7081 - val_accuracy: 0.4835\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9149 - val_loss: 0.7069 - val_accuracy: 0.5154\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9096 - val_loss: 0.7070 - val_accuracy: 0.5247\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9153 - val_loss: 0.6938 - val_accuracy: 0.5010\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9043 - val_loss: 0.6939 - val_accuracy: 0.4763\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9145 - val_loss: 0.7105 - val_accuracy: 0.4887\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2116 - accuracy: 0.9039 - val_loss: 0.7325 - val_accuracy: 0.4938\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2075 - accuracy: 0.9017 - val_loss: 0.7040 - val_accuracy: 0.5072\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9123 - val_loss: 0.7198 - val_accuracy: 0.4897\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2152 - accuracy: 0.9012 - val_loss: 0.7226 - val_accuracy: 0.5267\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9078 - val_loss: 0.6928 - val_accuracy: 0.5298\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9189 - val_loss: 0.6955 - val_accuracy: 0.5309\n","Score: 0.5308641791343689 \n","Parameters:  {'learning_rate': 0.10063994960294136, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7474 - accuracy: 0.9211 - val_loss: 0.6559 - val_accuracy: 0.6317\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1732 - accuracy: 0.9175 - val_loss: 0.6061 - val_accuracy: 0.6029\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1569 - accuracy: 0.9374 - val_loss: 0.4839 - val_accuracy: 0.7840\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9220 - val_loss: 0.5574 - val_accuracy: 0.7459\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9405 - val_loss: 0.4913 - val_accuracy: 0.7572\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9444 - val_loss: 0.4785 - val_accuracy: 0.7685\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1490 - accuracy: 0.9378 - val_loss: 0.5464 - val_accuracy: 0.7181\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9458 - val_loss: 0.4823 - val_accuracy: 0.7593\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1303 - accuracy: 0.9502 - val_loss: 0.4626 - val_accuracy: 0.7747\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1389 - accuracy: 0.9458 - val_loss: 0.4541 - val_accuracy: 0.7788\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9475 - val_loss: 0.4691 - val_accuracy: 0.7572\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1396 - accuracy: 0.9440 - val_loss: 0.4434 - val_accuracy: 0.7819\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1462 - accuracy: 0.9466 - val_loss: 0.4140 - val_accuracy: 0.8025\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9533 - val_loss: 0.3888 - val_accuracy: 0.8169\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9493 - val_loss: 0.3846 - val_accuracy: 0.8210\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1119 - accuracy: 0.9546 - val_loss: 0.3552 - val_accuracy: 0.8323\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1867 - accuracy: 0.9586 - val_loss: 0.3628 - val_accuracy: 0.8241\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1217 - accuracy: 0.9515 - val_loss: 0.3761 - val_accuracy: 0.8117\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1296 - accuracy: 0.9572 - val_loss: 0.4054 - val_accuracy: 0.8014\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1095 - accuracy: 0.9550 - val_loss: 0.4232 - val_accuracy: 0.8117\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1226 - accuracy: 0.9519 - val_loss: 0.3598 - val_accuracy: 0.8302\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1118 - accuracy: 0.9511 - val_loss: 0.3840 - val_accuracy: 0.8189\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3266 - accuracy: 0.9541 - val_loss: 0.4374 - val_accuracy: 0.8313\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9484 - val_loss: 0.3557 - val_accuracy: 0.8302\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1836 - accuracy: 0.9577 - val_loss: 0.3699 - val_accuracy: 0.8251\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1182 - accuracy: 0.9502 - val_loss: 0.3575 - val_accuracy: 0.8416\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1421 - accuracy: 0.9563 - val_loss: 0.4283 - val_accuracy: 0.7891\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9577 - val_loss: 0.3690 - val_accuracy: 0.8580\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9541 - val_loss: 0.3536 - val_accuracy: 0.8364\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1082 - accuracy: 0.9616 - val_loss: 0.3439 - val_accuracy: 0.8302\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9577 - val_loss: 0.3289 - val_accuracy: 0.8498\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1313 - accuracy: 0.9546 - val_loss: 0.3794 - val_accuracy: 0.8230\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9559 - val_loss: 0.3400 - val_accuracy: 0.8508\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2577 - accuracy: 0.9506 - val_loss: 0.3928 - val_accuracy: 0.8056\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.9537 - val_loss: 0.3791 - val_accuracy: 0.8364\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4099 - accuracy: 0.9502 - val_loss: 0.3717 - val_accuracy: 0.8333\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1354 - accuracy: 0.9572 - val_loss: 0.3698 - val_accuracy: 0.8323\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1071 - accuracy: 0.9541 - val_loss: 0.3337 - val_accuracy: 0.8344\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1151 - accuracy: 0.9533 - val_loss: 0.3399 - val_accuracy: 0.8292\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0893 - accuracy: 0.9656 - val_loss: 0.3274 - val_accuracy: 0.8591\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0881 - accuracy: 0.9638 - val_loss: 0.3360 - val_accuracy: 0.8508\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1048 - accuracy: 0.9550 - val_loss: 0.2904 - val_accuracy: 0.8693\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0911 - accuracy: 0.9616 - val_loss: 0.2986 - val_accuracy: 0.8611\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0988 - accuracy: 0.9634 - val_loss: 0.3532 - val_accuracy: 0.8549\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1025 - accuracy: 0.9603 - val_loss: 0.3133 - val_accuracy: 0.8621\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1005 - accuracy: 0.9603 - val_loss: 0.3579 - val_accuracy: 0.8570\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1035 - accuracy: 0.9625 - val_loss: 0.3190 - val_accuracy: 0.8704\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0919 - accuracy: 0.9678 - val_loss: 0.3838 - val_accuracy: 0.8519\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0971 - accuracy: 0.9577 - val_loss: 0.3283 - val_accuracy: 0.8436\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1279 - accuracy: 0.9563 - val_loss: 0.2910 - val_accuracy: 0.8673\n","Score: 0.8672839403152466 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 23630.7344 - accuracy: 0.9078 - val_loss: 0.6992 - val_accuracy: 0.4856\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2089 - accuracy: 0.9096 - val_loss: 0.6934 - val_accuracy: 0.4825\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9131 - val_loss: 0.6930 - val_accuracy: 0.5082\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2247 - accuracy: 0.9127 - val_loss: 0.6942 - val_accuracy: 0.5267\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2142 - accuracy: 0.9167 - val_loss: 0.6927 - val_accuracy: 0.5216\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9105 - val_loss: 0.6952 - val_accuracy: 0.4784\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2236 - accuracy: 0.8990 - val_loss: 0.6934 - val_accuracy: 0.4959\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2175 - accuracy: 0.9145 - val_loss: 0.6912 - val_accuracy: 0.5329\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2211 - accuracy: 0.9083 - val_loss: 0.7012 - val_accuracy: 0.4835\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9043 - val_loss: 0.6936 - val_accuracy: 0.5010\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9180 - val_loss: 0.6930 - val_accuracy: 0.5082\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2255 - accuracy: 0.9145 - val_loss: 0.6938 - val_accuracy: 0.5082\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2112 - accuracy: 0.9198 - val_loss: 0.7171 - val_accuracy: 0.5082\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2173 - accuracy: 0.9070 - val_loss: 0.6982 - val_accuracy: 0.4897\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2213 - accuracy: 0.9083 - val_loss: 0.6970 - val_accuracy: 0.4990\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.9127 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9149 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2172 - accuracy: 0.9149 - val_loss: 0.6985 - val_accuracy: 0.4938\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2286 - accuracy: 0.8990 - val_loss: 0.6939 - val_accuracy: 0.4897\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9008 - val_loss: 0.6961 - val_accuracy: 0.4763\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2198 - accuracy: 0.9101 - val_loss: 0.6943 - val_accuracy: 0.4743\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2214 - accuracy: 0.9127 - val_loss: 0.6931 - val_accuracy: 0.5154\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2160 - accuracy: 0.9096 - val_loss: 0.6925 - val_accuracy: 0.5206\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2172 - accuracy: 0.9092 - val_loss: 0.6967 - val_accuracy: 0.4969\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2306 - accuracy: 0.9030 - val_loss: 0.7027 - val_accuracy: 0.5113\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9087 - val_loss: 0.7032 - val_accuracy: 0.4969\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.9021 - val_loss: 0.7032 - val_accuracy: 0.4928\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2239 - accuracy: 0.9017 - val_loss: 0.6977 - val_accuracy: 0.5165\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9224 - val_loss: 0.6957 - val_accuracy: 0.5093\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2152 - accuracy: 0.9092 - val_loss: 0.6942 - val_accuracy: 0.4835\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2217 - accuracy: 0.9092 - val_loss: 0.7006 - val_accuracy: 0.5103\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2255 - accuracy: 0.9052 - val_loss: 0.6965 - val_accuracy: 0.4846\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2120 - accuracy: 0.9162 - val_loss: 0.6936 - val_accuracy: 0.4691\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2263 - accuracy: 0.9109 - val_loss: 0.7208 - val_accuracy: 0.5165\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9109 - val_loss: 0.6956 - val_accuracy: 0.5134\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2242 - accuracy: 0.9056 - val_loss: 0.6927 - val_accuracy: 0.5206\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2207 - accuracy: 0.9131 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2146 - accuracy: 0.9180 - val_loss: 0.6947 - val_accuracy: 0.5103\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2211 - accuracy: 0.9158 - val_loss: 0.6966 - val_accuracy: 0.5298\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2084 - accuracy: 0.9189 - val_loss: 0.6951 - val_accuracy: 0.5103\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2147 - accuracy: 0.9184 - val_loss: 0.7035 - val_accuracy: 0.5206\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9140 - val_loss: 0.6930 - val_accuracy: 0.5185\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2291 - accuracy: 0.9065 - val_loss: 0.6951 - val_accuracy: 0.4825\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9123 - val_loss: 0.7084 - val_accuracy: 0.4969\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2198 - accuracy: 0.9065 - val_loss: 0.7078 - val_accuracy: 0.5093\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2187 - accuracy: 0.9101 - val_loss: 0.6987 - val_accuracy: 0.5154\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2064 - accuracy: 0.9149 - val_loss: 0.6970 - val_accuracy: 0.4856\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9096 - val_loss: 0.6951 - val_accuracy: 0.4959\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9149 - val_loss: 0.6990 - val_accuracy: 0.5144\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2033 - accuracy: 0.9250 - val_loss: 0.6950 - val_accuracy: 0.5144\n","Score: 0.5144032835960388 \n","Parameters:  {'learning_rate': 0.05614061364721376, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0490 - accuracy: 0.9198 - val_loss: 0.6211 - val_accuracy: 0.6626\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2458 - accuracy: 0.9189 - val_loss: 0.6424 - val_accuracy: 0.6636\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2810 - accuracy: 0.9193 - val_loss: 0.6154 - val_accuracy: 0.6481\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9264 - val_loss: 0.6648 - val_accuracy: 0.6584\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1613 - accuracy: 0.9334 - val_loss: 0.5585 - val_accuracy: 0.7253\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1665 - accuracy: 0.9352 - val_loss: 0.5439 - val_accuracy: 0.7366\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1521 - accuracy: 0.9334 - val_loss: 0.5320 - val_accuracy: 0.7130\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9325 - val_loss: 0.5195 - val_accuracy: 0.7253\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1658 - accuracy: 0.9369 - val_loss: 0.5287 - val_accuracy: 0.7428\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9489 - val_loss: 0.5357 - val_accuracy: 0.7202\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1404 - accuracy: 0.9449 - val_loss: 0.5322 - val_accuracy: 0.7490\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9383 - val_loss: 0.4843 - val_accuracy: 0.7613\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.9449 - val_loss: 0.4719 - val_accuracy: 0.7644\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4304 - accuracy: 0.9387 - val_loss: 0.4940 - val_accuracy: 0.7634\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9449 - val_loss: 0.4450 - val_accuracy: 0.7798\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9475 - val_loss: 0.4377 - val_accuracy: 0.7953\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1589 - accuracy: 0.9458 - val_loss: 0.4701 - val_accuracy: 0.7840\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1389 - accuracy: 0.9458 - val_loss: 0.4247 - val_accuracy: 0.7901\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.9458 - val_loss: 0.4195 - val_accuracy: 0.8056\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9453 - val_loss: 0.4679 - val_accuracy: 0.8066\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9489 - val_loss: 0.4127 - val_accuracy: 0.8148\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1359 - accuracy: 0.9449 - val_loss: 0.4206 - val_accuracy: 0.7860\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9502 - val_loss: 0.4375 - val_accuracy: 0.7942\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9497 - val_loss: 0.4515 - val_accuracy: 0.7850\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1863 - accuracy: 0.9555 - val_loss: 0.5043 - val_accuracy: 0.7593\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3616 - accuracy: 0.9511 - val_loss: 0.3953 - val_accuracy: 0.8097\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2190 - accuracy: 0.9502 - val_loss: 0.4151 - val_accuracy: 0.8169\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1457 - accuracy: 0.9489 - val_loss: 0.4581 - val_accuracy: 0.7778\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1242 - accuracy: 0.9563 - val_loss: 0.3913 - val_accuracy: 0.8220\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9489 - val_loss: 0.4056 - val_accuracy: 0.8004\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9515 - val_loss: 0.4357 - val_accuracy: 0.7963\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9493 - val_loss: 0.3742 - val_accuracy: 0.8220\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1384 - accuracy: 0.9497 - val_loss: 0.4249 - val_accuracy: 0.8086\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9533 - val_loss: 0.3862 - val_accuracy: 0.8333\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9550 - val_loss: 0.3917 - val_accuracy: 0.8076\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1317 - accuracy: 0.9502 - val_loss: 0.3747 - val_accuracy: 0.8272\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.9612 - val_loss: 0.4011 - val_accuracy: 0.8158\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1002 - accuracy: 0.9599 - val_loss: 0.4564 - val_accuracy: 0.8004\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1136 - accuracy: 0.9541 - val_loss: 0.3428 - val_accuracy: 0.8416\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1041 - accuracy: 0.9608 - val_loss: 0.4385 - val_accuracy: 0.8200\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9541 - val_loss: 0.3799 - val_accuracy: 0.8200\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1073 - accuracy: 0.9581 - val_loss: 0.3237 - val_accuracy: 0.8591\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9586 - val_loss: 0.3860 - val_accuracy: 0.8241\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0992 - accuracy: 0.9630 - val_loss: 0.3870 - val_accuracy: 0.8302\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1399 - accuracy: 0.9594 - val_loss: 0.3646 - val_accuracy: 0.8272\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9656 - val_loss: 0.4928 - val_accuracy: 0.8405\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1011 - accuracy: 0.9647 - val_loss: 0.3178 - val_accuracy: 0.8611\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1676 - accuracy: 0.9555 - val_loss: 0.3645 - val_accuracy: 0.8282\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1580 - accuracy: 0.9559 - val_loss: 0.3130 - val_accuracy: 0.8549\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1052 - accuracy: 0.9700 - val_loss: 0.3166 - val_accuracy: 0.8611\n","Score: 0.8611111044883728 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4951 - accuracy: 0.9158 - val_loss: 0.6114 - val_accuracy: 0.6821\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1842 - accuracy: 0.9220 - val_loss: 0.5815 - val_accuracy: 0.6852\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2239 - accuracy: 0.9255 - val_loss: 0.5754 - val_accuracy: 0.6842\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1719 - accuracy: 0.9295 - val_loss: 0.5983 - val_accuracy: 0.6708\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9378 - val_loss: 0.5398 - val_accuracy: 0.7171\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9444 - val_loss: 0.4865 - val_accuracy: 0.7438\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2429 - accuracy: 0.9268 - val_loss: 0.5056 - val_accuracy: 0.7490\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9414 - val_loss: 0.5358 - val_accuracy: 0.7716\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9480 - val_loss: 0.4855 - val_accuracy: 0.7675\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1346 - accuracy: 0.9493 - val_loss: 0.4205 - val_accuracy: 0.8076\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1393 - accuracy: 0.9502 - val_loss: 0.4588 - val_accuracy: 0.7829\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1122 - accuracy: 0.9502 - val_loss: 0.3614 - val_accuracy: 0.8457\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1315 - accuracy: 0.9541 - val_loss: 0.3920 - val_accuracy: 0.8066\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1094 - accuracy: 0.9608 - val_loss: 0.4707 - val_accuracy: 0.8025\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1514 - accuracy: 0.9436 - val_loss: 0.3834 - val_accuracy: 0.8117\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1151 - accuracy: 0.9594 - val_loss: 0.4331 - val_accuracy: 0.7994\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9568 - val_loss: 0.4113 - val_accuracy: 0.8004\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1048 - accuracy: 0.9608 - val_loss: 0.3084 - val_accuracy: 0.8488\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9541 - val_loss: 0.3843 - val_accuracy: 0.8241\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.9630 - val_loss: 0.2623 - val_accuracy: 0.8735\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1518 - accuracy: 0.9568 - val_loss: 0.3440 - val_accuracy: 0.8416\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0820 - accuracy: 0.9656 - val_loss: 0.2883 - val_accuracy: 0.8765\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0917 - accuracy: 0.9625 - val_loss: 0.2913 - val_accuracy: 0.8508\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0890 - accuracy: 0.9718 - val_loss: 0.2538 - val_accuracy: 0.8899\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1656 - accuracy: 0.9603 - val_loss: 0.3842 - val_accuracy: 0.8405\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9568 - val_loss: 0.3451 - val_accuracy: 0.8539\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1198 - accuracy: 0.9608 - val_loss: 0.3681 - val_accuracy: 0.8354\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1310 - accuracy: 0.9484 - val_loss: 0.4706 - val_accuracy: 0.8364\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9625 - val_loss: 0.3430 - val_accuracy: 0.8498\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1025 - accuracy: 0.9608 - val_loss: 0.2780 - val_accuracy: 0.8765\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0885 - accuracy: 0.9665 - val_loss: 0.2957 - val_accuracy: 0.8735\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0670 - accuracy: 0.9744 - val_loss: 0.2856 - val_accuracy: 0.8951\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0828 - accuracy: 0.9757 - val_loss: 0.3033 - val_accuracy: 0.8735\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1004 - accuracy: 0.9669 - val_loss: 0.3057 - val_accuracy: 0.8611\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0712 - accuracy: 0.9740 - val_loss: 0.2100 - val_accuracy: 0.9177\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0983 - accuracy: 0.9687 - val_loss: 0.3000 - val_accuracy: 0.8652\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0972 - accuracy: 0.9740 - val_loss: 0.2711 - val_accuracy: 0.8920\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0757 - accuracy: 0.9744 - val_loss: 0.2586 - val_accuracy: 0.8992\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0614 - accuracy: 0.9824 - val_loss: 0.2211 - val_accuracy: 0.9167\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0607 - accuracy: 0.9806 - val_loss: 0.2425 - val_accuracy: 0.8961\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0795 - accuracy: 0.9709 - val_loss: 0.2310 - val_accuracy: 0.9146\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0869 - accuracy: 0.9731 - val_loss: 0.2761 - val_accuracy: 0.8879\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0680 - accuracy: 0.9788 - val_loss: 0.2068 - val_accuracy: 0.9126\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0466 - accuracy: 0.9850 - val_loss: 0.1853 - val_accuracy: 0.9352\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0702 - accuracy: 0.9793 - val_loss: 0.2512 - val_accuracy: 0.9023\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0609 - accuracy: 0.9797 - val_loss: 0.1677 - val_accuracy: 0.9372\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0552 - accuracy: 0.9828 - val_loss: 0.2063 - val_accuracy: 0.9311\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0530 - accuracy: 0.9863 - val_loss: 0.1664 - val_accuracy: 0.9383\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0605 - accuracy: 0.9819 - val_loss: 0.1653 - val_accuracy: 0.9342\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0528 - accuracy: 0.9859 - val_loss: 0.1541 - val_accuracy: 0.9455\n","Score: 0.9454732537269592 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Global:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 9524.5127 - accuracy: 0.8840 - val_loss: 0.7050 - val_accuracy: 0.5195\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9127 - val_loss: 1.1096 - val_accuracy: 0.5216\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1802 - accuracy: 0.9078 - val_loss: 0.7794 - val_accuracy: 0.5165\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1870 - accuracy: 0.9109 - val_loss: 0.7046 - val_accuracy: 0.4928\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9030 - val_loss: 0.7078 - val_accuracy: 0.5123\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1849 - accuracy: 0.9105 - val_loss: 0.7283 - val_accuracy: 0.5134\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1812 - accuracy: 0.9074 - val_loss: 0.7151 - val_accuracy: 0.5134\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1794 - accuracy: 0.9180 - val_loss: 0.9413 - val_accuracy: 0.5010\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9162 - val_loss: 1.1874 - val_accuracy: 0.5144\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1806 - accuracy: 0.9096 - val_loss: 0.7605 - val_accuracy: 0.5226\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1874 - accuracy: 0.9149 - val_loss: 0.6998 - val_accuracy: 0.5257\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1856 - accuracy: 0.9087 - val_loss: 0.8091 - val_accuracy: 0.5123\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1885 - accuracy: 0.9012 - val_loss: 0.6992 - val_accuracy: 0.4949\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9087 - val_loss: 0.6944 - val_accuracy: 0.5237\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9026 - val_loss: 0.7315 - val_accuracy: 0.4835\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9048 - val_loss: 0.7018 - val_accuracy: 0.5267\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1867 - accuracy: 0.9070 - val_loss: 0.7181 - val_accuracy: 0.4887\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9021 - val_loss: 0.6937 - val_accuracy: 0.4877\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2370 - accuracy: 0.9021 - val_loss: 0.6932 - val_accuracy: 0.4794\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2350 - accuracy: 0.9114 - val_loss: 0.6932 - val_accuracy: 0.4866\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2373 - accuracy: 0.9101 - val_loss: 0.6904 - val_accuracy: 0.5370\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2365 - accuracy: 0.9109 - val_loss: 0.6920 - val_accuracy: 0.5278\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2425 - accuracy: 0.9078 - val_loss: 0.6945 - val_accuracy: 0.4877\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2399 - accuracy: 0.9105 - val_loss: 0.6949 - val_accuracy: 0.5195\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2375 - accuracy: 0.9118 - val_loss: 0.6926 - val_accuracy: 0.5195\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2400 - accuracy: 0.9167 - val_loss: 0.6950 - val_accuracy: 0.5237\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2298 - accuracy: 0.9127 - val_loss: 0.6934 - val_accuracy: 0.4846\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2406 - accuracy: 0.9083 - val_loss: 0.6930 - val_accuracy: 0.5154\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2357 - accuracy: 0.9162 - val_loss: 0.6932 - val_accuracy: 0.5278\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2394 - accuracy: 0.9140 - val_loss: 0.6974 - val_accuracy: 0.5093\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2293 - accuracy: 0.9180 - val_loss: 0.6981 - val_accuracy: 0.4743\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2473 - accuracy: 0.8964 - val_loss: 0.6932 - val_accuracy: 0.4990\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2286 - accuracy: 0.9198 - val_loss: 0.6942 - val_accuracy: 0.5319\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2332 - accuracy: 0.9167 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2315 - accuracy: 0.9136 - val_loss: 0.6955 - val_accuracy: 0.4907\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2472 - accuracy: 0.8995 - val_loss: 0.6950 - val_accuracy: 0.4969\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2315 - accuracy: 0.9184 - val_loss: 0.6956 - val_accuracy: 0.5000\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2370 - accuracy: 0.9092 - val_loss: 0.6939 - val_accuracy: 0.4846\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2471 - accuracy: 0.9008 - val_loss: 0.6942 - val_accuracy: 0.4938\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2455 - accuracy: 0.8990 - val_loss: 0.6938 - val_accuracy: 0.4784\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2375 - accuracy: 0.9123 - val_loss: 0.6933 - val_accuracy: 0.4825\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2354 - accuracy: 0.9123 - val_loss: 0.6935 - val_accuracy: 0.4990\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2413 - accuracy: 0.9087 - val_loss: 0.6945 - val_accuracy: 0.4825\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2426 - accuracy: 0.9092 - val_loss: 0.6932 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2468 - accuracy: 0.9026 - val_loss: 0.7025 - val_accuracy: 0.5206\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2230 - accuracy: 0.9193 - val_loss: 0.6930 - val_accuracy: 0.5082\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2384 - accuracy: 0.9162 - val_loss: 0.7030 - val_accuracy: 0.5144\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2460 - accuracy: 0.9087 - val_loss: 0.7007 - val_accuracy: 0.5072\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2328 - accuracy: 0.9162 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2445 - accuracy: 0.9065 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Score: 0.5102880597114563 \n","Parameters:  {'learning_rate': 0.036674797960510874, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8752 - accuracy: 0.9127 - val_loss: 0.6316 - val_accuracy: 0.5967\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3752 - accuracy: 0.9162 - val_loss: 0.6222 - val_accuracy: 0.6955\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1824 - accuracy: 0.9140 - val_loss: 0.6034 - val_accuracy: 0.6914\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9334 - val_loss: 0.5542 - val_accuracy: 0.7222\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1557 - accuracy: 0.9387 - val_loss: 0.5279 - val_accuracy: 0.7541\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1769 - accuracy: 0.9383 - val_loss: 0.5721 - val_accuracy: 0.6852\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1378 - accuracy: 0.9427 - val_loss: 0.5294 - val_accuracy: 0.7335\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2513 - accuracy: 0.9272 - val_loss: 0.4995 - val_accuracy: 0.7521\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1637 - accuracy: 0.9330 - val_loss: 0.5021 - val_accuracy: 0.7438\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2296 - accuracy: 0.9427 - val_loss: 0.4902 - val_accuracy: 0.7582\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9453 - val_loss: 0.4778 - val_accuracy: 0.7737\n","Epoch 12/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1470 - accuracy: 0.9440 - val_loss: 0.4767 - val_accuracy: 0.7603\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1439 - accuracy: 0.9405 - val_loss: 0.4430 - val_accuracy: 0.7881\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9466 - val_loss: 0.4517 - val_accuracy: 0.7798\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1534 - accuracy: 0.9422 - val_loss: 0.4306 - val_accuracy: 0.8169\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3291 - accuracy: 0.9374 - val_loss: 0.4476 - val_accuracy: 0.7860\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1348 - accuracy: 0.9471 - val_loss: 0.4061 - val_accuracy: 0.8086\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2084 - accuracy: 0.9577 - val_loss: 0.4395 - val_accuracy: 0.8045\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1297 - accuracy: 0.9511 - val_loss: 0.3526 - val_accuracy: 0.8426\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0986 - accuracy: 0.9563 - val_loss: 0.3597 - val_accuracy: 0.8272\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1075 - accuracy: 0.9563 - val_loss: 0.3796 - val_accuracy: 0.8169\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1219 - accuracy: 0.9511 - val_loss: 0.3769 - val_accuracy: 0.8148\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1462 - accuracy: 0.9422 - val_loss: 0.4142 - val_accuracy: 0.8117\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9493 - val_loss: 0.3601 - val_accuracy: 0.8354\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1542 - accuracy: 0.9546 - val_loss: 0.3818 - val_accuracy: 0.8241\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1325 - accuracy: 0.9506 - val_loss: 0.3689 - val_accuracy: 0.8374\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9563 - val_loss: 0.3841 - val_accuracy: 0.8210\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0979 - accuracy: 0.9612 - val_loss: 0.3421 - val_accuracy: 0.8416\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1121 - accuracy: 0.9612 - val_loss: 0.3313 - val_accuracy: 0.8488\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.9493 - val_loss: 0.3581 - val_accuracy: 0.8426\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0883 - accuracy: 0.9669 - val_loss: 0.3007 - val_accuracy: 0.8601\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0891 - accuracy: 0.9678 - val_loss: 0.3328 - val_accuracy: 0.8601\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1074 - accuracy: 0.9612 - val_loss: 0.3662 - val_accuracy: 0.8344\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0991 - accuracy: 0.9643 - val_loss: 0.3265 - val_accuracy: 0.8447\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1089 - accuracy: 0.9599 - val_loss: 0.4497 - val_accuracy: 0.8097\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.9590 - val_loss: 0.3268 - val_accuracy: 0.8385\n","Epoch 37/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1484 - accuracy: 0.9590 - val_loss: 0.2991 - val_accuracy: 0.8683\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1568 - accuracy: 0.9616 - val_loss: 0.2953 - val_accuracy: 0.8591\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0933 - accuracy: 0.9652 - val_loss: 0.2885 - val_accuracy: 0.8549\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0930 - accuracy: 0.9722 - val_loss: 0.2734 - val_accuracy: 0.8663\n","Epoch 41/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1014 - accuracy: 0.9669 - val_loss: 0.3389 - val_accuracy: 0.8457\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1210 - accuracy: 0.9669 - val_loss: 0.3144 - val_accuracy: 0.8447\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0877 - accuracy: 0.9660 - val_loss: 0.2607 - val_accuracy: 0.8909\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9683 - val_loss: 0.3510 - val_accuracy: 0.8601\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0950 - accuracy: 0.9709 - val_loss: 0.2287 - val_accuracy: 0.9095\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1147 - accuracy: 0.9700 - val_loss: 0.2880 - val_accuracy: 0.8724\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0915 - accuracy: 0.9713 - val_loss: 0.2984 - val_accuracy: 0.8765\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0731 - accuracy: 0.9722 - val_loss: 0.2434 - val_accuracy: 0.9012\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0820 - accuracy: 0.9678 - val_loss: 0.2613 - val_accuracy: 0.8868\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0887 - accuracy: 0.9700 - val_loss: 0.3320 - val_accuracy: 0.8796\n","Score: 0.8796296119689941 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 177220.5000 - accuracy: 0.9048 - val_loss: 0.6998 - val_accuracy: 0.4938\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1873 - accuracy: 0.9118 - val_loss: 0.6953 - val_accuracy: 0.5062\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9153 - val_loss: 0.7029 - val_accuracy: 0.5144\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9136 - val_loss: 0.7743 - val_accuracy: 0.5093\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9034 - val_loss: 0.6981 - val_accuracy: 0.5154\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1787 - accuracy: 0.9259 - val_loss: 0.6952 - val_accuracy: 0.5247\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9136 - val_loss: 0.6965 - val_accuracy: 0.5175\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9149 - val_loss: 0.6915 - val_accuracy: 0.5319\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9158 - val_loss: 0.7835 - val_accuracy: 0.4856\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9087 - val_loss: 0.7028 - val_accuracy: 0.5021\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9171 - val_loss: 0.7056 - val_accuracy: 0.4825\n","Epoch 12/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1950 - accuracy: 0.9017 - val_loss: 0.7063 - val_accuracy: 0.5082\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9087 - val_loss: 0.7254 - val_accuracy: 0.5216\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1824 - accuracy: 0.9131 - val_loss: 0.6936 - val_accuracy: 0.4866\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2086 - accuracy: 0.9052 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9171 - val_loss: 0.6921 - val_accuracy: 0.5267\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9074 - val_loss: 0.7597 - val_accuracy: 0.4825\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9021 - val_loss: 0.6927 - val_accuracy: 0.5237\n","Epoch 19/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1932 - accuracy: 0.9114 - val_loss: 0.6935 - val_accuracy: 0.5051\n","Epoch 20/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2104 - accuracy: 0.9048 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9127 - val_loss: 0.7089 - val_accuracy: 0.5051\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9070 - val_loss: 0.6951 - val_accuracy: 0.4877\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2014 - accuracy: 0.9065 - val_loss: 0.7139 - val_accuracy: 0.5041\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2022 - accuracy: 0.9048 - val_loss: 0.6953 - val_accuracy: 0.4815\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2043 - accuracy: 0.9092 - val_loss: 0.6961 - val_accuracy: 0.5072\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1909 - accuracy: 0.9083 - val_loss: 0.7332 - val_accuracy: 0.5144\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1950 - accuracy: 0.9149 - val_loss: 0.7180 - val_accuracy: 0.5350\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1864 - accuracy: 0.9167 - val_loss: 0.7240 - val_accuracy: 0.5185\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9149 - val_loss: 0.7037 - val_accuracy: 0.4825\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.8955 - val_loss: 0.7196 - val_accuracy: 0.4743\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1991 - accuracy: 0.9026 - val_loss: 0.7098 - val_accuracy: 0.5216\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1873 - accuracy: 0.9224 - val_loss: 0.7429 - val_accuracy: 0.4774\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2025 - accuracy: 0.9052 - val_loss: 0.7322 - val_accuracy: 0.5093\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1842 - accuracy: 0.9127 - val_loss: 0.7020 - val_accuracy: 0.5000\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.9039 - val_loss: 0.6994 - val_accuracy: 0.5051\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1913 - accuracy: 0.9158 - val_loss: 0.6928 - val_accuracy: 0.5195\n","Epoch 37/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2007 - accuracy: 0.9127 - val_loss: 0.7059 - val_accuracy: 0.5267\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1925 - accuracy: 0.9109 - val_loss: 0.7030 - val_accuracy: 0.4722\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1941 - accuracy: 0.9043 - val_loss: 0.6978 - val_accuracy: 0.4846\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1925 - accuracy: 0.9083 - val_loss: 0.7202 - val_accuracy: 0.5082\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9158 - val_loss: 0.7143 - val_accuracy: 0.5216\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1935 - accuracy: 0.9118 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1845 - accuracy: 0.9233 - val_loss: 0.6928 - val_accuracy: 0.5154\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1960 - accuracy: 0.9162 - val_loss: 0.6933 - val_accuracy: 0.4815\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9092 - val_loss: 0.7150 - val_accuracy: 0.4774\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9105 - val_loss: 0.6924 - val_accuracy: 0.5247\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2109 - accuracy: 0.9078 - val_loss: 0.6994 - val_accuracy: 0.5144\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9043 - val_loss: 0.6931 - val_accuracy: 0.5093\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9096 - val_loss: 0.6925 - val_accuracy: 0.5237\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1829 - accuracy: 0.9202 - val_loss: 0.6919 - val_accuracy: 0.5350\n","Score: 0.5349794030189514 \n","Parameters:  {'learning_rate': 0.1263789255582349, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 701257.9375 - accuracy: 0.8801 - val_loss: 5.8425 - val_accuracy: 0.5288\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3159 - accuracy: 0.9034 - val_loss: 2.4598 - val_accuracy: 0.4846\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6506 - accuracy: 0.8955 - val_loss: 1.7312 - val_accuracy: 0.5082\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2979 - accuracy: 0.8973 - val_loss: 0.8071 - val_accuracy: 0.5247\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4891 - accuracy: 0.8955 - val_loss: 0.7648 - val_accuracy: 0.4846\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3567 - accuracy: 0.8818 - val_loss: 1.1999 - val_accuracy: 0.4774\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3133 - accuracy: 0.8959 - val_loss: 0.6992 - val_accuracy: 0.5206\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4004 - accuracy: 0.8889 - val_loss: 0.8643 - val_accuracy: 0.5000\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3438 - accuracy: 0.8929 - val_loss: 0.7176 - val_accuracy: 0.4856\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2388 - accuracy: 0.8959 - val_loss: 1.8132 - val_accuracy: 0.5041\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2749 - accuracy: 0.8902 - val_loss: 0.7043 - val_accuracy: 0.4691\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9118 - val_loss: 0.7281 - val_accuracy: 0.4640\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9136 - val_loss: 0.7015 - val_accuracy: 0.4979\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.8990 - val_loss: 0.6927 - val_accuracy: 0.5185\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2119 - accuracy: 0.9048 - val_loss: 0.6934 - val_accuracy: 0.5226\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9136 - val_loss: 0.6932 - val_accuracy: 0.5082\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9127 - val_loss: 0.6988 - val_accuracy: 0.4949\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1874 - accuracy: 0.9092 - val_loss: 0.7012 - val_accuracy: 0.5175\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9189 - val_loss: 0.6932 - val_accuracy: 0.5185\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9171 - val_loss: 0.7027 - val_accuracy: 0.5093\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9105 - val_loss: 0.6967 - val_accuracy: 0.5298\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9109 - val_loss: 0.7138 - val_accuracy: 0.5021\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9083 - val_loss: 0.7094 - val_accuracy: 0.5072\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2035 - accuracy: 0.9074 - val_loss: 0.7038 - val_accuracy: 0.5082\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1941 - accuracy: 0.9153 - val_loss: 0.7015 - val_accuracy: 0.4907\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9056 - val_loss: 0.6943 - val_accuracy: 0.5031\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9202 - val_loss: 0.6948 - val_accuracy: 0.5185\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1885 - accuracy: 0.9198 - val_loss: 0.7049 - val_accuracy: 0.4938\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1927 - accuracy: 0.9118 - val_loss: 0.7029 - val_accuracy: 0.5021\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9017 - val_loss: 0.7046 - val_accuracy: 0.4825\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9123 - val_loss: 0.6950 - val_accuracy: 0.4949\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9114 - val_loss: 0.7011 - val_accuracy: 0.4928\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9034 - val_loss: 0.7060 - val_accuracy: 0.5165\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9131 - val_loss: 0.6950 - val_accuracy: 0.5093\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9092 - val_loss: 0.6932 - val_accuracy: 0.4856\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9070 - val_loss: 0.7002 - val_accuracy: 0.5185\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1893 - accuracy: 0.9136 - val_loss: 0.6938 - val_accuracy: 0.5062\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9171 - val_loss: 0.6976 - val_accuracy: 0.4990\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9043 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1843 - accuracy: 0.9171 - val_loss: 0.6951 - val_accuracy: 0.5144\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9180 - val_loss: 0.6926 - val_accuracy: 0.5185\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9180 - val_loss: 0.7499 - val_accuracy: 0.4815\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9065 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.9083 - val_loss: 0.6934 - val_accuracy: 0.5185\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9162 - val_loss: 0.7047 - val_accuracy: 0.4938\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2117 - accuracy: 0.8981 - val_loss: 0.6995 - val_accuracy: 0.5154\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9118 - val_loss: 0.6957 - val_accuracy: 0.4938\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9114 - val_loss: 0.7422 - val_accuracy: 0.5082\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9158 - val_loss: 0.6949 - val_accuracy: 0.4856\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9065 - val_loss: 0.7066 - val_accuracy: 0.4774\n","Score: 0.47736626863479614 \n","Parameters:  {'learning_rate': 0.12304554990053325, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.2379 - accuracy: 0.9158 - val_loss: 0.6807 - val_accuracy: 0.5319\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2233 - accuracy: 0.9193 - val_loss: 0.7477 - val_accuracy: 0.6039\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9123 - val_loss: 0.6087 - val_accuracy: 0.6965\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1980 - accuracy: 0.9264 - val_loss: 0.5958 - val_accuracy: 0.6955\n","Epoch 5/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1677 - accuracy: 0.9228 - val_loss: 0.5657 - val_accuracy: 0.6831\n","Epoch 6/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.4461 - accuracy: 0.9365 - val_loss: 0.5547 - val_accuracy: 0.7202\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1455 - accuracy: 0.9352 - val_loss: 0.4860 - val_accuracy: 0.7644\n","Epoch 8/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1576 - accuracy: 0.9396 - val_loss: 0.4974 - val_accuracy: 0.7438\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9418 - val_loss: 0.4401 - val_accuracy: 0.7819\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1403 - accuracy: 0.9396 - val_loss: 0.4494 - val_accuracy: 0.7912\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1459 - accuracy: 0.9471 - val_loss: 0.4600 - val_accuracy: 0.7860\n","Epoch 12/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1342 - accuracy: 0.9484 - val_loss: 0.4331 - val_accuracy: 0.7973\n","Epoch 13/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1230 - accuracy: 0.9484 - val_loss: 0.4870 - val_accuracy: 0.7593\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1409 - accuracy: 0.9392 - val_loss: 0.4363 - val_accuracy: 0.7757\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1774 - accuracy: 0.9440 - val_loss: 0.4761 - val_accuracy: 0.7747\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1529 - accuracy: 0.9392 - val_loss: 0.5131 - val_accuracy: 0.7572\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1586 - accuracy: 0.9356 - val_loss: 0.4976 - val_accuracy: 0.7562\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9392 - val_loss: 0.5247 - val_accuracy: 0.7243\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1660 - accuracy: 0.9383 - val_loss: 0.4818 - val_accuracy: 0.7675\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9449 - val_loss: 0.5199 - val_accuracy: 0.7644\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1717 - accuracy: 0.9489 - val_loss: 0.4407 - val_accuracy: 0.7870\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9444 - val_loss: 0.4903 - val_accuracy: 0.7685\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1537 - accuracy: 0.9427 - val_loss: 0.4234 - val_accuracy: 0.8138\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9466 - val_loss: 0.4640 - val_accuracy: 0.7778\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1384 - accuracy: 0.9453 - val_loss: 0.4234 - val_accuracy: 0.8189\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9405 - val_loss: 0.4239 - val_accuracy: 0.7953\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1428 - accuracy: 0.9497 - val_loss: 0.4363 - val_accuracy: 0.8158\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4763 - accuracy: 0.9466 - val_loss: 0.4822 - val_accuracy: 0.7665\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9449 - val_loss: 0.4230 - val_accuracy: 0.8045\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1367 - accuracy: 0.9515 - val_loss: 0.4336 - val_accuracy: 0.8035\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1312 - accuracy: 0.9484 - val_loss: 0.4258 - val_accuracy: 0.8035\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9568 - val_loss: 0.4076 - val_accuracy: 0.8117\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9453 - val_loss: 0.4011 - val_accuracy: 0.8158\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1149 - accuracy: 0.9541 - val_loss: 0.4609 - val_accuracy: 0.8004\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.9449 - val_loss: 0.4303 - val_accuracy: 0.7932\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1556 - accuracy: 0.9458 - val_loss: 0.4426 - val_accuracy: 0.7870\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.9594 - val_loss: 0.4399 - val_accuracy: 0.7953\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1180 - accuracy: 0.9493 - val_loss: 0.3953 - val_accuracy: 0.8169\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1324 - accuracy: 0.9489 - val_loss: 0.3921 - val_accuracy: 0.8117\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1338 - accuracy: 0.9511 - val_loss: 0.4000 - val_accuracy: 0.8179\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.9546 - val_loss: 0.3664 - val_accuracy: 0.8333\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1939 - accuracy: 0.9414 - val_loss: 0.4298 - val_accuracy: 0.7994\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2504 - accuracy: 0.9400 - val_loss: 0.4078 - val_accuracy: 0.8158\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2143 - accuracy: 0.9392 - val_loss: 0.4370 - val_accuracy: 0.7870\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1286 - accuracy: 0.9475 - val_loss: 0.3801 - val_accuracy: 0.8220\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1088 - accuracy: 0.9577 - val_loss: 0.4026 - val_accuracy: 0.8200\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1633 - accuracy: 0.9519 - val_loss: 0.4336 - val_accuracy: 0.7963\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1212 - accuracy: 0.9493 - val_loss: 0.3988 - val_accuracy: 0.8210\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1495 - accuracy: 0.9493 - val_loss: 0.4372 - val_accuracy: 0.7973\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1461 - accuracy: 0.9519 - val_loss: 0.4023 - val_accuracy: 0.8097\n","Score: 0.8096708059310913 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5271 - accuracy: 0.9211 - val_loss: 0.6124 - val_accuracy: 0.7099\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9220 - val_loss: 0.6071 - val_accuracy: 0.6975\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1755 - accuracy: 0.9171 - val_loss: 0.5647 - val_accuracy: 0.7109\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1574 - accuracy: 0.9220 - val_loss: 0.5667 - val_accuracy: 0.7171\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1768 - accuracy: 0.9343 - val_loss: 0.5474 - val_accuracy: 0.7202\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9246 - val_loss: 0.5268 - val_accuracy: 0.7469\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1612 - accuracy: 0.9299 - val_loss: 0.5968 - val_accuracy: 0.7130\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1802 - accuracy: 0.9325 - val_loss: 0.4815 - val_accuracy: 0.7829\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.9334 - val_loss: 0.5400 - val_accuracy: 0.7397\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1636 - accuracy: 0.9352 - val_loss: 0.4703 - val_accuracy: 0.7706\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9392 - val_loss: 0.4689 - val_accuracy: 0.7778\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9347 - val_loss: 0.4510 - val_accuracy: 0.7675\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9422 - val_loss: 0.4335 - val_accuracy: 0.7850\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1344 - accuracy: 0.9436 - val_loss: 0.4124 - val_accuracy: 0.8004\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1305 - accuracy: 0.9436 - val_loss: 0.4094 - val_accuracy: 0.8004\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9511 - val_loss: 0.4839 - val_accuracy: 0.7737\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1261 - accuracy: 0.9493 - val_loss: 0.4212 - val_accuracy: 0.8014\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9462 - val_loss: 0.4130 - val_accuracy: 0.8220\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1591 - accuracy: 0.9484 - val_loss: 0.4484 - val_accuracy: 0.7726\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9524 - val_loss: 0.3909 - val_accuracy: 0.8200\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1438 - accuracy: 0.9524 - val_loss: 0.3909 - val_accuracy: 0.8230\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1254 - accuracy: 0.9458 - val_loss: 0.3884 - val_accuracy: 0.8302\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1369 - accuracy: 0.9475 - val_loss: 0.3936 - val_accuracy: 0.8107\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.9515 - val_loss: 0.4198 - val_accuracy: 0.8066\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9484 - val_loss: 0.4085 - val_accuracy: 0.8158\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9480 - val_loss: 0.4044 - val_accuracy: 0.8200\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1213 - accuracy: 0.9577 - val_loss: 0.4138 - val_accuracy: 0.8169\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9502 - val_loss: 0.3860 - val_accuracy: 0.8230\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9555 - val_loss: 0.3396 - val_accuracy: 0.8477\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1228 - accuracy: 0.9537 - val_loss: 0.3554 - val_accuracy: 0.8302\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1221 - accuracy: 0.9550 - val_loss: 0.4105 - val_accuracy: 0.8251\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1378 - accuracy: 0.9511 - val_loss: 0.4610 - val_accuracy: 0.7942\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.9489 - val_loss: 0.3319 - val_accuracy: 0.8344\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1242 - accuracy: 0.9528 - val_loss: 0.3778 - val_accuracy: 0.8107\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2730 - accuracy: 0.9453 - val_loss: 0.3900 - val_accuracy: 0.8210\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1256 - accuracy: 0.9497 - val_loss: 0.3518 - val_accuracy: 0.8436\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.9581 - val_loss: 0.3640 - val_accuracy: 0.8354\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1089 - accuracy: 0.9599 - val_loss: 0.3884 - val_accuracy: 0.8210\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1106 - accuracy: 0.9572 - val_loss: 0.3322 - val_accuracy: 0.8477\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1180 - accuracy: 0.9581 - val_loss: 0.3768 - val_accuracy: 0.8385\n","Epoch 41/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1273 - accuracy: 0.9555 - val_loss: 0.3180 - val_accuracy: 0.8477\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1212 - accuracy: 0.9555 - val_loss: 0.4012 - val_accuracy: 0.8210\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1048 - accuracy: 0.9541 - val_loss: 0.3481 - val_accuracy: 0.8354\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1154 - accuracy: 0.9515 - val_loss: 0.3663 - val_accuracy: 0.8292\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.9555 - val_loss: 0.3405 - val_accuracy: 0.8447\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9594 - val_loss: 0.3860 - val_accuracy: 0.8272\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1115 - accuracy: 0.9559 - val_loss: 0.3121 - val_accuracy: 0.8776\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1090 - accuracy: 0.9537 - val_loss: 0.3219 - val_accuracy: 0.8447\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1356 - accuracy: 0.9630 - val_loss: 0.3332 - val_accuracy: 0.8549\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1136 - accuracy: 0.9563 - val_loss: 0.3699 - val_accuracy: 0.8498\n","Score: 0.8497942090034485 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.3878 - accuracy: 0.9198 - val_loss: 0.6277 - val_accuracy: 0.6523\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1718 - accuracy: 0.9233 - val_loss: 0.5783 - val_accuracy: 0.7212\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9202 - val_loss: 0.5821 - val_accuracy: 0.7006\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1712 - accuracy: 0.9286 - val_loss: 0.5791 - val_accuracy: 0.7531\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1754 - accuracy: 0.9237 - val_loss: 0.4824 - val_accuracy: 0.7798\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1625 - accuracy: 0.9259 - val_loss: 0.5498 - val_accuracy: 0.7212\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2155 - accuracy: 0.9330 - val_loss: 0.5284 - val_accuracy: 0.7593\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1524 - accuracy: 0.9334 - val_loss: 0.5545 - val_accuracy: 0.7078\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9383 - val_loss: 0.4894 - val_accuracy: 0.7747\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1519 - accuracy: 0.9365 - val_loss: 0.4849 - val_accuracy: 0.7603\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1432 - accuracy: 0.9489 - val_loss: 0.4126 - val_accuracy: 0.8035\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5286 - accuracy: 0.9436 - val_loss: 0.4494 - val_accuracy: 0.7953\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1359 - accuracy: 0.9471 - val_loss: 0.4782 - val_accuracy: 0.7613\n","Epoch 14/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.3255 - accuracy: 0.9422 - val_loss: 0.4480 - val_accuracy: 0.7922\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1207 - accuracy: 0.9480 - val_loss: 0.4224 - val_accuracy: 0.7953\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1249 - accuracy: 0.9519 - val_loss: 0.4113 - val_accuracy: 0.7953\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9555 - val_loss: 0.4235 - val_accuracy: 0.8056\n","Epoch 18/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1083 - accuracy: 0.9541 - val_loss: 0.3711 - val_accuracy: 0.8282\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9515 - val_loss: 0.3626 - val_accuracy: 0.8385\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1429 - accuracy: 0.9533 - val_loss: 0.3821 - val_accuracy: 0.8220\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1144 - accuracy: 0.9590 - val_loss: 0.3771 - val_accuracy: 0.8261\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1130 - accuracy: 0.9559 - val_loss: 0.3893 - val_accuracy: 0.8261\n","Epoch 23/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1140 - accuracy: 0.9581 - val_loss: 0.4200 - val_accuracy: 0.7901\n","Epoch 24/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0969 - accuracy: 0.9669 - val_loss: 0.3288 - val_accuracy: 0.8508\n","Epoch 25/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0954 - accuracy: 0.9660 - val_loss: 0.4385 - val_accuracy: 0.8066\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9519 - val_loss: 0.3969 - val_accuracy: 0.8189\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1888 - accuracy: 0.9533 - val_loss: 0.3772 - val_accuracy: 0.8179\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0982 - accuracy: 0.9652 - val_loss: 0.3172 - val_accuracy: 0.8621\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1092 - accuracy: 0.9608 - val_loss: 0.2925 - val_accuracy: 0.8663\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0870 - accuracy: 0.9652 - val_loss: 0.3354 - val_accuracy: 0.8488\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1055 - accuracy: 0.9612 - val_loss: 0.3386 - val_accuracy: 0.8436\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0839 - accuracy: 0.9669 - val_loss: 0.3289 - val_accuracy: 0.8467\n","Epoch 33/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.0965 - accuracy: 0.9647 - val_loss: 0.3065 - val_accuracy: 0.8621\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0962 - accuracy: 0.9647 - val_loss: 0.2649 - val_accuracy: 0.8796\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1065 - accuracy: 0.9687 - val_loss: 0.2910 - val_accuracy: 0.8704\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0987 - accuracy: 0.9674 - val_loss: 0.2569 - val_accuracy: 0.8837\n","Epoch 37/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0999 - accuracy: 0.9709 - val_loss: 0.2395 - val_accuracy: 0.8940\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0696 - accuracy: 0.9762 - val_loss: 0.2819 - val_accuracy: 0.8827\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1401 - accuracy: 0.9722 - val_loss: 0.5594 - val_accuracy: 0.8477\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0947 - accuracy: 0.9669 - val_loss: 0.2616 - val_accuracy: 0.8848\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0850 - accuracy: 0.9722 - val_loss: 0.2073 - val_accuracy: 0.9167\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0782 - accuracy: 0.9700 - val_loss: 0.2361 - val_accuracy: 0.9033\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0636 - accuracy: 0.9784 - val_loss: 0.2514 - val_accuracy: 0.9126\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0680 - accuracy: 0.9749 - val_loss: 0.2428 - val_accuracy: 0.9074\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0719 - accuracy: 0.9749 - val_loss: 0.2033 - val_accuracy: 0.9126\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0676 - accuracy: 0.9753 - val_loss: 0.2186 - val_accuracy: 0.9002\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0747 - accuracy: 0.9762 - val_loss: 0.2966 - val_accuracy: 0.8529\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0730 - accuracy: 0.9780 - val_loss: 0.2298 - val_accuracy: 0.9074\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0490 - accuracy: 0.9797 - val_loss: 0.2197 - val_accuracy: 0.9074\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0618 - accuracy: 0.9762 - val_loss: 0.1978 - val_accuracy: 0.9270\n","Score: 0.9269547462463379 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0436 - accuracy: 0.9087 - val_loss: 0.6518 - val_accuracy: 0.6543\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1838 - accuracy: 0.9202 - val_loss: 0.6534 - val_accuracy: 0.5741\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1673 - accuracy: 0.9299 - val_loss: 0.6002 - val_accuracy: 0.6965\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1732 - accuracy: 0.9299 - val_loss: 0.6224 - val_accuracy: 0.6667\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2092 - accuracy: 0.9250 - val_loss: 0.5968 - val_accuracy: 0.6718\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9171 - val_loss: 0.6064 - val_accuracy: 0.6605\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1783 - accuracy: 0.9246 - val_loss: 0.5615 - val_accuracy: 0.6934\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2202 - accuracy: 0.9365 - val_loss: 0.5566 - val_accuracy: 0.7130\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9330 - val_loss: 0.5268 - val_accuracy: 0.7181\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1634 - accuracy: 0.9330 - val_loss: 0.5408 - val_accuracy: 0.7263\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1595 - accuracy: 0.9369 - val_loss: 0.5291 - val_accuracy: 0.7397\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1592 - accuracy: 0.9396 - val_loss: 0.5088 - val_accuracy: 0.7438\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9361 - val_loss: 0.5113 - val_accuracy: 0.7305\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9396 - val_loss: 0.4906 - val_accuracy: 0.7541\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1708 - accuracy: 0.9405 - val_loss: 0.5108 - val_accuracy: 0.7335\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1448 - accuracy: 0.9405 - val_loss: 0.4880 - val_accuracy: 0.7819\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9480 - val_loss: 0.4693 - val_accuracy: 0.7654\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6667 - accuracy: 0.9356 - val_loss: 0.4666 - val_accuracy: 0.7665\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1502 - accuracy: 0.9475 - val_loss: 0.4392 - val_accuracy: 0.7932\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1430 - accuracy: 0.9466 - val_loss: 0.4474 - val_accuracy: 0.7963\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9489 - val_loss: 0.4318 - val_accuracy: 0.7963\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1562 - accuracy: 0.9511 - val_loss: 0.4311 - val_accuracy: 0.7953\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1415 - accuracy: 0.9519 - val_loss: 0.4074 - val_accuracy: 0.8035\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1741 - accuracy: 0.9533 - val_loss: 0.4446 - val_accuracy: 0.7912\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1431 - accuracy: 0.9511 - val_loss: 0.4248 - val_accuracy: 0.7891\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1154 - accuracy: 0.9541 - val_loss: 0.3898 - val_accuracy: 0.8189\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1240 - accuracy: 0.9533 - val_loss: 0.4244 - val_accuracy: 0.8200\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2231 - accuracy: 0.9568 - val_loss: 0.4769 - val_accuracy: 0.7994\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1335 - accuracy: 0.9550 - val_loss: 0.4426 - val_accuracy: 0.8004\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1232 - accuracy: 0.9541 - val_loss: 0.3733 - val_accuracy: 0.8179\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1082 - accuracy: 0.9621 - val_loss: 0.3627 - val_accuracy: 0.8395\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9568 - val_loss: 0.3513 - val_accuracy: 0.8251\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1132 - accuracy: 0.9599 - val_loss: 0.3711 - val_accuracy: 0.8220\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1046 - accuracy: 0.9625 - val_loss: 0.3239 - val_accuracy: 0.8570\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1133 - accuracy: 0.9594 - val_loss: 0.3617 - val_accuracy: 0.8477\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2762 - accuracy: 0.9506 - val_loss: 0.3927 - val_accuracy: 0.8333\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1034 - accuracy: 0.9594 - val_loss: 0.3270 - val_accuracy: 0.8323\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0956 - accuracy: 0.9638 - val_loss: 0.3323 - val_accuracy: 0.8333\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0836 - accuracy: 0.9687 - val_loss: 0.2871 - val_accuracy: 0.8683\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1212 - accuracy: 0.9621 - val_loss: 0.2963 - val_accuracy: 0.8519\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0839 - accuracy: 0.9683 - val_loss: 0.2813 - val_accuracy: 0.8673\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1071 - accuracy: 0.9568 - val_loss: 0.2788 - val_accuracy: 0.8755\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0859 - accuracy: 0.9674 - val_loss: 0.2823 - val_accuracy: 0.8693\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1095 - accuracy: 0.9665 - val_loss: 0.3651 - val_accuracy: 0.8302\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2072 - accuracy: 0.9674 - val_loss: 0.3609 - val_accuracy: 0.8447\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2515 - accuracy: 0.9550 - val_loss: 0.4048 - val_accuracy: 0.8117\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1430 - accuracy: 0.9577 - val_loss: 0.6514 - val_accuracy: 0.7521\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1071 - accuracy: 0.9630 - val_loss: 0.3230 - val_accuracy: 0.8488\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.7358 - accuracy: 0.9643 - val_loss: 0.2950 - val_accuracy: 0.8663\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1115 - accuracy: 0.9608 - val_loss: 0.3569 - val_accuracy: 0.8302\n","Score: 0.8302469253540039 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 51268.3633 - accuracy: 0.8849 - val_loss: 0.9382 - val_accuracy: 0.4846\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3403 - accuracy: 0.8823 - val_loss: 0.6937 - val_accuracy: 0.5082\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2478 - accuracy: 0.8946 - val_loss: 0.7050 - val_accuracy: 0.4959\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3237 - accuracy: 0.8915 - val_loss: 0.7263 - val_accuracy: 0.4887\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3374 - accuracy: 0.8933 - val_loss: 0.8470 - val_accuracy: 0.5175\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2186 - accuracy: 0.8964 - val_loss: 0.7470 - val_accuracy: 0.5195\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.8915 - val_loss: 0.7999 - val_accuracy: 0.4743\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3100 - accuracy: 0.8889 - val_loss: 0.7037 - val_accuracy: 0.4897\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.9118 - val_loss: 0.7298 - val_accuracy: 0.4866\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2394 - accuracy: 0.9008 - val_loss: 0.7480 - val_accuracy: 0.5134\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2029 - accuracy: 0.9105 - val_loss: 0.7999 - val_accuracy: 0.5144\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9180 - val_loss: 0.7978 - val_accuracy: 0.4928\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2104 - accuracy: 0.9131 - val_loss: 0.7215 - val_accuracy: 0.4877\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9118 - val_loss: 0.7134 - val_accuracy: 0.4763\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9109 - val_loss: 0.7166 - val_accuracy: 0.5319\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1871 - accuracy: 0.9114 - val_loss: 0.7422 - val_accuracy: 0.5010\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9043 - val_loss: 0.6953 - val_accuracy: 0.4887\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.8981 - val_loss: 0.6953 - val_accuracy: 0.4660\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9087 - val_loss: 0.7000 - val_accuracy: 0.5031\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.8968 - val_loss: 0.6931 - val_accuracy: 0.5391\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1919 - accuracy: 0.9127 - val_loss: 0.6934 - val_accuracy: 0.4949\n","Epoch 22/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1940 - accuracy: 0.9114 - val_loss: 0.6945 - val_accuracy: 0.5000\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1970 - accuracy: 0.9070 - val_loss: 0.7004 - val_accuracy: 0.4990\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1913 - accuracy: 0.9127 - val_loss: 0.6936 - val_accuracy: 0.5257\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9140 - val_loss: 0.7038 - val_accuracy: 0.5103\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1885 - accuracy: 0.9153 - val_loss: 0.7015 - val_accuracy: 0.4722\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2044 - accuracy: 0.9065 - val_loss: 0.6980 - val_accuracy: 0.4979\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1948 - accuracy: 0.9039 - val_loss: 0.7142 - val_accuracy: 0.5195\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9087 - val_loss: 0.6977 - val_accuracy: 0.5021\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9114 - val_loss: 0.6922 - val_accuracy: 0.5247\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9118 - val_loss: 0.6939 - val_accuracy: 0.4794\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2094 - accuracy: 0.9004 - val_loss: 0.6977 - val_accuracy: 0.4681\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9136 - val_loss: 0.6956 - val_accuracy: 0.4743\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1904 - accuracy: 0.9175 - val_loss: 0.7113 - val_accuracy: 0.5031\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9074 - val_loss: 0.7160 - val_accuracy: 0.5206\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1913 - accuracy: 0.9184 - val_loss: 0.7194 - val_accuracy: 0.4969\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9008 - val_loss: 0.6929 - val_accuracy: 0.5144\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9140 - val_loss: 0.6936 - val_accuracy: 0.4825\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1944 - accuracy: 0.9061 - val_loss: 0.6934 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1869 - accuracy: 0.9198 - val_loss: 0.7133 - val_accuracy: 0.4938\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9052 - val_loss: 0.7159 - val_accuracy: 0.5010\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9026 - val_loss: 0.6992 - val_accuracy: 0.4794\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9043 - val_loss: 0.6967 - val_accuracy: 0.5206\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9101 - val_loss: 0.6954 - val_accuracy: 0.4918\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9092 - val_loss: 0.6961 - val_accuracy: 0.4825\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1882 - accuracy: 0.9162 - val_loss: 0.8143 - val_accuracy: 0.4887\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9039 - val_loss: 0.6929 - val_accuracy: 0.5288\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9083 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9078 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9131 - val_loss: 0.6999 - val_accuracy: 0.4681\n","Score: 0.4681069850921631 \n","Parameters:  {'learning_rate': 0.1249013384328705, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4423 - accuracy: 0.9202 - val_loss: 0.6590 - val_accuracy: 0.6379\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9136 - val_loss: 0.6290 - val_accuracy: 0.7016\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1729 - accuracy: 0.9224 - val_loss: 0.5770 - val_accuracy: 0.6924\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1806 - accuracy: 0.9250 - val_loss: 0.5355 - val_accuracy: 0.7346\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3782 - accuracy: 0.9277 - val_loss: 0.5463 - val_accuracy: 0.7202\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1631 - accuracy: 0.9339 - val_loss: 0.4968 - val_accuracy: 0.7562\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1547 - accuracy: 0.9396 - val_loss: 0.5136 - val_accuracy: 0.7521\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1514 - accuracy: 0.9440 - val_loss: 0.5099 - val_accuracy: 0.7356\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9392 - val_loss: 0.4710 - val_accuracy: 0.7644\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1502 - accuracy: 0.9374 - val_loss: 0.5314 - val_accuracy: 0.7263\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2297 - accuracy: 0.9427 - val_loss: 0.5077 - val_accuracy: 0.7582\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1396 - accuracy: 0.9502 - val_loss: 0.4622 - val_accuracy: 0.7737\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1733 - accuracy: 0.9422 - val_loss: 0.4894 - val_accuracy: 0.7603\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1399 - accuracy: 0.9489 - val_loss: 0.3827 - val_accuracy: 0.8045\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1289 - accuracy: 0.9506 - val_loss: 0.3732 - val_accuracy: 0.8138\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1285 - accuracy: 0.9515 - val_loss: 0.4232 - val_accuracy: 0.8097\n","Epoch 17/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1209 - accuracy: 0.9528 - val_loss: 0.4003 - val_accuracy: 0.8056\n","Epoch 18/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1262 - accuracy: 0.9524 - val_loss: 0.3911 - val_accuracy: 0.8302\n","Epoch 19/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1192 - accuracy: 0.9546 - val_loss: 0.3771 - val_accuracy: 0.8364\n","Epoch 20/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1194 - accuracy: 0.9550 - val_loss: 0.3613 - val_accuracy: 0.8395\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1172 - accuracy: 0.9546 - val_loss: 0.3989 - val_accuracy: 0.8148\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1193 - accuracy: 0.9537 - val_loss: 0.3831 - val_accuracy: 0.8272\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1277 - accuracy: 0.9489 - val_loss: 0.3785 - val_accuracy: 0.8333\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1475 - accuracy: 0.9537 - val_loss: 0.3677 - val_accuracy: 0.8117\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1055 - accuracy: 0.9621 - val_loss: 0.3974 - val_accuracy: 0.8251\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9590 - val_loss: 0.3821 - val_accuracy: 0.8323\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9546 - val_loss: 0.3542 - val_accuracy: 0.8385\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1087 - accuracy: 0.9599 - val_loss: 0.3527 - val_accuracy: 0.8292\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.9586 - val_loss: 0.4644 - val_accuracy: 0.8261\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1283 - accuracy: 0.9572 - val_loss: 0.4053 - val_accuracy: 0.8354\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0955 - accuracy: 0.9683 - val_loss: 0.4043 - val_accuracy: 0.8436\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1109 - accuracy: 0.9612 - val_loss: 0.3341 - val_accuracy: 0.8395\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1200 - accuracy: 0.9559 - val_loss: 0.3160 - val_accuracy: 0.8632\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9568 - val_loss: 0.3301 - val_accuracy: 0.8488\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1024 - accuracy: 0.9594 - val_loss: 0.3892 - val_accuracy: 0.8385\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1179 - accuracy: 0.9590 - val_loss: 0.3403 - val_accuracy: 0.8467\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9524 - val_loss: 0.3311 - val_accuracy: 0.8447\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1244 - accuracy: 0.9616 - val_loss: 0.3364 - val_accuracy: 0.8539\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0902 - accuracy: 0.9630 - val_loss: 0.3195 - val_accuracy: 0.8519\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.9511 - val_loss: 0.3561 - val_accuracy: 0.8344\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1033 - accuracy: 0.9590 - val_loss: 0.3219 - val_accuracy: 0.8529\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1010 - accuracy: 0.9581 - val_loss: 0.3293 - val_accuracy: 0.8508\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1397 - accuracy: 0.9625 - val_loss: 0.3205 - val_accuracy: 0.8704\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0963 - accuracy: 0.9634 - val_loss: 0.3227 - val_accuracy: 0.8488\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0820 - accuracy: 0.9731 - val_loss: 0.2967 - val_accuracy: 0.8683\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0989 - accuracy: 0.9643 - val_loss: 0.3170 - val_accuracy: 0.8601\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0963 - accuracy: 0.9687 - val_loss: 0.3033 - val_accuracy: 0.8673\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9590 - val_loss: 0.3236 - val_accuracy: 0.8652\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1089 - accuracy: 0.9656 - val_loss: 0.3203 - val_accuracy: 0.8704\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1069 - accuracy: 0.9603 - val_loss: 0.3132 - val_accuracy: 0.8724\n","Score: 0.8724279999732971 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 693732.5000 - accuracy: 0.8805 - val_loss: 36.8389 - val_accuracy: 0.4794\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 8.8034 - accuracy: 0.8898 - val_loss: 24.4127 - val_accuracy: 0.5237\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 2.9717 - accuracy: 0.8884 - val_loss: 8.7801 - val_accuracy: 0.5082\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 2.1447 - accuracy: 0.8942 - val_loss: 26.4882 - val_accuracy: 0.4877\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.6769 - accuracy: 0.8911 - val_loss: 0.7151 - val_accuracy: 0.4835\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9021 - val_loss: 0.6977 - val_accuracy: 0.5154\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1868 - accuracy: 0.9140 - val_loss: 0.6931 - val_accuracy: 0.5154\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9180 - val_loss: 0.7123 - val_accuracy: 0.5103\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2031 - accuracy: 0.9026 - val_loss: 0.6940 - val_accuracy: 0.4938\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1901 - accuracy: 0.9162 - val_loss: 0.7021 - val_accuracy: 0.5175\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9078 - val_loss: 0.6922 - val_accuracy: 0.5237\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9074 - val_loss: 0.7039 - val_accuracy: 0.5175\n","Epoch 13/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1956 - accuracy: 0.9109 - val_loss: 0.6931 - val_accuracy: 0.5134\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9158 - val_loss: 0.6937 - val_accuracy: 0.4877\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1873 - accuracy: 0.9127 - val_loss: 0.7052 - val_accuracy: 0.5237\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1950 - accuracy: 0.9039 - val_loss: 0.6971 - val_accuracy: 0.4712\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1867 - accuracy: 0.9101 - val_loss: 0.7258 - val_accuracy: 0.5062\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9149 - val_loss: 0.7704 - val_accuracy: 0.4815\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2031 - accuracy: 0.8999 - val_loss: 0.7016 - val_accuracy: 0.4979\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9008 - val_loss: 0.6942 - val_accuracy: 0.5185\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1858 - accuracy: 0.9070 - val_loss: 0.6962 - val_accuracy: 0.4784\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1899 - accuracy: 0.9167 - val_loss: 0.6989 - val_accuracy: 0.5082\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1865 - accuracy: 0.9167 - val_loss: 0.7776 - val_accuracy: 0.5103\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9175 - val_loss: 0.6968 - val_accuracy: 0.5247\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1944 - accuracy: 0.9061 - val_loss: 0.7412 - val_accuracy: 0.5021\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1926 - accuracy: 0.9140 - val_loss: 0.6972 - val_accuracy: 0.5062\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1860 - accuracy: 0.9092 - val_loss: 0.6958 - val_accuracy: 0.5134\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2001 - accuracy: 0.9105 - val_loss: 0.7235 - val_accuracy: 0.5154\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1929 - accuracy: 0.9078 - val_loss: 0.6937 - val_accuracy: 0.4949\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9140 - val_loss: 0.7311 - val_accuracy: 0.4897\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1988 - accuracy: 0.9048 - val_loss: 0.7469 - val_accuracy: 0.4938\n","Epoch 32/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1914 - accuracy: 0.8920 - val_loss: 0.7051 - val_accuracy: 0.4877\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1918 - accuracy: 0.9127 - val_loss: 0.7181 - val_accuracy: 0.5082\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1966 - accuracy: 0.9043 - val_loss: 0.7190 - val_accuracy: 0.4825\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1871 - accuracy: 0.9118 - val_loss: 0.7019 - val_accuracy: 0.4763\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9136 - val_loss: 0.7096 - val_accuracy: 0.4825\n","Epoch 37/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1890 - accuracy: 0.9056 - val_loss: 0.7004 - val_accuracy: 0.4794\n","Epoch 38/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1863 - accuracy: 0.9153 - val_loss: 0.6925 - val_accuracy: 0.5257\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2005 - accuracy: 0.9101 - val_loss: 0.7391 - val_accuracy: 0.4877\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1947 - accuracy: 0.9030 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 41/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1954 - accuracy: 0.9061 - val_loss: 0.7330 - val_accuracy: 0.4877\n","Epoch 42/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2015 - accuracy: 0.9074 - val_loss: 0.7018 - val_accuracy: 0.5144\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9096 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1959 - accuracy: 0.9074 - val_loss: 0.7018 - val_accuracy: 0.5051\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1855 - accuracy: 0.9123 - val_loss: 0.7339 - val_accuracy: 0.4897\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1934 - accuracy: 0.9092 - val_loss: 0.6938 - val_accuracy: 0.5041\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1935 - accuracy: 0.9017 - val_loss: 0.7032 - val_accuracy: 0.5175\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1904 - accuracy: 0.9105 - val_loss: 0.6927 - val_accuracy: 0.5185\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9149 - val_loss: 0.7184 - val_accuracy: 0.5000\n","Epoch 50/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1900 - accuracy: 0.9034 - val_loss: 0.6917 - val_accuracy: 0.5267\n","Score: 0.5267489552497864 \n","Parameters:  {'learning_rate': 0.1637064649142506, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 22039.1406 - accuracy: 0.8924 - val_loss: 0.6944 - val_accuracy: 0.5175\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2299 - accuracy: 0.9118 - val_loss: 0.6911 - val_accuracy: 0.5319\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2302 - accuracy: 0.9136 - val_loss: 0.6932 - val_accuracy: 0.4825\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2231 - accuracy: 0.9149 - val_loss: 0.6961 - val_accuracy: 0.5185\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2212 - accuracy: 0.9193 - val_loss: 0.7154 - val_accuracy: 0.5010\n","Epoch 6/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2202 - accuracy: 0.9136 - val_loss: 0.6988 - val_accuracy: 0.4815\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2250 - accuracy: 0.9092 - val_loss: 0.6933 - val_accuracy: 0.5175\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2249 - accuracy: 0.9162 - val_loss: 0.6963 - val_accuracy: 0.4877\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2215 - accuracy: 0.9118 - val_loss: 0.6932 - val_accuracy: 0.5103\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2223 - accuracy: 0.9149 - val_loss: 0.6947 - val_accuracy: 0.5031\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2197 - accuracy: 0.9162 - val_loss: 0.6934 - val_accuracy: 0.5062\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2234 - accuracy: 0.9131 - val_loss: 0.6935 - val_accuracy: 0.4918\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2317 - accuracy: 0.9043 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2129 - accuracy: 0.9224 - val_loss: 0.6958 - val_accuracy: 0.5185\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2367 - accuracy: 0.9105 - val_loss: 0.7024 - val_accuracy: 0.5000\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2223 - accuracy: 0.9092 - val_loss: 0.6938 - val_accuracy: 0.5185\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2318 - accuracy: 0.9118 - val_loss: 0.6962 - val_accuracy: 0.5113\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2252 - accuracy: 0.9140 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 19/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2256 - accuracy: 0.9224 - val_loss: 0.6967 - val_accuracy: 0.5175\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2263 - accuracy: 0.9153 - val_loss: 0.7021 - val_accuracy: 0.5082\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2271 - accuracy: 0.9101 - val_loss: 0.6941 - val_accuracy: 0.4825\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2302 - accuracy: 0.9056 - val_loss: 0.6992 - val_accuracy: 0.4856\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2291 - accuracy: 0.9017 - val_loss: 0.6935 - val_accuracy: 0.4825\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2279 - accuracy: 0.9052 - val_loss: 0.6955 - val_accuracy: 0.5113\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.9206 - val_loss: 0.6944 - val_accuracy: 0.4846\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2281 - accuracy: 0.9078 - val_loss: 0.6923 - val_accuracy: 0.5237\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2317 - accuracy: 0.9167 - val_loss: 0.7019 - val_accuracy: 0.5113\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2242 - accuracy: 0.9184 - val_loss: 0.7032 - val_accuracy: 0.5154\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2260 - accuracy: 0.9136 - val_loss: 0.6930 - val_accuracy: 0.5165\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2278 - accuracy: 0.9136 - val_loss: 0.7025 - val_accuracy: 0.5021\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2132 - accuracy: 0.9158 - val_loss: 0.7036 - val_accuracy: 0.4969\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2253 - accuracy: 0.9048 - val_loss: 0.6939 - val_accuracy: 0.4866\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2315 - accuracy: 0.9052 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2183 - accuracy: 0.9180 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2345 - accuracy: 0.9048 - val_loss: 0.6939 - val_accuracy: 0.4825\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2237 - accuracy: 0.9074 - val_loss: 0.6930 - val_accuracy: 0.5298\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2164 - accuracy: 0.9246 - val_loss: 0.6985 - val_accuracy: 0.4959\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2269 - accuracy: 0.9048 - val_loss: 0.7038 - val_accuracy: 0.4774\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2265 - accuracy: 0.9078 - val_loss: 0.7094 - val_accuracy: 0.4784\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.8981 - val_loss: 0.6931 - val_accuracy: 0.5195\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2226 - accuracy: 0.9153 - val_loss: 0.6927 - val_accuracy: 0.5195\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2218 - accuracy: 0.9162 - val_loss: 0.6950 - val_accuracy: 0.5093\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9065 - val_loss: 0.6972 - val_accuracy: 0.5113\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9153 - val_loss: 0.6917 - val_accuracy: 0.5381\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2313 - accuracy: 0.9065 - val_loss: 0.6928 - val_accuracy: 0.5195\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2289 - accuracy: 0.9043 - val_loss: 0.6933 - val_accuracy: 0.5041\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2247 - accuracy: 0.9096 - val_loss: 0.6915 - val_accuracy: 0.5309\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2130 - accuracy: 0.9228 - val_loss: 0.6959 - val_accuracy: 0.5175\n","Epoch 49/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2190 - accuracy: 0.9180 - val_loss: 0.6922 - val_accuracy: 0.5237\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2213 - accuracy: 0.9198 - val_loss: 0.7093 - val_accuracy: 0.5154\n","Score: 0.5154321193695068 \n","Parameters:  {'learning_rate': 0.045707760410235186, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4769 - accuracy: 0.9202 - val_loss: 0.6367 - val_accuracy: 0.6471\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1772 - accuracy: 0.9325 - val_loss: 0.5723 - val_accuracy: 0.6636\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1599 - accuracy: 0.9383 - val_loss: 0.5311 - val_accuracy: 0.7479\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1736 - accuracy: 0.9295 - val_loss: 0.4714 - val_accuracy: 0.7665\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1475 - accuracy: 0.9409 - val_loss: 0.4796 - val_accuracy: 0.7449\n","Epoch 6/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1556 - accuracy: 0.9392 - val_loss: 0.5024 - val_accuracy: 0.7479\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1475 - accuracy: 0.9409 - val_loss: 0.4704 - val_accuracy: 0.7706\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1453 - accuracy: 0.9436 - val_loss: 0.4401 - val_accuracy: 0.7953\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1633 - accuracy: 0.9369 - val_loss: 0.4482 - val_accuracy: 0.7798\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3771 - accuracy: 0.9339 - val_loss: 0.4634 - val_accuracy: 0.7767\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1449 - accuracy: 0.9436 - val_loss: 0.5211 - val_accuracy: 0.7551\n","Epoch 12/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1518 - accuracy: 0.9471 - val_loss: 0.5388 - val_accuracy: 0.7531\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9453 - val_loss: 0.4297 - val_accuracy: 0.7942\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9405 - val_loss: 0.4898 - val_accuracy: 0.7572\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1418 - accuracy: 0.9444 - val_loss: 0.4518 - val_accuracy: 0.7675\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1332 - accuracy: 0.9462 - val_loss: 0.4132 - val_accuracy: 0.8066\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1609 - accuracy: 0.9497 - val_loss: 0.4773 - val_accuracy: 0.7737\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9440 - val_loss: 0.4792 - val_accuracy: 0.7603\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1277 - accuracy: 0.9519 - val_loss: 0.4789 - val_accuracy: 0.7716\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1442 - accuracy: 0.9418 - val_loss: 0.4304 - val_accuracy: 0.7942\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1208 - accuracy: 0.9541 - val_loss: 0.4138 - val_accuracy: 0.7984\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9533 - val_loss: 0.3983 - val_accuracy: 0.8189\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1730 - accuracy: 0.9471 - val_loss: 0.4068 - val_accuracy: 0.8251\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1232 - accuracy: 0.9524 - val_loss: 0.4485 - val_accuracy: 0.8045\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9590 - val_loss: 0.3743 - val_accuracy: 0.8261\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1764 - accuracy: 0.9475 - val_loss: 0.4022 - val_accuracy: 0.8086\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9555 - val_loss: 0.4065 - val_accuracy: 0.8128\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9497 - val_loss: 0.4738 - val_accuracy: 0.7901\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9440 - val_loss: 0.3821 - val_accuracy: 0.8251\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9519 - val_loss: 0.4052 - val_accuracy: 0.7994\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9563 - val_loss: 0.3713 - val_accuracy: 0.8251\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1256 - accuracy: 0.9563 - val_loss: 0.4107 - val_accuracy: 0.8158\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1213 - accuracy: 0.9616 - val_loss: 0.3892 - val_accuracy: 0.8210\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1299 - accuracy: 0.9484 - val_loss: 0.4329 - val_accuracy: 0.7922\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1175 - accuracy: 0.9577 - val_loss: 0.3640 - val_accuracy: 0.8323\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9444 - val_loss: 0.3822 - val_accuracy: 0.8272\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1184 - accuracy: 0.9568 - val_loss: 0.3676 - val_accuracy: 0.8282\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1151 - accuracy: 0.9546 - val_loss: 0.3302 - val_accuracy: 0.8529\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1070 - accuracy: 0.9603 - val_loss: 0.3588 - val_accuracy: 0.8426\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0949 - accuracy: 0.9687 - val_loss: 0.3711 - val_accuracy: 0.8323\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1260 - accuracy: 0.9559 - val_loss: 0.3573 - val_accuracy: 0.8272\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.9524 - val_loss: 0.3416 - val_accuracy: 0.8519\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9537 - val_loss: 0.3981 - val_accuracy: 0.8364\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1248 - accuracy: 0.9563 - val_loss: 0.3376 - val_accuracy: 0.8344\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1275 - accuracy: 0.9563 - val_loss: 0.3309 - val_accuracy: 0.8498\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1156 - accuracy: 0.9550 - val_loss: 0.3685 - val_accuracy: 0.8405\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9616 - val_loss: 0.3215 - val_accuracy: 0.8488\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1032 - accuracy: 0.9638 - val_loss: 0.3489 - val_accuracy: 0.8405\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0955 - accuracy: 0.9638 - val_loss: 0.3220 - val_accuracy: 0.8508\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2782 - accuracy: 0.9594 - val_loss: 0.2879 - val_accuracy: 0.8735\n","Score: 0.8734567761421204 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5916 - accuracy: 0.9162 - val_loss: 0.6659 - val_accuracy: 0.6564\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9118 - val_loss: 0.6515 - val_accuracy: 0.5226\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9171 - val_loss: 0.6180 - val_accuracy: 0.7016\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1795 - accuracy: 0.9184 - val_loss: 0.6207 - val_accuracy: 0.6646\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2477 - accuracy: 0.9145 - val_loss: 0.6223 - val_accuracy: 0.6718\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.9211 - val_loss: 0.6281 - val_accuracy: 0.6739\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1706 - accuracy: 0.9202 - val_loss: 0.6497 - val_accuracy: 0.5021\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1633 - accuracy: 0.9312 - val_loss: 0.5730 - val_accuracy: 0.7150\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1806 - accuracy: 0.9295 - val_loss: 0.5787 - val_accuracy: 0.7305\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1545 - accuracy: 0.9458 - val_loss: 0.5777 - val_accuracy: 0.7202\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3536 - accuracy: 0.9325 - val_loss: 0.5107 - val_accuracy: 0.7356\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1663 - accuracy: 0.9334 - val_loss: 0.5147 - val_accuracy: 0.7387\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.9422 - val_loss: 0.4797 - val_accuracy: 0.7654\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1466 - accuracy: 0.9365 - val_loss: 0.4942 - val_accuracy: 0.7469\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1580 - accuracy: 0.9431 - val_loss: 0.5127 - val_accuracy: 0.7418\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1774 - accuracy: 0.9378 - val_loss: 0.4667 - val_accuracy: 0.7850\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9361 - val_loss: 0.4407 - val_accuracy: 0.7778\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1973 - accuracy: 0.9436 - val_loss: 0.4197 - val_accuracy: 0.8220\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1421 - accuracy: 0.9497 - val_loss: 0.4474 - val_accuracy: 0.7716\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1551 - accuracy: 0.9502 - val_loss: 0.4318 - val_accuracy: 0.7850\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1413 - accuracy: 0.9418 - val_loss: 0.4235 - val_accuracy: 0.7901\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1368 - accuracy: 0.9511 - val_loss: 0.4611 - val_accuracy: 0.7706\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1393 - accuracy: 0.9502 - val_loss: 0.4266 - val_accuracy: 0.8025\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1226 - accuracy: 0.9528 - val_loss: 0.4048 - val_accuracy: 0.8107\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9590 - val_loss: 0.4217 - val_accuracy: 0.7994\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1181 - accuracy: 0.9586 - val_loss: 0.3881 - val_accuracy: 0.8179\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1180 - accuracy: 0.9546 - val_loss: 0.4459 - val_accuracy: 0.7932\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9555 - val_loss: 0.3893 - val_accuracy: 0.8035\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1124 - accuracy: 0.9599 - val_loss: 0.3962 - val_accuracy: 0.8117\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1784 - accuracy: 0.9546 - val_loss: 0.4020 - val_accuracy: 0.8138\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1173 - accuracy: 0.9581 - val_loss: 0.3851 - val_accuracy: 0.8107\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1162 - accuracy: 0.9581 - val_loss: 0.3739 - val_accuracy: 0.8313\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1206 - accuracy: 0.9489 - val_loss: 0.4197 - val_accuracy: 0.8056\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1207 - accuracy: 0.9506 - val_loss: 0.3965 - val_accuracy: 0.8272\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1430 - accuracy: 0.9502 - val_loss: 0.3942 - val_accuracy: 0.8097\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1264 - accuracy: 0.9519 - val_loss: 0.3798 - val_accuracy: 0.8179\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1667 - accuracy: 0.9462 - val_loss: 0.3994 - val_accuracy: 0.8128\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1034 - accuracy: 0.9599 - val_loss: 0.3444 - val_accuracy: 0.8488\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9515 - val_loss: 0.4105 - val_accuracy: 0.8107\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7497 - accuracy: 0.9515 - val_loss: 0.3971 - val_accuracy: 0.8169\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1202 - accuracy: 0.9572 - val_loss: 0.3583 - val_accuracy: 0.8313\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1409 - accuracy: 0.9541 - val_loss: 0.3263 - val_accuracy: 0.8498\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1051 - accuracy: 0.9625 - val_loss: 0.3207 - val_accuracy: 0.8447\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0980 - accuracy: 0.9643 - val_loss: 0.3896 - val_accuracy: 0.8302\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0985 - accuracy: 0.9586 - val_loss: 0.3210 - val_accuracy: 0.8436\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0880 - accuracy: 0.9674 - val_loss: 0.2863 - val_accuracy: 0.8652\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0867 - accuracy: 0.9647 - val_loss: 0.3209 - val_accuracy: 0.8580\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9630 - val_loss: 0.3387 - val_accuracy: 0.8426\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1460 - accuracy: 0.9590 - val_loss: 0.3329 - val_accuracy: 0.8374\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1027 - accuracy: 0.9621 - val_loss: 0.3256 - val_accuracy: 0.8529\n","Score: 0.8528806567192078 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9417 - accuracy: 0.9211 - val_loss: 0.6832 - val_accuracy: 0.5885\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6016 - accuracy: 0.9198 - val_loss: 0.6014 - val_accuracy: 0.6986\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9211 - val_loss: 0.7546 - val_accuracy: 0.6574\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2712 - accuracy: 0.9167 - val_loss: 0.6539 - val_accuracy: 0.6831\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2493 - accuracy: 0.9198 - val_loss: 0.6597 - val_accuracy: 0.6543\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1768 - accuracy: 0.9131 - val_loss: 0.6075 - val_accuracy: 0.6698\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1749 - accuracy: 0.9211 - val_loss: 0.5871 - val_accuracy: 0.6780\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1738 - accuracy: 0.9211 - val_loss: 0.6000 - val_accuracy: 0.6389\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1794 - accuracy: 0.9175 - val_loss: 0.5771 - val_accuracy: 0.6636\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9330 - val_loss: 0.5727 - val_accuracy: 0.6574\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1623 - accuracy: 0.9325 - val_loss: 0.5929 - val_accuracy: 0.6872\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9127 - val_loss: 0.6039 - val_accuracy: 0.6163\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1696 - accuracy: 0.9184 - val_loss: 0.5739 - val_accuracy: 0.6492\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.9365 - val_loss: 0.5662 - val_accuracy: 0.6842\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1712 - accuracy: 0.9259 - val_loss: 0.6101 - val_accuracy: 0.7335\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1782 - accuracy: 0.9233 - val_loss: 0.5467 - val_accuracy: 0.6924\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1827 - accuracy: 0.9264 - val_loss: 0.5538 - val_accuracy: 0.6975\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1525 - accuracy: 0.9387 - val_loss: 0.5414 - val_accuracy: 0.6996\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1766 - accuracy: 0.9277 - val_loss: 0.5725 - val_accuracy: 0.6646\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1785 - accuracy: 0.9303 - val_loss: 0.5051 - val_accuracy: 0.7438\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1649 - accuracy: 0.9369 - val_loss: 0.5215 - val_accuracy: 0.7387\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9352 - val_loss: 0.5220 - val_accuracy: 0.7274\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9466 - val_loss: 0.5064 - val_accuracy: 0.7387\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1944 - accuracy: 0.9162 - val_loss: 0.5531 - val_accuracy: 0.6893\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1394 - accuracy: 0.9444 - val_loss: 0.5715 - val_accuracy: 0.7068\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1502 - accuracy: 0.9392 - val_loss: 0.4933 - val_accuracy: 0.7397\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9431 - val_loss: 0.5818 - val_accuracy: 0.6852\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9312 - val_loss: 0.4677 - val_accuracy: 0.7706\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2081 - accuracy: 0.9427 - val_loss: 0.5009 - val_accuracy: 0.7593\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9453 - val_loss: 0.4751 - val_accuracy: 0.7521\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1739 - accuracy: 0.9462 - val_loss: 0.4742 - val_accuracy: 0.7500\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1403 - accuracy: 0.9484 - val_loss: 0.4858 - val_accuracy: 0.7449\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1658 - accuracy: 0.9422 - val_loss: 0.4636 - val_accuracy: 0.7881\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9427 - val_loss: 0.5116 - val_accuracy: 0.7294\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9493 - val_loss: 0.4582 - val_accuracy: 0.7665\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1460 - accuracy: 0.9449 - val_loss: 0.4852 - val_accuracy: 0.7541\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1465 - accuracy: 0.9431 - val_loss: 0.4969 - val_accuracy: 0.7366\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1437 - accuracy: 0.9475 - val_loss: 0.5064 - val_accuracy: 0.7572\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1389 - accuracy: 0.9466 - val_loss: 0.4552 - val_accuracy: 0.7695\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1347 - accuracy: 0.9493 - val_loss: 0.4800 - val_accuracy: 0.7582\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9431 - val_loss: 0.4558 - val_accuracy: 0.7654\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9519 - val_loss: 0.4140 - val_accuracy: 0.7850\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1508 - accuracy: 0.9458 - val_loss: 0.4054 - val_accuracy: 0.7963\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.9559 - val_loss: 0.4179 - val_accuracy: 0.8035\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1236 - accuracy: 0.9519 - val_loss: 0.4217 - val_accuracy: 0.8025\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1422 - accuracy: 0.9418 - val_loss: 0.4272 - val_accuracy: 0.8004\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1380 - accuracy: 0.9480 - val_loss: 0.4430 - val_accuracy: 0.7912\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1399 - accuracy: 0.9497 - val_loss: 0.4568 - val_accuracy: 0.7798\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1405 - accuracy: 0.9489 - val_loss: 0.4288 - val_accuracy: 0.7891\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1507 - accuracy: 0.9440 - val_loss: 0.3953 - val_accuracy: 0.7994\n","Score: 0.7993826866149902 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 4551.5796 - accuracy: 0.9096 - val_loss: 0.7568 - val_accuracy: 0.4743\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1782 - accuracy: 0.9092 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2104 - accuracy: 0.9101 - val_loss: 0.6935 - val_accuracy: 0.5226\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2475 - accuracy: 0.9109 - val_loss: 0.6953 - val_accuracy: 0.5113\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2453 - accuracy: 0.9184 - val_loss: 0.7174 - val_accuracy: 0.5144\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2307 - accuracy: 0.9237 - val_loss: 0.7049 - val_accuracy: 0.5062\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2448 - accuracy: 0.9118 - val_loss: 0.6932 - val_accuracy: 0.5051\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2454 - accuracy: 0.9175 - val_loss: 0.6937 - val_accuracy: 0.5082\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2494 - accuracy: 0.9136 - val_loss: 0.6934 - val_accuracy: 0.4928\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2571 - accuracy: 0.9118 - val_loss: 0.7273 - val_accuracy: 0.5093\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2450 - accuracy: 0.9131 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2426 - accuracy: 0.9220 - val_loss: 0.7088 - val_accuracy: 0.5154\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2557 - accuracy: 0.9070 - val_loss: 0.6957 - val_accuracy: 0.5185\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2431 - accuracy: 0.9184 - val_loss: 0.6972 - val_accuracy: 0.5113\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2473 - accuracy: 0.9171 - val_loss: 0.6975 - val_accuracy: 0.5010\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2394 - accuracy: 0.9242 - val_loss: 0.7138 - val_accuracy: 0.5062\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2481 - accuracy: 0.9149 - val_loss: 0.6981 - val_accuracy: 0.5072\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2589 - accuracy: 0.9083 - val_loss: 0.6919 - val_accuracy: 0.5247\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2569 - accuracy: 0.9105 - val_loss: 0.6934 - val_accuracy: 0.5257\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2473 - accuracy: 0.9162 - val_loss: 0.6933 - val_accuracy: 0.5123\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2436 - accuracy: 0.9206 - val_loss: 0.7030 - val_accuracy: 0.5000\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2521 - accuracy: 0.9131 - val_loss: 0.6940 - val_accuracy: 0.5093\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2458 - accuracy: 0.9224 - val_loss: 0.6979 - val_accuracy: 0.5422\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2393 - accuracy: 0.9193 - val_loss: 0.6931 - val_accuracy: 0.5206\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2613 - accuracy: 0.9087 - val_loss: 0.7021 - val_accuracy: 0.5113\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2456 - accuracy: 0.9123 - val_loss: 0.6947 - val_accuracy: 0.4712\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2588 - accuracy: 0.9052 - val_loss: 0.6983 - val_accuracy: 0.5195\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2400 - accuracy: 0.9202 - val_loss: 0.6999 - val_accuracy: 0.5082\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2500 - accuracy: 0.9140 - val_loss: 0.6986 - val_accuracy: 0.5021\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2499 - accuracy: 0.9167 - val_loss: 0.6967 - val_accuracy: 0.5154\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2471 - accuracy: 0.9175 - val_loss: 0.6973 - val_accuracy: 0.5206\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2508 - accuracy: 0.9171 - val_loss: 0.7056 - val_accuracy: 0.5165\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2438 - accuracy: 0.9184 - val_loss: 0.7168 - val_accuracy: 0.5072\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2485 - accuracy: 0.9118 - val_loss: 0.6942 - val_accuracy: 0.5082\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2524 - accuracy: 0.9070 - val_loss: 0.6947 - val_accuracy: 0.4856\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2511 - accuracy: 0.9083 - val_loss: 0.7025 - val_accuracy: 0.5154\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2560 - accuracy: 0.9105 - val_loss: 0.6991 - val_accuracy: 0.5062\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2544 - accuracy: 0.9087 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2524 - accuracy: 0.9140 - val_loss: 0.6933 - val_accuracy: 0.5144\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2546 - accuracy: 0.9149 - val_loss: 0.6966 - val_accuracy: 0.5165\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2427 - accuracy: 0.9202 - val_loss: 0.7102 - val_accuracy: 0.4959\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2513 - accuracy: 0.9087 - val_loss: 0.6933 - val_accuracy: 0.4805\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2539 - accuracy: 0.9065 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2583 - accuracy: 0.9162 - val_loss: 0.7012 - val_accuracy: 0.5298\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2461 - accuracy: 0.9158 - val_loss: 0.6986 - val_accuracy: 0.5175\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2500 - accuracy: 0.9184 - val_loss: 0.7200 - val_accuracy: 0.5062\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9092 - val_loss: 0.6915 - val_accuracy: 0.5298\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2523 - accuracy: 0.9127 - val_loss: 0.6951 - val_accuracy: 0.5000\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2491 - accuracy: 0.9145 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9189 - val_loss: 0.7095 - val_accuracy: 0.5041\n","Score: 0.5041152238845825 \n","Parameters:  {'learning_rate': 0.029394091708996463, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 6101.4575 - accuracy: 0.9127 - val_loss: 0.6964 - val_accuracy: 0.5257\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2215 - accuracy: 0.9127 - val_loss: 0.6938 - val_accuracy: 0.5113\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2225 - accuracy: 0.9189 - val_loss: 0.7155 - val_accuracy: 0.4990\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2145 - accuracy: 0.9211 - val_loss: 0.6926 - val_accuracy: 0.5195\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2249 - accuracy: 0.9180 - val_loss: 0.6964 - val_accuracy: 0.5185\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9131 - val_loss: 0.7014 - val_accuracy: 0.4846\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2223 - accuracy: 0.9127 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2226 - accuracy: 0.9211 - val_loss: 0.6969 - val_accuracy: 0.5278\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2158 - accuracy: 0.9175 - val_loss: 0.6942 - val_accuracy: 0.5185\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2264 - accuracy: 0.9123 - val_loss: 0.6974 - val_accuracy: 0.5051\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2303 - accuracy: 0.9074 - val_loss: 0.7129 - val_accuracy: 0.4815\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2352 - accuracy: 0.8973 - val_loss: 0.6920 - val_accuracy: 0.5257\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9162 - val_loss: 0.6935 - val_accuracy: 0.4794\n","Epoch 14/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2178 - accuracy: 0.9158 - val_loss: 0.6986 - val_accuracy: 0.5093\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2273 - accuracy: 0.9118 - val_loss: 0.6920 - val_accuracy: 0.5237\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2243 - accuracy: 0.9180 - val_loss: 0.7135 - val_accuracy: 0.5144\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2093 - accuracy: 0.9180 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2260 - accuracy: 0.9175 - val_loss: 0.6947 - val_accuracy: 0.5216\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9202 - val_loss: 0.6943 - val_accuracy: 0.5113\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2283 - accuracy: 0.9087 - val_loss: 0.6932 - val_accuracy: 0.5031\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2139 - accuracy: 0.9162 - val_loss: 0.7012 - val_accuracy: 0.4743\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2246 - accuracy: 0.9083 - val_loss: 0.7052 - val_accuracy: 0.5041\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2216 - accuracy: 0.9149 - val_loss: 0.6940 - val_accuracy: 0.5041\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2207 - accuracy: 0.9215 - val_loss: 0.7077 - val_accuracy: 0.5329\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2164 - accuracy: 0.9202 - val_loss: 0.6922 - val_accuracy: 0.5247\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2149 - accuracy: 0.9167 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2206 - accuracy: 0.9184 - val_loss: 0.6941 - val_accuracy: 0.5278\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2231 - accuracy: 0.9171 - val_loss: 0.6939 - val_accuracy: 0.5206\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2197 - accuracy: 0.9215 - val_loss: 0.7000 - val_accuracy: 0.5257\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2200 - accuracy: 0.9105 - val_loss: 0.6940 - val_accuracy: 0.4805\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2352 - accuracy: 0.8986 - val_loss: 0.6925 - val_accuracy: 0.5206\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2170 - accuracy: 0.9180 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2220 - accuracy: 0.9215 - val_loss: 0.6970 - val_accuracy: 0.5237\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2188 - accuracy: 0.9158 - val_loss: 0.6958 - val_accuracy: 0.5031\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2204 - accuracy: 0.9114 - val_loss: 0.6933 - val_accuracy: 0.4825\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2234 - accuracy: 0.9162 - val_loss: 0.7002 - val_accuracy: 0.5103\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2237 - accuracy: 0.9145 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2283 - accuracy: 0.9096 - val_loss: 0.6921 - val_accuracy: 0.5247\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2239 - accuracy: 0.9140 - val_loss: 0.7016 - val_accuracy: 0.4774\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2310 - accuracy: 0.8946 - val_loss: 0.6930 - val_accuracy: 0.5144\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2210 - accuracy: 0.9136 - val_loss: 0.6950 - val_accuracy: 0.4784\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2340 - accuracy: 0.9030 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2280 - accuracy: 0.9136 - val_loss: 0.7001 - val_accuracy: 0.5226\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2274 - accuracy: 0.9158 - val_loss: 0.6929 - val_accuracy: 0.5195\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9206 - val_loss: 0.6940 - val_accuracy: 0.5062\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2247 - accuracy: 0.9149 - val_loss: 0.7052 - val_accuracy: 0.4959\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2204 - accuracy: 0.9224 - val_loss: 0.7339 - val_accuracy: 0.4990\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.9171 - val_loss: 0.6946 - val_accuracy: 0.5062\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2185 - accuracy: 0.9118 - val_loss: 0.6958 - val_accuracy: 0.4887\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2385 - accuracy: 0.9030 - val_loss: 0.6949 - val_accuracy: 0.5082\n","Score: 0.508230447769165 \n","Parameters:  {'learning_rate': 0.047045604263100636, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1925 - accuracy: 0.9162 - val_loss: 0.6815 - val_accuracy: 0.5123\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.9149 - val_loss: 0.6512 - val_accuracy: 0.6821\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1758 - accuracy: 0.9184 - val_loss: 0.6213 - val_accuracy: 0.7047\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1758 - accuracy: 0.9193 - val_loss: 0.6123 - val_accuracy: 0.7006\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6747 - accuracy: 0.9175 - val_loss: 0.5845 - val_accuracy: 0.7222\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1686 - accuracy: 0.9224 - val_loss: 0.5758 - val_accuracy: 0.7294\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1754 - accuracy: 0.9224 - val_loss: 0.5720 - val_accuracy: 0.7160\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9167 - val_loss: 0.5757 - val_accuracy: 0.7263\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9220 - val_loss: 0.5646 - val_accuracy: 0.7449\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9237 - val_loss: 0.5698 - val_accuracy: 0.7171\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9299 - val_loss: 0.5707 - val_accuracy: 0.7377\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4827 - accuracy: 0.9281 - val_loss: 0.5922 - val_accuracy: 0.6687\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1786 - accuracy: 0.9347 - val_loss: 0.4927 - val_accuracy: 0.7644\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1670 - accuracy: 0.9339 - val_loss: 0.4735 - val_accuracy: 0.7726\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.9396 - val_loss: 0.4963 - val_accuracy: 0.7747\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1567 - accuracy: 0.9339 - val_loss: 0.5599 - val_accuracy: 0.7150\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9400 - val_loss: 0.4529 - val_accuracy: 0.7850\n","Epoch 18/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1585 - accuracy: 0.9414 - val_loss: 0.4664 - val_accuracy: 0.7953\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1773 - accuracy: 0.9343 - val_loss: 0.5437 - val_accuracy: 0.7356\n","Epoch 20/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1641 - accuracy: 0.9334 - val_loss: 0.4702 - val_accuracy: 0.7891\n","Epoch 21/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.3715 - accuracy: 0.9449 - val_loss: 0.4505 - val_accuracy: 0.8004\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1474 - accuracy: 0.9440 - val_loss: 0.4671 - val_accuracy: 0.7788\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1557 - accuracy: 0.9392 - val_loss: 0.4391 - val_accuracy: 0.7932\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.9524 - val_loss: 0.4696 - val_accuracy: 0.7870\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1535 - accuracy: 0.9365 - val_loss: 0.4210 - val_accuracy: 0.8158\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9541 - val_loss: 0.4216 - val_accuracy: 0.8179\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1355 - accuracy: 0.9480 - val_loss: 0.4010 - val_accuracy: 0.8035\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1288 - accuracy: 0.9480 - val_loss: 0.4461 - val_accuracy: 0.7963\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2767 - accuracy: 0.9374 - val_loss: 0.3884 - val_accuracy: 0.8210\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1454 - accuracy: 0.9436 - val_loss: 0.4108 - val_accuracy: 0.8138\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1940 - accuracy: 0.9559 - val_loss: 0.4118 - val_accuracy: 0.8117\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9462 - val_loss: 0.4009 - val_accuracy: 0.8210\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9400 - val_loss: 0.3937 - val_accuracy: 0.8323\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1465 - accuracy: 0.9383 - val_loss: 0.4193 - val_accuracy: 0.8045\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9528 - val_loss: 0.4186 - val_accuracy: 0.8169\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9449 - val_loss: 0.4160 - val_accuracy: 0.8117\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9511 - val_loss: 0.3904 - val_accuracy: 0.8169\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1270 - accuracy: 0.9493 - val_loss: 0.4450 - val_accuracy: 0.8025\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1401 - accuracy: 0.9489 - val_loss: 0.3788 - val_accuracy: 0.8333\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1323 - accuracy: 0.9471 - val_loss: 0.3945 - val_accuracy: 0.8138\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1518 - accuracy: 0.9440 - val_loss: 0.4338 - val_accuracy: 0.7870\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2002 - accuracy: 0.9418 - val_loss: 0.4146 - val_accuracy: 0.8045\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1203 - accuracy: 0.9524 - val_loss: 0.3669 - val_accuracy: 0.8364\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1465 - accuracy: 0.9453 - val_loss: 0.3952 - val_accuracy: 0.8292\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1343 - accuracy: 0.9471 - val_loss: 0.4264 - val_accuracy: 0.7850\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1428 - accuracy: 0.9484 - val_loss: 0.4045 - val_accuracy: 0.8066\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2292 - accuracy: 0.9436 - val_loss: 0.4279 - val_accuracy: 0.8107\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1337 - accuracy: 0.9559 - val_loss: 0.4039 - val_accuracy: 0.8200\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9497 - val_loss: 0.4182 - val_accuracy: 0.8097\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1287 - accuracy: 0.9502 - val_loss: 0.4010 - val_accuracy: 0.8230\n","Score: 0.8230452537536621 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 340214.1875 - accuracy: 0.8990 - val_loss: 248.4969 - val_accuracy: 0.5895\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 22.4555 - accuracy: 0.9043 - val_loss: 1.9250 - val_accuracy: 0.4846\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 5.3556 - accuracy: 0.8955 - val_loss: 0.7823 - val_accuracy: 0.5062\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3047 - accuracy: 0.9056 - val_loss: 0.7024 - val_accuracy: 0.4825\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9114 - val_loss: 0.7161 - val_accuracy: 0.5257\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9092 - val_loss: 0.6934 - val_accuracy: 0.4907\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9118 - val_loss: 0.7006 - val_accuracy: 0.4959\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1997 - accuracy: 0.9105 - val_loss: 0.6944 - val_accuracy: 0.5123\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1997 - accuracy: 0.9158 - val_loss: 0.7033 - val_accuracy: 0.5051\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9092 - val_loss: 0.6999 - val_accuracy: 0.5165\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9149 - val_loss: 0.6964 - val_accuracy: 0.5072\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9118 - val_loss: 0.7297 - val_accuracy: 0.5010\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9087 - val_loss: 0.7248 - val_accuracy: 0.4866\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9030 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9198 - val_loss: 0.7609 - val_accuracy: 0.5051\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9175 - val_loss: 0.7194 - val_accuracy: 0.4815\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9087 - val_loss: 0.7143 - val_accuracy: 0.4763\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.8999 - val_loss: 0.6994 - val_accuracy: 0.5319\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2054 - accuracy: 0.9087 - val_loss: 0.6937 - val_accuracy: 0.4712\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9078 - val_loss: 0.6967 - val_accuracy: 0.5134\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9114 - val_loss: 0.6928 - val_accuracy: 0.5154\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9158 - val_loss: 0.6933 - val_accuracy: 0.5051\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2115 - accuracy: 0.9096 - val_loss: 0.6986 - val_accuracy: 0.4805\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9083 - val_loss: 0.7160 - val_accuracy: 0.5072\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9180 - val_loss: 0.7137 - val_accuracy: 0.4877\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.8977 - val_loss: 0.6931 - val_accuracy: 0.5123\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2116 - accuracy: 0.9074 - val_loss: 0.6951 - val_accuracy: 0.4938\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2190 - accuracy: 0.9043 - val_loss: 0.6928 - val_accuracy: 0.5123\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9215 - val_loss: 0.6947 - val_accuracy: 0.4815\n","Epoch 30/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2035 - accuracy: 0.9061 - val_loss: 0.7416 - val_accuracy: 0.4887\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2132 - accuracy: 0.8942 - val_loss: 0.7086 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.9052 - val_loss: 0.7230 - val_accuracy: 0.5134\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9175 - val_loss: 0.6988 - val_accuracy: 0.5154\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9153 - val_loss: 0.7001 - val_accuracy: 0.5062\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2002 - accuracy: 0.9167 - val_loss: 0.6971 - val_accuracy: 0.4918\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.9123 - val_loss: 0.6933 - val_accuracy: 0.5072\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9206 - val_loss: 0.7139 - val_accuracy: 0.5309\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2002 - accuracy: 0.9162 - val_loss: 0.6929 - val_accuracy: 0.5216\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9105 - val_loss: 0.7053 - val_accuracy: 0.5113\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9123 - val_loss: 0.7168 - val_accuracy: 0.5072\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9101 - val_loss: 0.6964 - val_accuracy: 0.5134\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9039 - val_loss: 0.6942 - val_accuracy: 0.4856\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2115 - accuracy: 0.9087 - val_loss: 0.6954 - val_accuracy: 0.4990\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2120 - accuracy: 0.9021 - val_loss: 0.7177 - val_accuracy: 0.4733\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9087 - val_loss: 0.7239 - val_accuracy: 0.5154\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9118 - val_loss: 0.6934 - val_accuracy: 0.4846\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9233 - val_loss: 0.7084 - val_accuracy: 0.5267\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9202 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9171 - val_loss: 0.7091 - val_accuracy: 0.4681\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9065 - val_loss: 0.6948 - val_accuracy: 0.5123\n","Score: 0.5123456716537476 \n","Parameters:  {'learning_rate': 0.08253476501615979, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.8905 - accuracy: 0.9118 - val_loss: 0.6711 - val_accuracy: 0.5340\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1875 - accuracy: 0.9167 - val_loss: 0.6764 - val_accuracy: 0.4979\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1821 - accuracy: 0.9180 - val_loss: 0.6610 - val_accuracy: 0.5679\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1847 - accuracy: 0.9215 - val_loss: 0.6822 - val_accuracy: 0.5010\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9136 - val_loss: 0.6425 - val_accuracy: 0.5967\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1777 - accuracy: 0.9246 - val_loss: 0.6152 - val_accuracy: 0.6399\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9308 - val_loss: 0.5968 - val_accuracy: 0.6986\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.9303 - val_loss: 0.5669 - val_accuracy: 0.7212\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1653 - accuracy: 0.9290 - val_loss: 0.5868 - val_accuracy: 0.6708\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1775 - accuracy: 0.9277 - val_loss: 0.5990 - val_accuracy: 0.7058\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2543 - accuracy: 0.9303 - val_loss: 0.5411 - val_accuracy: 0.7212\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1638 - accuracy: 0.9312 - val_loss: 1.0547 - val_accuracy: 0.5772\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1851 - accuracy: 0.9356 - val_loss: 0.5114 - val_accuracy: 0.7346\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1578 - accuracy: 0.9365 - val_loss: 0.5222 - val_accuracy: 0.7438\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1657 - accuracy: 0.9343 - val_loss: 0.5276 - val_accuracy: 0.7335\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2406 - accuracy: 0.9462 - val_loss: 0.5043 - val_accuracy: 0.7500\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1667 - accuracy: 0.9422 - val_loss: 0.5033 - val_accuracy: 0.7479\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1622 - accuracy: 0.9436 - val_loss: 0.5064 - val_accuracy: 0.7665\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1526 - accuracy: 0.9453 - val_loss: 0.5379 - val_accuracy: 0.7253\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8138 - accuracy: 0.9418 - val_loss: 0.4728 - val_accuracy: 0.7675\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1691 - accuracy: 0.9444 - val_loss: 0.4292 - val_accuracy: 0.7963\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1489 - accuracy: 0.9511 - val_loss: 0.4338 - val_accuracy: 0.7809\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1814 - accuracy: 0.9493 - val_loss: 0.4119 - val_accuracy: 0.7901\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1645 - accuracy: 0.9489 - val_loss: 0.4642 - val_accuracy: 0.7922\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9568 - val_loss: 0.4474 - val_accuracy: 0.7922\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9427 - val_loss: 0.4560 - val_accuracy: 0.7737\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1207 - accuracy: 0.9515 - val_loss: 0.3883 - val_accuracy: 0.8189\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1398 - accuracy: 0.9515 - val_loss: 0.4365 - val_accuracy: 0.7984\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9559 - val_loss: 0.4067 - val_accuracy: 0.8107\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1205 - accuracy: 0.9555 - val_loss: 0.4675 - val_accuracy: 0.7922\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1269 - accuracy: 0.9506 - val_loss: 0.3736 - val_accuracy: 0.8210\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1195 - accuracy: 0.9511 - val_loss: 0.3803 - val_accuracy: 0.8189\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9528 - val_loss: 0.4164 - val_accuracy: 0.8025\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1224 - accuracy: 0.9546 - val_loss: 0.3482 - val_accuracy: 0.8302\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1527 - accuracy: 0.9550 - val_loss: 0.3778 - val_accuracy: 0.8313\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1516 - accuracy: 0.9497 - val_loss: 0.4944 - val_accuracy: 0.7634\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9533 - val_loss: 0.3852 - val_accuracy: 0.8220\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1133 - accuracy: 0.9568 - val_loss: 0.3869 - val_accuracy: 0.8066\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1265 - accuracy: 0.9555 - val_loss: 0.3546 - val_accuracy: 0.8333\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.9577 - val_loss: 0.3366 - val_accuracy: 0.8498\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1280 - accuracy: 0.9515 - val_loss: 0.3956 - val_accuracy: 0.8189\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5715 - accuracy: 0.9502 - val_loss: 0.4220 - val_accuracy: 0.8107\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1253 - accuracy: 0.9612 - val_loss: 0.3622 - val_accuracy: 0.8333\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1095 - accuracy: 0.9599 - val_loss: 0.4872 - val_accuracy: 0.7819\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1051 - accuracy: 0.9621 - val_loss: 0.3224 - val_accuracy: 0.8621\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1158 - accuracy: 0.9563 - val_loss: 0.3255 - val_accuracy: 0.8601\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0933 - accuracy: 0.9638 - val_loss: 0.3638 - val_accuracy: 0.8467\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0967 - accuracy: 0.9709 - val_loss: 0.3261 - val_accuracy: 0.8498\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1004 - accuracy: 0.9634 - val_loss: 0.3376 - val_accuracy: 0.8580\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1035 - accuracy: 0.9647 - val_loss: 0.3004 - val_accuracy: 0.8704\n","Score: 0.8703703880310059 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 234126.1406 - accuracy: 0.8818 - val_loss: 2.6126 - val_accuracy: 0.5082\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4815 - accuracy: 0.8761 - val_loss: 0.7342 - val_accuracy: 0.4949\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2735 - accuracy: 0.8902 - val_loss: 1.3107 - val_accuracy: 0.4938\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3234 - accuracy: 0.8955 - val_loss: 0.7663 - val_accuracy: 0.4938\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3537 - accuracy: 0.8827 - val_loss: 0.8472 - val_accuracy: 0.5134\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2800 - accuracy: 0.8955 - val_loss: 0.6929 - val_accuracy: 0.5237\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3367 - accuracy: 0.8942 - val_loss: 1.0650 - val_accuracy: 0.5185\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2456 - accuracy: 0.8968 - val_loss: 0.8007 - val_accuracy: 0.5195\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3252 - accuracy: 0.8929 - val_loss: 0.7412 - val_accuracy: 0.4856\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2207 - accuracy: 0.8995 - val_loss: 0.6982 - val_accuracy: 0.4907\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2325 - accuracy: 0.8937 - val_loss: 0.6941 - val_accuracy: 0.5072\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2264 - accuracy: 0.8977 - val_loss: 0.8236 - val_accuracy: 0.5082\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9114 - val_loss: 0.7059 - val_accuracy: 0.4877\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2121 - accuracy: 0.9012 - val_loss: 0.7237 - val_accuracy: 0.5185\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9123 - val_loss: 0.7117 - val_accuracy: 0.5237\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9189 - val_loss: 0.7038 - val_accuracy: 0.4907\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9039 - val_loss: 0.7219 - val_accuracy: 0.5175\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9096 - val_loss: 0.7012 - val_accuracy: 0.5144\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9202 - val_loss: 0.6951 - val_accuracy: 0.5123\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9184 - val_loss: 0.6939 - val_accuracy: 0.5226\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2054 - accuracy: 0.9048 - val_loss: 0.6950 - val_accuracy: 0.5350\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1950 - accuracy: 0.9096 - val_loss: 0.6937 - val_accuracy: 0.5144\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2046 - accuracy: 0.9101 - val_loss: 0.7076 - val_accuracy: 0.5144\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9228 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9052 - val_loss: 0.6924 - val_accuracy: 0.5216\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9136 - val_loss: 0.6924 - val_accuracy: 0.5216\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9149 - val_loss: 0.6932 - val_accuracy: 0.5051\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9074 - val_loss: 0.7074 - val_accuracy: 0.5010\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2071 - accuracy: 0.9078 - val_loss: 0.6959 - val_accuracy: 0.5031\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9065 - val_loss: 0.6969 - val_accuracy: 0.4774\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9048 - val_loss: 0.6933 - val_accuracy: 0.5082\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9105 - val_loss: 0.6930 - val_accuracy: 0.5195\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2010 - accuracy: 0.9127 - val_loss: 0.7016 - val_accuracy: 0.4938\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9140 - val_loss: 0.7046 - val_accuracy: 0.5247\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9127 - val_loss: 0.7051 - val_accuracy: 0.5051\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9193 - val_loss: 0.7816 - val_accuracy: 0.4856\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9012 - val_loss: 0.7412 - val_accuracy: 0.4805\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9043 - val_loss: 0.6950 - val_accuracy: 0.4774\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9061 - val_loss: 0.7030 - val_accuracy: 0.5123\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1978 - accuracy: 0.9184 - val_loss: 0.6938 - val_accuracy: 0.5082\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9109 - val_loss: 0.6972 - val_accuracy: 0.5247\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9056 - val_loss: 0.6918 - val_accuracy: 0.5267\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9087 - val_loss: 0.7430 - val_accuracy: 0.5185\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9074 - val_loss: 0.6950 - val_accuracy: 0.5206\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9052 - val_loss: 0.7009 - val_accuracy: 0.4794\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9048 - val_loss: 0.7018 - val_accuracy: 0.5206\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1819 - accuracy: 0.9189 - val_loss: 0.6943 - val_accuracy: 0.5237\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9123 - val_loss: 0.6993 - val_accuracy: 0.5072\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9012 - val_loss: 0.6941 - val_accuracy: 0.4856\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9105 - val_loss: 0.6929 - val_accuracy: 0.5257\n","Score: 0.5257201790809631 \n","Parameters:  {'learning_rate': 0.11190073092755233, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 648177.1250 - accuracy: 0.8933 - val_loss: 0.6966 - val_accuracy: 0.4897\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2088 - accuracy: 0.9021 - val_loss: 0.7123 - val_accuracy: 0.5051\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9198 - val_loss: 0.6953 - val_accuracy: 0.4815\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9189 - val_loss: 0.6953 - val_accuracy: 0.5103\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9198 - val_loss: 0.7047 - val_accuracy: 0.4866\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9087 - val_loss: 0.7243 - val_accuracy: 0.4743\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.8986 - val_loss: 0.7063 - val_accuracy: 0.4846\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2033 - accuracy: 0.9048 - val_loss: 0.6968 - val_accuracy: 0.4825\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9061 - val_loss: 0.7005 - val_accuracy: 0.5123\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9087 - val_loss: 0.7077 - val_accuracy: 0.4897\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9083 - val_loss: 0.7284 - val_accuracy: 0.5082\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9109 - val_loss: 0.6935 - val_accuracy: 0.4774\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9145 - val_loss: 0.6963 - val_accuracy: 0.5134\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9052 - val_loss: 0.7153 - val_accuracy: 0.4856\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9026 - val_loss: 0.7021 - val_accuracy: 0.5000\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9105 - val_loss: 0.7231 - val_accuracy: 0.4979\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2187 - accuracy: 0.8968 - val_loss: 0.6946 - val_accuracy: 0.5257\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9114 - val_loss: 0.6932 - val_accuracy: 0.5062\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1808 - accuracy: 0.9242 - val_loss: 0.6911 - val_accuracy: 0.5329\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9136 - val_loss: 0.6996 - val_accuracy: 0.5021\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9158 - val_loss: 0.7381 - val_accuracy: 0.5010\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9180 - val_loss: 0.7038 - val_accuracy: 0.4918\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9043 - val_loss: 0.7282 - val_accuracy: 0.4763\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.9034 - val_loss: 0.6979 - val_accuracy: 0.4763\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9039 - val_loss: 0.6949 - val_accuracy: 0.4835\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9083 - val_loss: 0.6918 - val_accuracy: 0.5298\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9101 - val_loss: 0.7099 - val_accuracy: 0.5226\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2010 - accuracy: 0.9167 - val_loss: 0.6943 - val_accuracy: 0.4979\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1997 - accuracy: 0.9105 - val_loss: 0.7110 - val_accuracy: 0.5082\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1807 - accuracy: 0.9118 - val_loss: 0.6939 - val_accuracy: 0.4959\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9056 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9101 - val_loss: 0.6991 - val_accuracy: 0.5082\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9162 - val_loss: 0.6947 - val_accuracy: 0.4979\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9211 - val_loss: 0.6983 - val_accuracy: 0.5010\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1988 - accuracy: 0.9140 - val_loss: 0.6935 - val_accuracy: 0.4969\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9109 - val_loss: 0.6993 - val_accuracy: 0.5072\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9127 - val_loss: 0.6983 - val_accuracy: 0.4897\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9092 - val_loss: 0.7057 - val_accuracy: 0.4835\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9105 - val_loss: 0.7014 - val_accuracy: 0.5093\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9127 - val_loss: 0.7109 - val_accuracy: 0.5062\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9096 - val_loss: 0.6939 - val_accuracy: 0.5134\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9087 - val_loss: 0.7080 - val_accuracy: 0.4887\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9114 - val_loss: 0.6941 - val_accuracy: 0.4866\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9153 - val_loss: 0.7120 - val_accuracy: 0.5185\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1912 - accuracy: 0.9193 - val_loss: 0.7716 - val_accuracy: 0.5031\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1951 - accuracy: 0.9127 - val_loss: 0.6964 - val_accuracy: 0.5185\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2031 - accuracy: 0.9087 - val_loss: 0.6939 - val_accuracy: 0.4805\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2058 - accuracy: 0.9004 - val_loss: 0.7349 - val_accuracy: 0.4743\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9092 - val_loss: 0.7284 - val_accuracy: 0.5175\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9171 - val_loss: 0.6947 - val_accuracy: 0.4846\n","Score: 0.48456791043281555 \n","Parameters:  {'learning_rate': 0.1068032671079193, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 615503.6875 - accuracy: 0.8915 - val_loss: 2.6711 - val_accuracy: 0.4866\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.8956 - accuracy: 0.9039 - val_loss: 0.8874 - val_accuracy: 0.5134\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9127 - val_loss: 0.7780 - val_accuracy: 0.5041\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3595 - accuracy: 0.9026 - val_loss: 0.7730 - val_accuracy: 0.5216\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9206 - val_loss: 0.7776 - val_accuracy: 0.5216\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2301 - accuracy: 0.9153 - val_loss: 0.7146 - val_accuracy: 0.4949\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9083 - val_loss: 0.6966 - val_accuracy: 0.4959\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9074 - val_loss: 0.6992 - val_accuracy: 0.4712\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9017 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2046 - accuracy: 0.9167 - val_loss: 0.6946 - val_accuracy: 0.4897\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9052 - val_loss: 0.7466 - val_accuracy: 0.5216\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9149 - val_loss: 0.6982 - val_accuracy: 0.5216\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9101 - val_loss: 0.7364 - val_accuracy: 0.5237\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1877 - accuracy: 0.9153 - val_loss: 0.6917 - val_accuracy: 0.4959\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9145 - val_loss: 0.7001 - val_accuracy: 0.4846\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2098 - accuracy: 0.9021 - val_loss: 0.7394 - val_accuracy: 0.5267\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9061 - val_loss: 0.6904 - val_accuracy: 0.5165\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.9123 - val_loss: 0.6941 - val_accuracy: 0.4877\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9078 - val_loss: 0.6971 - val_accuracy: 0.4949\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2159 - accuracy: 0.9065 - val_loss: 0.7416 - val_accuracy: 0.5226\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1975 - accuracy: 0.9083 - val_loss: 0.8022 - val_accuracy: 0.4825\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2456 - accuracy: 0.9140 - val_loss: 0.6929 - val_accuracy: 0.5154\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9074 - val_loss: 0.7001 - val_accuracy: 0.5247\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9158 - val_loss: 0.7513 - val_accuracy: 0.4794\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9048 - val_loss: 0.7269 - val_accuracy: 0.4979\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9127 - val_loss: 0.6938 - val_accuracy: 0.4897\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9118 - val_loss: 0.6959 - val_accuracy: 0.4877\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1863 - accuracy: 0.9171 - val_loss: 0.6953 - val_accuracy: 0.4856\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1989 - accuracy: 0.9074 - val_loss: 0.6924 - val_accuracy: 0.5021\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9105 - val_loss: 0.6939 - val_accuracy: 0.4825\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9101 - val_loss: 0.6938 - val_accuracy: 0.5175\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1904 - accuracy: 0.9149 - val_loss: 0.6924 - val_accuracy: 0.5144\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9189 - val_loss: 0.7069 - val_accuracy: 0.4979\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9136 - val_loss: 0.6905 - val_accuracy: 0.5257\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9198 - val_loss: 0.7031 - val_accuracy: 0.5103\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1828 - accuracy: 0.9153 - val_loss: 0.6934 - val_accuracy: 0.5165\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9118 - val_loss: 0.6948 - val_accuracy: 0.5237\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9043 - val_loss: 0.7212 - val_accuracy: 0.4805\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9180 - val_loss: 0.7014 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9171 - val_loss: 0.6954 - val_accuracy: 0.5113\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9145 - val_loss: 0.6980 - val_accuracy: 0.5216\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1912 - accuracy: 0.9167 - val_loss: 0.6933 - val_accuracy: 0.5165\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1976 - accuracy: 0.9061 - val_loss: 0.7050 - val_accuracy: 0.4753\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9048 - val_loss: 0.7112 - val_accuracy: 0.5000\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1881 - accuracy: 0.9136 - val_loss: 0.7034 - val_accuracy: 0.4815\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9198 - val_loss: 0.7137 - val_accuracy: 0.5257\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9198 - val_loss: 0.6927 - val_accuracy: 0.4866\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9127 - val_loss: 0.6910 - val_accuracy: 0.5216\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.7035 - val_accuracy: 0.4887\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9127 - val_loss: 0.6943 - val_accuracy: 0.4866\n","Score: 0.4866255223751068 \n","Parameters:  {'learning_rate': 0.13130086734674343, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4773 - accuracy: 0.9171 - val_loss: 0.5708 - val_accuracy: 0.7428\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1725 - accuracy: 0.9162 - val_loss: 0.6106 - val_accuracy: 0.7058\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1608 - accuracy: 0.9343 - val_loss: 0.5161 - val_accuracy: 0.7397\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.9343 - val_loss: 0.5021 - val_accuracy: 0.7613\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4554 - accuracy: 0.9325 - val_loss: 0.5493 - val_accuracy: 0.7305\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2961 - accuracy: 0.9286 - val_loss: 0.4976 - val_accuracy: 0.7562\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1973 - accuracy: 0.9303 - val_loss: 0.4697 - val_accuracy: 0.7870\n","Epoch 8/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1701 - accuracy: 0.9427 - val_loss: 0.4638 - val_accuracy: 0.7809\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.9480 - val_loss: 0.5120 - val_accuracy: 0.7356\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1319 - accuracy: 0.9475 - val_loss: 0.4292 - val_accuracy: 0.7870\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1562 - accuracy: 0.9466 - val_loss: 0.4449 - val_accuracy: 0.7860\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9462 - val_loss: 0.4055 - val_accuracy: 0.8148\n","Epoch 13/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1399 - accuracy: 0.9462 - val_loss: 0.4221 - val_accuracy: 0.8045\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1178 - accuracy: 0.9524 - val_loss: 0.3984 - val_accuracy: 0.8230\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1354 - accuracy: 0.9546 - val_loss: 0.4212 - val_accuracy: 0.8138\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1110 - accuracy: 0.9541 - val_loss: 0.3705 - val_accuracy: 0.8128\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1281 - accuracy: 0.9511 - val_loss: 0.4146 - val_accuracy: 0.7963\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1053 - accuracy: 0.9652 - val_loss: 0.3492 - val_accuracy: 0.8436\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1340 - accuracy: 0.9506 - val_loss: 0.4114 - val_accuracy: 0.8045\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1061 - accuracy: 0.9660 - val_loss: 0.4233 - val_accuracy: 0.8282\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.9594 - val_loss: 0.4685 - val_accuracy: 0.8138\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1546 - accuracy: 0.9572 - val_loss: 0.4958 - val_accuracy: 0.7757\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1135 - accuracy: 0.9555 - val_loss: 0.3456 - val_accuracy: 0.8272\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1088 - accuracy: 0.9603 - val_loss: 0.3797 - val_accuracy: 0.8251\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1173 - accuracy: 0.9660 - val_loss: 0.3852 - val_accuracy: 0.8395\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1032 - accuracy: 0.9590 - val_loss: 0.3284 - val_accuracy: 0.8570\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1255 - accuracy: 0.9568 - val_loss: 0.3403 - val_accuracy: 0.8539\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1090 - accuracy: 0.9630 - val_loss: 0.3464 - val_accuracy: 0.8488\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.9594 - val_loss: 0.3329 - val_accuracy: 0.8436\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0864 - accuracy: 0.9696 - val_loss: 0.2924 - val_accuracy: 0.8642\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0835 - accuracy: 0.9660 - val_loss: 0.2675 - val_accuracy: 0.8848\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0783 - accuracy: 0.9687 - val_loss: 0.3358 - val_accuracy: 0.8765\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1006 - accuracy: 0.9599 - val_loss: 0.3852 - val_accuracy: 0.8549\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9581 - val_loss: 0.3189 - val_accuracy: 0.8580\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.9612 - val_loss: 0.3349 - val_accuracy: 0.8488\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9678 - val_loss: 0.3469 - val_accuracy: 0.8704\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0830 - accuracy: 0.9700 - val_loss: 0.2893 - val_accuracy: 0.8745\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0878 - accuracy: 0.9638 - val_loss: 0.3007 - val_accuracy: 0.8673\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0900 - accuracy: 0.9700 - val_loss: 0.2901 - val_accuracy: 0.8745\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0908 - accuracy: 0.9656 - val_loss: 0.3511 - val_accuracy: 0.8591\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0984 - accuracy: 0.9630 - val_loss: 0.2922 - val_accuracy: 0.8807\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0825 - accuracy: 0.9700 - val_loss: 0.3106 - val_accuracy: 0.8611\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0644 - accuracy: 0.9753 - val_loss: 0.2768 - val_accuracy: 0.8858\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0852 - accuracy: 0.9731 - val_loss: 0.2912 - val_accuracy: 0.8714\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1022 - accuracy: 0.9700 - val_loss: 0.3840 - val_accuracy: 0.8416\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0730 - accuracy: 0.9735 - val_loss: 0.2690 - val_accuracy: 0.8796\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0938 - accuracy: 0.9757 - val_loss: 0.2577 - val_accuracy: 0.8899\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0616 - accuracy: 0.9780 - val_loss: 0.2701 - val_accuracy: 0.8807\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0949 - accuracy: 0.9674 - val_loss: 0.2961 - val_accuracy: 0.8663\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0895 - accuracy: 0.9687 - val_loss: 0.2996 - val_accuracy: 0.8621\n","Score: 0.8621399402618408 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 77782.4297 - accuracy: 0.8907 - val_loss: 0.7348 - val_accuracy: 0.4753\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2304 - accuracy: 0.8902 - val_loss: 0.8900 - val_accuracy: 0.4856\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2318 - accuracy: 0.8968 - val_loss: 0.9012 - val_accuracy: 0.5113\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1752 - accuracy: 0.9114 - val_loss: 0.6964 - val_accuracy: 0.5309\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2086 - accuracy: 0.8995 - val_loss: 0.7929 - val_accuracy: 0.5298\n","Epoch 6/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2253 - accuracy: 0.8924 - val_loss: 0.7490 - val_accuracy: 0.4691\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2155 - accuracy: 0.9030 - val_loss: 0.7191 - val_accuracy: 0.4907\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.8995 - val_loss: 0.7414 - val_accuracy: 0.5062\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9043 - val_loss: 0.8629 - val_accuracy: 0.4979\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1920 - accuracy: 0.9048 - val_loss: 0.7004 - val_accuracy: 0.5113\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1741 - accuracy: 0.9153 - val_loss: 0.6930 - val_accuracy: 0.5113\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9092 - val_loss: 0.6936 - val_accuracy: 0.5401\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9158 - val_loss: 0.6932 - val_accuracy: 0.5206\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9052 - val_loss: 0.6953 - val_accuracy: 0.5226\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2082 - accuracy: 0.9162 - val_loss: 0.6954 - val_accuracy: 0.5103\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9123 - val_loss: 0.6986 - val_accuracy: 0.4959\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9131 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9189 - val_loss: 0.6934 - val_accuracy: 0.5113\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9070 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2138 - accuracy: 0.9030 - val_loss: 0.6929 - val_accuracy: 0.5134\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9149 - val_loss: 0.7378 - val_accuracy: 0.4846\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2118 - accuracy: 0.8942 - val_loss: 0.6947 - val_accuracy: 0.4784\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9096 - val_loss: 0.6981 - val_accuracy: 0.4784\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2101 - accuracy: 0.9065 - val_loss: 0.6982 - val_accuracy: 0.5031\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9224 - val_loss: 0.7069 - val_accuracy: 0.5144\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9096 - val_loss: 0.6951 - val_accuracy: 0.5144\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9074 - val_loss: 0.6933 - val_accuracy: 0.5082\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9065 - val_loss: 0.6950 - val_accuracy: 0.4969\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2130 - accuracy: 0.9056 - val_loss: 0.7039 - val_accuracy: 0.5257\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9206 - val_loss: 0.6996 - val_accuracy: 0.4846\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9105 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9145 - val_loss: 0.6959 - val_accuracy: 0.5103\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.9078 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2131 - accuracy: 0.9114 - val_loss: 0.6928 - val_accuracy: 0.5278\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9162 - val_loss: 0.7006 - val_accuracy: 0.5103\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2047 - accuracy: 0.9109 - val_loss: 0.7078 - val_accuracy: 0.5041\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9145 - val_loss: 0.6989 - val_accuracy: 0.4979\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.8986 - val_loss: 0.6937 - val_accuracy: 0.5072\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9167 - val_loss: 0.6997 - val_accuracy: 0.4763\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2101 - accuracy: 0.9052 - val_loss: 0.6955 - val_accuracy: 0.5072\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9096 - val_loss: 0.6945 - val_accuracy: 0.5103\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2105 - accuracy: 0.9061 - val_loss: 0.6973 - val_accuracy: 0.5062\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2002 - accuracy: 0.9153 - val_loss: 0.6973 - val_accuracy: 0.4753\n","Epoch 44/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2083 - accuracy: 0.9070 - val_loss: 0.6979 - val_accuracy: 0.4835\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2234 - accuracy: 0.8920 - val_loss: 0.6930 - val_accuracy: 0.5206\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1992 - accuracy: 0.9220 - val_loss: 0.7008 - val_accuracy: 0.4969\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9202 - val_loss: 0.6955 - val_accuracy: 0.4990\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2107 - accuracy: 0.9145 - val_loss: 0.6941 - val_accuracy: 0.5288\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9242 - val_loss: 0.7234 - val_accuracy: 0.5206\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9048 - val_loss: 0.7123 - val_accuracy: 0.5319\n","Score: 0.5318930149078369 \n","Parameters:  {'learning_rate': 0.07652581646687798, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6476 - accuracy: 0.9189 - val_loss: 0.6356 - val_accuracy: 0.6029\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1795 - accuracy: 0.9189 - val_loss: 0.6064 - val_accuracy: 0.6636\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1799 - accuracy: 0.9198 - val_loss: 0.6714 - val_accuracy: 0.5206\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1821 - accuracy: 0.9277 - val_loss: 0.5855 - val_accuracy: 0.6749\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9281 - val_loss: 0.5774 - val_accuracy: 0.6533\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1675 - accuracy: 0.9303 - val_loss: 0.6004 - val_accuracy: 0.6636\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1783 - accuracy: 0.9295 - val_loss: 0.5733 - val_accuracy: 0.6770\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1663 - accuracy: 0.9321 - val_loss: 0.5828 - val_accuracy: 0.6708\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1478 - accuracy: 0.9422 - val_loss: 0.5248 - val_accuracy: 0.7171\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2234 - accuracy: 0.9295 - val_loss: 0.5319 - val_accuracy: 0.7171\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.9286 - val_loss: 0.5678 - val_accuracy: 0.6903\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9400 - val_loss: 0.6723 - val_accuracy: 0.7387\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2214 - accuracy: 0.9228 - val_loss: 0.5418 - val_accuracy: 0.7150\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1669 - accuracy: 0.9374 - val_loss: 0.5334 - val_accuracy: 0.7212\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1855 - accuracy: 0.9400 - val_loss: 0.5504 - val_accuracy: 0.6914\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4534 - accuracy: 0.9369 - val_loss: 0.4904 - val_accuracy: 0.7593\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1624 - accuracy: 0.9396 - val_loss: 0.4966 - val_accuracy: 0.7521\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9449 - val_loss: 0.4945 - val_accuracy: 0.7438\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1721 - accuracy: 0.9431 - val_loss: 0.4524 - val_accuracy: 0.7850\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1413 - accuracy: 0.9444 - val_loss: 0.4912 - val_accuracy: 0.7788\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9480 - val_loss: 0.4457 - val_accuracy: 0.7778\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1640 - accuracy: 0.9414 - val_loss: 0.4206 - val_accuracy: 0.8148\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9400 - val_loss: 0.4459 - val_accuracy: 0.7716\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.9493 - val_loss: 0.4204 - val_accuracy: 0.7798\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1521 - accuracy: 0.9506 - val_loss: 0.4007 - val_accuracy: 0.8025\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9471 - val_loss: 0.4360 - val_accuracy: 0.7860\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1425 - accuracy: 0.9471 - val_loss: 0.4241 - val_accuracy: 0.7912\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1309 - accuracy: 0.9511 - val_loss: 0.4144 - val_accuracy: 0.7932\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1653 - accuracy: 0.9506 - val_loss: 0.4617 - val_accuracy: 0.7922\n","Epoch 30/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1795 - accuracy: 0.9519 - val_loss: 0.4299 - val_accuracy: 0.8097\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1360 - accuracy: 0.9502 - val_loss: 0.3803 - val_accuracy: 0.8107\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1167 - accuracy: 0.9555 - val_loss: 0.4059 - val_accuracy: 0.8200\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1239 - accuracy: 0.9528 - val_loss: 0.3807 - val_accuracy: 0.8189\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9577 - val_loss: 0.4210 - val_accuracy: 0.8251\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9524 - val_loss: 0.4435 - val_accuracy: 0.7901\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1313 - accuracy: 0.9484 - val_loss: 0.3705 - val_accuracy: 0.8241\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9484 - val_loss: 0.4402 - val_accuracy: 0.7695\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4151 - accuracy: 0.9511 - val_loss: 0.3755 - val_accuracy: 0.8189\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.9515 - val_loss: 0.3858 - val_accuracy: 0.8189\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1380 - accuracy: 0.9559 - val_loss: 0.3934 - val_accuracy: 0.8313\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2089 - accuracy: 0.9506 - val_loss: 0.4261 - val_accuracy: 0.8035\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1161 - accuracy: 0.9603 - val_loss: 0.3836 - val_accuracy: 0.8138\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1412 - accuracy: 0.9577 - val_loss: 0.4220 - val_accuracy: 0.8045\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1111 - accuracy: 0.9541 - val_loss: 0.3198 - val_accuracy: 0.8508\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.9612 - val_loss: 0.3573 - val_accuracy: 0.8230\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0967 - accuracy: 0.9612 - val_loss: 0.3173 - val_accuracy: 0.8601\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9546 - val_loss: 0.3727 - val_accuracy: 0.8272\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1235 - accuracy: 0.9533 - val_loss: 0.3689 - val_accuracy: 0.8272\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9515 - val_loss: 0.3575 - val_accuracy: 0.8313\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1033 - accuracy: 0.9577 - val_loss: 0.3438 - val_accuracy: 0.8323\n","Score: 0.8323045372962952 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.3179 - accuracy: 0.9158 - val_loss: 0.6414 - val_accuracy: 0.6286\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9397 - accuracy: 0.9281 - val_loss: 0.6631 - val_accuracy: 0.6800\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1482 - accuracy: 0.9422 - val_loss: 0.5003 - val_accuracy: 0.7407\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1392 - accuracy: 0.9418 - val_loss: 0.4980 - val_accuracy: 0.7407\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4443 - accuracy: 0.9347 - val_loss: 0.5319 - val_accuracy: 0.7016\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1595 - accuracy: 0.9409 - val_loss: 0.4978 - val_accuracy: 0.7274\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1608 - accuracy: 0.9396 - val_loss: 0.4840 - val_accuracy: 0.7562\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1338 - accuracy: 0.9480 - val_loss: 0.4803 - val_accuracy: 0.7932\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1372 - accuracy: 0.9506 - val_loss: 0.4922 - val_accuracy: 0.7644\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9524 - val_loss: 0.5073 - val_accuracy: 0.7623\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1453 - accuracy: 0.9453 - val_loss: 0.4635 - val_accuracy: 0.7675\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1424 - accuracy: 0.9444 - val_loss: 0.4861 - val_accuracy: 0.7593\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.9550 - val_loss: 0.4081 - val_accuracy: 0.8189\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9581 - val_loss: 0.4284 - val_accuracy: 0.8004\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9475 - val_loss: 0.4334 - val_accuracy: 0.8220\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2331 - accuracy: 0.9555 - val_loss: 0.4314 - val_accuracy: 0.7942\n","Epoch 17/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.3430 - accuracy: 0.9405 - val_loss: 0.4276 - val_accuracy: 0.7881\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1394 - accuracy: 0.9396 - val_loss: 0.3926 - val_accuracy: 0.8179\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1865 - accuracy: 0.9546 - val_loss: 0.4447 - val_accuracy: 0.7891\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1223 - accuracy: 0.9502 - val_loss: 0.3781 - val_accuracy: 0.8230\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1165 - accuracy: 0.9563 - val_loss: 0.3847 - val_accuracy: 0.8272\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1296 - accuracy: 0.9568 - val_loss: 0.4049 - val_accuracy: 0.8189\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9568 - val_loss: 0.4159 - val_accuracy: 0.8210\n","Epoch 24/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1198 - accuracy: 0.9502 - val_loss: 0.3761 - val_accuracy: 0.8189\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9563 - val_loss: 0.3676 - val_accuracy: 0.8313\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1259 - accuracy: 0.9555 - val_loss: 0.3529 - val_accuracy: 0.8426\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1310 - accuracy: 0.9524 - val_loss: 0.3936 - val_accuracy: 0.8230\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1098 - accuracy: 0.9590 - val_loss: 0.3774 - val_accuracy: 0.8261\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1026 - accuracy: 0.9594 - val_loss: 0.3487 - val_accuracy: 0.8374\n","Epoch 30/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1159 - accuracy: 0.9555 - val_loss: 0.4562 - val_accuracy: 0.7829\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.9550 - val_loss: 0.3599 - val_accuracy: 0.8241\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1012 - accuracy: 0.9559 - val_loss: 0.4259 - val_accuracy: 0.7829\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0984 - accuracy: 0.9616 - val_loss: 0.3907 - val_accuracy: 0.8272\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1103 - accuracy: 0.9572 - val_loss: 0.3566 - val_accuracy: 0.8230\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1484 - accuracy: 0.9528 - val_loss: 0.3659 - val_accuracy: 0.8251\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1163 - accuracy: 0.9581 - val_loss: 0.4101 - val_accuracy: 0.8230\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1049 - accuracy: 0.9608 - val_loss: 0.3708 - val_accuracy: 0.8292\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.9594 - val_loss: 0.3517 - val_accuracy: 0.8477\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1373 - accuracy: 0.9608 - val_loss: 0.3931 - val_accuracy: 0.8323\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1297 - accuracy: 0.9665 - val_loss: 0.3196 - val_accuracy: 0.8529\n","Epoch 41/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2942 - accuracy: 0.9453 - val_loss: 0.3473 - val_accuracy: 0.8477\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1455 - accuracy: 0.9603 - val_loss: 0.3269 - val_accuracy: 0.8416\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1235 - accuracy: 0.9594 - val_loss: 0.3336 - val_accuracy: 0.8467\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1313 - accuracy: 0.9612 - val_loss: 0.3239 - val_accuracy: 0.8477\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.9466 - val_loss: 0.3461 - val_accuracy: 0.8488\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1024 - accuracy: 0.9612 - val_loss: 0.3363 - val_accuracy: 0.8385\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0922 - accuracy: 0.9577 - val_loss: 0.3740 - val_accuracy: 0.8580\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1019 - accuracy: 0.9599 - val_loss: 0.3091 - val_accuracy: 0.8663\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1408 - accuracy: 0.9537 - val_loss: 0.3023 - val_accuracy: 0.8591\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9599 - val_loss: 0.3133 - val_accuracy: 0.8519\n","Score: 0.8518518805503845 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 3723109.2500 - accuracy: 0.9030 - val_loss: 0.6990 - val_accuracy: 0.5021\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9092 - val_loss: 0.6944 - val_accuracy: 0.4794\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9145 - val_loss: 0.8213 - val_accuracy: 0.4794\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1816 - accuracy: 0.9123 - val_loss: 0.7155 - val_accuracy: 0.5051\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9096 - val_loss: 0.6915 - val_accuracy: 0.5350\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9184 - val_loss: 0.8932 - val_accuracy: 0.5031\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1894 - accuracy: 0.9004 - val_loss: 0.7229 - val_accuracy: 0.5082\n","Epoch 8/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2022 - accuracy: 0.8951 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9167 - val_loss: 0.7881 - val_accuracy: 0.4763\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1986 - accuracy: 0.9043 - val_loss: 0.7040 - val_accuracy: 0.5165\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1874 - accuracy: 0.9123 - val_loss: 0.7564 - val_accuracy: 0.4959\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1837 - accuracy: 0.9162 - val_loss: 0.7265 - val_accuracy: 0.5195\n","Epoch 13/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1905 - accuracy: 0.9101 - val_loss: 0.7493 - val_accuracy: 0.4825\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9021 - val_loss: 0.6968 - val_accuracy: 0.5000\n","Epoch 15/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1913 - accuracy: 0.9145 - val_loss: 0.6944 - val_accuracy: 0.4856\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1946 - accuracy: 0.9043 - val_loss: 0.6942 - val_accuracy: 0.4877\n","Epoch 17/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2029 - accuracy: 0.9012 - val_loss: 0.6982 - val_accuracy: 0.4856\n","Epoch 18/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1987 - accuracy: 0.8995 - val_loss: 0.6943 - val_accuracy: 0.4835\n","Epoch 19/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2011 - accuracy: 0.9008 - val_loss: 0.7330 - val_accuracy: 0.4733\n","Epoch 20/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1914 - accuracy: 0.9052 - val_loss: 0.6928 - val_accuracy: 0.5123\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2018 - accuracy: 0.9034 - val_loss: 0.7790 - val_accuracy: 0.5134\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1932 - accuracy: 0.9101 - val_loss: 0.7076 - val_accuracy: 0.5237\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9114 - val_loss: 0.7167 - val_accuracy: 0.4846\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9021 - val_loss: 0.6975 - val_accuracy: 0.4866\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9017 - val_loss: 0.7251 - val_accuracy: 0.5103\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9149 - val_loss: 0.7410 - val_accuracy: 0.4599\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9017 - val_loss: 0.8381 - val_accuracy: 0.5021\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1896 - accuracy: 0.9109 - val_loss: 0.7632 - val_accuracy: 0.5093\n","Epoch 29/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1826 - accuracy: 0.9109 - val_loss: 0.6934 - val_accuracy: 0.5082\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9017 - val_loss: 0.6939 - val_accuracy: 0.5165\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1907 - accuracy: 0.9153 - val_loss: 0.7982 - val_accuracy: 0.4815\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1964 - accuracy: 0.9026 - val_loss: 0.7016 - val_accuracy: 0.5165\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1740 - accuracy: 0.9228 - val_loss: 0.7706 - val_accuracy: 0.4805\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1994 - accuracy: 0.8924 - val_loss: 0.7372 - val_accuracy: 0.5247\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9162 - val_loss: 0.7237 - val_accuracy: 0.4918\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9070 - val_loss: 0.7106 - val_accuracy: 0.5154\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1830 - accuracy: 0.9233 - val_loss: 0.8260 - val_accuracy: 0.4815\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9008 - val_loss: 0.6951 - val_accuracy: 0.5123\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1894 - accuracy: 0.9145 - val_loss: 0.6934 - val_accuracy: 0.5123\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9158 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9096 - val_loss: 0.6954 - val_accuracy: 0.4846\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1885 - accuracy: 0.9123 - val_loss: 0.6931 - val_accuracy: 0.5123\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9127 - val_loss: 0.6937 - val_accuracy: 0.4928\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1844 - accuracy: 0.9136 - val_loss: 0.6946 - val_accuracy: 0.4979\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1771 - accuracy: 0.9180 - val_loss: 0.7108 - val_accuracy: 0.4691\n","Epoch 46/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1935 - accuracy: 0.9048 - val_loss: 0.7523 - val_accuracy: 0.4887\n","Epoch 47/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1950 - accuracy: 0.9074 - val_loss: 0.7485 - val_accuracy: 0.5165\n","Epoch 48/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1990 - accuracy: 0.9136 - val_loss: 0.7084 - val_accuracy: 0.4990\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1941 - accuracy: 0.9078 - val_loss: 0.8358 - val_accuracy: 0.4959\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2057 - accuracy: 0.9021 - val_loss: 0.7010 - val_accuracy: 0.5195\n","Score: 0.5195473432540894 \n","Parameters:  {'learning_rate': 0.20813478968997567, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 115727.5312 - accuracy: 0.8942 - val_loss: 2.0523 - val_accuracy: 0.5329\n","Epoch 2/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.6615 - accuracy: 0.9061 - val_loss: 1.2263 - val_accuracy: 0.5134\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.3000 - accuracy: 0.9083 - val_loss: 0.9661 - val_accuracy: 0.5000\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2906 - accuracy: 0.9140 - val_loss: 0.8916 - val_accuracy: 0.5072\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2902 - accuracy: 0.9065 - val_loss: 0.7405 - val_accuracy: 0.5165\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9123 - val_loss: 0.6985 - val_accuracy: 0.5175\n","Epoch 7/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2003 - accuracy: 0.9153 - val_loss: 0.6943 - val_accuracy: 0.4805\n","Epoch 8/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2061 - accuracy: 0.9008 - val_loss: 0.6842 - val_accuracy: 0.5041\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2085 - accuracy: 0.9021 - val_loss: 0.6955 - val_accuracy: 0.4918\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1973 - accuracy: 0.9149 - val_loss: 0.7080 - val_accuracy: 0.5237\n","Epoch 11/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1905 - accuracy: 0.9189 - val_loss: 0.7162 - val_accuracy: 0.4846\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2131 - accuracy: 0.9034 - val_loss: 0.6841 - val_accuracy: 0.5288\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2132 - accuracy: 0.9167 - val_loss: 0.6968 - val_accuracy: 0.4753\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.8942 - val_loss: 0.7388 - val_accuracy: 0.5113\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1827 - accuracy: 0.9158 - val_loss: 0.7291 - val_accuracy: 0.4784\n","Epoch 16/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2026 - accuracy: 0.9052 - val_loss: 0.7576 - val_accuracy: 0.5010\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2093 - accuracy: 0.9114 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9215 - val_loss: 0.7235 - val_accuracy: 0.5103\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2097 - accuracy: 0.9105 - val_loss: 0.6944 - val_accuracy: 0.4887\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2064 - accuracy: 0.9114 - val_loss: 0.7255 - val_accuracy: 0.4763\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2066 - accuracy: 0.8999 - val_loss: 0.6943 - val_accuracy: 0.5154\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9061 - val_loss: 0.6960 - val_accuracy: 0.4733\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9092 - val_loss: 0.7021 - val_accuracy: 0.4825\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2097 - accuracy: 0.9083 - val_loss: 0.7012 - val_accuracy: 0.4835\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9083 - val_loss: 0.6993 - val_accuracy: 0.4835\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1999 - accuracy: 0.9087 - val_loss: 0.7573 - val_accuracy: 0.5154\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9175 - val_loss: 0.7203 - val_accuracy: 0.5031\n","Epoch 28/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1935 - accuracy: 0.9198 - val_loss: 0.6951 - val_accuracy: 0.5010\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.8999 - val_loss: 0.6987 - val_accuracy: 0.5103\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1941 - accuracy: 0.9215 - val_loss: 0.7128 - val_accuracy: 0.4753\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2063 - accuracy: 0.9021 - val_loss: 0.7040 - val_accuracy: 0.4846\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9109 - val_loss: 0.6927 - val_accuracy: 0.5175\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9202 - val_loss: 0.7427 - val_accuracy: 0.5216\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1989 - accuracy: 0.9145 - val_loss: 0.6961 - val_accuracy: 0.5154\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2051 - accuracy: 0.9065 - val_loss: 0.6939 - val_accuracy: 0.5093\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9158 - val_loss: 0.6971 - val_accuracy: 0.5134\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9162 - val_loss: 0.6939 - val_accuracy: 0.4763\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9118 - val_loss: 0.6928 - val_accuracy: 0.5278\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2075 - accuracy: 0.9078 - val_loss: 0.6931 - val_accuracy: 0.5103\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9127 - val_loss: 0.6966 - val_accuracy: 0.4743\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9065 - val_loss: 0.6981 - val_accuracy: 0.5113\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.9034 - val_loss: 0.6930 - val_accuracy: 0.5082\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9061 - val_loss: 0.7173 - val_accuracy: 0.5062\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.9109 - val_loss: 0.7024 - val_accuracy: 0.4897\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.8981 - val_loss: 0.7238 - val_accuracy: 0.5123\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9198 - val_loss: 0.6939 - val_accuracy: 0.5031\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2122 - accuracy: 0.9083 - val_loss: 0.6932 - val_accuracy: 0.4969\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9145 - val_loss: 0.6982 - val_accuracy: 0.4702\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9083 - val_loss: 0.6949 - val_accuracy: 0.4743\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9004 - val_loss: 0.6977 - val_accuracy: 0.4918\n","Score: 0.49176955223083496 \n","Parameters:  {'learning_rate': 0.08633985900442104, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 45954.0859 - accuracy: 0.8796 - val_loss: 77.7294 - val_accuracy: 0.5134\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 6.1849 - accuracy: 0.8915 - val_loss: 6.0037 - val_accuracy: 0.4990\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.5631 - accuracy: 0.8959 - val_loss: 0.6711 - val_accuracy: 0.6533\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2479 - accuracy: 0.9105 - val_loss: 0.6333 - val_accuracy: 0.6862\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1932 - accuracy: 0.9074 - val_loss: 0.7126 - val_accuracy: 0.5103\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1815 - accuracy: 0.9233 - val_loss: 0.6774 - val_accuracy: 0.5772\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1870 - accuracy: 0.9074 - val_loss: 0.6868 - val_accuracy: 0.5165\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1894 - accuracy: 0.9123 - val_loss: 0.6897 - val_accuracy: 0.5113\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1912 - accuracy: 0.9109 - val_loss: 0.6813 - val_accuracy: 0.5998\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9101 - val_loss: 0.7029 - val_accuracy: 0.5123\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1751 - accuracy: 0.9171 - val_loss: 0.6895 - val_accuracy: 0.5370\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1832 - accuracy: 0.9065 - val_loss: 0.6866 - val_accuracy: 0.5494\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.8999 - val_loss: 0.7291 - val_accuracy: 0.4825\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9136 - val_loss: 0.7291 - val_accuracy: 0.4825\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9061 - val_loss: 0.6933 - val_accuracy: 0.5093\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9123 - val_loss: 0.6979 - val_accuracy: 0.4733\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9215 - val_loss: 0.7524 - val_accuracy: 0.5103\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9131 - val_loss: 0.6964 - val_accuracy: 0.4959\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2143 - accuracy: 0.8995 - val_loss: 0.6937 - val_accuracy: 0.4938\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2092 - accuracy: 0.9145 - val_loss: 0.6942 - val_accuracy: 0.5093\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.9101 - val_loss: 0.6947 - val_accuracy: 0.5072\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9145 - val_loss: 0.7012 - val_accuracy: 0.4866\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2115 - accuracy: 0.8981 - val_loss: 0.6923 - val_accuracy: 0.5226\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9096 - val_loss: 0.6939 - val_accuracy: 0.4928\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9149 - val_loss: 0.7045 - val_accuracy: 0.4918\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9039 - val_loss: 0.6954 - val_accuracy: 0.5134\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2115 - accuracy: 0.9131 - val_loss: 0.6975 - val_accuracy: 0.5103\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2064 - accuracy: 0.9123 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9224 - val_loss: 0.6993 - val_accuracy: 0.5051\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2122 - accuracy: 0.9114 - val_loss: 0.7073 - val_accuracy: 0.4846\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2231 - accuracy: 0.9030 - val_loss: 0.7001 - val_accuracy: 0.5113\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.9193 - val_loss: 0.6938 - val_accuracy: 0.5144\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9184 - val_loss: 0.7045 - val_accuracy: 0.5226\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2054 - accuracy: 0.9131 - val_loss: 0.6973 - val_accuracy: 0.5298\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9233 - val_loss: 0.7070 - val_accuracy: 0.5021\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2084 - accuracy: 0.9065 - val_loss: 0.6987 - val_accuracy: 0.5031\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2125 - accuracy: 0.9083 - val_loss: 0.6985 - val_accuracy: 0.5175\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9193 - val_loss: 0.7191 - val_accuracy: 0.4763\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.9105 - val_loss: 0.6982 - val_accuracy: 0.5041\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9180 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2060 - accuracy: 0.9070 - val_loss: 0.6931 - val_accuracy: 0.5082\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9101 - val_loss: 0.6941 - val_accuracy: 0.4969\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2116 - accuracy: 0.9101 - val_loss: 0.6992 - val_accuracy: 0.4846\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2117 - accuracy: 0.9070 - val_loss: 0.6962 - val_accuracy: 0.4784\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2101 - accuracy: 0.9109 - val_loss: 0.6950 - val_accuracy: 0.4866\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9140 - val_loss: 0.7003 - val_accuracy: 0.5154\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9149 - val_loss: 0.7076 - val_accuracy: 0.5175\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9140 - val_loss: 0.6945 - val_accuracy: 0.4949\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2115 - accuracy: 0.9109 - val_loss: 0.6934 - val_accuracy: 0.5062\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9215 - val_loss: 0.6981 - val_accuracy: 0.5123\n","Score: 0.5123456716537476 \n","Parameters:  {'learning_rate': 0.06803126872043003, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 2354097.0000 - accuracy: 0.8898 - val_loss: 2.0986 - val_accuracy: 0.4949\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2689 - accuracy: 0.9030 - val_loss: 0.8032 - val_accuracy: 0.4866\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2125 - accuracy: 0.9048 - val_loss: 0.8704 - val_accuracy: 0.4907\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2160 - accuracy: 0.9052 - val_loss: 0.6998 - val_accuracy: 0.5041\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9078 - val_loss: 0.7060 - val_accuracy: 0.4763\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.8977 - val_loss: 0.7975 - val_accuracy: 0.5103\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.8964 - val_loss: 0.7442 - val_accuracy: 0.4918\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2137 - accuracy: 0.8986 - val_loss: 0.7222 - val_accuracy: 0.5257\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.8986 - val_loss: 0.7626 - val_accuracy: 0.5093\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.8951 - val_loss: 0.7062 - val_accuracy: 0.5051\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9153 - val_loss: 0.7424 - val_accuracy: 0.4671\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.8999 - val_loss: 0.8621 - val_accuracy: 0.4907\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2200 - accuracy: 0.8933 - val_loss: 0.7301 - val_accuracy: 0.5000\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9087 - val_loss: 0.9307 - val_accuracy: 0.4722\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9039 - val_loss: 0.9488 - val_accuracy: 0.4835\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2189 - accuracy: 0.9008 - val_loss: 0.8285 - val_accuracy: 0.4774\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2424 - accuracy: 0.8990 - val_loss: 0.7197 - val_accuracy: 0.4846\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.8968 - val_loss: 0.7040 - val_accuracy: 0.4835\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9021 - val_loss: 0.6998 - val_accuracy: 0.5123\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9070 - val_loss: 0.6933 - val_accuracy: 0.5072\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1834 - accuracy: 0.9096 - val_loss: 0.6961 - val_accuracy: 0.4825\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1855 - accuracy: 0.9074 - val_loss: 0.7069 - val_accuracy: 0.4866\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1915 - accuracy: 0.8981 - val_loss: 0.6927 - val_accuracy: 0.5175\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9184 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9149 - val_loss: 0.7178 - val_accuracy: 0.4794\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9092 - val_loss: 0.7025 - val_accuracy: 0.5021\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9224 - val_loss: 0.9518 - val_accuracy: 0.4825\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9056 - val_loss: 0.7286 - val_accuracy: 0.4990\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9123 - val_loss: 0.7233 - val_accuracy: 0.5247\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.9167 - val_loss: 0.7464 - val_accuracy: 0.4887\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9061 - val_loss: 0.6951 - val_accuracy: 0.4938\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1880 - accuracy: 0.9105 - val_loss: 0.7429 - val_accuracy: 0.4763\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9052 - val_loss: 0.7076 - val_accuracy: 0.5113\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1793 - accuracy: 0.9131 - val_loss: 0.6927 - val_accuracy: 0.5257\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1810 - accuracy: 0.9167 - val_loss: 0.7396 - val_accuracy: 0.4805\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9048 - val_loss: 0.7287 - val_accuracy: 0.5072\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9184 - val_loss: 0.6982 - val_accuracy: 0.4825\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1831 - accuracy: 0.9153 - val_loss: 0.7288 - val_accuracy: 0.5144\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1799 - accuracy: 0.9180 - val_loss: 0.7059 - val_accuracy: 0.4763\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9043 - val_loss: 0.9597 - val_accuracy: 0.5123\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9087 - val_loss: 0.7093 - val_accuracy: 0.5154\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1900 - accuracy: 0.9065 - val_loss: 0.6922 - val_accuracy: 0.5216\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9070 - val_loss: 0.6945 - val_accuracy: 0.4681\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9162 - val_loss: 0.7020 - val_accuracy: 0.4825\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1861 - accuracy: 0.9136 - val_loss: 0.7195 - val_accuracy: 0.5021\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9034 - val_loss: 0.6931 - val_accuracy: 0.5154\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9211 - val_loss: 0.8523 - val_accuracy: 0.4928\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1867 - accuracy: 0.8990 - val_loss: 0.6940 - val_accuracy: 0.5154\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1945 - accuracy: 0.9105 - val_loss: 0.6933 - val_accuracy: 0.5165\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9131 - val_loss: 0.6924 - val_accuracy: 0.5257\n","Score: 0.5257201790809631 \n","Parameters:  {'learning_rate': 0.20176583472623957, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7764 - accuracy: 0.9140 - val_loss: 0.6415 - val_accuracy: 0.6883\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1805 - accuracy: 0.9193 - val_loss: 0.6469 - val_accuracy: 0.6142\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2113 - accuracy: 0.9193 - val_loss: 0.6383 - val_accuracy: 0.6656\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1868 - accuracy: 0.9272 - val_loss: 0.6196 - val_accuracy: 0.6893\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1846 - accuracy: 0.9286 - val_loss: 0.5897 - val_accuracy: 0.7243\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1681 - accuracy: 0.9286 - val_loss: 0.5760 - val_accuracy: 0.7233\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1540 - accuracy: 0.9330 - val_loss: 0.5881 - val_accuracy: 0.7150\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1601 - accuracy: 0.9339 - val_loss: 0.5382 - val_accuracy: 0.7613\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1661 - accuracy: 0.9325 - val_loss: 0.5510 - val_accuracy: 0.7078\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9339 - val_loss: 0.5429 - val_accuracy: 0.7274\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1652 - accuracy: 0.9361 - val_loss: 0.5509 - val_accuracy: 0.7387\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1741 - accuracy: 0.9299 - val_loss: 0.5578 - val_accuracy: 0.6914\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1490 - accuracy: 0.9418 - val_loss: 0.5166 - val_accuracy: 0.7510\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1507 - accuracy: 0.9383 - val_loss: 0.4966 - val_accuracy: 0.7593\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3014 - accuracy: 0.9414 - val_loss: 0.4791 - val_accuracy: 0.7737\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9356 - val_loss: 0.5028 - val_accuracy: 0.7469\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1710 - accuracy: 0.9378 - val_loss: 0.4771 - val_accuracy: 0.7685\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3105 - accuracy: 0.9502 - val_loss: 0.5501 - val_accuracy: 0.7603\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1615 - accuracy: 0.9378 - val_loss: 0.4395 - val_accuracy: 0.7860\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1349 - accuracy: 0.9458 - val_loss: 0.4423 - val_accuracy: 0.8014\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3398 - accuracy: 0.9449 - val_loss: 0.4365 - val_accuracy: 0.7963\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1348 - accuracy: 0.9489 - val_loss: 0.4126 - val_accuracy: 0.7994\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9590 - val_loss: 0.4125 - val_accuracy: 0.8056\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1593 - accuracy: 0.9502 - val_loss: 0.4112 - val_accuracy: 0.8004\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1515 - accuracy: 0.9511 - val_loss: 0.5477 - val_accuracy: 0.7294\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1081 - accuracy: 0.9625 - val_loss: 0.3805 - val_accuracy: 0.8076\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1406 - accuracy: 0.9563 - val_loss: 0.3775 - val_accuracy: 0.8220\n","Epoch 28/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1248 - accuracy: 0.9528 - val_loss: 0.4398 - val_accuracy: 0.8004\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9493 - val_loss: 0.3656 - val_accuracy: 0.8086\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1076 - accuracy: 0.9660 - val_loss: 0.5264 - val_accuracy: 0.8086\n","Epoch 31/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1290 - accuracy: 0.9559 - val_loss: 0.3199 - val_accuracy: 0.8436\n","Epoch 32/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0998 - accuracy: 0.9608 - val_loss: 0.3250 - val_accuracy: 0.8374\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1063 - accuracy: 0.9590 - val_loss: 0.3168 - val_accuracy: 0.8591\n","Epoch 34/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1042 - accuracy: 0.9621 - val_loss: 0.3521 - val_accuracy: 0.8724\n","Epoch 35/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1693 - accuracy: 0.9559 - val_loss: 0.3045 - val_accuracy: 0.8467\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1326 - accuracy: 0.9594 - val_loss: 0.2769 - val_accuracy: 0.8776\n","Epoch 37/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0962 - accuracy: 0.9638 - val_loss: 0.2781 - val_accuracy: 0.8673\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0938 - accuracy: 0.9674 - val_loss: 0.2481 - val_accuracy: 0.8827\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9691 - val_loss: 0.3029 - val_accuracy: 0.8642\n","Epoch 40/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.3978 - val_accuracy: 0.8076\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0936 - accuracy: 0.9683 - val_loss: 0.2665 - val_accuracy: 0.8704\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0795 - accuracy: 0.9731 - val_loss: 0.2547 - val_accuracy: 0.8909\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0795 - accuracy: 0.9775 - val_loss: 0.2571 - val_accuracy: 0.8827\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0809 - accuracy: 0.9713 - val_loss: 0.2312 - val_accuracy: 0.9012\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0804 - accuracy: 0.9784 - val_loss: 0.3732 - val_accuracy: 0.8673\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9771 - val_loss: 0.2063 - val_accuracy: 0.9043\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0708 - accuracy: 0.9797 - val_loss: 0.2311 - val_accuracy: 0.8981\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0615 - accuracy: 0.9762 - val_loss: 0.2188 - val_accuracy: 0.9177\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0552 - accuracy: 0.9766 - val_loss: 0.1639 - val_accuracy: 0.9321\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0434 - accuracy: 0.9797 - val_loss: 0.2169 - val_accuracy: 0.9095\n","Score: 0.9094650149345398 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 2351.4026 - accuracy: 0.9017 - val_loss: 0.7035 - val_accuracy: 0.4846\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1941 - accuracy: 0.9118 - val_loss: 0.6952 - val_accuracy: 0.5072\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2445 - accuracy: 0.9153 - val_loss: 0.6929 - val_accuracy: 0.5154\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2503 - accuracy: 0.9211 - val_loss: 0.7080 - val_accuracy: 0.5165\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9096 - val_loss: 0.6946 - val_accuracy: 0.5082\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2702 - accuracy: 0.9078 - val_loss: 0.6963 - val_accuracy: 0.5154\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2581 - accuracy: 0.9145 - val_loss: 0.7004 - val_accuracy: 0.4990\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2629 - accuracy: 0.9123 - val_loss: 0.7070 - val_accuracy: 0.5103\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2637 - accuracy: 0.9092 - val_loss: 0.6929 - val_accuracy: 0.5267\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2702 - accuracy: 0.9105 - val_loss: 0.7009 - val_accuracy: 0.5144\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2602 - accuracy: 0.9127 - val_loss: 0.6962 - val_accuracy: 0.5134\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2458 - accuracy: 0.9228 - val_loss: 0.7158 - val_accuracy: 0.5031\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2642 - accuracy: 0.9096 - val_loss: 0.6950 - val_accuracy: 0.5206\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2538 - accuracy: 0.9184 - val_loss: 0.7146 - val_accuracy: 0.5000\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2440 - accuracy: 0.9228 - val_loss: 0.7369 - val_accuracy: 0.5041\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2496 - accuracy: 0.9158 - val_loss: 0.6984 - val_accuracy: 0.5216\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2530 - accuracy: 0.9198 - val_loss: 0.7180 - val_accuracy: 0.5072\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2566 - accuracy: 0.9109 - val_loss: 0.6943 - val_accuracy: 0.5113\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2558 - accuracy: 0.9162 - val_loss: 0.7013 - val_accuracy: 0.5134\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2625 - accuracy: 0.9127 - val_loss: 0.7089 - val_accuracy: 0.5051\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2598 - accuracy: 0.9105 - val_loss: 0.6937 - val_accuracy: 0.5134\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2678 - accuracy: 0.9145 - val_loss: 0.7070 - val_accuracy: 0.5257\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2506 - accuracy: 0.9171 - val_loss: 0.6971 - val_accuracy: 0.5309\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2506 - accuracy: 0.9171 - val_loss: 0.7010 - val_accuracy: 0.5093\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2567 - accuracy: 0.9149 - val_loss: 0.6971 - val_accuracy: 0.5195\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2632 - accuracy: 0.9096 - val_loss: 0.6957 - val_accuracy: 0.5123\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2577 - accuracy: 0.9123 - val_loss: 0.6952 - val_accuracy: 0.5072\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2640 - accuracy: 0.9136 - val_loss: 0.7111 - val_accuracy: 0.5010\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2512 - accuracy: 0.9180 - val_loss: 0.6999 - val_accuracy: 0.5041\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2589 - accuracy: 0.9092 - val_loss: 0.6934 - val_accuracy: 0.5103\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2607 - accuracy: 0.9167 - val_loss: 0.6985 - val_accuracy: 0.5154\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2599 - accuracy: 0.9127 - val_loss: 0.6929 - val_accuracy: 0.5237\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2589 - accuracy: 0.9171 - val_loss: 0.7040 - val_accuracy: 0.5226\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2528 - accuracy: 0.9180 - val_loss: 0.7022 - val_accuracy: 0.5247\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2554 - accuracy: 0.9136 - val_loss: 0.6928 - val_accuracy: 0.5206\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2630 - accuracy: 0.9123 - val_loss: 0.6956 - val_accuracy: 0.5226\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2665 - accuracy: 0.9087 - val_loss: 0.6982 - val_accuracy: 0.5021\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2659 - accuracy: 0.9114 - val_loss: 0.6997 - val_accuracy: 0.5226\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2594 - accuracy: 0.9184 - val_loss: 0.7249 - val_accuracy: 0.5010\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2604 - accuracy: 0.9056 - val_loss: 0.6940 - val_accuracy: 0.4887\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2707 - accuracy: 0.9034 - val_loss: 0.6988 - val_accuracy: 0.5123\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2495 - accuracy: 0.9211 - val_loss: 0.7116 - val_accuracy: 0.5185\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2569 - accuracy: 0.9123 - val_loss: 0.6989 - val_accuracy: 0.4969\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2537 - accuracy: 0.9224 - val_loss: 0.7296 - val_accuracy: 0.4897\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2575 - accuracy: 0.9145 - val_loss: 0.7161 - val_accuracy: 0.5021\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2551 - accuracy: 0.9162 - val_loss: 0.7017 - val_accuracy: 0.5288\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2600 - accuracy: 0.9092 - val_loss: 0.6947 - val_accuracy: 0.5216\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2630 - accuracy: 0.9158 - val_loss: 0.7049 - val_accuracy: 0.5319\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2498 - accuracy: 0.9167 - val_loss: 0.7077 - val_accuracy: 0.5051\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2653 - accuracy: 0.9118 - val_loss: 0.7079 - val_accuracy: 0.5113\n","Score: 0.5113168954849243 \n","Parameters:  {'learning_rate': 0.02634565642590457, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 3650.0171 - accuracy: 0.8827 - val_loss: 0.7113 - val_accuracy: 0.4835\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2169 - accuracy: 0.9118 - val_loss: 0.7002 - val_accuracy: 0.4733\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2198 - accuracy: 0.9061 - val_loss: 0.6979 - val_accuracy: 0.5113\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2175 - accuracy: 0.9153 - val_loss: 0.6968 - val_accuracy: 0.4969\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2300 - accuracy: 0.9158 - val_loss: 0.6945 - val_accuracy: 0.4815\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2377 - accuracy: 0.9074 - val_loss: 0.6935 - val_accuracy: 0.4835\n","Epoch 7/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2401 - accuracy: 0.9061 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 8/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2396 - accuracy: 0.9162 - val_loss: 0.6972 - val_accuracy: 0.5093\n","Epoch 9/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2338 - accuracy: 0.9175 - val_loss: 0.6956 - val_accuracy: 0.5134\n","Epoch 10/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2351 - accuracy: 0.9175 - val_loss: 0.7066 - val_accuracy: 0.5041\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2371 - accuracy: 0.9101 - val_loss: 0.6980 - val_accuracy: 0.5195\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9096 - val_loss: 0.6935 - val_accuracy: 0.4887\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2414 - accuracy: 0.8995 - val_loss: 0.6994 - val_accuracy: 0.4877\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2371 - accuracy: 0.9052 - val_loss: 0.6953 - val_accuracy: 0.5072\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2368 - accuracy: 0.9114 - val_loss: 0.6934 - val_accuracy: 0.5051\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2348 - accuracy: 0.9167 - val_loss: 0.6963 - val_accuracy: 0.5134\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2412 - accuracy: 0.9114 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2451 - accuracy: 0.9092 - val_loss: 0.6900 - val_accuracy: 0.5432\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2316 - accuracy: 0.9175 - val_loss: 0.6941 - val_accuracy: 0.5175\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2366 - accuracy: 0.9114 - val_loss: 0.6978 - val_accuracy: 0.4897\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2440 - accuracy: 0.8995 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2381 - accuracy: 0.9131 - val_loss: 0.6926 - val_accuracy: 0.5185\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2372 - accuracy: 0.9153 - val_loss: 0.6934 - val_accuracy: 0.5021\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2359 - accuracy: 0.9198 - val_loss: 0.7062 - val_accuracy: 0.5134\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2320 - accuracy: 0.9158 - val_loss: 0.6995 - val_accuracy: 0.4990\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2340 - accuracy: 0.9131 - val_loss: 0.6940 - val_accuracy: 0.5123\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2228 - accuracy: 0.9224 - val_loss: 0.6967 - val_accuracy: 0.5021\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2417 - accuracy: 0.9140 - val_loss: 0.7010 - val_accuracy: 0.5041\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2339 - accuracy: 0.9145 - val_loss: 0.6928 - val_accuracy: 0.5226\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2423 - accuracy: 0.9105 - val_loss: 0.6919 - val_accuracy: 0.5298\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2263 - accuracy: 0.9184 - val_loss: 0.6956 - val_accuracy: 0.4938\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2409 - accuracy: 0.9136 - val_loss: 0.6950 - val_accuracy: 0.5237\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2347 - accuracy: 0.9153 - val_loss: 0.6934 - val_accuracy: 0.5051\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.9171 - val_loss: 0.6928 - val_accuracy: 0.5185\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2377 - accuracy: 0.9140 - val_loss: 0.6933 - val_accuracy: 0.5154\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2407 - accuracy: 0.9109 - val_loss: 0.6942 - val_accuracy: 0.4763\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2337 - accuracy: 0.9114 - val_loss: 0.6945 - val_accuracy: 0.4907\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2404 - accuracy: 0.9087 - val_loss: 0.7084 - val_accuracy: 0.5113\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2273 - accuracy: 0.9167 - val_loss: 0.6953 - val_accuracy: 0.4784\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2416 - accuracy: 0.9052 - val_loss: 0.6927 - val_accuracy: 0.5185\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2476 - accuracy: 0.9105 - val_loss: 0.6946 - val_accuracy: 0.5206\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2350 - accuracy: 0.9140 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2399 - accuracy: 0.9092 - val_loss: 0.6963 - val_accuracy: 0.4856\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2470 - accuracy: 0.9026 - val_loss: 0.6965 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2394 - accuracy: 0.9105 - val_loss: 0.6919 - val_accuracy: 0.5247\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2295 - accuracy: 0.9220 - val_loss: 0.6995 - val_accuracy: 0.5041\n","Epoch 47/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.2371 - accuracy: 0.9114 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2425 - accuracy: 0.9105 - val_loss: 0.6946 - val_accuracy: 0.5000\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2388 - accuracy: 0.9123 - val_loss: 0.6929 - val_accuracy: 0.5226\n","Epoch 50/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2398 - accuracy: 0.9171 - val_loss: 0.6928 - val_accuracy: 0.5185\n","Score: 0.5185185074806213 \n","Parameters:  {'learning_rate': 0.036670648242523064, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 3160701.0000 - accuracy: 0.9043 - val_loss: 0.7065 - val_accuracy: 0.4846\n","Epoch 2/50\n","567/567 [==============================] - 2s 4ms/step - loss: 0.1989 - accuracy: 0.9078 - val_loss: 0.6936 - val_accuracy: 0.5195\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1773 - accuracy: 0.9215 - val_loss: 0.7214 - val_accuracy: 0.4753\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1915 - accuracy: 0.9145 - val_loss: 0.6957 - val_accuracy: 0.4938\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9061 - val_loss: 0.6937 - val_accuracy: 0.5103\n","Epoch 6/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2061 - accuracy: 0.8946 - val_loss: 0.7073 - val_accuracy: 0.4805\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1870 - accuracy: 0.9127 - val_loss: 0.7376 - val_accuracy: 0.5216\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9034 - val_loss: 0.6982 - val_accuracy: 0.4825\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9083 - val_loss: 0.6955 - val_accuracy: 0.5031\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1874 - accuracy: 0.9101 - val_loss: 0.7610 - val_accuracy: 0.4969\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1845 - accuracy: 0.9026 - val_loss: 0.7000 - val_accuracy: 0.4835\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9021 - val_loss: 0.6978 - val_accuracy: 0.4733\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9087 - val_loss: 0.7062 - val_accuracy: 0.5134\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9056 - val_loss: 0.7118 - val_accuracy: 0.4887\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.8968 - val_loss: 0.6936 - val_accuracy: 0.5082\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9017 - val_loss: 0.7911 - val_accuracy: 0.5206\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1929 - accuracy: 0.9109 - val_loss: 0.7065 - val_accuracy: 0.4743\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9114 - val_loss: 0.7001 - val_accuracy: 0.4856\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9136 - val_loss: 0.6977 - val_accuracy: 0.4825\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9065 - val_loss: 0.7089 - val_accuracy: 0.4835\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.8999 - val_loss: 0.7311 - val_accuracy: 0.5082\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9131 - val_loss: 0.7209 - val_accuracy: 0.4907\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9123 - val_loss: 0.6970 - val_accuracy: 0.5031\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.9101 - val_loss: 0.7330 - val_accuracy: 0.4763\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.8986 - val_loss: 0.7505 - val_accuracy: 0.4846\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1929 - accuracy: 0.9061 - val_loss: 0.6939 - val_accuracy: 0.4722\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9083 - val_loss: 0.6938 - val_accuracy: 0.4969\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9070 - val_loss: 0.7057 - val_accuracy: 0.4887\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9021 - val_loss: 0.6939 - val_accuracy: 0.5041\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1880 - accuracy: 0.9149 - val_loss: 0.6979 - val_accuracy: 0.4907\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9030 - val_loss: 0.6960 - val_accuracy: 0.4907\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1811 - accuracy: 0.9123 - val_loss: 0.6953 - val_accuracy: 0.4877\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9070 - val_loss: 0.6945 - val_accuracy: 0.4959\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1988 - accuracy: 0.9052 - val_loss: 0.6975 - val_accuracy: 0.4897\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9048 - val_loss: 0.6931 - val_accuracy: 0.5103\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1876 - accuracy: 0.9171 - val_loss: 0.6931 - val_accuracy: 0.5093\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1941 - accuracy: 0.9101 - val_loss: 0.6990 - val_accuracy: 0.5041\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1873 - accuracy: 0.9211 - val_loss: 0.7140 - val_accuracy: 0.4877\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.8995 - val_loss: 0.7239 - val_accuracy: 0.5123\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9070 - val_loss: 0.7025 - val_accuracy: 0.4959\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1832 - accuracy: 0.9242 - val_loss: 0.6975 - val_accuracy: 0.5093\n","Epoch 42/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2009 - accuracy: 0.9052 - val_loss: 0.6949 - val_accuracy: 0.5010\n","Epoch 43/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1959 - accuracy: 0.9109 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1840 - accuracy: 0.9202 - val_loss: 0.7170 - val_accuracy: 0.4712\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9092 - val_loss: 0.7333 - val_accuracy: 0.5175\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9109 - val_loss: 0.6962 - val_accuracy: 0.5329\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9052 - val_loss: 0.7002 - val_accuracy: 0.4763\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9109 - val_loss: 0.7052 - val_accuracy: 0.4887\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1848 - accuracy: 0.9083 - val_loss: 0.6991 - val_accuracy: 0.5021\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9114 - val_loss: 0.6924 - val_accuracy: 0.5340\n","Score: 0.5339506268501282 \n","Parameters:  {'learning_rate': 0.20744935100613254, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 561498.8125 - accuracy: 0.9008 - val_loss: 0.6930 - val_accuracy: 0.5195\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9184 - val_loss: 0.7151 - val_accuracy: 0.4938\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9083 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.9123 - val_loss: 0.7097 - val_accuracy: 0.5185\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.9162 - val_loss: 0.7234 - val_accuracy: 0.4805\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9083 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9105 - val_loss: 0.6939 - val_accuracy: 0.4733\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1975 - accuracy: 0.9101 - val_loss: 0.7342 - val_accuracy: 0.4763\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9026 - val_loss: 0.6942 - val_accuracy: 0.5093\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9118 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9167 - val_loss: 0.6985 - val_accuracy: 0.5093\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9092 - val_loss: 0.7105 - val_accuracy: 0.5072\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1875 - accuracy: 0.9233 - val_loss: 0.7966 - val_accuracy: 0.5123\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1878 - accuracy: 0.9136 - val_loss: 0.6977 - val_accuracy: 0.4784\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2120 - accuracy: 0.9030 - val_loss: 0.7020 - val_accuracy: 0.4938\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2116 - accuracy: 0.9070 - val_loss: 0.6967 - val_accuracy: 0.5154\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9118 - val_loss: 0.7208 - val_accuracy: 0.4877\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9083 - val_loss: 0.7277 - val_accuracy: 0.4949\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9114 - val_loss: 0.7206 - val_accuracy: 0.4877\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.8999 - val_loss: 0.6964 - val_accuracy: 0.5278\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9224 - val_loss: 0.6945 - val_accuracy: 0.5041\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9167 - val_loss: 0.7471 - val_accuracy: 0.4794\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.9048 - val_loss: 0.7097 - val_accuracy: 0.4928\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9118 - val_loss: 0.7212 - val_accuracy: 0.5134\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9052 - val_loss: 0.6965 - val_accuracy: 0.5000\n","Epoch 26/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2063 - accuracy: 0.9101 - val_loss: 0.7136 - val_accuracy: 0.5206\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9198 - val_loss: 0.7264 - val_accuracy: 0.4774\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9052 - val_loss: 0.7043 - val_accuracy: 0.5062\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1879 - accuracy: 0.9056 - val_loss: 0.6975 - val_accuracy: 0.4794\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2077 - accuracy: 0.9092 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9109 - val_loss: 0.7331 - val_accuracy: 0.4866\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9039 - val_loss: 0.6953 - val_accuracy: 0.5185\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9167 - val_loss: 0.6991 - val_accuracy: 0.4733\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9140 - val_loss: 0.6947 - val_accuracy: 0.5278\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9083 - val_loss: 0.6957 - val_accuracy: 0.5237\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9092 - val_loss: 0.7062 - val_accuracy: 0.5123\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9189 - val_loss: 0.7089 - val_accuracy: 0.5175\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9189 - val_loss: 0.7130 - val_accuracy: 0.4722\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9052 - val_loss: 0.7004 - val_accuracy: 0.4887\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.8981 - val_loss: 0.7258 - val_accuracy: 0.5185\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9158 - val_loss: 0.6926 - val_accuracy: 0.5185\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9167 - val_loss: 0.7063 - val_accuracy: 0.4835\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9052 - val_loss: 0.7050 - val_accuracy: 0.5288\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9131 - val_loss: 0.7061 - val_accuracy: 0.5051\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9127 - val_loss: 0.6937 - val_accuracy: 0.5123\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1999 - accuracy: 0.9145 - val_loss: 0.6964 - val_accuracy: 0.4835\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9167 - val_loss: 0.6930 - val_accuracy: 0.5165\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9118 - val_loss: 0.7013 - val_accuracy: 0.5123\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1945 - accuracy: 0.9228 - val_loss: 0.6962 - val_accuracy: 0.4753\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2107 - accuracy: 0.9008 - val_loss: 0.6979 - val_accuracy: 0.5082\n","Score: 0.508230447769165 \n","Parameters:  {'learning_rate': 0.0934314056090162, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4923 - accuracy: 0.9162 - val_loss: 0.6495 - val_accuracy: 0.6307\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1719 - accuracy: 0.9312 - val_loss: 0.5999 - val_accuracy: 0.6975\n","Epoch 3/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2454 - accuracy: 0.9136 - val_loss: 0.5894 - val_accuracy: 0.7130\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2093 - accuracy: 0.9171 - val_loss: 0.6517 - val_accuracy: 0.6163\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1664 - accuracy: 0.9281 - val_loss: 0.5888 - val_accuracy: 0.7222\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5836 - accuracy: 0.9414 - val_loss: 0.5592 - val_accuracy: 0.7140\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9378 - val_loss: 0.5695 - val_accuracy: 0.7088\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1736 - accuracy: 0.9299 - val_loss: 0.5171 - val_accuracy: 0.7346\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1755 - accuracy: 0.9365 - val_loss: 0.5558 - val_accuracy: 0.7346\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1513 - accuracy: 0.9356 - val_loss: 0.5107 - val_accuracy: 0.7572\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1560 - accuracy: 0.9405 - val_loss: 0.5343 - val_accuracy: 0.7305\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1578 - accuracy: 0.9405 - val_loss: 0.5072 - val_accuracy: 0.7418\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2166 - accuracy: 0.9330 - val_loss: 0.5109 - val_accuracy: 0.7665\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1555 - accuracy: 0.9365 - val_loss: 0.4953 - val_accuracy: 0.7685\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1516 - accuracy: 0.9484 - val_loss: 0.5174 - val_accuracy: 0.7695\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1455 - accuracy: 0.9502 - val_loss: 0.4836 - val_accuracy: 0.7685\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1592 - accuracy: 0.9436 - val_loss: 0.4942 - val_accuracy: 0.7490\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9427 - val_loss: 0.5372 - val_accuracy: 0.7634\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2097 - accuracy: 0.9414 - val_loss: 0.4902 - val_accuracy: 0.7438\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.9418 - val_loss: 0.4616 - val_accuracy: 0.7819\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1699 - accuracy: 0.9449 - val_loss: 0.4389 - val_accuracy: 0.7891\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1256 - accuracy: 0.9511 - val_loss: 0.4553 - val_accuracy: 0.7881\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1368 - accuracy: 0.9484 - val_loss: 0.4232 - val_accuracy: 0.8035\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1521 - accuracy: 0.9453 - val_loss: 0.4344 - val_accuracy: 0.8158\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1739 - accuracy: 0.9471 - val_loss: 0.4574 - val_accuracy: 0.7860\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9493 - val_loss: 0.4790 - val_accuracy: 0.7665\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1320 - accuracy: 0.9502 - val_loss: 0.4365 - val_accuracy: 0.7922\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9440 - val_loss: 0.4462 - val_accuracy: 0.7891\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1822 - accuracy: 0.9365 - val_loss: 0.4785 - val_accuracy: 0.7860\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1407 - accuracy: 0.9493 - val_loss: 0.4928 - val_accuracy: 0.7654\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9519 - val_loss: 0.4921 - val_accuracy: 0.7757\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9484 - val_loss: 0.4294 - val_accuracy: 0.7922\n","Epoch 33/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1661 - accuracy: 0.9392 - val_loss: 0.4282 - val_accuracy: 0.7881\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1275 - accuracy: 0.9511 - val_loss: 0.4134 - val_accuracy: 0.8138\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1242 - accuracy: 0.9546 - val_loss: 0.4223 - val_accuracy: 0.8138\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1334 - accuracy: 0.9458 - val_loss: 0.4164 - val_accuracy: 0.7953\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9422 - val_loss: 0.4309 - val_accuracy: 0.7994\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2528 - accuracy: 0.9449 - val_loss: 0.4538 - val_accuracy: 0.7973\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9458 - val_loss: 0.4846 - val_accuracy: 0.7881\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9458 - val_loss: 0.4347 - val_accuracy: 0.7984\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9537 - val_loss: 0.4248 - val_accuracy: 0.8158\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9515 - val_loss: 0.4556 - val_accuracy: 0.7809\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9511 - val_loss: 0.4168 - val_accuracy: 0.8056\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1226 - accuracy: 0.9515 - val_loss: 0.3949 - val_accuracy: 0.8056\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9515 - val_loss: 0.4243 - val_accuracy: 0.8076\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1374 - accuracy: 0.9462 - val_loss: 0.4353 - val_accuracy: 0.8056\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2254 - accuracy: 0.9608 - val_loss: 0.4036 - val_accuracy: 0.8230\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1173 - accuracy: 0.9599 - val_loss: 0.4496 - val_accuracy: 0.8210\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9511 - val_loss: 0.3673 - val_accuracy: 0.8313\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1197 - accuracy: 0.9563 - val_loss: 0.3879 - val_accuracy: 0.8241\n","Score: 0.8240740895271301 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6999 - accuracy: 0.9140 - val_loss: 0.7083 - val_accuracy: 0.5288\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3034 - accuracy: 0.9012 - val_loss: 0.6947 - val_accuracy: 0.5298\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9096 - val_loss: 0.7076 - val_accuracy: 0.5267\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1901 - accuracy: 0.9149 - val_loss: 0.6964 - val_accuracy: 0.5154\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9171 - val_loss: 0.7195 - val_accuracy: 0.5103\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2507 - accuracy: 0.9184 - val_loss: 0.6515 - val_accuracy: 0.6903\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9215 - val_loss: 0.5916 - val_accuracy: 0.6934\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2532 - accuracy: 0.9299 - val_loss: 0.5938 - val_accuracy: 0.6523\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9378 - val_loss: 0.5371 - val_accuracy: 0.7109\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1562 - accuracy: 0.9339 - val_loss: 0.4986 - val_accuracy: 0.7685\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1709 - accuracy: 0.9361 - val_loss: 0.5296 - val_accuracy: 0.7366\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1575 - accuracy: 0.9339 - val_loss: 0.4836 - val_accuracy: 0.7541\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1438 - accuracy: 0.9427 - val_loss: 0.4594 - val_accuracy: 0.7912\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1615 - accuracy: 0.9466 - val_loss: 0.4791 - val_accuracy: 0.7942\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1718 - accuracy: 0.9299 - val_loss: 0.5734 - val_accuracy: 0.7459\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9444 - val_loss: 0.4557 - val_accuracy: 0.7654\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1362 - accuracy: 0.9480 - val_loss: 0.4438 - val_accuracy: 0.7757\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1365 - accuracy: 0.9546 - val_loss: 0.4213 - val_accuracy: 0.7953\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9436 - val_loss: 0.4432 - val_accuracy: 0.7973\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9471 - val_loss: 0.4209 - val_accuracy: 0.7994\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9471 - val_loss: 0.4407 - val_accuracy: 0.7829\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1434 - accuracy: 0.9466 - val_loss: 0.4159 - val_accuracy: 0.8025\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1392 - accuracy: 0.9528 - val_loss: 0.4252 - val_accuracy: 0.8014\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2552 - accuracy: 0.9515 - val_loss: 0.4570 - val_accuracy: 0.7840\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1409 - accuracy: 0.9453 - val_loss: 0.4782 - val_accuracy: 0.7695\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1747 - accuracy: 0.9528 - val_loss: 0.4538 - val_accuracy: 0.7850\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9466 - val_loss: 0.4226 - val_accuracy: 0.7994\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1406 - accuracy: 0.9449 - val_loss: 0.4264 - val_accuracy: 0.8035\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2392 - accuracy: 0.9480 - val_loss: 0.4697 - val_accuracy: 0.7685\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1482 - accuracy: 0.9466 - val_loss: 0.4329 - val_accuracy: 0.7881\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1745 - accuracy: 0.9497 - val_loss: 0.4109 - val_accuracy: 0.8128\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2324 - accuracy: 0.9480 - val_loss: 0.3991 - val_accuracy: 0.8169\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1326 - accuracy: 0.9586 - val_loss: 0.3921 - val_accuracy: 0.8138\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1089 - accuracy: 0.9594 - val_loss: 0.3891 - val_accuracy: 0.8179\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1008 - accuracy: 0.9568 - val_loss: 0.3079 - val_accuracy: 0.8395\n","Epoch 36/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.0897 - accuracy: 0.9656 - val_loss: 0.2957 - val_accuracy: 0.8570\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1163 - accuracy: 0.9599 - val_loss: 0.3878 - val_accuracy: 0.8076\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0975 - accuracy: 0.9612 - val_loss: 0.3151 - val_accuracy: 0.8704\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1085 - accuracy: 0.9625 - val_loss: 0.2744 - val_accuracy: 0.8807\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1149 - accuracy: 0.9599 - val_loss: 0.2450 - val_accuracy: 0.8951\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0937 - accuracy: 0.9687 - val_loss: 0.2940 - val_accuracy: 0.8735\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0774 - accuracy: 0.9722 - val_loss: 0.2964 - val_accuracy: 0.8817\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0706 - accuracy: 0.9678 - val_loss: 0.2749 - val_accuracy: 0.8765\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1234 - accuracy: 0.9541 - val_loss: 0.3453 - val_accuracy: 0.8436\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1060 - accuracy: 0.9652 - val_loss: 0.3529 - val_accuracy: 0.8508\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1222 - accuracy: 0.9572 - val_loss: 0.3265 - val_accuracy: 0.8488\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0820 - accuracy: 0.9700 - val_loss: 0.2161 - val_accuracy: 0.8981\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9709 - val_loss: 0.2913 - val_accuracy: 0.8755\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0988 - accuracy: 0.9691 - val_loss: 0.2279 - val_accuracy: 0.9126\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0748 - accuracy: 0.9731 - val_loss: 0.1697 - val_accuracy: 0.9280\n","Score: 0.9279835224151611 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9554 - accuracy: 0.9149 - val_loss: 0.6171 - val_accuracy: 0.7109\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9224 - val_loss: 0.6146 - val_accuracy: 0.6893\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3067 - accuracy: 0.9286 - val_loss: 0.6068 - val_accuracy: 0.7325\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9255 - val_loss: 0.5048 - val_accuracy: 0.7541\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1701 - accuracy: 0.9339 - val_loss: 0.5774 - val_accuracy: 0.6811\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1771 - accuracy: 0.9228 - val_loss: 0.5921 - val_accuracy: 0.6667\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9109 - val_loss: 0.5743 - val_accuracy: 0.7263\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2762 - accuracy: 0.9286 - val_loss: 0.5370 - val_accuracy: 0.7078\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2679 - accuracy: 0.9149 - val_loss: 0.5740 - val_accuracy: 0.7212\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9308 - val_loss: 0.5419 - val_accuracy: 0.7665\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9343 - val_loss: 0.5240 - val_accuracy: 0.7253\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1397 - accuracy: 0.9427 - val_loss: 0.5152 - val_accuracy: 0.7613\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9449 - val_loss: 0.4464 - val_accuracy: 0.7737\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1439 - accuracy: 0.9369 - val_loss: 0.4391 - val_accuracy: 0.7778\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1449 - accuracy: 0.9409 - val_loss: 0.4389 - val_accuracy: 0.7809\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9506 - val_loss: 0.3886 - val_accuracy: 0.8179\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1265 - accuracy: 0.9502 - val_loss: 0.3779 - val_accuracy: 0.8220\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9475 - val_loss: 0.3599 - val_accuracy: 0.8272\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1156 - accuracy: 0.9519 - val_loss: 0.3546 - val_accuracy: 0.8292\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9484 - val_loss: 0.3752 - val_accuracy: 0.8097\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9471 - val_loss: 0.4003 - val_accuracy: 0.8158\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1412 - accuracy: 0.9480 - val_loss: 0.4012 - val_accuracy: 0.8107\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1844 - accuracy: 0.9541 - val_loss: 0.3622 - val_accuracy: 0.8097\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1196 - accuracy: 0.9581 - val_loss: 0.3384 - val_accuracy: 0.8364\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1187 - accuracy: 0.9612 - val_loss: 0.3548 - val_accuracy: 0.8200\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9572 - val_loss: 0.2983 - val_accuracy: 0.8447\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0880 - accuracy: 0.9630 - val_loss: 0.2681 - val_accuracy: 0.8786\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0868 - accuracy: 0.9683 - val_loss: 0.3738 - val_accuracy: 0.8529\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0857 - accuracy: 0.9647 - val_loss: 0.3129 - val_accuracy: 0.8529\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0863 - accuracy: 0.9687 - val_loss: 0.2516 - val_accuracy: 0.8940\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2701 - accuracy: 0.9524 - val_loss: 0.4250 - val_accuracy: 0.7767\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.9577 - val_loss: 0.3286 - val_accuracy: 0.8488\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1017 - accuracy: 0.9630 - val_loss: 0.3130 - val_accuracy: 0.8704\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0812 - accuracy: 0.9656 - val_loss: 0.2985 - val_accuracy: 0.8611\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.3196 - val_accuracy: 0.8621\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1000 - accuracy: 0.9660 - val_loss: 0.3534 - val_accuracy: 0.8560\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0701 - accuracy: 0.9775 - val_loss: 0.2500 - val_accuracy: 0.8868\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9696 - val_loss: 0.2147 - val_accuracy: 0.9043\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9696 - val_loss: 0.2038 - val_accuracy: 0.9167\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0681 - accuracy: 0.9788 - val_loss: 0.2305 - val_accuracy: 0.8992\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0664 - accuracy: 0.9757 - val_loss: 0.2092 - val_accuracy: 0.9198\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0512 - accuracy: 0.9810 - val_loss: 0.2256 - val_accuracy: 0.9177\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.1561 - val_accuracy: 0.9393\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.2362 - val_accuracy: 0.9023\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0498 - accuracy: 0.9802 - val_loss: 0.2002 - val_accuracy: 0.9198\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.2416 - val_accuracy: 0.8971\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0705 - accuracy: 0.9749 - val_loss: 0.1731 - val_accuracy: 0.9362\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0429 - accuracy: 0.9832 - val_loss: 0.2001 - val_accuracy: 0.9259\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 0.2344 - val_accuracy: 0.8961\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1063 - accuracy: 0.9810 - val_loss: 0.1881 - val_accuracy: 0.9342\n","Score: 0.9341563582420349 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 5605139.0000 - accuracy: 0.8959 - val_loss: 1.0349 - val_accuracy: 0.5062\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2797 - accuracy: 0.8911 - val_loss: 0.7062 - val_accuracy: 0.5185\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1852 - accuracy: 0.9118 - val_loss: 0.6976 - val_accuracy: 0.5103\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9136 - val_loss: 0.7412 - val_accuracy: 0.4825\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9092 - val_loss: 0.6995 - val_accuracy: 0.4815\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.8880 - val_loss: 0.6958 - val_accuracy: 0.4928\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1885 - accuracy: 0.9167 - val_loss: 0.6937 - val_accuracy: 0.4877\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.8995 - val_loss: 0.7619 - val_accuracy: 0.5072\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9198 - val_loss: 0.7305 - val_accuracy: 0.4722\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.8999 - val_loss: 0.7654 - val_accuracy: 0.5144\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9096 - val_loss: 0.6966 - val_accuracy: 0.5134\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1901 - accuracy: 0.9145 - val_loss: 0.6962 - val_accuracy: 0.4825\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9070 - val_loss: 0.6942 - val_accuracy: 0.5010\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9127 - val_loss: 0.7519 - val_accuracy: 0.4949\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1878 - accuracy: 0.9149 - val_loss: 0.7312 - val_accuracy: 0.4866\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9030 - val_loss: 0.6928 - val_accuracy: 0.5123\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9096 - val_loss: 0.7343 - val_accuracy: 0.4918\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9048 - val_loss: 0.7120 - val_accuracy: 0.4938\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9021 - val_loss: 0.6997 - val_accuracy: 0.4887\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9153 - val_loss: 0.7588 - val_accuracy: 0.4712\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9052 - val_loss: 0.7030 - val_accuracy: 0.4825\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.9189 - val_loss: 0.7011 - val_accuracy: 0.5206\n","Epoch 23/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1887 - accuracy: 0.9105 - val_loss: 0.6913 - val_accuracy: 0.5329\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9206 - val_loss: 0.7001 - val_accuracy: 0.4877\n","Epoch 25/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2034 - accuracy: 0.8999 - val_loss: 0.7034 - val_accuracy: 0.5134\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9092 - val_loss: 0.7275 - val_accuracy: 0.5278\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9158 - val_loss: 0.7299 - val_accuracy: 0.5165\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9096 - val_loss: 0.7297 - val_accuracy: 0.4887\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9136 - val_loss: 0.6934 - val_accuracy: 0.4815\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9026 - val_loss: 0.7298 - val_accuracy: 0.5360\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1852 - accuracy: 0.9184 - val_loss: 0.7061 - val_accuracy: 0.4897\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9109 - val_loss: 0.7530 - val_accuracy: 0.5144\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9180 - val_loss: 0.6926 - val_accuracy: 0.5185\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9145 - val_loss: 0.6915 - val_accuracy: 0.5298\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1904 - accuracy: 0.9167 - val_loss: 0.7280 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9061 - val_loss: 0.7144 - val_accuracy: 0.5062\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1885 - accuracy: 0.9193 - val_loss: 0.7233 - val_accuracy: 0.4794\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9004 - val_loss: 0.6963 - val_accuracy: 0.4938\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9153 - val_loss: 0.6961 - val_accuracy: 0.4753\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9087 - val_loss: 0.6958 - val_accuracy: 0.4866\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9123 - val_loss: 0.6963 - val_accuracy: 0.5093\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9109 - val_loss: 0.7406 - val_accuracy: 0.5144\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9078 - val_loss: 0.6933 - val_accuracy: 0.4990\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9153 - val_loss: 0.7023 - val_accuracy: 0.5175\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9096 - val_loss: 0.7202 - val_accuracy: 0.4979\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9092 - val_loss: 0.6953 - val_accuracy: 0.4763\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9127 - val_loss: 0.7327 - val_accuracy: 0.5062\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1785 - accuracy: 0.9140 - val_loss: 0.6952 - val_accuracy: 0.4722\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9096 - val_loss: 0.6937 - val_accuracy: 0.4784\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9145 - val_loss: 0.7508 - val_accuracy: 0.4877\n","Score: 0.48765432834625244 \n","Parameters:  {'learning_rate': 0.20074077672044854, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5838 - accuracy: 0.9087 - val_loss: 0.6547 - val_accuracy: 0.5885\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1875 - accuracy: 0.9153 - val_loss: 0.6388 - val_accuracy: 0.6368\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4963 - accuracy: 0.9202 - val_loss: 0.6457 - val_accuracy: 0.6296\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.9171 - val_loss: 0.6143 - val_accuracy: 0.6821\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2272 - accuracy: 0.9140 - val_loss: 0.6151 - val_accuracy: 0.7078\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2292 - accuracy: 0.9228 - val_loss: 0.6009 - val_accuracy: 0.6790\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1796 - accuracy: 0.9281 - val_loss: 0.5761 - val_accuracy: 0.6739\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1557 - accuracy: 0.9308 - val_loss: 0.5355 - val_accuracy: 0.7088\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1609 - accuracy: 0.9308 - val_loss: 0.4927 - val_accuracy: 0.7315\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1659 - accuracy: 0.9339 - val_loss: 0.5005 - val_accuracy: 0.7479\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1806 - accuracy: 0.9475 - val_loss: 0.4964 - val_accuracy: 0.7438\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9462 - val_loss: 0.4649 - val_accuracy: 0.7695\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1390 - accuracy: 0.9449 - val_loss: 0.4445 - val_accuracy: 0.7798\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9524 - val_loss: 0.4375 - val_accuracy: 0.7984\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9383 - val_loss: 0.4324 - val_accuracy: 0.7850\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.9480 - val_loss: 0.4182 - val_accuracy: 0.8313\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1724 - accuracy: 0.9475 - val_loss: 0.5028 - val_accuracy: 0.7829\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1465 - accuracy: 0.9471 - val_loss: 0.4013 - val_accuracy: 0.8169\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1398 - accuracy: 0.9453 - val_loss: 0.3967 - val_accuracy: 0.8117\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9471 - val_loss: 0.4241 - val_accuracy: 0.8117\n","Epoch 21/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1319 - accuracy: 0.9493 - val_loss: 0.3918 - val_accuracy: 0.8086\n","Epoch 22/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1155 - accuracy: 0.9537 - val_loss: 0.4267 - val_accuracy: 0.8179\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1230 - accuracy: 0.9502 - val_loss: 0.3845 - val_accuracy: 0.8200\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1650 - accuracy: 0.9462 - val_loss: 0.4336 - val_accuracy: 0.7994\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1317 - accuracy: 0.9524 - val_loss: 0.4118 - val_accuracy: 0.8117\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9586 - val_loss: 0.4130 - val_accuracy: 0.8158\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9511 - val_loss: 0.4470 - val_accuracy: 0.7829\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9475 - val_loss: 0.4353 - val_accuracy: 0.7932\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1277 - accuracy: 0.9497 - val_loss: 0.3654 - val_accuracy: 0.8313\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9568 - val_loss: 0.3896 - val_accuracy: 0.8189\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2241 - accuracy: 0.9563 - val_loss: 0.3935 - val_accuracy: 0.8169\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1198 - accuracy: 0.9537 - val_loss: 0.3805 - val_accuracy: 0.8241\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.9418 - val_loss: 0.4487 - val_accuracy: 0.7901\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1183 - accuracy: 0.9533 - val_loss: 0.3816 - val_accuracy: 0.8241\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2088 - accuracy: 0.9511 - val_loss: 0.3862 - val_accuracy: 0.8251\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.9563 - val_loss: 0.5747 - val_accuracy: 0.8117\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1594 - accuracy: 0.9502 - val_loss: 0.3796 - val_accuracy: 0.8426\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1354 - accuracy: 0.9533 - val_loss: 0.4031 - val_accuracy: 0.8169\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1139 - accuracy: 0.9572 - val_loss: 0.4108 - val_accuracy: 0.8210\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1188 - accuracy: 0.9541 - val_loss: 0.3832 - val_accuracy: 0.8241\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1098 - accuracy: 0.9586 - val_loss: 0.4284 - val_accuracy: 0.8220\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1051 - accuracy: 0.9563 - val_loss: 0.3620 - val_accuracy: 0.8447\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9563 - val_loss: 0.3285 - val_accuracy: 0.8519\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2639 - accuracy: 0.9559 - val_loss: 0.3720 - val_accuracy: 0.8447\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1149 - accuracy: 0.9572 - val_loss: 0.4056 - val_accuracy: 0.8498\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9599 - val_loss: 0.3387 - val_accuracy: 0.8426\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1397 - accuracy: 0.9506 - val_loss: 0.3603 - val_accuracy: 0.8405\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1289 - accuracy: 0.9515 - val_loss: 0.6819 - val_accuracy: 0.8056\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9466 - val_loss: 0.3387 - val_accuracy: 0.8529\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1103 - accuracy: 0.9612 - val_loss: 0.3131 - val_accuracy: 0.8570\n","Score: 0.8569958806037903 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7984 - accuracy: 0.9109 - val_loss: 0.6517 - val_accuracy: 0.5175\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1642 - accuracy: 0.9228 - val_loss: 0.6185 - val_accuracy: 0.5422\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1652 - accuracy: 0.9281 - val_loss: 0.6558 - val_accuracy: 0.6317\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1593 - accuracy: 0.9286 - val_loss: 0.5698 - val_accuracy: 0.7047\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1667 - accuracy: 0.9369 - val_loss: 0.5284 - val_accuracy: 0.7531\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1559 - accuracy: 0.9303 - val_loss: 0.5706 - val_accuracy: 0.6893\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8088 - accuracy: 0.9237 - val_loss: 0.5274 - val_accuracy: 0.7191\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2487 - accuracy: 0.9374 - val_loss: 0.5390 - val_accuracy: 0.7253\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9409 - val_loss: 0.4673 - val_accuracy: 0.7757\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1768 - accuracy: 0.9339 - val_loss: 0.4622 - val_accuracy: 0.7726\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9436 - val_loss: 0.4554 - val_accuracy: 0.7582\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9497 - val_loss: 0.4410 - val_accuracy: 0.7829\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1490 - accuracy: 0.9409 - val_loss: 0.4455 - val_accuracy: 0.7788\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9555 - val_loss: 0.4722 - val_accuracy: 0.7654\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1326 - accuracy: 0.9541 - val_loss: 0.4517 - val_accuracy: 0.7716\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1219 - accuracy: 0.9563 - val_loss: 0.4521 - val_accuracy: 0.7685\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1379 - accuracy: 0.9475 - val_loss: 0.4363 - val_accuracy: 0.7963\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9511 - val_loss: 0.4293 - val_accuracy: 0.7809\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1394 - accuracy: 0.9511 - val_loss: 0.3909 - val_accuracy: 0.8138\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9436 - val_loss: 0.4366 - val_accuracy: 0.7912\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9515 - val_loss: 0.4155 - val_accuracy: 0.8035\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1183 - accuracy: 0.9515 - val_loss: 0.3542 - val_accuracy: 0.8241\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9480 - val_loss: 0.4023 - val_accuracy: 0.8014\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9502 - val_loss: 0.4758 - val_accuracy: 0.7850\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1343 - accuracy: 0.9471 - val_loss: 0.4205 - val_accuracy: 0.8086\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9489 - val_loss: 0.4185 - val_accuracy: 0.8035\n","Epoch 27/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1172 - accuracy: 0.9502 - val_loss: 0.3898 - val_accuracy: 0.8158\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9515 - val_loss: 0.3782 - val_accuracy: 0.8302\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.9511 - val_loss: 0.3305 - val_accuracy: 0.8313\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1107 - accuracy: 0.9608 - val_loss: 0.4005 - val_accuracy: 0.8128\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9471 - val_loss: 0.3997 - val_accuracy: 0.8076\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9431 - val_loss: 0.4165 - val_accuracy: 0.7901\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1605 - accuracy: 0.9541 - val_loss: 0.3534 - val_accuracy: 0.8179\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1393 - accuracy: 0.9555 - val_loss: 0.3875 - val_accuracy: 0.8148\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1477 - accuracy: 0.9466 - val_loss: 0.3502 - val_accuracy: 0.8436\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1114 - accuracy: 0.9533 - val_loss: 0.4009 - val_accuracy: 0.7922\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9537 - val_loss: 0.3720 - val_accuracy: 0.8200\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1242 - accuracy: 0.9528 - val_loss: 0.3419 - val_accuracy: 0.8416\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9572 - val_loss: 0.3824 - val_accuracy: 0.8117\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1023 - accuracy: 0.9568 - val_loss: 0.3616 - val_accuracy: 0.8354\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9630 - val_loss: 0.3618 - val_accuracy: 0.8385\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1062 - accuracy: 0.9599 - val_loss: 0.3676 - val_accuracy: 0.8354\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9475 - val_loss: 0.3341 - val_accuracy: 0.8405\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9541 - val_loss: 0.3566 - val_accuracy: 0.8302\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9603 - val_loss: 0.3562 - val_accuracy: 0.8272\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1815 - accuracy: 0.9519 - val_loss: 0.3977 - val_accuracy: 0.8251\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1172 - accuracy: 0.9577 - val_loss: 0.4698 - val_accuracy: 0.8302\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9581 - val_loss: 0.3417 - val_accuracy: 0.8302\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1212 - accuracy: 0.9524 - val_loss: 0.3734 - val_accuracy: 0.8179\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1052 - accuracy: 0.9647 - val_loss: 0.3085 - val_accuracy: 0.8477\n","Score: 0.8477365970611572 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9928 - accuracy: 0.9123 - val_loss: 0.6942 - val_accuracy: 0.5113\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3507 - accuracy: 0.9162 - val_loss: 0.7520 - val_accuracy: 0.5144\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3342 - accuracy: 0.9118 - val_loss: 0.7806 - val_accuracy: 0.5134\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2695 - accuracy: 0.9175 - val_loss: 0.6404 - val_accuracy: 0.6492\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2604 - accuracy: 0.9131 - val_loss: 0.6576 - val_accuracy: 0.6667\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2308 - accuracy: 0.9092 - val_loss: 0.6458 - val_accuracy: 0.5525\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1717 - accuracy: 0.9224 - val_loss: 0.6150 - val_accuracy: 0.6790\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9184 - val_loss: 0.8169 - val_accuracy: 0.5237\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2399 - accuracy: 0.9198 - val_loss: 0.6220 - val_accuracy: 0.6749\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1727 - accuracy: 0.9255 - val_loss: 0.5418 - val_accuracy: 0.7078\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3175 - accuracy: 0.9343 - val_loss: 0.5526 - val_accuracy: 0.7181\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1733 - accuracy: 0.9312 - val_loss: 0.4917 - val_accuracy: 0.7747\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2159 - accuracy: 0.9396 - val_loss: 0.4767 - val_accuracy: 0.7675\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1756 - accuracy: 0.9290 - val_loss: 0.5239 - val_accuracy: 0.7212\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1600 - accuracy: 0.9303 - val_loss: 0.4736 - val_accuracy: 0.7531\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2984 - accuracy: 0.9312 - val_loss: 0.4606 - val_accuracy: 0.7726\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.9475 - val_loss: 0.4238 - val_accuracy: 0.8025\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1221 - accuracy: 0.9519 - val_loss: 0.3871 - val_accuracy: 0.8189\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1408 - accuracy: 0.9444 - val_loss: 0.6119 - val_accuracy: 0.7449\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9475 - val_loss: 0.3450 - val_accuracy: 0.8395\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1691 - accuracy: 0.9541 - val_loss: 0.6007 - val_accuracy: 0.7438\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.9502 - val_loss: 0.3424 - val_accuracy: 0.8385\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1691 - accuracy: 0.9497 - val_loss: 0.4125 - val_accuracy: 0.7901\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9581 - val_loss: 0.3313 - val_accuracy: 0.8282\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1277 - accuracy: 0.9537 - val_loss: 0.3944 - val_accuracy: 0.8313\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1157 - accuracy: 0.9599 - val_loss: 0.3441 - val_accuracy: 0.8673\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9537 - val_loss: 0.5264 - val_accuracy: 0.8241\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1097 - accuracy: 0.9559 - val_loss: 0.3405 - val_accuracy: 0.8189\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9586 - val_loss: 0.3433 - val_accuracy: 0.8467\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0910 - accuracy: 0.9630 - val_loss: 0.3480 - val_accuracy: 0.8405\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1120 - accuracy: 0.9599 - val_loss: 0.3651 - val_accuracy: 0.8333\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1099 - accuracy: 0.9638 - val_loss: 0.3594 - val_accuracy: 0.8477\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0963 - accuracy: 0.9594 - val_loss: 0.3302 - val_accuracy: 0.8467\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1058 - accuracy: 0.9630 - val_loss: 0.2950 - val_accuracy: 0.8745\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0914 - accuracy: 0.9678 - val_loss: 0.2661 - val_accuracy: 0.8714\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0839 - accuracy: 0.9634 - val_loss: 0.3636 - val_accuracy: 0.8488\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9616 - val_loss: 0.2750 - val_accuracy: 0.8673\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0820 - accuracy: 0.9687 - val_loss: 0.2296 - val_accuracy: 0.8992\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0779 - accuracy: 0.9674 - val_loss: 0.2870 - val_accuracy: 0.8539\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0780 - accuracy: 0.9683 - val_loss: 0.2884 - val_accuracy: 0.8920\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0734 - accuracy: 0.9757 - val_loss: 0.2314 - val_accuracy: 0.9053\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0743 - accuracy: 0.9705 - val_loss: 0.1944 - val_accuracy: 0.9105\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0680 - accuracy: 0.9749 - val_loss: 0.1995 - val_accuracy: 0.9249\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1037 - accuracy: 0.9674 - val_loss: 0.7205 - val_accuracy: 0.8611\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0668 - accuracy: 0.9762 - val_loss: 0.2521 - val_accuracy: 0.8971\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0648 - accuracy: 0.9744 - val_loss: 0.2683 - val_accuracy: 0.8920\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0516 - accuracy: 0.9824 - val_loss: 0.3181 - val_accuracy: 0.9012\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0555 - accuracy: 0.9802 - val_loss: 0.1796 - val_accuracy: 0.9208\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0626 - accuracy: 0.9775 - val_loss: 0.2192 - val_accuracy: 0.9095\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0522 - accuracy: 0.9819 - val_loss: 0.1775 - val_accuracy: 0.9249\n","Score: 0.9248971343040466 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9516 - accuracy: 0.9162 - val_loss: 0.5990 - val_accuracy: 0.6986\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2769 - accuracy: 0.9237 - val_loss: 0.6452 - val_accuracy: 0.6564\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2278 - accuracy: 0.9272 - val_loss: 0.5066 - val_accuracy: 0.7449\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1779 - accuracy: 0.9365 - val_loss: 0.5175 - val_accuracy: 0.7233\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1547 - accuracy: 0.9343 - val_loss: 0.4662 - val_accuracy: 0.7613\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9356 - val_loss: 0.4664 - val_accuracy: 0.7634\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1401 - accuracy: 0.9422 - val_loss: 0.4978 - val_accuracy: 0.7490\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9440 - val_loss: 0.4709 - val_accuracy: 0.7613\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1392 - accuracy: 0.9453 - val_loss: 0.4940 - val_accuracy: 0.7623\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1480 - accuracy: 0.9369 - val_loss: 0.4760 - val_accuracy: 0.7675\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1396 - accuracy: 0.9462 - val_loss: 0.4448 - val_accuracy: 0.7891\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1399 - accuracy: 0.9497 - val_loss: 0.4307 - val_accuracy: 0.8045\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1404 - accuracy: 0.9475 - val_loss: 0.4309 - val_accuracy: 0.8107\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9462 - val_loss: 0.4708 - val_accuracy: 0.7922\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1542 - accuracy: 0.9493 - val_loss: 0.4335 - val_accuracy: 0.8086\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1290 - accuracy: 0.9528 - val_loss: 0.4893 - val_accuracy: 0.7490\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1479 - accuracy: 0.9453 - val_loss: 0.4225 - val_accuracy: 0.8014\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1666 - accuracy: 0.9475 - val_loss: 0.4336 - val_accuracy: 0.7860\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1277 - accuracy: 0.9506 - val_loss: 0.4423 - val_accuracy: 0.8097\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9528 - val_loss: 0.3957 - val_accuracy: 0.8230\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1103 - accuracy: 0.9616 - val_loss: 0.3906 - val_accuracy: 0.8097\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1265 - accuracy: 0.9502 - val_loss: 0.3894 - val_accuracy: 0.8210\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 0.3930 - val_accuracy: 0.8148\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9497 - val_loss: 0.4239 - val_accuracy: 0.8086\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9480 - val_loss: 0.4267 - val_accuracy: 0.8138\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1554 - accuracy: 0.9484 - val_loss: 0.3760 - val_accuracy: 0.8179\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1190 - accuracy: 0.9541 - val_loss: 0.3751 - val_accuracy: 0.8282\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1779 - accuracy: 0.9519 - val_loss: 0.4026 - val_accuracy: 0.8158\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9533 - val_loss: 0.3807 - val_accuracy: 0.8169\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9502 - val_loss: 0.3712 - val_accuracy: 0.8354\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.9528 - val_loss: 0.3819 - val_accuracy: 0.8282\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1216 - accuracy: 0.9462 - val_loss: 0.4027 - val_accuracy: 0.8210\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9480 - val_loss: 0.3605 - val_accuracy: 0.8364\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1151 - accuracy: 0.9563 - val_loss: 0.3956 - val_accuracy: 0.8230\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9568 - val_loss: 0.3618 - val_accuracy: 0.8426\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2567 - accuracy: 0.9546 - val_loss: 0.3662 - val_accuracy: 0.8282\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1473 - accuracy: 0.9621 - val_loss: 0.3882 - val_accuracy: 0.8220\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1074 - accuracy: 0.9563 - val_loss: 0.3784 - val_accuracy: 0.8261\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9559 - val_loss: 0.3327 - val_accuracy: 0.8570\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1761 - accuracy: 0.9563 - val_loss: 0.3809 - val_accuracy: 0.8179\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1774 - accuracy: 0.9533 - val_loss: 0.3576 - val_accuracy: 0.8272\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1561 - accuracy: 0.9444 - val_loss: 0.3949 - val_accuracy: 0.8200\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1555 - accuracy: 0.9568 - val_loss: 0.3978 - val_accuracy: 0.8292\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1264 - accuracy: 0.9537 - val_loss: 0.3363 - val_accuracy: 0.8457\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.9519 - val_loss: 0.3698 - val_accuracy: 0.8230\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1214 - accuracy: 0.9506 - val_loss: 0.3407 - val_accuracy: 0.8477\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1241 - accuracy: 0.9524 - val_loss: 0.3510 - val_accuracy: 0.8477\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.9519 - val_loss: 0.3292 - val_accuracy: 0.8539\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1530 - accuracy: 0.9524 - val_loss: 0.3327 - val_accuracy: 0.8416\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1064 - accuracy: 0.9581 - val_loss: 0.3347 - val_accuracy: 0.8539\n","Score: 0.8539094924926758 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 269340.8750 - accuracy: 0.8889 - val_loss: 3.3265 - val_accuracy: 0.5391\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.6352 - accuracy: 0.9123 - val_loss: 2.0522 - val_accuracy: 0.5278\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7298 - accuracy: 0.9087 - val_loss: 1.3779 - val_accuracy: 0.5514\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4453 - accuracy: 0.9109 - val_loss: 0.9826 - val_accuracy: 0.5360\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3841 - accuracy: 0.9056 - val_loss: 1.0626 - val_accuracy: 0.4897\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2793 - accuracy: 0.9043 - val_loss: 0.8643 - val_accuracy: 0.5257\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2313 - accuracy: 0.9118 - val_loss: 0.7879 - val_accuracy: 0.5329\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1976 - accuracy: 0.9228 - val_loss: 0.7848 - val_accuracy: 0.4979\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.9114 - val_loss: 0.8150 - val_accuracy: 0.5360\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 25.9584 - accuracy: 0.9175 - val_loss: 0.6898 - val_accuracy: 0.4825\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9101 - val_loss: 0.6971 - val_accuracy: 0.4825\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2150 - accuracy: 0.9017 - val_loss: 0.6888 - val_accuracy: 0.5278\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9123 - val_loss: 0.7069 - val_accuracy: 0.4866\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2059 - accuracy: 0.8929 - val_loss: 0.6906 - val_accuracy: 0.4681\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9118 - val_loss: 0.7025 - val_accuracy: 0.4969\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9162 - val_loss: 0.7333 - val_accuracy: 0.4835\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9052 - val_loss: 0.6907 - val_accuracy: 0.4733\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9167 - val_loss: 0.6908 - val_accuracy: 0.5195\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1837 - accuracy: 0.9215 - val_loss: 0.7082 - val_accuracy: 0.4846\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.8990 - val_loss: 0.6932 - val_accuracy: 0.4753\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.8959 - val_loss: 0.6925 - val_accuracy: 0.4825\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9189 - val_loss: 0.7465 - val_accuracy: 0.4774\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9048 - val_loss: 0.7148 - val_accuracy: 0.5175\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9149 - val_loss: 0.7096 - val_accuracy: 0.4743\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1945 - accuracy: 0.9034 - val_loss: 0.7183 - val_accuracy: 0.4907\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9074 - val_loss: 0.6907 - val_accuracy: 0.4949\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9105 - val_loss: 0.6981 - val_accuracy: 0.5237\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9153 - val_loss: 0.6896 - val_accuracy: 0.5216\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9065 - val_loss: 0.7198 - val_accuracy: 0.4763\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9065 - val_loss: 0.6894 - val_accuracy: 0.5319\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9153 - val_loss: 0.7548 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 12.8469 - accuracy: 0.9140 - val_loss: 1.0356 - val_accuracy: 0.4846\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 20.2646 - accuracy: 0.8995 - val_loss: 0.7019 - val_accuracy: 0.4825\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9083 - val_loss: 0.7177 - val_accuracy: 0.5072\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9101 - val_loss: 0.6975 - val_accuracy: 0.4928\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9123 - val_loss: 0.7005 - val_accuracy: 0.4743\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9056 - val_loss: 0.7695 - val_accuracy: 0.5113\n","Epoch 38/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1957 - accuracy: 0.9123 - val_loss: 0.6919 - val_accuracy: 0.5247\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1893 - accuracy: 0.9140 - val_loss: 0.6968 - val_accuracy: 0.5103\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9175 - val_loss: 0.7334 - val_accuracy: 0.5144\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9180 - val_loss: 0.7798 - val_accuracy: 0.5103\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9114 - val_loss: 0.7594 - val_accuracy: 0.4702\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1997 - accuracy: 0.9083 - val_loss: 0.6984 - val_accuracy: 0.5216\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.9087 - val_loss: 0.6942 - val_accuracy: 0.5103\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9101 - val_loss: 0.6996 - val_accuracy: 0.5041\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9105 - val_loss: 0.7179 - val_accuracy: 0.4990\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9056 - val_loss: 0.7065 - val_accuracy: 0.5010\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9131 - val_loss: 0.6981 - val_accuracy: 0.5257\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9131 - val_loss: 0.7175 - val_accuracy: 0.5165\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9175 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Score: 0.5113168954849243 \n","Parameters:  {'learning_rate': 0.127606649422205, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 469144.3125 - accuracy: 0.9048 - val_loss: 0.6939 - val_accuracy: 0.5082\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9092 - val_loss: 0.7027 - val_accuracy: 0.5041\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9131 - val_loss: 0.7158 - val_accuracy: 0.5021\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9056 - val_loss: 0.6947 - val_accuracy: 0.5062\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9153 - val_loss: 0.6942 - val_accuracy: 0.5062\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9145 - val_loss: 0.6942 - val_accuracy: 0.4887\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9101 - val_loss: 0.7427 - val_accuracy: 0.5103\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9149 - val_loss: 0.7761 - val_accuracy: 0.5237\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1900 - accuracy: 0.9171 - val_loss: 0.6984 - val_accuracy: 0.4897\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9034 - val_loss: 0.6953 - val_accuracy: 0.5206\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9101 - val_loss: 0.6954 - val_accuracy: 0.4774\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9017 - val_loss: 0.6982 - val_accuracy: 0.5134\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9118 - val_loss: 0.6902 - val_accuracy: 0.5340\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1801 - accuracy: 0.9171 - val_loss: 0.6936 - val_accuracy: 0.5113\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9171 - val_loss: 0.6985 - val_accuracy: 0.5021\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9131 - val_loss: 0.7227 - val_accuracy: 0.4794\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2103 - accuracy: 0.9012 - val_loss: 0.6964 - val_accuracy: 0.5195\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2002 - accuracy: 0.9039 - val_loss: 0.6941 - val_accuracy: 0.4846\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2088 - accuracy: 0.8968 - val_loss: 0.7398 - val_accuracy: 0.5123\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9096 - val_loss: 0.7057 - val_accuracy: 0.4918\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9101 - val_loss: 0.7127 - val_accuracy: 0.5093\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9078 - val_loss: 0.7208 - val_accuracy: 0.4846\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9140 - val_loss: 0.7067 - val_accuracy: 0.4887\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9123 - val_loss: 0.7144 - val_accuracy: 0.4856\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9048 - val_loss: 0.7000 - val_accuracy: 0.4959\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9061 - val_loss: 0.6956 - val_accuracy: 0.4969\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2029 - accuracy: 0.9039 - val_loss: 0.6945 - val_accuracy: 0.4969\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1975 - accuracy: 0.9083 - val_loss: 0.6950 - val_accuracy: 0.5165\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1779 - accuracy: 0.9175 - val_loss: 0.7240 - val_accuracy: 0.5175\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9118 - val_loss: 0.6943 - val_accuracy: 0.4856\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2003 - accuracy: 0.9078 - val_loss: 0.6935 - val_accuracy: 0.5185\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9048 - val_loss: 0.6943 - val_accuracy: 0.5062\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9136 - val_loss: 0.6928 - val_accuracy: 0.5123\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9087 - val_loss: 0.7132 - val_accuracy: 0.5144\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9140 - val_loss: 0.7111 - val_accuracy: 0.5154\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9149 - val_loss: 0.7011 - val_accuracy: 0.5041\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9123 - val_loss: 0.6941 - val_accuracy: 0.4928\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9193 - val_loss: 0.7414 - val_accuracy: 0.4866\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1978 - accuracy: 0.8968 - val_loss: 0.7087 - val_accuracy: 0.4887\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9109 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9070 - val_loss: 0.7039 - val_accuracy: 0.4743\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.6970 - val_accuracy: 0.4938\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9052 - val_loss: 0.7013 - val_accuracy: 0.5134\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9171 - val_loss: 0.6938 - val_accuracy: 0.5021\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1885 - accuracy: 0.9158 - val_loss: 0.7209 - val_accuracy: 0.4835\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9012 - val_loss: 0.7211 - val_accuracy: 0.5195\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9145 - val_loss: 0.7064 - val_accuracy: 0.4959\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.8981 - val_loss: 0.6918 - val_accuracy: 0.5278\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9030 - val_loss: 0.6943 - val_accuracy: 0.4846\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.9061 - val_loss: 0.6945 - val_accuracy: 0.5154\n","Score: 0.5154321193695068 \n","Parameters:  {'learning_rate': 0.12503732471792153, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 225310.3281 - accuracy: 0.8937 - val_loss: 1.0103 - val_accuracy: 0.4609\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 4.3318 - accuracy: 0.9052 - val_loss: 0.9079 - val_accuracy: 0.5144\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.9514 - accuracy: 0.9175 - val_loss: 0.8263 - val_accuracy: 0.5175\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2640 - accuracy: 0.9136 - val_loss: 0.6988 - val_accuracy: 0.4784\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2036 - accuracy: 0.9061 - val_loss: 0.6926 - val_accuracy: 0.5226\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9153 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2112 - accuracy: 0.9034 - val_loss: 0.6934 - val_accuracy: 0.4990\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9145 - val_loss: 0.6942 - val_accuracy: 0.5051\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1907 - accuracy: 0.9167 - val_loss: 0.6940 - val_accuracy: 0.5021\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9193 - val_loss: 0.7291 - val_accuracy: 0.5154\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1988 - accuracy: 0.9149 - val_loss: 0.7558 - val_accuracy: 0.5072\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2033 - accuracy: 0.9123 - val_loss: 0.7146 - val_accuracy: 0.4856\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9026 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2060 - accuracy: 0.9123 - val_loss: 0.6932 - val_accuracy: 0.5021\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9149 - val_loss: 0.6937 - val_accuracy: 0.5288\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9140 - val_loss: 0.7148 - val_accuracy: 0.4877\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9039 - val_loss: 0.6917 - val_accuracy: 0.5412\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2142 - accuracy: 0.9114 - val_loss: 0.6960 - val_accuracy: 0.4856\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9109 - val_loss: 0.6931 - val_accuracy: 0.5031\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9131 - val_loss: 0.7234 - val_accuracy: 0.5216\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2110 - accuracy: 0.9083 - val_loss: 0.7214 - val_accuracy: 0.4918\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9056 - val_loss: 0.6959 - val_accuracy: 0.5103\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1941 - accuracy: 0.9127 - val_loss: 0.6935 - val_accuracy: 0.4949\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2003 - accuracy: 0.9158 - val_loss: 0.6958 - val_accuracy: 0.5309\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9127 - val_loss: 0.6908 - val_accuracy: 0.5340\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9189 - val_loss: 0.6957 - val_accuracy: 0.5113\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2063 - accuracy: 0.9096 - val_loss: 0.6939 - val_accuracy: 0.5041\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9101 - val_loss: 0.6939 - val_accuracy: 0.5288\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9149 - val_loss: 0.7107 - val_accuracy: 0.4928\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2131 - accuracy: 0.9087 - val_loss: 0.7131 - val_accuracy: 0.4990\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1881 - accuracy: 0.9237 - val_loss: 0.7238 - val_accuracy: 0.4856\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9056 - val_loss: 0.6921 - val_accuracy: 0.5278\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9114 - val_loss: 0.6996 - val_accuracy: 0.5195\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9136 - val_loss: 0.6935 - val_accuracy: 0.5010\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9180 - val_loss: 0.6928 - val_accuracy: 0.5257\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.9070 - val_loss: 0.6960 - val_accuracy: 0.5165\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9153 - val_loss: 0.6988 - val_accuracy: 0.4702\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9012 - val_loss: 0.7229 - val_accuracy: 0.5237\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9118 - val_loss: 0.7040 - val_accuracy: 0.5216\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9149 - val_loss: 0.7004 - val_accuracy: 0.4825\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.9061 - val_loss: 0.6937 - val_accuracy: 0.4897\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2064 - accuracy: 0.9078 - val_loss: 0.6988 - val_accuracy: 0.4846\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2052 - accuracy: 0.9056 - val_loss: 0.6933 - val_accuracy: 0.4938\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9114 - val_loss: 0.6930 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9149 - val_loss: 0.7429 - val_accuracy: 0.4774\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.9056 - val_loss: 0.7009 - val_accuracy: 0.4743\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1941 - accuracy: 0.9153 - val_loss: 0.6934 - val_accuracy: 0.4949\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9136 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9153 - val_loss: 0.6937 - val_accuracy: 0.5000\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9123 - val_loss: 0.6938 - val_accuracy: 0.4928\n","Score: 0.4927983582019806 \n","Parameters:  {'learning_rate': 0.09337015815438703, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5614 - accuracy: 0.9145 - val_loss: 0.6454 - val_accuracy: 0.5689\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9149 - val_loss: 0.6202 - val_accuracy: 0.6698\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9136 - val_loss: 0.6058 - val_accuracy: 0.6728\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1818 - accuracy: 0.9127 - val_loss: 0.6257 - val_accuracy: 0.6101\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1658 - accuracy: 0.9228 - val_loss: 0.5799 - val_accuracy: 0.6852\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2995 - accuracy: 0.9211 - val_loss: 0.5820 - val_accuracy: 0.6852\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2579 - accuracy: 0.9242 - val_loss: 0.5715 - val_accuracy: 0.7006\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1836 - accuracy: 0.9114 - val_loss: 0.6208 - val_accuracy: 0.6656\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1761 - accuracy: 0.9145 - val_loss: 0.6921 - val_accuracy: 0.5195\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1805 - accuracy: 0.9087 - val_loss: 0.6113 - val_accuracy: 0.5267\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1829 - accuracy: 0.9136 - val_loss: 0.6157 - val_accuracy: 0.6584\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1788 - accuracy: 0.9250 - val_loss: 0.5945 - val_accuracy: 0.6790\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1700 - accuracy: 0.9242 - val_loss: 0.6434 - val_accuracy: 0.6317\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1577 - accuracy: 0.9242 - val_loss: 0.6090 - val_accuracy: 0.7099\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9233 - val_loss: 0.5872 - val_accuracy: 0.6780\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.9246 - val_loss: 0.5692 - val_accuracy: 0.7037\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1635 - accuracy: 0.9215 - val_loss: 0.5840 - val_accuracy: 0.6893\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1678 - accuracy: 0.9220 - val_loss: 0.6028 - val_accuracy: 0.6831\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1755 - accuracy: 0.9140 - val_loss: 0.5901 - val_accuracy: 0.6728\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9123 - val_loss: 0.6995 - val_accuracy: 0.5226\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3409 - accuracy: 0.9153 - val_loss: 0.6321 - val_accuracy: 0.6749\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0329 - accuracy: 0.9303 - val_loss: 0.5830 - val_accuracy: 0.7284\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1839 - accuracy: 0.9325 - val_loss: 0.5616 - val_accuracy: 0.7335\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9383 - val_loss: 0.5404 - val_accuracy: 0.7840\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1647 - accuracy: 0.9369 - val_loss: 0.5502 - val_accuracy: 0.7284\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1584 - accuracy: 0.9365 - val_loss: 0.5458 - val_accuracy: 0.7356\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1692 - accuracy: 0.9264 - val_loss: 0.5144 - val_accuracy: 0.7788\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1585 - accuracy: 0.9343 - val_loss: 0.5149 - val_accuracy: 0.7726\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1605 - accuracy: 0.9347 - val_loss: 0.5205 - val_accuracy: 0.7531\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.9444 - val_loss: 0.4738 - val_accuracy: 0.7809\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1346 - accuracy: 0.9515 - val_loss: 0.4767 - val_accuracy: 0.7798\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9405 - val_loss: 0.4680 - val_accuracy: 0.7747\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9480 - val_loss: 0.4697 - val_accuracy: 0.7860\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1497 - accuracy: 0.9431 - val_loss: 0.4696 - val_accuracy: 0.7757\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9396 - val_loss: 0.4795 - val_accuracy: 0.7665\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1547 - accuracy: 0.9449 - val_loss: 0.4436 - val_accuracy: 0.7891\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1778 - accuracy: 0.9489 - val_loss: 0.4794 - val_accuracy: 0.7809\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1325 - accuracy: 0.9444 - val_loss: 0.4338 - val_accuracy: 0.7809\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1337 - accuracy: 0.9449 - val_loss: 0.4548 - val_accuracy: 0.7809\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1861 - accuracy: 0.9466 - val_loss: 0.4528 - val_accuracy: 0.7912\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1482 - accuracy: 0.9462 - val_loss: 1.0111 - val_accuracy: 0.6636\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9524 - val_loss: 0.4354 - val_accuracy: 0.7953\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1305 - accuracy: 0.9533 - val_loss: 0.4027 - val_accuracy: 0.8056\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1809 - accuracy: 0.9444 - val_loss: 0.4495 - val_accuracy: 0.7665\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9497 - val_loss: 0.4370 - val_accuracy: 0.7798\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1365 - accuracy: 0.9440 - val_loss: 0.4485 - val_accuracy: 0.7953\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9528 - val_loss: 0.4311 - val_accuracy: 0.8014\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.9555 - val_loss: 0.3784 - val_accuracy: 0.8261\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1462 - accuracy: 0.9519 - val_loss: 0.5320 - val_accuracy: 0.7665\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1453 - accuracy: 0.9541 - val_loss: 0.4094 - val_accuracy: 0.8086\n","Score: 0.8086419701576233 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1481 - accuracy: 0.9206 - val_loss: 0.6429 - val_accuracy: 0.6903\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2366 - accuracy: 0.9255 - val_loss: 0.5876 - val_accuracy: 0.6914\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1605 - accuracy: 0.9272 - val_loss: 0.5016 - val_accuracy: 0.7469\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9334 - val_loss: 0.5192 - val_accuracy: 0.7531\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1571 - accuracy: 0.9383 - val_loss: 0.5082 - val_accuracy: 0.7397\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1450 - accuracy: 0.9347 - val_loss: 0.5084 - val_accuracy: 0.7459\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1423 - accuracy: 0.9471 - val_loss: 0.4801 - val_accuracy: 0.7644\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.9466 - val_loss: 0.5356 - val_accuracy: 0.7757\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9387 - val_loss: 0.4749 - val_accuracy: 0.7603\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1295 - accuracy: 0.9475 - val_loss: 0.4806 - val_accuracy: 0.7685\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1355 - accuracy: 0.9475 - val_loss: 0.4449 - val_accuracy: 0.7840\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9519 - val_loss: 0.4455 - val_accuracy: 0.7819\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1504 - accuracy: 0.9453 - val_loss: 0.4317 - val_accuracy: 0.7809\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9471 - val_loss: 0.7653 - val_accuracy: 0.7438\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9533 - val_loss: 0.4531 - val_accuracy: 0.7634\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1299 - accuracy: 0.9511 - val_loss: 0.4071 - val_accuracy: 0.8076\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1541 - accuracy: 0.9550 - val_loss: 0.4191 - val_accuracy: 0.8158\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9458 - val_loss: 0.4145 - val_accuracy: 0.7973\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1367 - accuracy: 0.9550 - val_loss: 0.4206 - val_accuracy: 0.7973\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1397 - accuracy: 0.9493 - val_loss: 0.4015 - val_accuracy: 0.8066\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9489 - val_loss: 0.3901 - val_accuracy: 0.8220\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9471 - val_loss: 0.4024 - val_accuracy: 0.7942\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1112 - accuracy: 0.9616 - val_loss: 0.5062 - val_accuracy: 0.7901\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1105 - accuracy: 0.9546 - val_loss: 0.3642 - val_accuracy: 0.8354\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1217 - accuracy: 0.9563 - val_loss: 0.3864 - val_accuracy: 0.8097\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1466 - accuracy: 0.9594 - val_loss: 0.3597 - val_accuracy: 0.8313\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1091 - accuracy: 0.9608 - val_loss: 0.3922 - val_accuracy: 0.8292\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1204 - accuracy: 0.9541 - val_loss: 0.4459 - val_accuracy: 0.7860\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1062 - accuracy: 0.9616 - val_loss: 0.3709 - val_accuracy: 0.8405\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9546 - val_loss: 0.3453 - val_accuracy: 0.8436\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9568 - val_loss: 0.4330 - val_accuracy: 0.8014\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9555 - val_loss: 0.4118 - val_accuracy: 0.8107\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0989 - accuracy: 0.9630 - val_loss: 0.3640 - val_accuracy: 0.8323\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1132 - accuracy: 0.9594 - val_loss: 0.3162 - val_accuracy: 0.8683\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.3249 - val_accuracy: 0.8529\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0956 - accuracy: 0.9660 - val_loss: 0.3307 - val_accuracy: 0.8498\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9568 - val_loss: 0.3335 - val_accuracy: 0.8447\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.9581 - val_loss: 0.3242 - val_accuracy: 0.8580\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0988 - accuracy: 0.9634 - val_loss: 0.3518 - val_accuracy: 0.8529\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1037 - accuracy: 0.9616 - val_loss: 0.3845 - val_accuracy: 0.8282\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1024 - accuracy: 0.9660 - val_loss: 0.3510 - val_accuracy: 0.8364\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1027 - accuracy: 0.9612 - val_loss: 0.3130 - val_accuracy: 0.8539\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9616 - val_loss: 0.3204 - val_accuracy: 0.8601\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1166 - accuracy: 0.9625 - val_loss: 0.3200 - val_accuracy: 0.8570\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1332 - accuracy: 0.9612 - val_loss: 0.3145 - val_accuracy: 0.8570\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0954 - accuracy: 0.9674 - val_loss: 0.3730 - val_accuracy: 0.8426\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0957 - accuracy: 0.9652 - val_loss: 0.3523 - val_accuracy: 0.8426\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0952 - accuracy: 0.9608 - val_loss: 0.3167 - val_accuracy: 0.8663\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0838 - accuracy: 0.9731 - val_loss: 0.4886 - val_accuracy: 0.8220\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 0.3008 - val_accuracy: 0.8621\n","Score: 0.8621399402618408 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7551 - accuracy: 0.9180 - val_loss: 0.6195 - val_accuracy: 0.6883\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1791 - accuracy: 0.9153 - val_loss: 0.5911 - val_accuracy: 0.6872\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2075 - accuracy: 0.9140 - val_loss: 0.6487 - val_accuracy: 0.6615\n","Epoch 4/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1940 - accuracy: 0.9220 - val_loss: 0.5890 - val_accuracy: 0.6811\n","Epoch 5/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1843 - accuracy: 0.9114 - val_loss: 0.6194 - val_accuracy: 0.6337\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1614 - accuracy: 0.9352 - val_loss: 0.6273 - val_accuracy: 0.6698\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1787 - accuracy: 0.9215 - val_loss: 0.5913 - val_accuracy: 0.6358\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1628 - accuracy: 0.9361 - val_loss: 0.5696 - val_accuracy: 0.6821\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1778 - accuracy: 0.9277 - val_loss: 0.5211 - val_accuracy: 0.7109\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9281 - val_loss: 0.6883 - val_accuracy: 0.6512\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1560 - accuracy: 0.9365 - val_loss: 0.5944 - val_accuracy: 0.6883\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1534 - accuracy: 0.9383 - val_loss: 0.5128 - val_accuracy: 0.7335\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1695 - accuracy: 0.9272 - val_loss: 0.5503 - val_accuracy: 0.7593\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1782 - accuracy: 0.9268 - val_loss: 0.5601 - val_accuracy: 0.7428\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1792 - accuracy: 0.9383 - val_loss: 0.4703 - val_accuracy: 0.7942\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1508 - accuracy: 0.9400 - val_loss: 0.4921 - val_accuracy: 0.7593\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1388 - accuracy: 0.9462 - val_loss: 0.4314 - val_accuracy: 0.7942\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1398 - accuracy: 0.9471 - val_loss: 0.4371 - val_accuracy: 0.7860\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2689 - accuracy: 0.9409 - val_loss: 0.4336 - val_accuracy: 0.7994\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1414 - accuracy: 0.9444 - val_loss: 0.4559 - val_accuracy: 0.7819\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1692 - accuracy: 0.9405 - val_loss: 0.4368 - val_accuracy: 0.7901\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1450 - accuracy: 0.9427 - val_loss: 0.4628 - val_accuracy: 0.7942\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1733 - accuracy: 0.9475 - val_loss: 0.4961 - val_accuracy: 0.7685\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6731 - accuracy: 0.9352 - val_loss: 0.4528 - val_accuracy: 0.7984\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1584 - accuracy: 0.9387 - val_loss: 0.4829 - val_accuracy: 0.7531\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9506 - val_loss: 0.4059 - val_accuracy: 0.8200\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.9550 - val_loss: 0.4095 - val_accuracy: 0.8179\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9405 - val_loss: 0.4255 - val_accuracy: 0.7984\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1130 - accuracy: 0.9541 - val_loss: 0.4519 - val_accuracy: 0.8138\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1344 - accuracy: 0.9462 - val_loss: 0.4017 - val_accuracy: 0.8179\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1378 - accuracy: 0.9475 - val_loss: 0.4439 - val_accuracy: 0.7973\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1254 - accuracy: 0.9524 - val_loss: 0.4051 - val_accuracy: 0.8138\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1546 - accuracy: 0.9361 - val_loss: 0.4540 - val_accuracy: 0.7798\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1236 - accuracy: 0.9502 - val_loss: 0.4165 - val_accuracy: 0.8025\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2641 - accuracy: 0.9414 - val_loss: 0.4070 - val_accuracy: 0.7973\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1989 - accuracy: 0.9453 - val_loss: 0.3892 - val_accuracy: 0.8138\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1614 - accuracy: 0.9493 - val_loss: 0.4105 - val_accuracy: 0.8148\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1412 - accuracy: 0.9440 - val_loss: 0.4139 - val_accuracy: 0.7912\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1319 - accuracy: 0.9466 - val_loss: 0.3899 - val_accuracy: 0.8230\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1298 - accuracy: 0.9502 - val_loss: 0.4058 - val_accuracy: 0.8292\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9577 - val_loss: 0.3892 - val_accuracy: 0.8302\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1255 - accuracy: 0.9511 - val_loss: 0.4290 - val_accuracy: 0.8138\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1094 - accuracy: 0.9546 - val_loss: 0.4072 - val_accuracy: 0.8117\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9563 - val_loss: 0.4066 - val_accuracy: 0.8076\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1529 - accuracy: 0.9528 - val_loss: 0.4537 - val_accuracy: 0.7932\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1178 - accuracy: 0.9524 - val_loss: 0.4230 - val_accuracy: 0.8066\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1467 - accuracy: 0.9528 - val_loss: 0.4255 - val_accuracy: 0.7870\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1462 - accuracy: 0.9511 - val_loss: 0.4334 - val_accuracy: 0.7953\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1180 - accuracy: 0.9572 - val_loss: 0.3904 - val_accuracy: 0.8426\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1750 - accuracy: 0.9444 - val_loss: 0.4115 - val_accuracy: 0.8086\n","Score: 0.8086419701576233 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 136239.1406 - accuracy: 0.9074 - val_loss: 0.6973 - val_accuracy: 0.5185\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1824 - accuracy: 0.9149 - val_loss: 0.6930 - val_accuracy: 0.5113\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1852 - accuracy: 0.9118 - val_loss: 0.6934 - val_accuracy: 0.4866\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9171 - val_loss: 0.7039 - val_accuracy: 0.5062\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9167 - val_loss: 0.6959 - val_accuracy: 0.5051\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9162 - val_loss: 0.6925 - val_accuracy: 0.5288\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9048 - val_loss: 0.6934 - val_accuracy: 0.5103\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9087 - val_loss: 0.7140 - val_accuracy: 0.5093\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1874 - accuracy: 0.9149 - val_loss: 0.6963 - val_accuracy: 0.5175\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9114 - val_loss: 0.6929 - val_accuracy: 0.5144\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2059 - accuracy: 0.9056 - val_loss: 0.6932 - val_accuracy: 0.4815\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9092 - val_loss: 0.6951 - val_accuracy: 0.4815\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9030 - val_loss: 0.6928 - val_accuracy: 0.5165\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9109 - val_loss: 0.6928 - val_accuracy: 0.5195\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.9070 - val_loss: 0.7131 - val_accuracy: 0.5165\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2064 - accuracy: 0.9092 - val_loss: 0.6954 - val_accuracy: 0.4835\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9070 - val_loss: 0.6969 - val_accuracy: 0.4815\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9074 - val_loss: 0.6950 - val_accuracy: 0.4805\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9175 - val_loss: 0.6915 - val_accuracy: 0.5309\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9149 - val_loss: 0.6922 - val_accuracy: 0.5216\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9118 - val_loss: 0.6931 - val_accuracy: 0.5195\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9083 - val_loss: 0.7625 - val_accuracy: 0.5082\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9131 - val_loss: 0.7008 - val_accuracy: 0.5093\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9149 - val_loss: 0.7020 - val_accuracy: 0.5216\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.9149 - val_loss: 0.7046 - val_accuracy: 0.4887\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1976 - accuracy: 0.9092 - val_loss: 0.6932 - val_accuracy: 0.4887\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9136 - val_loss: 0.6930 - val_accuracy: 0.5185\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9123 - val_loss: 0.7067 - val_accuracy: 0.5206\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9158 - val_loss: 0.6940 - val_accuracy: 0.4743\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9109 - val_loss: 0.6932 - val_accuracy: 0.4949\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9162 - val_loss: 0.6956 - val_accuracy: 0.4805\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9078 - val_loss: 0.7506 - val_accuracy: 0.5134\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9153 - val_loss: 0.6930 - val_accuracy: 0.5082\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9105 - val_loss: 0.6933 - val_accuracy: 0.4907\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1907 - accuracy: 0.9127 - val_loss: 0.6924 - val_accuracy: 0.5288\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9123 - val_loss: 0.7087 - val_accuracy: 0.4825\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2027 - accuracy: 0.8951 - val_loss: 0.7910 - val_accuracy: 0.4835\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.8990 - val_loss: 0.6952 - val_accuracy: 0.5093\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9145 - val_loss: 0.6966 - val_accuracy: 0.4763\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9074 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9105 - val_loss: 0.6957 - val_accuracy: 0.4774\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2047 - accuracy: 0.9087 - val_loss: 0.6932 - val_accuracy: 0.4877\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9140 - val_loss: 0.7293 - val_accuracy: 0.4949\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2155 - accuracy: 0.9026 - val_loss: 0.6927 - val_accuracy: 0.5237\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9105 - val_loss: 0.7011 - val_accuracy: 0.5113\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9153 - val_loss: 0.7123 - val_accuracy: 0.4733\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9087 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9109 - val_loss: 0.6931 - val_accuracy: 0.5113\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9149 - val_loss: 0.6938 - val_accuracy: 0.4990\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9131 - val_loss: 0.7162 - val_accuracy: 0.5113\n","Score: 0.5113168954849243 \n","Parameters:  {'learning_rate': 0.11362868878611847, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1682 - accuracy: 0.9171 - val_loss: 0.7142 - val_accuracy: 0.5195\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2512 - accuracy: 0.9131 - val_loss: 0.7276 - val_accuracy: 0.5041\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6144 - accuracy: 0.9123 - val_loss: 0.6921 - val_accuracy: 0.5072\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1988 - accuracy: 0.9109 - val_loss: 0.7654 - val_accuracy: 0.5175\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2459 - accuracy: 0.9048 - val_loss: 0.6883 - val_accuracy: 0.5051\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9202 - val_loss: 0.6654 - val_accuracy: 0.5730\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1831 - accuracy: 0.9140 - val_loss: 0.7133 - val_accuracy: 0.4856\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4877 - accuracy: 0.9189 - val_loss: 0.5967 - val_accuracy: 0.7047\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9127 - val_loss: 0.7165 - val_accuracy: 0.5576\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2573 - accuracy: 0.9233 - val_loss: 0.5945 - val_accuracy: 0.6903\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2394 - accuracy: 0.9215 - val_loss: 0.5769 - val_accuracy: 0.7068\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1615 - accuracy: 0.9409 - val_loss: 0.5422 - val_accuracy: 0.7356\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5318 - accuracy: 0.9272 - val_loss: 0.5274 - val_accuracy: 0.7912\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9339 - val_loss: 0.5410 - val_accuracy: 0.7233\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1414 - accuracy: 0.9431 - val_loss: 0.5092 - val_accuracy: 0.7654\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9466 - val_loss: 0.5069 - val_accuracy: 0.7449\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2172 - accuracy: 0.9427 - val_loss: 0.5395 - val_accuracy: 0.7479\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3339 - accuracy: 0.9383 - val_loss: 0.4729 - val_accuracy: 0.7510\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9414 - val_loss: 0.4765 - val_accuracy: 0.7778\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1566 - accuracy: 0.9440 - val_loss: 0.4241 - val_accuracy: 0.8014\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9427 - val_loss: 0.4210 - val_accuracy: 0.8014\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9480 - val_loss: 0.4031 - val_accuracy: 0.8200\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1197 - accuracy: 0.9550 - val_loss: 0.3870 - val_accuracy: 0.8251\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1398 - accuracy: 0.9414 - val_loss: 0.4365 - val_accuracy: 0.7994\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1696 - accuracy: 0.9515 - val_loss: 0.4050 - val_accuracy: 0.8241\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1846 - accuracy: 0.9475 - val_loss: 0.4170 - val_accuracy: 0.8220\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9515 - val_loss: 0.4778 - val_accuracy: 0.7747\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1136 - accuracy: 0.9506 - val_loss: 0.3960 - val_accuracy: 0.8179\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1126 - accuracy: 0.9537 - val_loss: 0.4364 - val_accuracy: 0.8056\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9608 - val_loss: 0.3741 - val_accuracy: 0.8313\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9559 - val_loss: 0.4109 - val_accuracy: 0.8076\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2818 - accuracy: 0.9422 - val_loss: 0.3853 - val_accuracy: 0.8138\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1390 - accuracy: 0.9533 - val_loss: 0.4288 - val_accuracy: 0.7912\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9546 - val_loss: 0.3991 - val_accuracy: 0.8169\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1182 - accuracy: 0.9550 - val_loss: 0.4122 - val_accuracy: 0.8210\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1102 - accuracy: 0.9546 - val_loss: 0.3908 - val_accuracy: 0.8241\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0988 - accuracy: 0.9603 - val_loss: 0.3438 - val_accuracy: 0.8416\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9515 - val_loss: 0.3499 - val_accuracy: 0.8467\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1139 - accuracy: 0.9625 - val_loss: 0.3161 - val_accuracy: 0.8488\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0841 - accuracy: 0.9660 - val_loss: 0.3433 - val_accuracy: 0.8467\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0991 - accuracy: 0.9603 - val_loss: 0.3516 - val_accuracy: 0.8560\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1023 - accuracy: 0.9643 - val_loss: 0.3288 - val_accuracy: 0.8539\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9634 - val_loss: 0.3838 - val_accuracy: 0.8344\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1207 - accuracy: 0.9577 - val_loss: 0.3442 - val_accuracy: 0.8611\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9590 - val_loss: 0.3110 - val_accuracy: 0.8601\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1077 - accuracy: 0.9577 - val_loss: 0.2949 - val_accuracy: 0.8611\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0978 - accuracy: 0.9687 - val_loss: 0.3005 - val_accuracy: 0.8652\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9634 - val_loss: 0.2817 - val_accuracy: 0.8693\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0788 - accuracy: 0.9696 - val_loss: 0.3190 - val_accuracy: 0.8591\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1033 - accuracy: 0.9669 - val_loss: 0.2549 - val_accuracy: 0.8858\n","Score: 0.8858024477958679 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9868 - accuracy: 0.9215 - val_loss: 0.6320 - val_accuracy: 0.6358\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1720 - accuracy: 0.9228 - val_loss: 0.6124 - val_accuracy: 0.6533\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2475 - accuracy: 0.9198 - val_loss: 0.6317 - val_accuracy: 0.6574\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1858 - accuracy: 0.9299 - val_loss: 0.5295 - val_accuracy: 0.7263\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9303 - val_loss: 0.5364 - val_accuracy: 0.7387\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1580 - accuracy: 0.9334 - val_loss: 0.5321 - val_accuracy: 0.7233\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1848 - accuracy: 0.9303 - val_loss: 0.4989 - val_accuracy: 0.7356\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1553 - accuracy: 0.9361 - val_loss: 0.4434 - val_accuracy: 0.7747\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2232 - accuracy: 0.9325 - val_loss: 0.4944 - val_accuracy: 0.7531\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.9440 - val_loss: 0.4422 - val_accuracy: 0.7912\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9515 - val_loss: 0.4442 - val_accuracy: 0.7922\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9524 - val_loss: 0.4155 - val_accuracy: 0.8004\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1212 - accuracy: 0.9493 - val_loss: 0.4220 - val_accuracy: 0.7932\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9502 - val_loss: 0.4150 - val_accuracy: 0.8158\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1591 - accuracy: 0.9506 - val_loss: 0.4199 - val_accuracy: 0.8035\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9528 - val_loss: 0.4308 - val_accuracy: 0.7870\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1356 - accuracy: 0.9489 - val_loss: 0.4356 - val_accuracy: 0.7994\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1391 - accuracy: 0.9537 - val_loss: 0.4272 - val_accuracy: 0.7932\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1552 - accuracy: 0.9493 - val_loss: 0.4246 - val_accuracy: 0.8004\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1738 - accuracy: 0.9546 - val_loss: 0.3727 - val_accuracy: 0.8333\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9546 - val_loss: 0.3671 - val_accuracy: 0.8292\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1223 - accuracy: 0.9493 - val_loss: 0.3886 - val_accuracy: 0.8220\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1837 - accuracy: 0.9506 - val_loss: 0.3376 - val_accuracy: 0.8488\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9519 - val_loss: 0.3493 - val_accuracy: 0.8416\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1414 - accuracy: 0.9555 - val_loss: 0.3615 - val_accuracy: 0.8292\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1179 - accuracy: 0.9581 - val_loss: 0.3635 - val_accuracy: 0.8447\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1114 - accuracy: 0.9599 - val_loss: 0.3294 - val_accuracy: 0.8529\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9581 - val_loss: 0.3586 - val_accuracy: 0.8241\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1045 - accuracy: 0.9608 - val_loss: 0.3654 - val_accuracy: 0.8364\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1626 - accuracy: 0.9537 - val_loss: 0.4724 - val_accuracy: 0.7963\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1079 - accuracy: 0.9581 - val_loss: 0.3382 - val_accuracy: 0.8416\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1008 - accuracy: 0.9608 - val_loss: 0.3461 - val_accuracy: 0.8457\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1074 - accuracy: 0.9586 - val_loss: 0.3216 - val_accuracy: 0.8457\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1141 - accuracy: 0.9599 - val_loss: 0.3626 - val_accuracy: 0.8374\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1041 - accuracy: 0.9616 - val_loss: 0.3849 - val_accuracy: 0.8282\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1349 - accuracy: 0.9577 - val_loss: 0.3274 - val_accuracy: 0.8467\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0882 - accuracy: 0.9660 - val_loss: 0.3377 - val_accuracy: 0.8508\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0834 - accuracy: 0.9656 - val_loss: 0.3365 - val_accuracy: 0.8601\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9621 - val_loss: 0.3205 - val_accuracy: 0.8580\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0794 - accuracy: 0.9731 - val_loss: 0.2792 - val_accuracy: 0.8745\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0918 - accuracy: 0.9696 - val_loss: 0.2664 - val_accuracy: 0.8827\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0979 - accuracy: 0.9608 - val_loss: 0.2626 - val_accuracy: 0.8817\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0919 - accuracy: 0.9713 - val_loss: 0.3007 - val_accuracy: 0.8611\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9735 - val_loss: 0.2771 - val_accuracy: 0.8786\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0797 - accuracy: 0.9669 - val_loss: 0.2680 - val_accuracy: 0.8765\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1054 - accuracy: 0.9727 - val_loss: 0.2809 - val_accuracy: 0.8909\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0888 - accuracy: 0.9621 - val_loss: 0.3059 - val_accuracy: 0.8683\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9669 - val_loss: 0.2719 - val_accuracy: 0.8683\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0923 - accuracy: 0.9700 - val_loss: 0.2532 - val_accuracy: 0.8858\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0750 - accuracy: 0.9722 - val_loss: 0.2340 - val_accuracy: 0.8961\n","Score: 0.8960905075073242 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 10796.5703 - accuracy: 0.8867 - val_loss: 0.7305 - val_accuracy: 0.4969\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9008 - val_loss: 0.7201 - val_accuracy: 0.5051\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.8973 - val_loss: 0.6950 - val_accuracy: 0.5154\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9070 - val_loss: 0.7311 - val_accuracy: 0.5175\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9096 - val_loss: 1.0725 - val_accuracy: 0.5154\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1904 - accuracy: 0.9070 - val_loss: 0.7307 - val_accuracy: 0.5206\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1728 - accuracy: 0.9149 - val_loss: 0.6955 - val_accuracy: 0.4733\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9034 - val_loss: 0.7563 - val_accuracy: 0.4671\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.8942 - val_loss: 0.6950 - val_accuracy: 0.4835\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9065 - val_loss: 0.6938 - val_accuracy: 0.5144\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9056 - val_loss: 0.7295 - val_accuracy: 0.4784\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9109 - val_loss: 0.7048 - val_accuracy: 0.4856\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2090 - accuracy: 0.9004 - val_loss: 0.6943 - val_accuracy: 0.5103\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9189 - val_loss: 0.6980 - val_accuracy: 0.5041\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9180 - val_loss: 0.6997 - val_accuracy: 0.5082\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9184 - val_loss: 0.7143 - val_accuracy: 0.4784\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9039 - val_loss: 0.6929 - val_accuracy: 0.5134\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9162 - val_loss: 0.6929 - val_accuracy: 0.5216\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9131 - val_loss: 0.6933 - val_accuracy: 0.4979\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.9065 - val_loss: 0.6940 - val_accuracy: 0.4928\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2077 - accuracy: 0.9034 - val_loss: 0.6984 - val_accuracy: 0.4866\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2056 - accuracy: 0.9065 - val_loss: 0.6938 - val_accuracy: 0.5226\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9189 - val_loss: 0.6932 - val_accuracy: 0.5041\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9211 - val_loss: 0.6933 - val_accuracy: 0.4949\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9211 - val_loss: 0.6988 - val_accuracy: 0.5082\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9123 - val_loss: 0.6932 - val_accuracy: 0.5278\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.9123 - val_loss: 0.6975 - val_accuracy: 0.5216\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9149 - val_loss: 0.6951 - val_accuracy: 0.4969\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9149 - val_loss: 0.7506 - val_accuracy: 0.4846\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2105 - accuracy: 0.8929 - val_loss: 0.6978 - val_accuracy: 0.4907\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9136 - val_loss: 0.7142 - val_accuracy: 0.4815\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9109 - val_loss: 0.6937 - val_accuracy: 0.5154\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9175 - val_loss: 0.7194 - val_accuracy: 0.4887\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9034 - val_loss: 0.6918 - val_accuracy: 0.5340\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.9136 - val_loss: 0.6938 - val_accuracy: 0.5185\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9092 - val_loss: 0.7003 - val_accuracy: 0.5062\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2139 - accuracy: 0.9101 - val_loss: 0.6944 - val_accuracy: 0.4794\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2109 - accuracy: 0.9061 - val_loss: 0.6947 - val_accuracy: 0.4856\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2027 - accuracy: 0.9149 - val_loss: 0.6949 - val_accuracy: 0.4753\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2085 - accuracy: 0.9171 - val_loss: 0.7019 - val_accuracy: 0.4979\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9109 - val_loss: 0.7057 - val_accuracy: 0.4794\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2121 - accuracy: 0.9092 - val_loss: 0.6974 - val_accuracy: 0.5165\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9198 - val_loss: 0.6974 - val_accuracy: 0.4763\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.9021 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2081 - accuracy: 0.9123 - val_loss: 0.7056 - val_accuracy: 0.4784\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2093 - accuracy: 0.9105 - val_loss: 0.7002 - val_accuracy: 0.5195\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9158 - val_loss: 0.7060 - val_accuracy: 0.5062\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9162 - val_loss: 0.7105 - val_accuracy: 0.4691\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2047 - accuracy: 0.9136 - val_loss: 0.6922 - val_accuracy: 0.5226\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2202 - accuracy: 0.9092 - val_loss: 0.7078 - val_accuracy: 0.4856\n","Score: 0.4855967164039612 \n","Parameters:  {'learning_rate': 0.07586741961315685, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0467 - accuracy: 0.9083 - val_loss: 0.6852 - val_accuracy: 0.5370\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2190 - accuracy: 0.9105 - val_loss: 0.6729 - val_accuracy: 0.5175\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9127 - val_loss: 0.6913 - val_accuracy: 0.5123\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9127 - val_loss: 0.6886 - val_accuracy: 0.5021\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9087 - val_loss: 0.6402 - val_accuracy: 0.5720\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1746 - accuracy: 0.9158 - val_loss: 0.6081 - val_accuracy: 0.6564\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1818 - accuracy: 0.9070 - val_loss: 0.5972 - val_accuracy: 0.7027\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9101 - val_loss: 0.6296 - val_accuracy: 0.6183\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2261 - accuracy: 0.9127 - val_loss: 0.6174 - val_accuracy: 0.6667\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1789 - accuracy: 0.9101 - val_loss: 0.6033 - val_accuracy: 0.6677\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1793 - accuracy: 0.9136 - val_loss: 0.6109 - val_accuracy: 0.5947\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1774 - accuracy: 0.9167 - val_loss: 0.5842 - val_accuracy: 0.6667\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1604 - accuracy: 0.9250 - val_loss: 0.5884 - val_accuracy: 0.7037\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1730 - accuracy: 0.9202 - val_loss: 0.5698 - val_accuracy: 0.7191\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1643 - accuracy: 0.9330 - val_loss: 0.5927 - val_accuracy: 0.7222\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1735 - accuracy: 0.9246 - val_loss: 0.5580 - val_accuracy: 0.6955\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1623 - accuracy: 0.9308 - val_loss: 0.5378 - val_accuracy: 0.7150\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1694 - accuracy: 0.9193 - val_loss: 0.5279 - val_accuracy: 0.7181\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1611 - accuracy: 0.9330 - val_loss: 0.5129 - val_accuracy: 0.7366\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.9361 - val_loss: 0.4902 - val_accuracy: 0.7490\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1630 - accuracy: 0.9405 - val_loss: 0.5001 - val_accuracy: 0.7510\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1593 - accuracy: 0.9422 - val_loss: 0.4973 - val_accuracy: 0.7603\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3770 - accuracy: 0.9325 - val_loss: 0.5267 - val_accuracy: 0.7305\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1787 - accuracy: 0.9339 - val_loss: 0.5514 - val_accuracy: 0.7109\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1749 - accuracy: 0.9405 - val_loss: 0.4718 - val_accuracy: 0.7603\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1380 - accuracy: 0.9356 - val_loss: 0.4850 - val_accuracy: 0.7479\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.9414 - val_loss: 0.5062 - val_accuracy: 0.7459\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1480 - accuracy: 0.9436 - val_loss: 0.5024 - val_accuracy: 0.7449\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1463 - accuracy: 0.9489 - val_loss: 0.4438 - val_accuracy: 0.7984\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1555 - accuracy: 0.9369 - val_loss: 0.4440 - val_accuracy: 0.7973\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9502 - val_loss: 0.4536 - val_accuracy: 0.7870\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3991 - accuracy: 0.9325 - val_loss: 0.4704 - val_accuracy: 0.7788\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9449 - val_loss: 0.5016 - val_accuracy: 0.7798\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1380 - accuracy: 0.9414 - val_loss: 0.4363 - val_accuracy: 0.7912\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1398 - accuracy: 0.9458 - val_loss: 0.4089 - val_accuracy: 0.7953\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1209 - accuracy: 0.9550 - val_loss: 0.4268 - val_accuracy: 0.8148\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1177 - accuracy: 0.9541 - val_loss: 0.4247 - val_accuracy: 0.8076\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1437 - accuracy: 0.9444 - val_loss: 0.4252 - val_accuracy: 0.7942\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1295 - accuracy: 0.9506 - val_loss: 0.4072 - val_accuracy: 0.8025\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1464 - accuracy: 0.9387 - val_loss: 0.3941 - val_accuracy: 0.8241\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1204 - accuracy: 0.9546 - val_loss: 0.3959 - val_accuracy: 0.8261\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9480 - val_loss: 0.4215 - val_accuracy: 0.8045\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2515 - accuracy: 0.9374 - val_loss: 0.4102 - val_accuracy: 0.7973\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2368 - accuracy: 0.9246 - val_loss: 0.4873 - val_accuracy: 0.7881\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1503 - accuracy: 0.9449 - val_loss: 0.4306 - val_accuracy: 0.7922\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9533 - val_loss: 0.4253 - val_accuracy: 0.7942\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9471 - val_loss: 0.4482 - val_accuracy: 0.7922\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1290 - accuracy: 0.9537 - val_loss: 0.4148 - val_accuracy: 0.8138\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9431 - val_loss: 0.4025 - val_accuracy: 0.8107\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9511 - val_loss: 0.3969 - val_accuracy: 0.8138\n","Score: 0.8137860298156738 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 154.5129 - accuracy: 0.9078 - val_loss: 0.6928 - val_accuracy: 0.5154\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9145 - val_loss: 0.6928 - val_accuracy: 0.5165\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2105 - accuracy: 0.9127 - val_loss: 0.6948 - val_accuracy: 0.4609\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2334 - accuracy: 0.9052 - val_loss: 0.6956 - val_accuracy: 0.5247\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2422 - accuracy: 0.9175 - val_loss: 0.7118 - val_accuracy: 0.5082\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2601 - accuracy: 0.9140 - val_loss: 0.7190 - val_accuracy: 0.5144\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2846 - accuracy: 0.9171 - val_loss: 0.8316 - val_accuracy: 0.5103\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2843 - accuracy: 0.9145 - val_loss: 0.8278 - val_accuracy: 0.5134\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2826 - accuracy: 0.9171 - val_loss: 0.8712 - val_accuracy: 0.5062\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2818 - accuracy: 0.9162 - val_loss: 0.8366 - val_accuracy: 0.5175\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2904 - accuracy: 0.9114 - val_loss: 0.8100 - val_accuracy: 0.5206\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2864 - accuracy: 0.9136 - val_loss: 0.8290 - val_accuracy: 0.5113\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2816 - accuracy: 0.9189 - val_loss: 0.8346 - val_accuracy: 0.5298\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2812 - accuracy: 0.9162 - val_loss: 0.8322 - val_accuracy: 0.5226\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2854 - accuracy: 0.9153 - val_loss: 0.8589 - val_accuracy: 0.5072\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2915 - accuracy: 0.9109 - val_loss: 0.8215 - val_accuracy: 0.5144\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2819 - accuracy: 0.9180 - val_loss: 0.8526 - val_accuracy: 0.5175\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2849 - accuracy: 0.9153 - val_loss: 0.8571 - val_accuracy: 0.5051\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2806 - accuracy: 0.9175 - val_loss: 0.8444 - val_accuracy: 0.5247\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2882 - accuracy: 0.9123 - val_loss: 0.8131 - val_accuracy: 0.5257\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2972 - accuracy: 0.9092 - val_loss: 0.8349 - val_accuracy: 0.4969\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2954 - accuracy: 0.9114 - val_loss: 0.8387 - val_accuracy: 0.5093\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2902 - accuracy: 0.9149 - val_loss: 0.8845 - val_accuracy: 0.4918\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2799 - accuracy: 0.9189 - val_loss: 0.8610 - val_accuracy: 0.5267\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2772 - accuracy: 0.9189 - val_loss: 0.8707 - val_accuracy: 0.5185\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2874 - accuracy: 0.9114 - val_loss: 0.8298 - val_accuracy: 0.5031\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2931 - accuracy: 0.9114 - val_loss: 0.8005 - val_accuracy: 0.5278\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2869 - accuracy: 0.9149 - val_loss: 0.8337 - val_accuracy: 0.5154\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2848 - accuracy: 0.9158 - val_loss: 0.8307 - val_accuracy: 0.5216\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2857 - accuracy: 0.9145 - val_loss: 0.8369 - val_accuracy: 0.5103\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2876 - accuracy: 0.9140 - val_loss: 0.8361 - val_accuracy: 0.5154\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2874 - accuracy: 0.9140 - val_loss: 0.8612 - val_accuracy: 0.4938\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2884 - accuracy: 0.9136 - val_loss: 0.8301 - val_accuracy: 0.5154\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2768 - accuracy: 0.9215 - val_loss: 0.8671 - val_accuracy: 0.5216\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2738 - accuracy: 0.9202 - val_loss: 0.8590 - val_accuracy: 0.5093\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2654 - accuracy: 0.9259 - val_loss: 0.9136 - val_accuracy: 0.5134\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2707 - accuracy: 0.9184 - val_loss: 0.8599 - val_accuracy: 0.5041\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2838 - accuracy: 0.9149 - val_loss: 0.8197 - val_accuracy: 0.5206\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2864 - accuracy: 0.9136 - val_loss: 0.8359 - val_accuracy: 0.5072\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2827 - accuracy: 0.9175 - val_loss: 0.8553 - val_accuracy: 0.5082\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2843 - accuracy: 0.9149 - val_loss: 0.8327 - val_accuracy: 0.5226\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2842 - accuracy: 0.9158 - val_loss: 0.8422 - val_accuracy: 0.5154\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2919 - accuracy: 0.9101 - val_loss: 0.8189 - val_accuracy: 0.5093\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2935 - accuracy: 0.9118 - val_loss: 0.8296 - val_accuracy: 0.5103\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2998 - accuracy: 0.9056 - val_loss: 0.7904 - val_accuracy: 0.5144\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2850 - accuracy: 0.9193 - val_loss: 0.8827 - val_accuracy: 0.5031\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2912 - accuracy: 0.9096 - val_loss: 0.8105 - val_accuracy: 0.5154\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2879 - accuracy: 0.9158 - val_loss: 0.8324 - val_accuracy: 0.5226\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2887 - accuracy: 0.9127 - val_loss: 0.8551 - val_accuracy: 0.4990\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2887 - accuracy: 0.9140 - val_loss: 0.8495 - val_accuracy: 0.5021\n","Score: 0.5020576119422913 \n","Parameters:  {'learning_rate': 0.013181013751081046, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0468 - accuracy: 0.9074 - val_loss: 0.6504 - val_accuracy: 0.5329\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1759 - accuracy: 0.9237 - val_loss: 0.5750 - val_accuracy: 0.7109\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1726 - accuracy: 0.9330 - val_loss: 0.6242 - val_accuracy: 0.6605\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9242 - val_loss: 0.5870 - val_accuracy: 0.7202\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1798 - accuracy: 0.9233 - val_loss: 0.5519 - val_accuracy: 0.7140\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1489 - accuracy: 0.9418 - val_loss: 0.5082 - val_accuracy: 0.7160\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1775 - accuracy: 0.9242 - val_loss: 0.6171 - val_accuracy: 0.5689\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1756 - accuracy: 0.9114 - val_loss: 0.5963 - val_accuracy: 0.6914\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1751 - accuracy: 0.9180 - val_loss: 0.5718 - val_accuracy: 0.6800\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9242 - val_loss: 0.5745 - val_accuracy: 0.6965\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1012 - accuracy: 0.9250 - val_loss: 0.5504 - val_accuracy: 0.7016\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1716 - accuracy: 0.9414 - val_loss: 0.5622 - val_accuracy: 0.6790\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1694 - accuracy: 0.9268 - val_loss: 0.5414 - val_accuracy: 0.7243\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9330 - val_loss: 0.5200 - val_accuracy: 0.7346\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1715 - accuracy: 0.9409 - val_loss: 0.5158 - val_accuracy: 0.7582\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9378 - val_loss: 0.4914 - val_accuracy: 0.7479\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1554 - accuracy: 0.9392 - val_loss: 0.4592 - val_accuracy: 0.7593\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1393 - accuracy: 0.9427 - val_loss: 0.4711 - val_accuracy: 0.7891\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1397 - accuracy: 0.9466 - val_loss: 0.4491 - val_accuracy: 0.7922\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2402 - accuracy: 0.9409 - val_loss: 0.4346 - val_accuracy: 0.7984\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1340 - accuracy: 0.9497 - val_loss: 0.4581 - val_accuracy: 0.7860\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9409 - val_loss: 0.4543 - val_accuracy: 0.7881\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1275 - accuracy: 0.9502 - val_loss: 0.4502 - val_accuracy: 0.7840\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.9511 - val_loss: 0.4176 - val_accuracy: 0.7994\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1652 - accuracy: 0.9436 - val_loss: 0.4369 - val_accuracy: 0.8025\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1469 - accuracy: 0.9453 - val_loss: 0.5196 - val_accuracy: 0.7490\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9471 - val_loss: 0.4059 - val_accuracy: 0.8014\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1461 - accuracy: 0.9511 - val_loss: 0.3994 - val_accuracy: 0.8220\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9497 - val_loss: 0.4195 - val_accuracy: 0.7953\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1289 - accuracy: 0.9541 - val_loss: 0.4286 - val_accuracy: 0.8179\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.9515 - val_loss: 0.3812 - val_accuracy: 0.8138\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1714 - accuracy: 0.9396 - val_loss: 0.3978 - val_accuracy: 0.8025\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1239 - accuracy: 0.9555 - val_loss: 0.4065 - val_accuracy: 0.8179\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9519 - val_loss: 0.3870 - val_accuracy: 0.8189\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1530 - accuracy: 0.9489 - val_loss: 0.4228 - val_accuracy: 0.8107\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1528 - accuracy: 0.9506 - val_loss: 0.3937 - val_accuracy: 0.8241\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1133 - accuracy: 0.9546 - val_loss: 0.3610 - val_accuracy: 0.8200\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9528 - val_loss: 0.3795 - val_accuracy: 0.8302\n","Epoch 39/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.1211 - accuracy: 0.9537 - val_loss: 0.3671 - val_accuracy: 0.8333\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9493 - val_loss: 0.3895 - val_accuracy: 0.8261\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1090 - accuracy: 0.9528 - val_loss: 0.3860 - val_accuracy: 0.8220\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9563 - val_loss: 0.4098 - val_accuracy: 0.8128\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1340 - accuracy: 0.9568 - val_loss: 0.3495 - val_accuracy: 0.8333\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1118 - accuracy: 0.9581 - val_loss: 0.3308 - val_accuracy: 0.8580\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0983 - accuracy: 0.9625 - val_loss: 0.3326 - val_accuracy: 0.8477\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1196 - accuracy: 0.9590 - val_loss: 0.3760 - val_accuracy: 0.8282\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0973 - accuracy: 0.9656 - val_loss: 0.3032 - val_accuracy: 0.8724\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9660 - val_loss: 0.3009 - val_accuracy: 0.8591\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0888 - accuracy: 0.9621 - val_loss: 0.3236 - val_accuracy: 0.8488\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1106 - accuracy: 0.9577 - val_loss: 0.3196 - val_accuracy: 0.8621\n","Score: 0.8621399402618408 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 15382.2295 - accuracy: 0.8942 - val_loss: 0.7024 - val_accuracy: 0.4702\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1877 - accuracy: 0.9039 - val_loss: 0.7027 - val_accuracy: 0.5206\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1750 - accuracy: 0.9056 - val_loss: 0.7041 - val_accuracy: 0.4825\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.8955 - val_loss: 0.7127 - val_accuracy: 0.4835\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.8898 - val_loss: 0.6986 - val_accuracy: 0.5000\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9114 - val_loss: 0.7002 - val_accuracy: 0.5103\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2139 - accuracy: 0.9175 - val_loss: 0.6996 - val_accuracy: 0.5216\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2088 - accuracy: 0.9211 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2197 - accuracy: 0.9136 - val_loss: 0.6939 - val_accuracy: 0.5134\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9136 - val_loss: 0.6939 - val_accuracy: 0.4866\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2384 - accuracy: 0.8986 - val_loss: 0.6965 - val_accuracy: 0.4897\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2180 - accuracy: 0.9105 - val_loss: 0.6931 - val_accuracy: 0.5144\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2303 - accuracy: 0.9061 - val_loss: 0.6932 - val_accuracy: 0.4918\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2204 - accuracy: 0.9131 - val_loss: 0.7057 - val_accuracy: 0.5031\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2276 - accuracy: 0.8951 - val_loss: 0.6988 - val_accuracy: 0.4846\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.9162 - val_loss: 0.7060 - val_accuracy: 0.5123\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9202 - val_loss: 0.6970 - val_accuracy: 0.5082\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9184 - val_loss: 0.6929 - val_accuracy: 0.5103\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.9123 - val_loss: 0.6964 - val_accuracy: 0.5154\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2156 - accuracy: 0.9158 - val_loss: 0.6953 - val_accuracy: 0.4979\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2231 - accuracy: 0.9065 - val_loss: 0.6956 - val_accuracy: 0.4866\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2226 - accuracy: 0.9065 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2285 - accuracy: 0.9039 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2107 - accuracy: 0.9193 - val_loss: 0.7001 - val_accuracy: 0.5051\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9131 - val_loss: 0.6914 - val_accuracy: 0.5298\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2232 - accuracy: 0.9145 - val_loss: 0.6958 - val_accuracy: 0.5031\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2120 - accuracy: 0.9114 - val_loss: 0.6933 - val_accuracy: 0.4866\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9043 - val_loss: 0.6920 - val_accuracy: 0.5309\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2173 - accuracy: 0.9211 - val_loss: 0.7106 - val_accuracy: 0.5062\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2139 - accuracy: 0.9149 - val_loss: 0.6929 - val_accuracy: 0.5185\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2266 - accuracy: 0.9123 - val_loss: 0.6952 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2192 - accuracy: 0.9140 - val_loss: 0.6966 - val_accuracy: 0.4938\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2162 - accuracy: 0.9114 - val_loss: 0.6969 - val_accuracy: 0.5123\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.9145 - val_loss: 0.6987 - val_accuracy: 0.5093\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2185 - accuracy: 0.9136 - val_loss: 0.6954 - val_accuracy: 0.5000\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.9056 - val_loss: 0.6960 - val_accuracy: 0.4938\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2226 - accuracy: 0.9074 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2172 - accuracy: 0.9131 - val_loss: 0.6945 - val_accuracy: 0.4949\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2251 - accuracy: 0.9065 - val_loss: 0.6954 - val_accuracy: 0.4846\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2248 - accuracy: 0.9078 - val_loss: 0.6936 - val_accuracy: 0.5010\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2254 - accuracy: 0.9149 - val_loss: 0.7001 - val_accuracy: 0.5185\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2165 - accuracy: 0.9193 - val_loss: 0.6930 - val_accuracy: 0.5175\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2136 - accuracy: 0.9215 - val_loss: 0.6967 - val_accuracy: 0.5072\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2205 - accuracy: 0.9158 - val_loss: 0.6982 - val_accuracy: 0.5103\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2281 - accuracy: 0.9127 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2207 - accuracy: 0.9158 - val_loss: 0.6942 - val_accuracy: 0.5185\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2206 - accuracy: 0.9162 - val_loss: 0.6921 - val_accuracy: 0.5257\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2185 - accuracy: 0.9171 - val_loss: 0.6976 - val_accuracy: 0.5082\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2223 - accuracy: 0.9158 - val_loss: 0.7078 - val_accuracy: 0.5237\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2157 - accuracy: 0.9167 - val_loss: 0.6957 - val_accuracy: 0.5185\n","Score: 0.5185185074806213 \n","Parameters:  {'learning_rate': 0.05051336057585467, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1420.7449 - accuracy: 0.9065 - val_loss: 0.6933 - val_accuracy: 0.5062\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9180 - val_loss: 0.6958 - val_accuracy: 0.4969\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2568 - accuracy: 0.9061 - val_loss: 0.6952 - val_accuracy: 0.5340\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2622 - accuracy: 0.9065 - val_loss: 0.6940 - val_accuracy: 0.5175\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2577 - accuracy: 0.9145 - val_loss: 0.6970 - val_accuracy: 0.5144\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2605 - accuracy: 0.9096 - val_loss: 0.6930 - val_accuracy: 0.5206\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2688 - accuracy: 0.9109 - val_loss: 0.7146 - val_accuracy: 0.5051\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.9145 - val_loss: 0.7230 - val_accuracy: 0.5000\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2564 - accuracy: 0.9114 - val_loss: 0.6954 - val_accuracy: 0.5041\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2564 - accuracy: 0.9180 - val_loss: 0.7049 - val_accuracy: 0.5175\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2501 - accuracy: 0.9202 - val_loss: 0.7221 - val_accuracy: 0.5031\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2591 - accuracy: 0.9083 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2619 - accuracy: 0.9149 - val_loss: 0.7077 - val_accuracy: 0.5093\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.9277 - val_loss: 0.7266 - val_accuracy: 0.5113\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2541 - accuracy: 0.9140 - val_loss: 0.7066 - val_accuracy: 0.5082\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2557 - accuracy: 0.9083 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2557 - accuracy: 0.9220 - val_loss: 0.7140 - val_accuracy: 0.5123\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2561 - accuracy: 0.9096 - val_loss: 0.6935 - val_accuracy: 0.5103\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.9224 - val_loss: 0.7284 - val_accuracy: 0.5144\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2520 - accuracy: 0.9180 - val_loss: 0.7155 - val_accuracy: 0.5247\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2463 - accuracy: 0.9189 - val_loss: 0.7153 - val_accuracy: 0.4825\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2518 - accuracy: 0.9167 - val_loss: 0.7036 - val_accuracy: 0.5072\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2596 - accuracy: 0.9127 - val_loss: 0.7005 - val_accuracy: 0.5134\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2527 - accuracy: 0.9145 - val_loss: 0.6941 - val_accuracy: 0.5134\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2648 - accuracy: 0.9171 - val_loss: 0.7245 - val_accuracy: 0.5165\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2547 - accuracy: 0.9158 - val_loss: 0.7079 - val_accuracy: 0.5175\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2579 - accuracy: 0.9118 - val_loss: 0.6988 - val_accuracy: 0.5000\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2495 - accuracy: 0.9184 - val_loss: 0.6988 - val_accuracy: 0.5144\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2573 - accuracy: 0.9189 - val_loss: 0.7129 - val_accuracy: 0.5134\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2536 - accuracy: 0.9162 - val_loss: 0.7003 - val_accuracy: 0.5144\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2581 - accuracy: 0.9109 - val_loss: 0.6922 - val_accuracy: 0.5257\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2628 - accuracy: 0.9118 - val_loss: 0.6961 - val_accuracy: 0.5185\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.9167 - val_loss: 0.7014 - val_accuracy: 0.5237\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2524 - accuracy: 0.9162 - val_loss: 0.7015 - val_accuracy: 0.5165\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2622 - accuracy: 0.9114 - val_loss: 0.6971 - val_accuracy: 0.5103\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2624 - accuracy: 0.9149 - val_loss: 0.7056 - val_accuracy: 0.5051\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2552 - accuracy: 0.9109 - val_loss: 0.6930 - val_accuracy: 0.5185\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2573 - accuracy: 0.9189 - val_loss: 0.7067 - val_accuracy: 0.5103\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2510 - accuracy: 0.9153 - val_loss: 0.6931 - val_accuracy: 0.5175\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2578 - accuracy: 0.9193 - val_loss: 0.7167 - val_accuracy: 0.5206\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2521 - accuracy: 0.9167 - val_loss: 0.7057 - val_accuracy: 0.5154\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2550 - accuracy: 0.9162 - val_loss: 0.6974 - val_accuracy: 0.5247\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2526 - accuracy: 0.9149 - val_loss: 0.6924 - val_accuracy: 0.5298\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2578 - accuracy: 0.9175 - val_loss: 0.6954 - val_accuracy: 0.5206\n","Epoch 45/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2629 - accuracy: 0.9118 - val_loss: 0.6970 - val_accuracy: 0.5237\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2646 - accuracy: 0.9140 - val_loss: 0.7029 - val_accuracy: 0.5329\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2593 - accuracy: 0.9109 - val_loss: 0.6941 - val_accuracy: 0.5103\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2504 - accuracy: 0.9206 - val_loss: 0.6944 - val_accuracy: 0.5278\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2567 - accuracy: 0.9145 - val_loss: 0.6926 - val_accuracy: 0.5267\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2634 - accuracy: 0.9145 - val_loss: 0.7207 - val_accuracy: 0.5041\n","Score: 0.5041152238845825 \n","Parameters:  {'learning_rate': 0.026025789488152713, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1335.1301 - accuracy: 0.8907 - val_loss: 0.6998 - val_accuracy: 0.5165\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9167 - val_loss: 0.6924 - val_accuracy: 0.5309\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2276 - accuracy: 0.9198 - val_loss: 0.6992 - val_accuracy: 0.5051\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.9167 - val_loss: 0.6954 - val_accuracy: 0.5216\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2372 - accuracy: 0.9206 - val_loss: 0.7110 - val_accuracy: 0.5185\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2398 - accuracy: 0.9127 - val_loss: 0.7035 - val_accuracy: 0.4990\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2351 - accuracy: 0.9193 - val_loss: 0.7061 - val_accuracy: 0.5093\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9056 - val_loss: 0.6970 - val_accuracy: 0.5134\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2479 - accuracy: 0.9158 - val_loss: 0.7066 - val_accuracy: 0.5206\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2492 - accuracy: 0.9131 - val_loss: 0.6929 - val_accuracy: 0.5319\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2625 - accuracy: 0.9189 - val_loss: 0.7356 - val_accuracy: 0.5144\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2718 - accuracy: 0.9096 - val_loss: 0.7223 - val_accuracy: 0.5051\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2676 - accuracy: 0.9175 - val_loss: 0.7221 - val_accuracy: 0.5195\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2675 - accuracy: 0.9127 - val_loss: 0.7027 - val_accuracy: 0.5216\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2673 - accuracy: 0.9184 - val_loss: 0.7458 - val_accuracy: 0.5000\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2699 - accuracy: 0.9145 - val_loss: 0.7230 - val_accuracy: 0.5113\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2692 - accuracy: 0.9136 - val_loss: 0.7216 - val_accuracy: 0.5021\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2713 - accuracy: 0.9123 - val_loss: 0.7147 - val_accuracy: 0.5134\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2644 - accuracy: 0.9211 - val_loss: 0.7616 - val_accuracy: 0.5093\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2594 - accuracy: 0.9167 - val_loss: 0.7204 - val_accuracy: 0.5185\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2640 - accuracy: 0.9202 - val_loss: 0.7317 - val_accuracy: 0.5216\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2718 - accuracy: 0.9096 - val_loss: 0.7102 - val_accuracy: 0.5175\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2649 - accuracy: 0.9193 - val_loss: 0.7475 - val_accuracy: 0.5093\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2685 - accuracy: 0.9127 - val_loss: 0.7247 - val_accuracy: 0.5082\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2745 - accuracy: 0.9074 - val_loss: 0.7017 - val_accuracy: 0.5072\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2695 - accuracy: 0.9220 - val_loss: 0.7693 - val_accuracy: 0.5072\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2581 - accuracy: 0.9220 - val_loss: 0.7722 - val_accuracy: 0.5123\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2568 - accuracy: 0.9175 - val_loss: 0.7252 - val_accuracy: 0.5082\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2673 - accuracy: 0.9167 - val_loss: 0.7301 - val_accuracy: 0.5082\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2671 - accuracy: 0.9131 - val_loss: 0.7168 - val_accuracy: 0.5113\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2703 - accuracy: 0.9149 - val_loss: 0.7197 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2719 - accuracy: 0.9127 - val_loss: 0.7175 - val_accuracy: 0.5041\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2664 - accuracy: 0.9145 - val_loss: 0.7214 - val_accuracy: 0.4979\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2713 - accuracy: 0.9153 - val_loss: 0.7132 - val_accuracy: 0.5226\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2689 - accuracy: 0.9131 - val_loss: 0.7162 - val_accuracy: 0.5051\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2750 - accuracy: 0.9145 - val_loss: 0.7447 - val_accuracy: 0.5031\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2769 - accuracy: 0.9074 - val_loss: 0.7019 - val_accuracy: 0.5257\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2617 - accuracy: 0.9228 - val_loss: 0.7575 - val_accuracy: 0.5093\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2587 - accuracy: 0.9180 - val_loss: 0.7268 - val_accuracy: 0.5237\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2669 - accuracy: 0.9153 - val_loss: 0.7204 - val_accuracy: 0.5154\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2706 - accuracy: 0.9158 - val_loss: 0.7292 - val_accuracy: 0.5237\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2633 - accuracy: 0.9184 - val_loss: 0.7363 - val_accuracy: 0.5082\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2675 - accuracy: 0.9136 - val_loss: 0.7175 - val_accuracy: 0.5082\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2710 - accuracy: 0.9145 - val_loss: 0.7177 - val_accuracy: 0.5165\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2765 - accuracy: 0.9109 - val_loss: 0.7178 - val_accuracy: 0.5144\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2705 - accuracy: 0.9131 - val_loss: 0.7157 - val_accuracy: 0.5123\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2660 - accuracy: 0.9202 - val_loss: 0.7460 - val_accuracy: 0.5103\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2685 - accuracy: 0.9109 - val_loss: 0.7111 - val_accuracy: 0.5165\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2720 - accuracy: 0.9140 - val_loss: 0.7125 - val_accuracy: 0.5144\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2689 - accuracy: 0.9153 - val_loss: 0.7215 - val_accuracy: 0.5154\n","Score: 0.5154321193695068 \n","Parameters:  {'learning_rate': 0.021320127068987275, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.4722 - accuracy: 0.9356 - val_loss: 0.7183 - val_accuracy: 0.6461\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2444 - accuracy: 0.9361 - val_loss: 0.5812 - val_accuracy: 0.6914\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1695 - accuracy: 0.9308 - val_loss: 0.5033 - val_accuracy: 0.7531\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1977 - accuracy: 0.9356 - val_loss: 0.4798 - val_accuracy: 0.7623\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1762 - accuracy: 0.9453 - val_loss: 0.4636 - val_accuracy: 0.7716\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1702 - accuracy: 0.9422 - val_loss: 0.4599 - val_accuracy: 0.7860\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1520 - accuracy: 0.9365 - val_loss: 0.5467 - val_accuracy: 0.7191\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2003 - accuracy: 0.9480 - val_loss: 0.4533 - val_accuracy: 0.7932\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1813 - accuracy: 0.9378 - val_loss: 0.4433 - val_accuracy: 0.7963\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9414 - val_loss: 0.4658 - val_accuracy: 0.7870\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9497 - val_loss: 0.4459 - val_accuracy: 0.7860\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2333 - accuracy: 0.9356 - val_loss: 0.5060 - val_accuracy: 0.7222\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9524 - val_loss: 0.4082 - val_accuracy: 0.7984\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1269 - accuracy: 0.9453 - val_loss: 0.4534 - val_accuracy: 0.7860\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1155 - accuracy: 0.9511 - val_loss: 0.3422 - val_accuracy: 0.8447\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1234 - accuracy: 0.9577 - val_loss: 0.3797 - val_accuracy: 0.8128\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0936 - accuracy: 0.9634 - val_loss: 0.2986 - val_accuracy: 0.8673\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1866 - accuracy: 0.9466 - val_loss: 0.4658 - val_accuracy: 0.7695\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.9497 - val_loss: 0.4218 - val_accuracy: 0.8169\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1321 - accuracy: 0.9519 - val_loss: 0.3739 - val_accuracy: 0.8200\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1215 - accuracy: 0.9541 - val_loss: 0.8078 - val_accuracy: 0.7870\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1809 - accuracy: 0.9541 - val_loss: 0.4563 - val_accuracy: 0.7850\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1480 - accuracy: 0.9453 - val_loss: 0.4346 - val_accuracy: 0.7973\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1308 - accuracy: 0.9471 - val_loss: 0.4391 - val_accuracy: 0.7984\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1172 - accuracy: 0.9572 - val_loss: 0.4409 - val_accuracy: 0.8107\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1512 - accuracy: 0.9502 - val_loss: 0.3908 - val_accuracy: 0.8179\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9475 - val_loss: 0.4085 - val_accuracy: 0.7953\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1331 - accuracy: 0.9515 - val_loss: 0.4081 - val_accuracy: 0.8117\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1391 - accuracy: 0.9550 - val_loss: 0.3856 - val_accuracy: 0.8035\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1260 - accuracy: 0.9493 - val_loss: 0.3714 - val_accuracy: 0.8189\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1103 - accuracy: 0.9625 - val_loss: 0.3978 - val_accuracy: 0.8354\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1187 - accuracy: 0.9568 - val_loss: 0.3871 - val_accuracy: 0.8251\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9511 - val_loss: 0.3511 - val_accuracy: 0.8426\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1135 - accuracy: 0.9603 - val_loss: 0.3418 - val_accuracy: 0.8488\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1432 - accuracy: 0.9612 - val_loss: 0.3855 - val_accuracy: 0.8200\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1097 - accuracy: 0.9612 - val_loss: 0.3516 - val_accuracy: 0.8395\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1099 - accuracy: 0.9559 - val_loss: 0.3314 - val_accuracy: 0.8416\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1194 - accuracy: 0.9612 - val_loss: 0.3463 - val_accuracy: 0.8374\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1087 - accuracy: 0.9643 - val_loss: 0.3331 - val_accuracy: 0.8436\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1079 - accuracy: 0.9590 - val_loss: 0.3132 - val_accuracy: 0.8663\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1038 - accuracy: 0.9638 - val_loss: 0.3756 - val_accuracy: 0.8560\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1355 - accuracy: 0.9594 - val_loss: 0.3457 - val_accuracy: 0.8477\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1171 - accuracy: 0.9612 - val_loss: 0.3216 - val_accuracy: 0.8508\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1079 - accuracy: 0.9665 - val_loss: 0.3998 - val_accuracy: 0.8477\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0909 - accuracy: 0.9616 - val_loss: 0.2687 - val_accuracy: 0.8827\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1098 - accuracy: 0.9647 - val_loss: 0.3084 - val_accuracy: 0.8611\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0821 - accuracy: 0.9749 - val_loss: 0.2668 - val_accuracy: 0.8858\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0883 - accuracy: 0.9665 - val_loss: 0.2903 - val_accuracy: 0.8858\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0829 - accuracy: 0.9731 - val_loss: 0.2877 - val_accuracy: 0.8776\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0883 - accuracy: 0.9727 - val_loss: 0.2902 - val_accuracy: 0.8858\n","Score: 0.8858024477958679 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.6710 - accuracy: 0.9162 - val_loss: 0.5853 - val_accuracy: 0.7294\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1642 - accuracy: 0.9299 - val_loss: 0.5890 - val_accuracy: 0.7531\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2396 - accuracy: 0.9405 - val_loss: 0.4837 - val_accuracy: 0.7325\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1688 - accuracy: 0.9427 - val_loss: 0.7759 - val_accuracy: 0.5947\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1526 - accuracy: 0.9392 - val_loss: 0.4956 - val_accuracy: 0.7469\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3412 - accuracy: 0.9378 - val_loss: 0.4687 - val_accuracy: 0.7706\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1807 - accuracy: 0.9440 - val_loss: 0.4423 - val_accuracy: 0.7798\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1585 - accuracy: 0.9497 - val_loss: 0.4822 - val_accuracy: 0.7757\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9422 - val_loss: 0.4361 - val_accuracy: 0.7850\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1206 - accuracy: 0.9458 - val_loss: 0.4195 - val_accuracy: 0.7994\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1349 - accuracy: 0.9453 - val_loss: 0.5149 - val_accuracy: 0.7685\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1598 - accuracy: 0.9422 - val_loss: 0.4169 - val_accuracy: 0.8076\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1411 - accuracy: 0.9586 - val_loss: 0.4242 - val_accuracy: 0.7942\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1374 - accuracy: 0.9497 - val_loss: 0.4336 - val_accuracy: 0.7870\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1835 - accuracy: 0.9528 - val_loss: 0.4213 - val_accuracy: 0.8045\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1391 - accuracy: 0.9484 - val_loss: 0.4435 - val_accuracy: 0.7634\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2322 - accuracy: 0.9519 - val_loss: 0.4319 - val_accuracy: 0.7850\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1544 - accuracy: 0.9497 - val_loss: 0.4055 - val_accuracy: 0.8128\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1206 - accuracy: 0.9541 - val_loss: 0.4068 - val_accuracy: 0.8097\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1332 - accuracy: 0.9502 - val_loss: 0.4324 - val_accuracy: 0.8169\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1557 - accuracy: 0.9502 - val_loss: 0.4107 - val_accuracy: 0.8066\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1261 - accuracy: 0.9506 - val_loss: 0.4072 - val_accuracy: 0.7901\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1620 - accuracy: 0.9511 - val_loss: 0.4227 - val_accuracy: 0.8004\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1737 - accuracy: 0.9436 - val_loss: 0.3977 - val_accuracy: 0.8169\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1610 - accuracy: 0.9497 - val_loss: 0.4084 - val_accuracy: 0.8045\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1219 - accuracy: 0.9577 - val_loss: 0.4184 - val_accuracy: 0.8169\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1359 - accuracy: 0.9489 - val_loss: 0.4028 - val_accuracy: 0.8066\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1408 - accuracy: 0.9515 - val_loss: 0.4144 - val_accuracy: 0.8107\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1237 - accuracy: 0.9475 - val_loss: 0.4469 - val_accuracy: 0.8025\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9515 - val_loss: 0.4120 - val_accuracy: 0.8107\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2028 - accuracy: 0.9506 - val_loss: 0.4092 - val_accuracy: 0.8169\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1165 - accuracy: 0.9528 - val_loss: 0.4042 - val_accuracy: 0.8004\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1351 - accuracy: 0.9528 - val_loss: 0.4541 - val_accuracy: 0.7932\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1494 - accuracy: 0.9533 - val_loss: 0.3810 - val_accuracy: 0.8282\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9489 - val_loss: 0.5173 - val_accuracy: 0.7798\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9466 - val_loss: 0.3892 - val_accuracy: 0.8097\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1129 - accuracy: 0.9625 - val_loss: 0.3836 - val_accuracy: 0.8436\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1234 - accuracy: 0.9515 - val_loss: 0.4029 - val_accuracy: 0.8158\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1216 - accuracy: 0.9546 - val_loss: 0.3666 - val_accuracy: 0.8374\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1080 - accuracy: 0.9541 - val_loss: 0.3846 - val_accuracy: 0.8241\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1385 - accuracy: 0.9581 - val_loss: 0.3531 - val_accuracy: 0.8333\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1048 - accuracy: 0.9559 - val_loss: 0.3497 - val_accuracy: 0.8519\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1410 - accuracy: 0.9502 - val_loss: 0.3766 - val_accuracy: 0.8323\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1776 - accuracy: 0.9621 - val_loss: 0.3531 - val_accuracy: 0.8405\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1168 - accuracy: 0.9581 - val_loss: 0.3741 - val_accuracy: 0.8261\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.9506 - val_loss: 0.3449 - val_accuracy: 0.8374\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1018 - accuracy: 0.9638 - val_loss: 0.3653 - val_accuracy: 0.8169\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9581 - val_loss: 0.3883 - val_accuracy: 0.8230\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1263 - accuracy: 0.9537 - val_loss: 0.3479 - val_accuracy: 0.8426\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0979 - accuracy: 0.9638 - val_loss: 0.3457 - val_accuracy: 0.8395\n","Score: 0.8395061492919922 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9889 - accuracy: 0.9193 - val_loss: 0.6167 - val_accuracy: 0.6965\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2744 - accuracy: 0.9242 - val_loss: 0.6187 - val_accuracy: 0.6728\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1655 - accuracy: 0.9246 - val_loss: 0.6216 - val_accuracy: 0.6749\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.9312 - val_loss: 0.5266 - val_accuracy: 0.7510\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1622 - accuracy: 0.9303 - val_loss: 0.5858 - val_accuracy: 0.6934\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1467 - accuracy: 0.9458 - val_loss: 0.4566 - val_accuracy: 0.7767\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1490 - accuracy: 0.9462 - val_loss: 0.4756 - val_accuracy: 0.7675\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1900 - accuracy: 0.9361 - val_loss: 0.4928 - val_accuracy: 0.7644\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1594 - accuracy: 0.9339 - val_loss: 0.5208 - val_accuracy: 0.7675\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1342 - accuracy: 0.9493 - val_loss: 0.4272 - val_accuracy: 0.7819\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1309 - accuracy: 0.9453 - val_loss: 0.4698 - val_accuracy: 0.7747\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1464 - accuracy: 0.9497 - val_loss: 0.4158 - val_accuracy: 0.8004\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9361 - val_loss: 0.4471 - val_accuracy: 0.7932\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1604 - accuracy: 0.9347 - val_loss: 0.4937 - val_accuracy: 0.7675\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9458 - val_loss: 0.4401 - val_accuracy: 0.7778\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1521 - accuracy: 0.9484 - val_loss: 0.4177 - val_accuracy: 0.8210\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9506 - val_loss: 0.4355 - val_accuracy: 0.8045\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1437 - accuracy: 0.9466 - val_loss: 0.3922 - val_accuracy: 0.8128\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1212 - accuracy: 0.9524 - val_loss: 0.4090 - val_accuracy: 0.7870\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1357 - accuracy: 0.9475 - val_loss: 0.3976 - val_accuracy: 0.8138\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9524 - val_loss: 0.4200 - val_accuracy: 0.8004\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2759 - accuracy: 0.9484 - val_loss: 0.3819 - val_accuracy: 0.8189\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1323 - accuracy: 0.9484 - val_loss: 0.4124 - val_accuracy: 0.8086\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1349 - accuracy: 0.9519 - val_loss: 0.4365 - val_accuracy: 0.8086\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.2963 - accuracy: 0.9458 - val_loss: 0.3986 - val_accuracy: 0.8200\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3253 - accuracy: 0.9502 - val_loss: 0.4179 - val_accuracy: 0.8076\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1227 - accuracy: 0.9559 - val_loss: 0.3634 - val_accuracy: 0.8251\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3347 - accuracy: 0.9550 - val_loss: 0.3657 - val_accuracy: 0.8272\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1483 - accuracy: 0.9475 - val_loss: 0.4157 - val_accuracy: 0.8457\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1154 - accuracy: 0.9581 - val_loss: 0.3071 - val_accuracy: 0.8539\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1076 - accuracy: 0.9616 - val_loss: 0.3817 - val_accuracy: 0.8354\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.9581 - val_loss: 0.3035 - val_accuracy: 0.8601\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1988 - accuracy: 0.9559 - val_loss: 0.3563 - val_accuracy: 0.8333\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1156 - accuracy: 0.9577 - val_loss: 0.3653 - val_accuracy: 0.8313\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1244 - accuracy: 0.9559 - val_loss: 0.4047 - val_accuracy: 0.8230\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1631 - accuracy: 0.9396 - val_loss: 0.3791 - val_accuracy: 0.8138\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9594 - val_loss: 0.3165 - val_accuracy: 0.8457\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0961 - accuracy: 0.9603 - val_loss: 0.3349 - val_accuracy: 0.8580\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1134 - accuracy: 0.9577 - val_loss: 0.3900 - val_accuracy: 0.8241\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9634 - val_loss: 0.3097 - val_accuracy: 0.8580\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0884 - accuracy: 0.9634 - val_loss: 0.3286 - val_accuracy: 0.8570\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0880 - accuracy: 0.9660 - val_loss: 0.2947 - val_accuracy: 0.8621\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0891 - accuracy: 0.9608 - val_loss: 0.2979 - val_accuracy: 0.8724\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9594 - val_loss: 0.2778 - val_accuracy: 0.8693\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.2604 - val_accuracy: 0.8765\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0812 - accuracy: 0.9691 - val_loss: 0.2221 - val_accuracy: 0.8909\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0736 - accuracy: 0.9731 - val_loss: 0.2522 - val_accuracy: 0.8899\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0852 - accuracy: 0.9652 - val_loss: 0.3002 - val_accuracy: 0.8580\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0838 - accuracy: 0.9683 - val_loss: 0.2414 - val_accuracy: 0.8971\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9652 - val_loss: 0.2824 - val_accuracy: 0.8745\n","Score: 0.8744856119155884 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 1.0151 - accuracy: 0.9127 - val_loss: 0.5886 - val_accuracy: 0.6955\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3401 - accuracy: 0.9277 - val_loss: 0.5426 - val_accuracy: 0.7253\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9321 - val_loss: 0.5845 - val_accuracy: 0.7109\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2273 - accuracy: 0.9193 - val_loss: 0.5559 - val_accuracy: 0.7305\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1537 - accuracy: 0.9277 - val_loss: 0.5454 - val_accuracy: 0.7356\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1762 - accuracy: 0.9264 - val_loss: 0.5574 - val_accuracy: 0.7171\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1617 - accuracy: 0.9228 - val_loss: 0.5306 - val_accuracy: 0.7315\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1749 - accuracy: 0.9325 - val_loss: 0.5142 - val_accuracy: 0.7418\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1455 - accuracy: 0.9422 - val_loss: 0.5400 - val_accuracy: 0.7418\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1685 - accuracy: 0.9396 - val_loss: 0.4870 - val_accuracy: 0.7644\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1546 - accuracy: 0.9374 - val_loss: 0.4882 - val_accuracy: 0.7675\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9497 - val_loss: 0.4700 - val_accuracy: 0.7438\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1813 - accuracy: 0.9458 - val_loss: 0.4347 - val_accuracy: 0.7778\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2212 - accuracy: 0.9374 - val_loss: 0.6256 - val_accuracy: 0.6276\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1453 - accuracy: 0.9489 - val_loss: 0.4697 - val_accuracy: 0.7757\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1370 - accuracy: 0.9519 - val_loss: 0.4957 - val_accuracy: 0.7644\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9444 - val_loss: 0.4242 - val_accuracy: 0.7994\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9453 - val_loss: 0.4762 - val_accuracy: 0.7665\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1343 - accuracy: 0.9422 - val_loss: 0.4148 - val_accuracy: 0.8117\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1340 - accuracy: 0.9422 - val_loss: 0.4562 - val_accuracy: 0.7829\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1801 - accuracy: 0.9374 - val_loss: 0.4204 - val_accuracy: 0.8035\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1287 - accuracy: 0.9537 - val_loss: 0.3822 - val_accuracy: 0.8333\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3363 - accuracy: 0.9502 - val_loss: 0.3781 - val_accuracy: 0.8169\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1299 - accuracy: 0.9524 - val_loss: 0.4618 - val_accuracy: 0.7881\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1388 - accuracy: 0.9497 - val_loss: 0.4861 - val_accuracy: 0.7562\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3211 - accuracy: 0.9378 - val_loss: 0.4059 - val_accuracy: 0.7860\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1184 - accuracy: 0.9528 - val_loss: 0.3819 - val_accuracy: 0.8426\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1389 - accuracy: 0.9519 - val_loss: 0.4436 - val_accuracy: 0.7829\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1265 - accuracy: 0.9546 - val_loss: 0.3648 - val_accuracy: 0.8241\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.9537 - val_loss: 0.5269 - val_accuracy: 0.7891\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9519 - val_loss: 0.3669 - val_accuracy: 0.8272\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1317 - accuracy: 0.9572 - val_loss: 0.3591 - val_accuracy: 0.8354\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.9559 - val_loss: 0.4928 - val_accuracy: 0.7726\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0945 - accuracy: 0.9660 - val_loss: 0.3787 - val_accuracy: 0.8272\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1094 - accuracy: 0.9537 - val_loss: 0.3146 - val_accuracy: 0.8488\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1217 - accuracy: 0.9586 - val_loss: 0.2797 - val_accuracy: 0.8714\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9665 - val_loss: 0.2892 - val_accuracy: 0.8642\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1058 - accuracy: 0.9687 - val_loss: 0.3120 - val_accuracy: 0.8632\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0940 - accuracy: 0.9612 - val_loss: 0.3526 - val_accuracy: 0.8467\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1066 - accuracy: 0.9647 - val_loss: 0.2717 - val_accuracy: 0.8858\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1070 - accuracy: 0.9608 - val_loss: 0.3046 - val_accuracy: 0.8837\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1558 - accuracy: 0.9563 - val_loss: 0.2679 - val_accuracy: 0.8765\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0912 - accuracy: 0.9674 - val_loss: 0.2297 - val_accuracy: 0.8981\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0696 - accuracy: 0.9735 - val_loss: 0.3828 - val_accuracy: 0.8621\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0817 - accuracy: 0.9718 - val_loss: 0.2411 - val_accuracy: 0.8909\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2627 - accuracy: 0.9612 - val_loss: 0.3133 - val_accuracy: 0.8591\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0957 - accuracy: 0.9652 - val_loss: 0.3308 - val_accuracy: 0.8776\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1169 - accuracy: 0.9590 - val_loss: 0.3099 - val_accuracy: 0.8632\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1067 - accuracy: 0.9660 - val_loss: 0.3496 - val_accuracy: 0.8745\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0837 - accuracy: 0.9691 - val_loss: 0.2508 - val_accuracy: 0.8920\n","Score: 0.8919752836227417 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 1972.8690 - accuracy: 0.9083 - val_loss: 0.6935 - val_accuracy: 0.4938\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1916 - accuracy: 0.9012 - val_loss: 0.6918 - val_accuracy: 0.5298\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9140 - val_loss: 0.6987 - val_accuracy: 0.5278\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1850 - accuracy: 0.9136 - val_loss: 0.6960 - val_accuracy: 0.4784\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2558 - accuracy: 0.9074 - val_loss: 0.7098 - val_accuracy: 0.5072\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2512 - accuracy: 0.9131 - val_loss: 0.6921 - val_accuracy: 0.5298\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9198 - val_loss: 0.7033 - val_accuracy: 0.5082\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2523 - accuracy: 0.9171 - val_loss: 0.7015 - val_accuracy: 0.4979\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2397 - accuracy: 0.9211 - val_loss: 0.6968 - val_accuracy: 0.5113\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2533 - accuracy: 0.9167 - val_loss: 0.6960 - val_accuracy: 0.5195\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2503 - accuracy: 0.9153 - val_loss: 0.6937 - val_accuracy: 0.5154\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2624 - accuracy: 0.9136 - val_loss: 0.7062 - val_accuracy: 0.5123\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2558 - accuracy: 0.9087 - val_loss: 0.6926 - val_accuracy: 0.5206\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2588 - accuracy: 0.9184 - val_loss: 0.7137 - val_accuracy: 0.5195\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2526 - accuracy: 0.9145 - val_loss: 0.7025 - val_accuracy: 0.5123\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2539 - accuracy: 0.9140 - val_loss: 0.6939 - val_accuracy: 0.5134\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2638 - accuracy: 0.9105 - val_loss: 0.6934 - val_accuracy: 0.5257\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2569 - accuracy: 0.9127 - val_loss: 0.6950 - val_accuracy: 0.5154\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2575 - accuracy: 0.9167 - val_loss: 0.7045 - val_accuracy: 0.5113\n","Epoch 20/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2556 - accuracy: 0.9175 - val_loss: 0.7111 - val_accuracy: 0.5031\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2541 - accuracy: 0.9131 - val_loss: 0.6957 - val_accuracy: 0.5154\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2582 - accuracy: 0.9123 - val_loss: 0.6940 - val_accuracy: 0.5185\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2620 - accuracy: 0.9158 - val_loss: 0.7094 - val_accuracy: 0.5144\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2524 - accuracy: 0.9180 - val_loss: 0.7049 - val_accuracy: 0.5185\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2524 - accuracy: 0.9136 - val_loss: 0.6935 - val_accuracy: 0.5267\n","Epoch 26/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2536 - accuracy: 0.9189 - val_loss: 0.7032 - val_accuracy: 0.5247\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2472 - accuracy: 0.9237 - val_loss: 0.7298 - val_accuracy: 0.5072\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2488 - accuracy: 0.9131 - val_loss: 0.6924 - val_accuracy: 0.5206\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2551 - accuracy: 0.9140 - val_loss: 0.6967 - val_accuracy: 0.5103\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2515 - accuracy: 0.9202 - val_loss: 0.7155 - val_accuracy: 0.5021\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2503 - accuracy: 0.9118 - val_loss: 0.6940 - val_accuracy: 0.4794\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2590 - accuracy: 0.9083 - val_loss: 0.7139 - val_accuracy: 0.5226\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2500 - accuracy: 0.9162 - val_loss: 0.6932 - val_accuracy: 0.5278\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2641 - accuracy: 0.9145 - val_loss: 0.7192 - val_accuracy: 0.4990\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2584 - accuracy: 0.9114 - val_loss: 0.7006 - val_accuracy: 0.5123\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2566 - accuracy: 0.9167 - val_loss: 0.7028 - val_accuracy: 0.5319\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2421 - accuracy: 0.9228 - val_loss: 0.7040 - val_accuracy: 0.5267\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2575 - accuracy: 0.9092 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2637 - accuracy: 0.9101 - val_loss: 0.7035 - val_accuracy: 0.4990\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2498 - accuracy: 0.9193 - val_loss: 0.7015 - val_accuracy: 0.5195\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2587 - accuracy: 0.9123 - val_loss: 0.6936 - val_accuracy: 0.5288\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2504 - accuracy: 0.9198 - val_loss: 0.7049 - val_accuracy: 0.5134\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2493 - accuracy: 0.9184 - val_loss: 0.7085 - val_accuracy: 0.5123\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2537 - accuracy: 0.9123 - val_loss: 0.6980 - val_accuracy: 0.5103\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9158 - val_loss: 0.7093 - val_accuracy: 0.5051\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2529 - accuracy: 0.9158 - val_loss: 0.7044 - val_accuracy: 0.5000\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2552 - accuracy: 0.9149 - val_loss: 0.7026 - val_accuracy: 0.5041\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2534 - accuracy: 0.9158 - val_loss: 0.6975 - val_accuracy: 0.5144\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2524 - accuracy: 0.9131 - val_loss: 0.6954 - val_accuracy: 0.5031\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2603 - accuracy: 0.9145 - val_loss: 0.6935 - val_accuracy: 0.5309\n","Score: 0.5308641791343689 \n","Parameters:  {'learning_rate': 0.02704746326379556, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 2177195.0000 - accuracy: 0.9087 - val_loss: 0.7092 - val_accuracy: 0.4691\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.8977 - val_loss: 0.7260 - val_accuracy: 0.5144\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9074 - val_loss: 0.6985 - val_accuracy: 0.4990\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9092 - val_loss: 0.6930 - val_accuracy: 0.5082\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9123 - val_loss: 0.6919 - val_accuracy: 0.5247\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.9153 - val_loss: 0.7382 - val_accuracy: 0.5195\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1831 - accuracy: 0.9153 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9096 - val_loss: 0.6937 - val_accuracy: 0.5195\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9087 - val_loss: 0.6932 - val_accuracy: 0.4774\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9004 - val_loss: 0.7129 - val_accuracy: 0.4784\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1929 - accuracy: 0.9052 - val_loss: 0.6934 - val_accuracy: 0.5021\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1893 - accuracy: 0.9118 - val_loss: 0.7237 - val_accuracy: 0.4722\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.8964 - val_loss: 0.7319 - val_accuracy: 0.5041\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9048 - val_loss: 0.6964 - val_accuracy: 0.5185\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9140 - val_loss: 0.6964 - val_accuracy: 0.5226\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9131 - val_loss: 0.6953 - val_accuracy: 0.5257\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1852 - accuracy: 0.9105 - val_loss: 0.6958 - val_accuracy: 0.4990\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1848 - accuracy: 0.9092 - val_loss: 0.7001 - val_accuracy: 0.5288\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1832 - accuracy: 0.9215 - val_loss: 0.7320 - val_accuracy: 0.4835\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.8902 - val_loss: 0.7045 - val_accuracy: 0.5144\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9083 - val_loss: 0.7249 - val_accuracy: 0.4897\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.8946 - val_loss: 0.6934 - val_accuracy: 0.5185\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9030 - val_loss: 0.7027 - val_accuracy: 0.5113\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9105 - val_loss: 0.7117 - val_accuracy: 0.4712\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9070 - val_loss: 0.7039 - val_accuracy: 0.5072\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1915 - accuracy: 0.9114 - val_loss: 0.6928 - val_accuracy: 0.5175\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9074 - val_loss: 0.7000 - val_accuracy: 0.4877\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9030 - val_loss: 0.7231 - val_accuracy: 0.5195\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9101 - val_loss: 0.6927 - val_accuracy: 0.5206\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1871 - accuracy: 0.9136 - val_loss: 0.7424 - val_accuracy: 0.4815\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9114 - val_loss: 0.6998 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9087 - val_loss: 0.6939 - val_accuracy: 0.5123\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9004 - val_loss: 0.7131 - val_accuracy: 0.5062\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1915 - accuracy: 0.9127 - val_loss: 0.7014 - val_accuracy: 0.5257\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2003 - accuracy: 0.9056 - val_loss: 0.7120 - val_accuracy: 0.4681\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9056 - val_loss: 0.6995 - val_accuracy: 0.5226\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9078 - val_loss: 0.7074 - val_accuracy: 0.5226\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.9118 - val_loss: 0.6991 - val_accuracy: 0.5041\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9083 - val_loss: 0.7307 - val_accuracy: 0.5309\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1766 - accuracy: 0.9224 - val_loss: 0.7167 - val_accuracy: 0.4877\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9056 - val_loss: 0.6928 - val_accuracy: 0.5165\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1802 - accuracy: 0.9206 - val_loss: 0.6960 - val_accuracy: 0.4815\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9105 - val_loss: 0.7103 - val_accuracy: 0.5134\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1809 - accuracy: 0.9149 - val_loss: 0.7173 - val_accuracy: 0.5257\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9052 - val_loss: 0.7281 - val_accuracy: 0.5432\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9065 - val_loss: 0.7111 - val_accuracy: 0.5175\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9145 - val_loss: 0.6983 - val_accuracy: 0.5134\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1973 - accuracy: 0.9083 - val_loss: 0.7372 - val_accuracy: 0.4784\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1952 - accuracy: 0.9109 - val_loss: 0.7607 - val_accuracy: 0.4949\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9136 - val_loss: 0.7421 - val_accuracy: 0.4815\n","Score: 0.48148149251937866 \n","Parameters:  {'learning_rate': 0.16951570786826164, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 40000.9766 - accuracy: 0.9021 - val_loss: 0.6932 - val_accuracy: 0.5134\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2130 - accuracy: 0.9004 - val_loss: 0.6958 - val_accuracy: 0.4856\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9127 - val_loss: 0.7438 - val_accuracy: 0.5206\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9043 - val_loss: 0.7009 - val_accuracy: 0.5051\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9056 - val_loss: 0.7187 - val_accuracy: 0.5257\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1877 - accuracy: 0.9096 - val_loss: 0.7287 - val_accuracy: 0.5062\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1911 - accuracy: 0.9065 - val_loss: 0.7024 - val_accuracy: 0.4897\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1959 - accuracy: 0.9114 - val_loss: 0.7020 - val_accuracy: 0.5010\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2005 - accuracy: 0.9180 - val_loss: 0.7028 - val_accuracy: 0.5206\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2142 - accuracy: 0.9131 - val_loss: 0.6949 - val_accuracy: 0.5113\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2147 - accuracy: 0.9171 - val_loss: 0.6924 - val_accuracy: 0.5329\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2113 - accuracy: 0.9193 - val_loss: 0.6955 - val_accuracy: 0.4969\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2191 - accuracy: 0.9083 - val_loss: 0.6931 - val_accuracy: 0.5154\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2168 - accuracy: 0.9189 - val_loss: 0.6934 - val_accuracy: 0.5154\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9206 - val_loss: 0.7227 - val_accuracy: 0.5051\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2107 - accuracy: 0.9145 - val_loss: 0.6966 - val_accuracy: 0.5144\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2184 - accuracy: 0.9123 - val_loss: 0.6932 - val_accuracy: 0.4835\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2221 - accuracy: 0.8990 - val_loss: 0.6955 - val_accuracy: 0.5021\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2196 - accuracy: 0.9048 - val_loss: 0.6939 - val_accuracy: 0.4835\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2181 - accuracy: 0.9145 - val_loss: 0.6988 - val_accuracy: 0.5021\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2190 - accuracy: 0.9118 - val_loss: 0.6950 - val_accuracy: 0.5093\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2191 - accuracy: 0.9171 - val_loss: 0.6949 - val_accuracy: 0.5062\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9056 - val_loss: 0.6922 - val_accuracy: 0.5247\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2157 - accuracy: 0.9114 - val_loss: 0.6988 - val_accuracy: 0.5031\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2215 - accuracy: 0.9105 - val_loss: 0.6953 - val_accuracy: 0.4856\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2113 - accuracy: 0.9078 - val_loss: 0.7063 - val_accuracy: 0.4815\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2196 - accuracy: 0.9034 - val_loss: 0.6963 - val_accuracy: 0.4805\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.9078 - val_loss: 0.7002 - val_accuracy: 0.4774\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.9070 - val_loss: 0.7004 - val_accuracy: 0.5185\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9145 - val_loss: 0.6978 - val_accuracy: 0.5072\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2157 - accuracy: 0.9167 - val_loss: 0.7031 - val_accuracy: 0.5144\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2148 - accuracy: 0.9123 - val_loss: 0.7007 - val_accuracy: 0.4979\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2046 - accuracy: 0.9233 - val_loss: 0.6967 - val_accuracy: 0.5082\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2147 - accuracy: 0.9149 - val_loss: 0.7070 - val_accuracy: 0.4825\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2280 - accuracy: 0.8977 - val_loss: 0.6927 - val_accuracy: 0.5175\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2246 - accuracy: 0.9131 - val_loss: 0.6963 - val_accuracy: 0.5165\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9118 - val_loss: 0.6976 - val_accuracy: 0.5041\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2146 - accuracy: 0.9030 - val_loss: 0.7121 - val_accuracy: 0.5237\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2121 - accuracy: 0.9105 - val_loss: 0.6936 - val_accuracy: 0.4825\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2181 - accuracy: 0.9114 - val_loss: 0.6938 - val_accuracy: 0.4979\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2252 - accuracy: 0.9101 - val_loss: 0.6933 - val_accuracy: 0.5093\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2128 - accuracy: 0.9087 - val_loss: 0.6943 - val_accuracy: 0.4763\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2138 - accuracy: 0.9131 - val_loss: 0.6930 - val_accuracy: 0.5175\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2115 - accuracy: 0.9149 - val_loss: 0.7047 - val_accuracy: 0.4866\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9096 - val_loss: 0.7213 - val_accuracy: 0.4897\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2323 - accuracy: 0.8946 - val_loss: 0.6967 - val_accuracy: 0.4825\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.9021 - val_loss: 0.6911 - val_accuracy: 0.5381\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2110 - accuracy: 0.9224 - val_loss: 0.6986 - val_accuracy: 0.5247\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2063 - accuracy: 0.9171 - val_loss: 0.6932 - val_accuracy: 0.5072\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2130 - accuracy: 0.9092 - val_loss: 0.6951 - val_accuracy: 0.4990\n","Score: 0.49897119402885437 \n","Parameters:  {'learning_rate': 0.057993723690159614, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 19985.3320 - accuracy: 0.8999 - val_loss: 0.7270 - val_accuracy: 0.5319\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1761 - accuracy: 0.9175 - val_loss: 0.6994 - val_accuracy: 0.5123\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2145 - accuracy: 0.9105 - val_loss: 0.6963 - val_accuracy: 0.4763\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2158 - accuracy: 0.9048 - val_loss: 0.6960 - val_accuracy: 0.4815\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2116 - accuracy: 0.9070 - val_loss: 0.6980 - val_accuracy: 0.5093\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2108 - accuracy: 0.9153 - val_loss: 0.6965 - val_accuracy: 0.5051\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2172 - accuracy: 0.9061 - val_loss: 0.6945 - val_accuracy: 0.5041\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.9096 - val_loss: 0.6933 - val_accuracy: 0.5000\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2125 - accuracy: 0.9083 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9175 - val_loss: 0.7095 - val_accuracy: 0.4691\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2106 - accuracy: 0.9087 - val_loss: 0.6971 - val_accuracy: 0.5031\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2187 - accuracy: 0.9092 - val_loss: 0.7312 - val_accuracy: 0.4835\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2264 - accuracy: 0.8977 - val_loss: 0.6962 - val_accuracy: 0.4825\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2172 - accuracy: 0.9096 - val_loss: 0.6938 - val_accuracy: 0.5062\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9175 - val_loss: 0.7008 - val_accuracy: 0.5082\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2079 - accuracy: 0.9096 - val_loss: 0.6931 - val_accuracy: 0.5031\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2079 - accuracy: 0.9101 - val_loss: 0.6936 - val_accuracy: 0.4866\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9109 - val_loss: 0.6959 - val_accuracy: 0.5000\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2164 - accuracy: 0.9074 - val_loss: 0.7005 - val_accuracy: 0.5093\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9167 - val_loss: 0.6911 - val_accuracy: 0.5319\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2153 - accuracy: 0.9087 - val_loss: 0.7231 - val_accuracy: 0.4763\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2129 - accuracy: 0.9017 - val_loss: 0.6987 - val_accuracy: 0.4918\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2081 - accuracy: 0.9101 - val_loss: 0.7123 - val_accuracy: 0.5134\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9193 - val_loss: 0.7047 - val_accuracy: 0.5103\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2020 - accuracy: 0.9092 - val_loss: 0.6939 - val_accuracy: 0.5185\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2111 - accuracy: 0.9101 - val_loss: 0.6934 - val_accuracy: 0.4969\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2109 - accuracy: 0.9123 - val_loss: 0.6949 - val_accuracy: 0.5185\n","Epoch 28/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2059 - accuracy: 0.9158 - val_loss: 0.7045 - val_accuracy: 0.4856\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2184 - accuracy: 0.8981 - val_loss: 0.6936 - val_accuracy: 0.5154\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2092 - accuracy: 0.9136 - val_loss: 0.6942 - val_accuracy: 0.5062\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2062 - accuracy: 0.9189 - val_loss: 0.7010 - val_accuracy: 0.5175\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2084 - accuracy: 0.9140 - val_loss: 0.6938 - val_accuracy: 0.4815\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2113 - accuracy: 0.9056 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2043 - accuracy: 0.9202 - val_loss: 0.7059 - val_accuracy: 0.5267\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9127 - val_loss: 0.6971 - val_accuracy: 0.5206\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2123 - accuracy: 0.9109 - val_loss: 0.6932 - val_accuracy: 0.5093\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2139 - accuracy: 0.9180 - val_loss: 0.7124 - val_accuracy: 0.5021\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9153 - val_loss: 0.6963 - val_accuracy: 0.4928\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2033 - accuracy: 0.9021 - val_loss: 0.6917 - val_accuracy: 0.5267\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2170 - accuracy: 0.9043 - val_loss: 0.6947 - val_accuracy: 0.4835\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2132 - accuracy: 0.9087 - val_loss: 0.6928 - val_accuracy: 0.5123\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.9189 - val_loss: 0.6937 - val_accuracy: 0.4969\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2062 - accuracy: 0.9136 - val_loss: 0.7375 - val_accuracy: 0.5113\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.9136 - val_loss: 0.6956 - val_accuracy: 0.5010\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2088 - accuracy: 0.9123 - val_loss: 0.7048 - val_accuracy: 0.5010\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2169 - accuracy: 0.8915 - val_loss: 0.6918 - val_accuracy: 0.5267\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2040 - accuracy: 0.9074 - val_loss: 0.6949 - val_accuracy: 0.5175\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2063 - accuracy: 0.9171 - val_loss: 0.6929 - val_accuracy: 0.5134\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2169 - accuracy: 0.9109 - val_loss: 0.6976 - val_accuracy: 0.5041\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2103 - accuracy: 0.9158 - val_loss: 0.6982 - val_accuracy: 0.4856\n","Score: 0.4855967164039612 \n","Parameters:  {'learning_rate': 0.06876542797638535, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6118 - accuracy: 0.9202 - val_loss: 0.6005 - val_accuracy: 0.6996\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1806 - accuracy: 0.9167 - val_loss: 0.5875 - val_accuracy: 0.7335\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1675 - accuracy: 0.9392 - val_loss: 0.5678 - val_accuracy: 0.6944\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1763 - accuracy: 0.9378 - val_loss: 0.5447 - val_accuracy: 0.7356\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1488 - accuracy: 0.9356 - val_loss: 0.5331 - val_accuracy: 0.7459\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9277 - val_loss: 0.5373 - val_accuracy: 0.7335\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3520 - accuracy: 0.9264 - val_loss: 0.5564 - val_accuracy: 0.7130\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1655 - accuracy: 0.9299 - val_loss: 0.4973 - val_accuracy: 0.7850\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1687 - accuracy: 0.9347 - val_loss: 0.5065 - val_accuracy: 0.7798\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1979 - accuracy: 0.9092 - val_loss: 0.6247 - val_accuracy: 0.6924\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1559 - accuracy: 0.9286 - val_loss: 0.5383 - val_accuracy: 0.7675\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1867 - accuracy: 0.9321 - val_loss: 0.5172 - val_accuracy: 0.7541\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2605 - accuracy: 0.9312 - val_loss: 0.5429 - val_accuracy: 0.7531\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1768 - accuracy: 0.9374 - val_loss: 0.5385 - val_accuracy: 0.7346\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1770 - accuracy: 0.9396 - val_loss: 0.4926 - val_accuracy: 0.7675\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1613 - accuracy: 0.9400 - val_loss: 0.4618 - val_accuracy: 0.7963\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1637 - accuracy: 0.9405 - val_loss: 0.5276 - val_accuracy: 0.7366\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1423 - accuracy: 0.9480 - val_loss: 0.4704 - val_accuracy: 0.7901\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1479 - accuracy: 0.9453 - val_loss: 0.5136 - val_accuracy: 0.7428\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1631 - accuracy: 0.9444 - val_loss: 0.4604 - val_accuracy: 0.7716\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1921 - accuracy: 0.9431 - val_loss: 0.4264 - val_accuracy: 0.7942\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1497 - accuracy: 0.9449 - val_loss: 0.5504 - val_accuracy: 0.7274\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9524 - val_loss: 0.4556 - val_accuracy: 0.7973\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1393 - accuracy: 0.9466 - val_loss: 0.4272 - val_accuracy: 0.7860\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1474 - accuracy: 0.9493 - val_loss: 0.4324 - val_accuracy: 0.7809\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.9489 - val_loss: 0.4416 - val_accuracy: 0.7953\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4164 - accuracy: 0.9418 - val_loss: 0.4161 - val_accuracy: 0.8086\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1210 - accuracy: 0.9550 - val_loss: 0.4870 - val_accuracy: 0.7891\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1235 - accuracy: 0.9515 - val_loss: 0.4131 - val_accuracy: 0.8117\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9431 - val_loss: 0.3956 - val_accuracy: 0.8251\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1290 - accuracy: 0.9511 - val_loss: 0.4414 - val_accuracy: 0.8004\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1680 - accuracy: 0.9480 - val_loss: 0.4250 - val_accuracy: 0.8014\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1452 - accuracy: 0.9427 - val_loss: 0.4545 - val_accuracy: 0.7757\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1200 - accuracy: 0.9572 - val_loss: 0.4445 - val_accuracy: 0.7891\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1854 - accuracy: 0.9506 - val_loss: 0.4061 - val_accuracy: 0.8056\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1733 - accuracy: 0.9546 - val_loss: 0.4297 - val_accuracy: 0.7953\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1301 - accuracy: 0.9533 - val_loss: 0.3963 - val_accuracy: 0.8179\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1319 - accuracy: 0.9506 - val_loss: 0.4052 - val_accuracy: 0.8045\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.9515 - val_loss: 0.4047 - val_accuracy: 0.8189\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1461 - accuracy: 0.9453 - val_loss: 0.4162 - val_accuracy: 0.7912\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1154 - accuracy: 0.9559 - val_loss: 0.4068 - val_accuracy: 0.8066\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1154 - accuracy: 0.9541 - val_loss: 0.3820 - val_accuracy: 0.8302\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1157 - accuracy: 0.9577 - val_loss: 0.3936 - val_accuracy: 0.8189\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1320 - accuracy: 0.9475 - val_loss: 0.3712 - val_accuracy: 0.8200\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1096 - accuracy: 0.9559 - val_loss: 0.3926 - val_accuracy: 0.8241\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1133 - accuracy: 0.9524 - val_loss: 0.3929 - val_accuracy: 0.8251\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1437 - accuracy: 0.9493 - val_loss: 0.3751 - val_accuracy: 0.8272\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1057 - accuracy: 0.9590 - val_loss: 0.3628 - val_accuracy: 0.8272\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1107 - accuracy: 0.9537 - val_loss: 0.3700 - val_accuracy: 0.8374\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9599 - val_loss: 0.3494 - val_accuracy: 0.8436\n","Score: 0.8436213731765747 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7454 - accuracy: 0.9193 - val_loss: 0.6841 - val_accuracy: 0.5257\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2398 - accuracy: 0.9295 - val_loss: 0.6129 - val_accuracy: 0.6749\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3701 - accuracy: 0.9308 - val_loss: 0.6191 - val_accuracy: 0.6523\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1699 - accuracy: 0.9242 - val_loss: 0.7029 - val_accuracy: 0.6440\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1647 - accuracy: 0.9312 - val_loss: 0.5180 - val_accuracy: 0.7335\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1543 - accuracy: 0.9286 - val_loss: 0.5034 - val_accuracy: 0.7263\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9334 - val_loss: 0.6451 - val_accuracy: 0.6677\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9436 - val_loss: 0.5352 - val_accuracy: 0.7027\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1472 - accuracy: 0.9462 - val_loss: 0.4976 - val_accuracy: 0.7346\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9409 - val_loss: 0.5138 - val_accuracy: 0.7346\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1697 - accuracy: 0.9422 - val_loss: 0.4578 - val_accuracy: 0.7963\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9387 - val_loss: 0.5578 - val_accuracy: 0.6903\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1450 - accuracy: 0.9374 - val_loss: 0.4659 - val_accuracy: 0.7562\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1516 - accuracy: 0.9374 - val_loss: 0.5145 - val_accuracy: 0.7356\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6285 - accuracy: 0.9303 - val_loss: 0.5091 - val_accuracy: 0.7644\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9462 - val_loss: 0.4819 - val_accuracy: 0.7726\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9414 - val_loss: 0.4382 - val_accuracy: 0.8004\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1390 - accuracy: 0.9493 - val_loss: 0.4459 - val_accuracy: 0.7788\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1512 - accuracy: 0.9418 - val_loss: 0.4641 - val_accuracy: 0.7788\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2233 - accuracy: 0.9462 - val_loss: 0.4323 - val_accuracy: 0.8004\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1248 - accuracy: 0.9502 - val_loss: 0.4671 - val_accuracy: 0.7942\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1351 - accuracy: 0.9519 - val_loss: 0.4662 - val_accuracy: 0.7778\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4741 - accuracy: 0.9444 - val_loss: 0.4461 - val_accuracy: 0.7778\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1448 - accuracy: 0.9453 - val_loss: 0.4302 - val_accuracy: 0.7881\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2213 - accuracy: 0.9414 - val_loss: 0.3978 - val_accuracy: 0.8128\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1564 - accuracy: 0.9383 - val_loss: 0.4277 - val_accuracy: 0.7953\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1347 - accuracy: 0.9511 - val_loss: 0.4090 - val_accuracy: 0.8097\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1248 - accuracy: 0.9603 - val_loss: 0.3781 - val_accuracy: 0.8138\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1297 - accuracy: 0.9537 - val_loss: 0.3985 - val_accuracy: 0.8200\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1304 - accuracy: 0.9511 - val_loss: 0.4151 - val_accuracy: 0.7932\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1024 - accuracy: 0.9572 - val_loss: 0.4223 - val_accuracy: 0.8035\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1391 - accuracy: 0.9511 - val_loss: 0.3758 - val_accuracy: 0.8261\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1169 - accuracy: 0.9581 - val_loss: 0.3894 - val_accuracy: 0.8117\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9475 - val_loss: 0.3337 - val_accuracy: 0.8405\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1217 - accuracy: 0.9546 - val_loss: 0.3638 - val_accuracy: 0.8416\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0995 - accuracy: 0.9608 - val_loss: 0.3191 - val_accuracy: 0.8549\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1073 - accuracy: 0.9643 - val_loss: 0.3275 - val_accuracy: 0.8570\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0930 - accuracy: 0.9665 - val_loss: 0.3263 - val_accuracy: 0.8405\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0824 - accuracy: 0.9669 - val_loss: 0.3284 - val_accuracy: 0.8488\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2239 - accuracy: 0.9471 - val_loss: 0.4033 - val_accuracy: 0.8148\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1085 - accuracy: 0.9603 - val_loss: 0.3816 - val_accuracy: 0.8230\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1100 - accuracy: 0.9612 - val_loss: 0.3542 - val_accuracy: 0.8354\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1061 - accuracy: 0.9683 - val_loss: 0.3770 - val_accuracy: 0.8251\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9511 - val_loss: 0.4006 - val_accuracy: 0.8128\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9519 - val_loss: 0.4181 - val_accuracy: 0.8272\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9616 - val_loss: 0.3343 - val_accuracy: 0.8467\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1091 - accuracy: 0.9537 - val_loss: 0.3587 - val_accuracy: 0.8210\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1250 - accuracy: 0.9713 - val_loss: 0.3423 - val_accuracy: 0.8467\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0923 - accuracy: 0.9660 - val_loss: 0.3700 - val_accuracy: 0.8374\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1099 - accuracy: 0.9594 - val_loss: 0.3208 - val_accuracy: 0.8529\n","Score: 0.8528806567192078 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.9597 - accuracy: 0.9123 - val_loss: 0.6567 - val_accuracy: 0.6718\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1753 - accuracy: 0.9264 - val_loss: 0.6266 - val_accuracy: 0.7058\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.9383 - val_loss: 0.6354 - val_accuracy: 0.7027\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1794 - accuracy: 0.9246 - val_loss: 0.6120 - val_accuracy: 0.6831\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1689 - accuracy: 0.9325 - val_loss: 0.5803 - val_accuracy: 0.7150\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1877 - accuracy: 0.9312 - val_loss: 0.5761 - val_accuracy: 0.6975\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3385 - accuracy: 0.9334 - val_loss: 0.5738 - val_accuracy: 0.7058\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9233 - val_loss: 0.5865 - val_accuracy: 0.7099\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1766 - accuracy: 0.9325 - val_loss: 0.5683 - val_accuracy: 0.7222\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2622 - accuracy: 0.9361 - val_loss: 0.5500 - val_accuracy: 0.7284\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3786 - accuracy: 0.9409 - val_loss: 0.5620 - val_accuracy: 0.7088\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2518 - accuracy: 0.9361 - val_loss: 0.5818 - val_accuracy: 0.7078\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1678 - accuracy: 0.9436 - val_loss: 0.5451 - val_accuracy: 0.7315\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1741 - accuracy: 0.9352 - val_loss: 0.5323 - val_accuracy: 0.7397\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2289 - accuracy: 0.9383 - val_loss: 0.5066 - val_accuracy: 0.7685\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3856 - accuracy: 0.9378 - val_loss: 0.5043 - val_accuracy: 0.7551\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1663 - accuracy: 0.9414 - val_loss: 0.5483 - val_accuracy: 0.7088\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1619 - accuracy: 0.9400 - val_loss: 0.5099 - val_accuracy: 0.7377\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1501 - accuracy: 0.9444 - val_loss: 0.4685 - val_accuracy: 0.7788\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1429 - accuracy: 0.9471 - val_loss: 0.4521 - val_accuracy: 0.7706\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9489 - val_loss: 0.5094 - val_accuracy: 0.7685\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.9528 - val_loss: 0.4701 - val_accuracy: 0.7994\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1509 - accuracy: 0.9427 - val_loss: 0.4704 - val_accuracy: 0.7737\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9409 - val_loss: 0.4512 - val_accuracy: 0.7809\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1601 - accuracy: 0.9436 - val_loss: 0.4691 - val_accuracy: 0.7726\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1405 - accuracy: 0.9422 - val_loss: 0.4635 - val_accuracy: 0.7840\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9541 - val_loss: 0.4571 - val_accuracy: 0.7901\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1398 - accuracy: 0.9409 - val_loss: 0.4364 - val_accuracy: 0.7994\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1287 - accuracy: 0.9458 - val_loss: 0.4381 - val_accuracy: 0.8014\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1635 - accuracy: 0.9444 - val_loss: 0.4326 - val_accuracy: 0.8035\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9471 - val_loss: 0.4668 - val_accuracy: 0.7870\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1919 - accuracy: 0.9422 - val_loss: 0.4395 - val_accuracy: 0.7963\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1563 - accuracy: 0.9471 - val_loss: 0.4241 - val_accuracy: 0.8251\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1744 - accuracy: 0.9387 - val_loss: 0.4564 - val_accuracy: 0.7922\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9533 - val_loss: 0.4397 - val_accuracy: 0.8025\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1365 - accuracy: 0.9506 - val_loss: 0.3783 - val_accuracy: 0.8282\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1229 - accuracy: 0.9541 - val_loss: 0.4268 - val_accuracy: 0.8158\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1326 - accuracy: 0.9577 - val_loss: 0.4201 - val_accuracy: 0.7953\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9489 - val_loss: 0.3811 - val_accuracy: 0.8230\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1477 - accuracy: 0.9453 - val_loss: 0.3885 - val_accuracy: 0.8272\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9511 - val_loss: 0.4013 - val_accuracy: 0.8241\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9594 - val_loss: 0.4513 - val_accuracy: 0.8313\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1143 - accuracy: 0.9581 - val_loss: 0.4161 - val_accuracy: 0.8189\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1693 - accuracy: 0.9568 - val_loss: 0.4249 - val_accuracy: 0.8107\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1551 - accuracy: 0.9528 - val_loss: 0.3628 - val_accuracy: 0.8282\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9559 - val_loss: 0.3298 - val_accuracy: 0.8436\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1069 - accuracy: 0.9599 - val_loss: 0.3300 - val_accuracy: 0.8364\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1031 - accuracy: 0.9630 - val_loss: 0.3262 - val_accuracy: 0.8467\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0971 - accuracy: 0.9634 - val_loss: 0.3469 - val_accuracy: 0.8580\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1077 - accuracy: 0.9656 - val_loss: 0.2899 - val_accuracy: 0.8755\n","Score: 0.8755143880844116 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 131804.2031 - accuracy: 0.8929 - val_loss: 3.7118 - val_accuracy: 0.5031\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5892 - accuracy: 0.9052 - val_loss: 1.3255 - val_accuracy: 0.4815\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3554 - accuracy: 0.8849 - val_loss: 0.7257 - val_accuracy: 0.4887\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2447 - accuracy: 0.8981 - val_loss: 0.7526 - val_accuracy: 0.5309\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9114 - val_loss: 0.7365 - val_accuracy: 0.5113\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2634 - accuracy: 0.9039 - val_loss: 0.8317 - val_accuracy: 0.5267\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2631 - accuracy: 0.8884 - val_loss: 0.7389 - val_accuracy: 0.5226\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2222 - accuracy: 0.9078 - val_loss: 0.9120 - val_accuracy: 0.5072\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2258 - accuracy: 0.8898 - val_loss: 0.7155 - val_accuracy: 0.4949\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9078 - val_loss: 0.7907 - val_accuracy: 0.4846\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2363 - accuracy: 0.8876 - val_loss: 0.7859 - val_accuracy: 0.5165\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.9026 - val_loss: 0.7258 - val_accuracy: 0.5082\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2181 - accuracy: 0.9012 - val_loss: 0.8908 - val_accuracy: 0.4794\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2086 - accuracy: 0.9052 - val_loss: 0.6975 - val_accuracy: 0.4979\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1873 - accuracy: 0.9131 - val_loss: 0.6948 - val_accuracy: 0.4887\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9118 - val_loss: 0.6975 - val_accuracy: 0.4712\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2052 - accuracy: 0.9105 - val_loss: 0.6965 - val_accuracy: 0.5175\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9114 - val_loss: 0.6931 - val_accuracy: 0.5195\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9189 - val_loss: 0.6946 - val_accuracy: 0.5123\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9118 - val_loss: 0.7176 - val_accuracy: 0.4794\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9109 - val_loss: 0.6915 - val_accuracy: 0.5309\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9145 - val_loss: 0.6944 - val_accuracy: 0.4846\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9074 - val_loss: 0.6969 - val_accuracy: 0.4794\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9092 - val_loss: 0.7068 - val_accuracy: 0.5113\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9158 - val_loss: 0.7014 - val_accuracy: 0.4825\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9096 - val_loss: 0.6932 - val_accuracy: 0.4928\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2132 - accuracy: 0.9043 - val_loss: 0.6987 - val_accuracy: 0.5021\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9167 - val_loss: 0.6941 - val_accuracy: 0.4856\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9136 - val_loss: 0.7061 - val_accuracy: 0.4794\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2072 - accuracy: 0.9043 - val_loss: 0.6935 - val_accuracy: 0.5031\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.9052 - val_loss: 0.6984 - val_accuracy: 0.4938\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9123 - val_loss: 0.7033 - val_accuracy: 0.5226\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9162 - val_loss: 0.7046 - val_accuracy: 0.5072\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9158 - val_loss: 0.6939 - val_accuracy: 0.4887\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2081 - accuracy: 0.9039 - val_loss: 0.6929 - val_accuracy: 0.5144\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9096 - val_loss: 0.6941 - val_accuracy: 0.5031\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2010 - accuracy: 0.9101 - val_loss: 0.7199 - val_accuracy: 0.4835\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2132 - accuracy: 0.8973 - val_loss: 0.7242 - val_accuracy: 0.4743\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9096 - val_loss: 0.6940 - val_accuracy: 0.5123\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9149 - val_loss: 0.7093 - val_accuracy: 0.4877\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9087 - val_loss: 0.7204 - val_accuracy: 0.4969\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9021 - val_loss: 0.7044 - val_accuracy: 0.5082\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9109 - val_loss: 0.7239 - val_accuracy: 0.4897\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.8986 - val_loss: 0.7043 - val_accuracy: 0.5206\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2135 - accuracy: 0.9118 - val_loss: 0.6969 - val_accuracy: 0.5082\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9167 - val_loss: 0.7342 - val_accuracy: 0.5123\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2009 - accuracy: 0.9109 - val_loss: 0.7056 - val_accuracy: 0.5247\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1885 - accuracy: 0.9237 - val_loss: 0.7152 - val_accuracy: 0.5278\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9087 - val_loss: 0.7329 - val_accuracy: 0.4897\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2020 - accuracy: 0.9030 - val_loss: 0.7021 - val_accuracy: 0.4897\n","Score: 0.4897119402885437 \n","Parameters:  {'learning_rate': 0.0960382016226025, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8226 - accuracy: 0.9175 - val_loss: 0.6157 - val_accuracy: 0.6780\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9206 - val_loss: 0.5820 - val_accuracy: 0.7160\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.9378 - val_loss: 0.5325 - val_accuracy: 0.7377\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1797 - accuracy: 0.9356 - val_loss: 0.5036 - val_accuracy: 0.7469\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9365 - val_loss: 0.5108 - val_accuracy: 0.7418\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2276 - accuracy: 0.9378 - val_loss: 0.4727 - val_accuracy: 0.7582\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1485 - accuracy: 0.9409 - val_loss: 0.5123 - val_accuracy: 0.7541\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2547 - accuracy: 0.9418 - val_loss: 0.4609 - val_accuracy: 0.7881\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1514 - accuracy: 0.9414 - val_loss: 0.5632 - val_accuracy: 0.6831\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.9466 - val_loss: 0.4370 - val_accuracy: 0.7942\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.9502 - val_loss: 0.4027 - val_accuracy: 0.8025\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9524 - val_loss: 0.4445 - val_accuracy: 0.7870\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1304 - accuracy: 0.9462 - val_loss: 0.4526 - val_accuracy: 0.7757\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1267 - accuracy: 0.9471 - val_loss: 0.4135 - val_accuracy: 0.7963\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1413 - accuracy: 0.9511 - val_loss: 0.4111 - val_accuracy: 0.7963\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1325 - accuracy: 0.9506 - val_loss: 0.4068 - val_accuracy: 0.8066\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9453 - val_loss: 0.3712 - val_accuracy: 0.8272\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1067 - accuracy: 0.9590 - val_loss: 0.3635 - val_accuracy: 0.8364\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1455 - accuracy: 0.9475 - val_loss: 0.4397 - val_accuracy: 0.7850\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1198 - accuracy: 0.9515 - val_loss: 0.4038 - val_accuracy: 0.7963\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1325 - accuracy: 0.9506 - val_loss: 0.3914 - val_accuracy: 0.8076\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9515 - val_loss: 0.3663 - val_accuracy: 0.8313\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1225 - accuracy: 0.9515 - val_loss: 0.3779 - val_accuracy: 0.8282\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1165 - accuracy: 0.9524 - val_loss: 0.3717 - val_accuracy: 0.8344\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1611 - accuracy: 0.9462 - val_loss: 0.3827 - val_accuracy: 0.8282\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9577 - val_loss: 0.3725 - val_accuracy: 0.8313\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9506 - val_loss: 0.3699 - val_accuracy: 0.8189\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1109 - accuracy: 0.9581 - val_loss: 0.3869 - val_accuracy: 0.8014\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1283 - accuracy: 0.9502 - val_loss: 0.3530 - val_accuracy: 0.8220\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1114 - accuracy: 0.9568 - val_loss: 0.3462 - val_accuracy: 0.8354\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9524 - val_loss: 0.4077 - val_accuracy: 0.8086\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9608 - val_loss: 0.3351 - val_accuracy: 0.8519\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1061 - accuracy: 0.9572 - val_loss: 0.4285 - val_accuracy: 0.8272\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.9568 - val_loss: 0.3292 - val_accuracy: 0.8436\n","Epoch 35/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1014 - accuracy: 0.9669 - val_loss: 0.3747 - val_accuracy: 0.8374\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1076 - accuracy: 0.9590 - val_loss: 0.3260 - val_accuracy: 0.8549\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1497 - accuracy: 0.9625 - val_loss: 0.3246 - val_accuracy: 0.8477\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1523 - accuracy: 0.9599 - val_loss: 0.3128 - val_accuracy: 0.8652\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0879 - accuracy: 0.9674 - val_loss: 0.3403 - val_accuracy: 0.8632\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1362 - accuracy: 0.9497 - val_loss: 0.3141 - val_accuracy: 0.8560\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1085 - accuracy: 0.9608 - val_loss: 0.3159 - val_accuracy: 0.8693\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1107 - accuracy: 0.9586 - val_loss: 0.3490 - val_accuracy: 0.8591\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1017 - accuracy: 0.9586 - val_loss: 0.3625 - val_accuracy: 0.8426\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1130 - accuracy: 0.9594 - val_loss: 0.3570 - val_accuracy: 0.8426\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1102 - accuracy: 0.9581 - val_loss: 0.3236 - val_accuracy: 0.8621\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1072 - accuracy: 0.9665 - val_loss: 0.3409 - val_accuracy: 0.8549\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1076 - accuracy: 0.9643 - val_loss: 0.3309 - val_accuracy: 0.8683\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0991 - accuracy: 0.9687 - val_loss: 0.2856 - val_accuracy: 0.8765\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0924 - accuracy: 0.9665 - val_loss: 0.2839 - val_accuracy: 0.8776\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1007 - accuracy: 0.9638 - val_loss: 0.3068 - val_accuracy: 0.8591\n","Score: 0.8590534925460815 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.4680 - accuracy: 0.9070 - val_loss: 0.6610 - val_accuracy: 0.5545\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1855 - accuracy: 0.9215 - val_loss: 0.6424 - val_accuracy: 0.6420\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1729 - accuracy: 0.9171 - val_loss: 0.6221 - val_accuracy: 0.6121\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1719 - accuracy: 0.9206 - val_loss: 0.5978 - val_accuracy: 0.6996\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1711 - accuracy: 0.9237 - val_loss: 0.5845 - val_accuracy: 0.7016\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2381 - accuracy: 0.9259 - val_loss: 0.5432 - val_accuracy: 0.7263\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1815 - accuracy: 0.9290 - val_loss: 0.5137 - val_accuracy: 0.7541\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9352 - val_loss: 0.5157 - val_accuracy: 0.7407\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9449 - val_loss: 0.5538 - val_accuracy: 0.7253\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.5064 - accuracy: 0.9228 - val_loss: 0.5579 - val_accuracy: 0.6852\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9339 - val_loss: 0.5143 - val_accuracy: 0.7346\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9422 - val_loss: 0.5199 - val_accuracy: 0.7274\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1732 - accuracy: 0.9339 - val_loss: 0.4773 - val_accuracy: 0.7490\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1805 - accuracy: 0.9396 - val_loss: 0.4904 - val_accuracy: 0.7593\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3162 - accuracy: 0.9458 - val_loss: 0.4682 - val_accuracy: 0.7767\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1648 - accuracy: 0.9440 - val_loss: 0.4846 - val_accuracy: 0.7809\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1549 - accuracy: 0.9502 - val_loss: 0.5936 - val_accuracy: 0.7737\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2445 - accuracy: 0.9462 - val_loss: 0.4739 - val_accuracy: 0.7531\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1432 - accuracy: 0.9449 - val_loss: 0.4725 - val_accuracy: 0.7716\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1432 - accuracy: 0.9444 - val_loss: 0.5775 - val_accuracy: 0.7623\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1457 - accuracy: 0.9436 - val_loss: 0.4905 - val_accuracy: 0.7706\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1769 - accuracy: 0.9431 - val_loss: 0.4350 - val_accuracy: 0.7953\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1412 - accuracy: 0.9471 - val_loss: 0.4602 - val_accuracy: 0.7860\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1632 - accuracy: 0.9453 - val_loss: 0.4417 - val_accuracy: 0.7994\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9502 - val_loss: 0.4254 - val_accuracy: 0.7912\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1605 - accuracy: 0.9422 - val_loss: 0.5435 - val_accuracy: 0.7305\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1577 - accuracy: 0.9453 - val_loss: 0.4559 - val_accuracy: 0.7850\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1456 - accuracy: 0.9436 - val_loss: 0.4263 - val_accuracy: 0.7953\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1539 - accuracy: 0.9506 - val_loss: 0.4408 - val_accuracy: 0.7840\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1476 - accuracy: 0.9493 - val_loss: 0.4468 - val_accuracy: 0.7860\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9511 - val_loss: 0.4681 - val_accuracy: 0.7901\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2047 - accuracy: 0.9519 - val_loss: 0.4347 - val_accuracy: 0.7942\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1369 - accuracy: 0.9489 - val_loss: 0.4138 - val_accuracy: 0.7973\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1226 - accuracy: 0.9484 - val_loss: 0.4434 - val_accuracy: 0.8107\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1407 - accuracy: 0.9444 - val_loss: 0.3993 - val_accuracy: 0.8097\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9484 - val_loss: 0.4395 - val_accuracy: 0.7994\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1465 - accuracy: 0.9449 - val_loss: 0.4249 - val_accuracy: 0.7932\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1391 - accuracy: 0.9475 - val_loss: 0.4506 - val_accuracy: 0.7778\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2544 - accuracy: 0.9480 - val_loss: 0.4153 - val_accuracy: 0.7922\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.9537 - val_loss: 0.4167 - val_accuracy: 0.8025\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1340 - accuracy: 0.9519 - val_loss: 0.3827 - val_accuracy: 0.8323\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1335 - accuracy: 0.9489 - val_loss: 0.4604 - val_accuracy: 0.7932\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1427 - accuracy: 0.9489 - val_loss: 0.4130 - val_accuracy: 0.8220\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1280 - accuracy: 0.9480 - val_loss: 0.4034 - val_accuracy: 0.8066\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1206 - accuracy: 0.9537 - val_loss: 0.4245 - val_accuracy: 0.7829\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.9511 - val_loss: 0.3949 - val_accuracy: 0.8169\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1403 - accuracy: 0.9515 - val_loss: 0.4342 - val_accuracy: 0.8035\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1271 - accuracy: 0.9471 - val_loss: 0.4018 - val_accuracy: 0.8066\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1329 - accuracy: 0.9541 - val_loss: 0.3873 - val_accuracy: 0.8241\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1298 - accuracy: 0.9497 - val_loss: 0.3971 - val_accuracy: 0.8210\n","Score: 0.8209876418113708 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8443 - accuracy: 0.9264 - val_loss: 0.6555 - val_accuracy: 0.6039\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1788 - accuracy: 0.9162 - val_loss: 0.5692 - val_accuracy: 0.7006\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1552 - accuracy: 0.9290 - val_loss: 0.5436 - val_accuracy: 0.7325\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9396 - val_loss: 0.4785 - val_accuracy: 0.7716\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1681 - accuracy: 0.9325 - val_loss: 0.4929 - val_accuracy: 0.7603\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9436 - val_loss: 0.5065 - val_accuracy: 0.7366\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4007 - accuracy: 0.9352 - val_loss: 0.4554 - val_accuracy: 0.7870\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1545 - accuracy: 0.9414 - val_loss: 0.4466 - val_accuracy: 0.7973\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1378 - accuracy: 0.9471 - val_loss: 0.3965 - val_accuracy: 0.8066\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1423 - accuracy: 0.9462 - val_loss: 0.4110 - val_accuracy: 0.8158\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1474 - accuracy: 0.9449 - val_loss: 0.4337 - val_accuracy: 0.7840\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1299 - accuracy: 0.9515 - val_loss: 0.4432 - val_accuracy: 0.7850\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1418 - accuracy: 0.9484 - val_loss: 0.4169 - val_accuracy: 0.8056\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1617 - accuracy: 0.9453 - val_loss: 0.4083 - val_accuracy: 0.8200\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9458 - val_loss: 0.3754 - val_accuracy: 0.8313\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1531 - accuracy: 0.9489 - val_loss: 0.4392 - val_accuracy: 0.7665\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1295 - accuracy: 0.9475 - val_loss: 0.3785 - val_accuracy: 0.8158\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1603 - accuracy: 0.9431 - val_loss: 0.5022 - val_accuracy: 0.8004\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9422 - val_loss: 0.3966 - val_accuracy: 0.8076\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1176 - accuracy: 0.9594 - val_loss: 0.3474 - val_accuracy: 0.8323\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1309 - accuracy: 0.9581 - val_loss: 0.3633 - val_accuracy: 0.8282\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1021 - accuracy: 0.9546 - val_loss: 0.3640 - val_accuracy: 0.8374\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.9568 - val_loss: 0.4046 - val_accuracy: 0.8282\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1193 - accuracy: 0.9541 - val_loss: 0.5037 - val_accuracy: 0.8066\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1054 - accuracy: 0.9568 - val_loss: 0.3345 - val_accuracy: 0.8457\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0941 - accuracy: 0.9665 - val_loss: 0.3328 - val_accuracy: 0.8621\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9559 - val_loss: 0.3517 - val_accuracy: 0.8251\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1091 - accuracy: 0.9559 - val_loss: 0.3811 - val_accuracy: 0.8323\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1566 - accuracy: 0.9555 - val_loss: 0.3818 - val_accuracy: 0.8210\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1211 - accuracy: 0.9581 - val_loss: 0.3688 - val_accuracy: 0.8447\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1020 - accuracy: 0.9590 - val_loss: 0.3514 - val_accuracy: 0.8508\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1687 - accuracy: 0.9533 - val_loss: 0.3687 - val_accuracy: 0.8302\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1275 - accuracy: 0.9563 - val_loss: 0.3131 - val_accuracy: 0.8570\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2058 - accuracy: 0.9568 - val_loss: 0.4282 - val_accuracy: 0.8158\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1107 - accuracy: 0.9616 - val_loss: 0.3562 - val_accuracy: 0.8323\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1406 - accuracy: 0.9546 - val_loss: 0.3456 - val_accuracy: 0.8405\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1092 - accuracy: 0.9550 - val_loss: 0.3648 - val_accuracy: 0.8282\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1731 - accuracy: 0.9608 - val_loss: 0.3422 - val_accuracy: 0.8436\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0985 - accuracy: 0.9678 - val_loss: 0.3492 - val_accuracy: 0.8405\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1999 - accuracy: 0.9603 - val_loss: 0.3493 - val_accuracy: 0.8354\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.9656 - val_loss: 0.2990 - val_accuracy: 0.8519\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1182 - accuracy: 0.9594 - val_loss: 0.3169 - val_accuracy: 0.8426\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0922 - accuracy: 0.9656 - val_loss: 0.3175 - val_accuracy: 0.8529\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0834 - accuracy: 0.9674 - val_loss: 0.2966 - val_accuracy: 0.8745\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1067 - accuracy: 0.9660 - val_loss: 0.4142 - val_accuracy: 0.8519\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1016 - accuracy: 0.9638 - val_loss: 0.2873 - val_accuracy: 0.8673\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1051 - accuracy: 0.9665 - val_loss: 0.3074 - val_accuracy: 0.8632\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1079 - accuracy: 0.9634 - val_loss: 0.3022 - val_accuracy: 0.8704\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0870 - accuracy: 0.9687 - val_loss: 0.3001 - val_accuracy: 0.8632\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1254 - accuracy: 0.9643 - val_loss: 0.3400 - val_accuracy: 0.8580\n","Score: 0.8580247163772583 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8327 - accuracy: 0.9180 - val_loss: 0.6276 - val_accuracy: 0.6420\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2418 - accuracy: 0.9228 - val_loss: 0.6953 - val_accuracy: 0.5895\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2332 - accuracy: 0.9347 - val_loss: 0.5839 - val_accuracy: 0.7335\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5233 - accuracy: 0.9343 - val_loss: 0.5116 - val_accuracy: 0.7623\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1591 - accuracy: 0.9396 - val_loss: 0.5378 - val_accuracy: 0.7294\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1551 - accuracy: 0.9356 - val_loss: 0.4702 - val_accuracy: 0.7634\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1317 - accuracy: 0.9475 - val_loss: 0.4748 - val_accuracy: 0.7737\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1711 - accuracy: 0.9436 - val_loss: 0.5056 - val_accuracy: 0.7438\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9400 - val_loss: 0.5138 - val_accuracy: 0.7613\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1310 - accuracy: 0.9493 - val_loss: 0.4211 - val_accuracy: 0.8004\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9489 - val_loss: 0.4197 - val_accuracy: 0.8220\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9400 - val_loss: 0.4100 - val_accuracy: 0.8169\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9515 - val_loss: 0.3899 - val_accuracy: 0.8354\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1539 - accuracy: 0.9497 - val_loss: 0.4421 - val_accuracy: 0.7737\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1591 - accuracy: 0.9475 - val_loss: 0.4897 - val_accuracy: 0.7593\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9524 - val_loss: 0.4683 - val_accuracy: 0.7788\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9568 - val_loss: 0.3835 - val_accuracy: 0.8241\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1817 - accuracy: 0.9444 - val_loss: 0.4003 - val_accuracy: 0.8128\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1235 - accuracy: 0.9511 - val_loss: 0.3727 - val_accuracy: 0.8189\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1151 - accuracy: 0.9559 - val_loss: 0.4559 - val_accuracy: 0.7984\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9541 - val_loss: 0.3745 - val_accuracy: 0.8364\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1193 - accuracy: 0.9568 - val_loss: 0.3767 - val_accuracy: 0.8282\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1516 - accuracy: 0.9594 - val_loss: 0.4346 - val_accuracy: 0.8117\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1261 - accuracy: 0.9515 - val_loss: 0.3931 - val_accuracy: 0.8107\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1270 - accuracy: 0.9524 - val_loss: 0.3719 - val_accuracy: 0.8169\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1097 - accuracy: 0.9519 - val_loss: 0.3628 - val_accuracy: 0.8364\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2183 - accuracy: 0.9444 - val_loss: 0.4065 - val_accuracy: 0.8056\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1278 - accuracy: 0.9533 - val_loss: 0.3499 - val_accuracy: 0.8333\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1288 - accuracy: 0.9502 - val_loss: 0.3959 - val_accuracy: 0.8241\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9533 - val_loss: 0.4670 - val_accuracy: 0.7973\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9524 - val_loss: 0.3634 - val_accuracy: 0.8261\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1518 - accuracy: 0.9515 - val_loss: 0.3719 - val_accuracy: 0.8395\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9541 - val_loss: 0.3480 - val_accuracy: 0.8570\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4080 - accuracy: 0.9484 - val_loss: 0.3872 - val_accuracy: 0.8251\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1445 - accuracy: 0.9546 - val_loss: 0.3999 - val_accuracy: 0.8241\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1117 - accuracy: 0.9563 - val_loss: 0.3858 - val_accuracy: 0.8210\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1279 - accuracy: 0.9563 - val_loss: 0.3604 - val_accuracy: 0.8302\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1040 - accuracy: 0.9647 - val_loss: 0.3419 - val_accuracy: 0.8457\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1131 - accuracy: 0.9586 - val_loss: 0.3251 - val_accuracy: 0.8508\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2181 - accuracy: 0.9440 - val_loss: 0.3628 - val_accuracy: 0.8282\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1073 - accuracy: 0.9621 - val_loss: 0.3323 - val_accuracy: 0.8426\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0941 - accuracy: 0.9643 - val_loss: 0.3497 - val_accuracy: 0.8292\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1056 - accuracy: 0.9634 - val_loss: 0.2987 - val_accuracy: 0.8683\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1105 - accuracy: 0.9568 - val_loss: 0.3799 - val_accuracy: 0.8189\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1127 - accuracy: 0.9638 - val_loss: 0.3242 - val_accuracy: 0.8591\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0921 - accuracy: 0.9634 - val_loss: 0.2989 - val_accuracy: 0.8642\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0753 - accuracy: 0.9731 - val_loss: 0.3148 - val_accuracy: 0.8714\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0956 - accuracy: 0.9660 - val_loss: 0.3272 - val_accuracy: 0.8488\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0909 - accuracy: 0.9687 - val_loss: 0.3107 - val_accuracy: 0.8673\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0905 - accuracy: 0.9634 - val_loss: 0.3041 - val_accuracy: 0.8776\n","Score: 0.8775720000267029 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1799 - accuracy: 0.9096 - val_loss: 0.6799 - val_accuracy: 0.5195\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2075 - accuracy: 0.9202 - val_loss: 0.6146 - val_accuracy: 0.7078\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1771 - accuracy: 0.9127 - val_loss: 0.6442 - val_accuracy: 0.5340\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9330 - val_loss: 0.5617 - val_accuracy: 0.7305\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1508 - accuracy: 0.9422 - val_loss: 0.5881 - val_accuracy: 0.7212\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1750 - accuracy: 0.9255 - val_loss: 0.5334 - val_accuracy: 0.7531\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1777 - accuracy: 0.9312 - val_loss: 0.5455 - val_accuracy: 0.7325\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1863 - accuracy: 0.9387 - val_loss: 0.4945 - val_accuracy: 0.7449\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1365 - accuracy: 0.9418 - val_loss: 0.4571 - val_accuracy: 0.7901\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1487 - accuracy: 0.9347 - val_loss: 0.4678 - val_accuracy: 0.7747\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1493 - accuracy: 0.9396 - val_loss: 0.5602 - val_accuracy: 0.7150\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9436 - val_loss: 0.4583 - val_accuracy: 0.7870\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9449 - val_loss: 0.4308 - val_accuracy: 0.7891\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1395 - accuracy: 0.9462 - val_loss: 0.4484 - val_accuracy: 0.7994\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1439 - accuracy: 0.9475 - val_loss: 0.4321 - val_accuracy: 0.7994\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1262 - accuracy: 0.9471 - val_loss: 0.4305 - val_accuracy: 0.8014\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1407 - accuracy: 0.9453 - val_loss: 0.4912 - val_accuracy: 0.7840\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9436 - val_loss: 0.4684 - val_accuracy: 0.7901\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1334 - accuracy: 0.9449 - val_loss: 0.4402 - val_accuracy: 0.8004\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3140 - accuracy: 0.9400 - val_loss: 0.4788 - val_accuracy: 0.7778\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1660 - accuracy: 0.9453 - val_loss: 0.4161 - val_accuracy: 0.8117\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1312 - accuracy: 0.9480 - val_loss: 0.4286 - val_accuracy: 0.8035\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1526 - accuracy: 0.9431 - val_loss: 0.4163 - val_accuracy: 0.8004\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1562 - accuracy: 0.9515 - val_loss: 0.4240 - val_accuracy: 0.7881\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9541 - val_loss: 0.3914 - val_accuracy: 0.8302\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1271 - accuracy: 0.9475 - val_loss: 0.4250 - val_accuracy: 0.8014\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9436 - val_loss: 0.4257 - val_accuracy: 0.8107\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1190 - accuracy: 0.9528 - val_loss: 0.4388 - val_accuracy: 0.8025\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1428 - accuracy: 0.9436 - val_loss: 0.4014 - val_accuracy: 0.8076\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1626 - accuracy: 0.9489 - val_loss: 0.4373 - val_accuracy: 0.7912\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1353 - accuracy: 0.9484 - val_loss: 0.4057 - val_accuracy: 0.8097\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1145 - accuracy: 0.9541 - val_loss: 0.4255 - val_accuracy: 0.8107\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1474 - accuracy: 0.9559 - val_loss: 0.3771 - val_accuracy: 0.8313\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1367 - accuracy: 0.9484 - val_loss: 0.4160 - val_accuracy: 0.8128\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1349 - accuracy: 0.9489 - val_loss: 0.3978 - val_accuracy: 0.8097\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1623 - accuracy: 0.9462 - val_loss: 0.4196 - val_accuracy: 0.8004\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1363 - accuracy: 0.9546 - val_loss: 0.4229 - val_accuracy: 0.8086\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3004 - accuracy: 0.9453 - val_loss: 0.4028 - val_accuracy: 0.7994\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1042 - accuracy: 0.9599 - val_loss: 0.3701 - val_accuracy: 0.8251\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1289 - accuracy: 0.9506 - val_loss: 0.4104 - val_accuracy: 0.8200\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1212 - accuracy: 0.9489 - val_loss: 0.3763 - val_accuracy: 0.8313\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2000 - accuracy: 0.9405 - val_loss: 0.3892 - val_accuracy: 0.8138\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1254 - accuracy: 0.9449 - val_loss: 0.3946 - val_accuracy: 0.8158\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9519 - val_loss: 0.4048 - val_accuracy: 0.8097\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1280 - accuracy: 0.9453 - val_loss: 0.4152 - val_accuracy: 0.8148\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.9568 - val_loss: 0.4057 - val_accuracy: 0.8014\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1168 - accuracy: 0.9590 - val_loss: 0.3605 - val_accuracy: 0.8302\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9528 - val_loss: 0.4158 - val_accuracy: 0.8035\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1421 - accuracy: 0.9484 - val_loss: 0.3932 - val_accuracy: 0.8272\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9559 - val_loss: 0.4453 - val_accuracy: 0.8251\n","Score: 0.8251028656959534 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.5326 - accuracy: 0.9153 - val_loss: 0.6653 - val_accuracy: 0.6327\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2146 - accuracy: 0.9087 - val_loss: 0.7534 - val_accuracy: 0.4897\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1738 - accuracy: 0.9136 - val_loss: 0.6046 - val_accuracy: 0.6790\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9118 - val_loss: 0.6015 - val_accuracy: 0.6481\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1785 - accuracy: 0.9202 - val_loss: 0.5903 - val_accuracy: 0.6615\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1695 - accuracy: 0.9211 - val_loss: 0.5921 - val_accuracy: 0.6677\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9250 - val_loss: 0.5911 - val_accuracy: 0.6440\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1723 - accuracy: 0.9317 - val_loss: 0.5455 - val_accuracy: 0.6996\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2218 - accuracy: 0.9334 - val_loss: 0.5582 - val_accuracy: 0.6800\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1750 - accuracy: 0.9330 - val_loss: 0.5688 - val_accuracy: 0.6996\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1630 - accuracy: 0.9365 - val_loss: 0.5272 - val_accuracy: 0.7243\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9422 - val_loss: 0.5366 - val_accuracy: 0.7294\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1713 - accuracy: 0.9299 - val_loss: 0.5512 - val_accuracy: 0.6903\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1552 - accuracy: 0.9365 - val_loss: 0.5245 - val_accuracy: 0.7058\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1580 - accuracy: 0.9383 - val_loss: 0.4602 - val_accuracy: 0.7819\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.9374 - val_loss: 0.5388 - val_accuracy: 0.7335\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1609 - accuracy: 0.9409 - val_loss: 0.4910 - val_accuracy: 0.7654\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1525 - accuracy: 0.9414 - val_loss: 0.4724 - val_accuracy: 0.7778\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2334 - accuracy: 0.9378 - val_loss: 0.4972 - val_accuracy: 0.7870\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9396 - val_loss: 0.4889 - val_accuracy: 0.7469\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9387 - val_loss: 0.4514 - val_accuracy: 0.7716\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1518 - accuracy: 0.9453 - val_loss: 0.5268 - val_accuracy: 0.7274\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1458 - accuracy: 0.9471 - val_loss: 0.4474 - val_accuracy: 0.7819\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1401 - accuracy: 0.9506 - val_loss: 0.4327 - val_accuracy: 0.8014\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1366 - accuracy: 0.9453 - val_loss: 0.4264 - val_accuracy: 0.8056\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.9541 - val_loss: 0.4103 - val_accuracy: 0.8148\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9528 - val_loss: 0.4148 - val_accuracy: 0.8066\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9475 - val_loss: 0.4494 - val_accuracy: 0.7850\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1512 - accuracy: 0.9524 - val_loss: 0.4138 - val_accuracy: 0.8251\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9462 - val_loss: 0.4197 - val_accuracy: 0.8004\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2158 - accuracy: 0.9387 - val_loss: 0.4869 - val_accuracy: 0.7521\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1640 - accuracy: 0.9303 - val_loss: 0.4912 - val_accuracy: 0.7562\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9440 - val_loss: 0.4161 - val_accuracy: 0.8014\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1538 - accuracy: 0.9440 - val_loss: 0.3995 - val_accuracy: 0.8117\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1424 - accuracy: 0.9449 - val_loss: 0.4257 - val_accuracy: 0.7973\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1555 - accuracy: 0.9444 - val_loss: 0.3951 - val_accuracy: 0.7942\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1402 - accuracy: 0.9431 - val_loss: 0.4117 - val_accuracy: 0.8045\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9414 - val_loss: 0.4086 - val_accuracy: 0.8158\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1559 - accuracy: 0.9308 - val_loss: 0.5103 - val_accuracy: 0.7449\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1290 - accuracy: 0.9493 - val_loss: 0.4289 - val_accuracy: 0.7922\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1315 - accuracy: 0.9506 - val_loss: 0.3828 - val_accuracy: 0.8189\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9528 - val_loss: 0.3839 - val_accuracy: 0.8241\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2175 - accuracy: 0.9440 - val_loss: 0.4085 - val_accuracy: 0.8004\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1617 - accuracy: 0.9506 - val_loss: 0.4045 - val_accuracy: 0.8179\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9528 - val_loss: 0.4670 - val_accuracy: 0.7767\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1451 - accuracy: 0.9466 - val_loss: 0.4299 - val_accuracy: 0.8076\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9444 - val_loss: 0.4107 - val_accuracy: 0.7984\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1534 - accuracy: 0.9484 - val_loss: 0.4495 - val_accuracy: 0.7973\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.9515 - val_loss: 0.4321 - val_accuracy: 0.8128\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1404 - accuracy: 0.9440 - val_loss: 0.3816 - val_accuracy: 0.8169\n","Score: 0.8168724179267883 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 29561.5547 - accuracy: 0.8933 - val_loss: 0.7068 - val_accuracy: 0.4794\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9052 - val_loss: 0.8315 - val_accuracy: 0.4897\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 190.7312 - accuracy: 0.9026 - val_loss: 0.7066 - val_accuracy: 0.5041\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1837 - accuracy: 0.9127 - val_loss: 0.7612 - val_accuracy: 0.4959\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9061 - val_loss: 0.7087 - val_accuracy: 0.4835\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1989 - accuracy: 0.8968 - val_loss: 0.6943 - val_accuracy: 0.4990\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9140 - val_loss: 0.7115 - val_accuracy: 0.4733\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2202 - accuracy: 0.9004 - val_loss: 0.6941 - val_accuracy: 0.5082\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2160 - accuracy: 0.9180 - val_loss: 0.7066 - val_accuracy: 0.5154\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9131 - val_loss: 0.7151 - val_accuracy: 0.4969\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2173 - accuracy: 0.9105 - val_loss: 0.7115 - val_accuracy: 0.5206\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2147 - accuracy: 0.9140 - val_loss: 0.6996 - val_accuracy: 0.5093\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9162 - val_loss: 0.6944 - val_accuracy: 0.5175\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2174 - accuracy: 0.9153 - val_loss: 0.7014 - val_accuracy: 0.5062\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2030 - accuracy: 0.9153 - val_loss: 0.6942 - val_accuracy: 0.5175\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9211 - val_loss: 0.6973 - val_accuracy: 0.5062\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2210 - accuracy: 0.9114 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2098 - accuracy: 0.9211 - val_loss: 0.6977 - val_accuracy: 0.4990\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.9074 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2302 - accuracy: 0.9061 - val_loss: 0.6949 - val_accuracy: 0.4877\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2187 - accuracy: 0.9105 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2143 - accuracy: 0.9193 - val_loss: 0.7060 - val_accuracy: 0.5010\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2138 - accuracy: 0.9127 - val_loss: 0.6951 - val_accuracy: 0.4763\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2101 - accuracy: 0.9078 - val_loss: 0.7004 - val_accuracy: 0.5185\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2244 - accuracy: 0.9114 - val_loss: 0.6974 - val_accuracy: 0.4743\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9074 - val_loss: 0.6935 - val_accuracy: 0.5010\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.9136 - val_loss: 0.7074 - val_accuracy: 0.5195\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2228 - accuracy: 0.9145 - val_loss: 0.7053 - val_accuracy: 0.5062\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2141 - accuracy: 0.9101 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2119 - accuracy: 0.9105 - val_loss: 0.6999 - val_accuracy: 0.4938\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2181 - accuracy: 0.9070 - val_loss: 0.6924 - val_accuracy: 0.5247\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2196 - accuracy: 0.9136 - val_loss: 0.6934 - val_accuracy: 0.4794\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2142 - accuracy: 0.9145 - val_loss: 0.6956 - val_accuracy: 0.5154\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2158 - accuracy: 0.9101 - val_loss: 0.6938 - val_accuracy: 0.4784\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2266 - accuracy: 0.9021 - val_loss: 0.6933 - val_accuracy: 0.4866\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2245 - accuracy: 0.9127 - val_loss: 0.6994 - val_accuracy: 0.5247\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2155 - accuracy: 0.9056 - val_loss: 0.7123 - val_accuracy: 0.4949\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2166 - accuracy: 0.9078 - val_loss: 0.6961 - val_accuracy: 0.4877\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2173 - accuracy: 0.9162 - val_loss: 0.7072 - val_accuracy: 0.5154\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2150 - accuracy: 0.9162 - val_loss: 0.6951 - val_accuracy: 0.4743\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.9105 - val_loss: 0.6927 - val_accuracy: 0.5278\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9131 - val_loss: 0.6934 - val_accuracy: 0.5144\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2098 - accuracy: 0.9184 - val_loss: 0.6929 - val_accuracy: 0.5144\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2157 - accuracy: 0.9162 - val_loss: 0.6929 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2242 - accuracy: 0.9153 - val_loss: 0.7098 - val_accuracy: 0.4990\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2209 - accuracy: 0.9136 - val_loss: 0.6926 - val_accuracy: 0.5185\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.9162 - val_loss: 0.6932 - val_accuracy: 0.4918\n","Epoch 48/50\n","567/567 [==============================] - 3s 4ms/step - loss: 0.2242 - accuracy: 0.9109 - val_loss: 0.6929 - val_accuracy: 0.5206\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2191 - accuracy: 0.9184 - val_loss: 0.6986 - val_accuracy: 0.5288\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2128 - accuracy: 0.9118 - val_loss: 0.6932 - val_accuracy: 0.5031\n","Score: 0.5030864477157593 \n","Parameters:  {'learning_rate': 0.0559432309934929, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1037 - accuracy: 0.9083 - val_loss: 0.7033 - val_accuracy: 0.5442\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1671 - accuracy: 0.9233 - val_loss: 0.6317 - val_accuracy: 0.6636\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1784 - accuracy: 0.9184 - val_loss: 0.6284 - val_accuracy: 0.6461\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1738 - accuracy: 0.9237 - val_loss: 0.6233 - val_accuracy: 0.6975\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9140 - val_loss: 0.6224 - val_accuracy: 0.6626\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1794 - accuracy: 0.9281 - val_loss: 0.6020 - val_accuracy: 0.6811\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7498 - accuracy: 0.9202 - val_loss: 0.5951 - val_accuracy: 0.7109\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9237 - val_loss: 0.5782 - val_accuracy: 0.7459\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1702 - accuracy: 0.9299 - val_loss: 0.5959 - val_accuracy: 0.7047\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9268 - val_loss: 0.6292 - val_accuracy: 0.6687\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.5276 - accuracy: 0.9290 - val_loss: 0.5886 - val_accuracy: 0.6883\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3847 - accuracy: 0.9339 - val_loss: 0.5850 - val_accuracy: 0.7233\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1750 - accuracy: 0.9352 - val_loss: 0.5937 - val_accuracy: 0.7233\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1777 - accuracy: 0.9317 - val_loss: 0.5788 - val_accuracy: 0.7078\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1635 - accuracy: 0.9343 - val_loss: 0.5686 - val_accuracy: 0.7037\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1690 - accuracy: 0.9409 - val_loss: 0.5416 - val_accuracy: 0.7284\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1567 - accuracy: 0.9374 - val_loss: 0.5226 - val_accuracy: 0.7212\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3690 - accuracy: 0.9339 - val_loss: 0.5355 - val_accuracy: 0.7181\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1435 - accuracy: 0.9422 - val_loss: 0.5266 - val_accuracy: 0.7366\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1796 - accuracy: 0.9374 - val_loss: 0.5109 - val_accuracy: 0.7387\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1487 - accuracy: 0.9422 - val_loss: 0.4952 - val_accuracy: 0.7479\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1518 - accuracy: 0.9387 - val_loss: 0.5053 - val_accuracy: 0.7593\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1377 - accuracy: 0.9436 - val_loss: 0.4905 - val_accuracy: 0.7582\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1446 - accuracy: 0.9392 - val_loss: 0.4755 - val_accuracy: 0.7726\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6050 - accuracy: 0.9369 - val_loss: 0.4538 - val_accuracy: 0.8086\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4002 - accuracy: 0.9409 - val_loss: 0.4717 - val_accuracy: 0.7860\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1229 - accuracy: 0.9568 - val_loss: 0.4170 - val_accuracy: 0.8292\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1249 - accuracy: 0.9519 - val_loss: 0.4482 - val_accuracy: 0.7747\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1482 - accuracy: 0.9511 - val_loss: 0.3436 - val_accuracy: 0.8447\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1254 - accuracy: 0.9568 - val_loss: 0.3869 - val_accuracy: 0.8416\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2463 - accuracy: 0.9466 - val_loss: 0.4220 - val_accuracy: 0.8148\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1785 - accuracy: 0.9462 - val_loss: 0.4161 - val_accuracy: 0.8076\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9515 - val_loss: 0.4439 - val_accuracy: 0.7840\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9440 - val_loss: 0.4039 - val_accuracy: 0.8272\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1764 - accuracy: 0.9489 - val_loss: 0.4626 - val_accuracy: 0.7922\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9519 - val_loss: 0.4076 - val_accuracy: 0.7994\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9502 - val_loss: 0.3707 - val_accuracy: 0.8251\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1479 - accuracy: 0.9497 - val_loss: 0.4147 - val_accuracy: 0.7994\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1544 - accuracy: 0.9599 - val_loss: 0.3618 - val_accuracy: 0.8272\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1069 - accuracy: 0.9643 - val_loss: 0.4382 - val_accuracy: 0.8086\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1069 - accuracy: 0.9572 - val_loss: 0.3259 - val_accuracy: 0.8591\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1127 - accuracy: 0.9563 - val_loss: 0.3598 - val_accuracy: 0.8426\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1041 - accuracy: 0.9634 - val_loss: 0.3595 - val_accuracy: 0.8467\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9586 - val_loss: 0.4013 - val_accuracy: 0.8138\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1351 - accuracy: 0.9546 - val_loss: 0.3821 - val_accuracy: 0.8251\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1539 - accuracy: 0.9555 - val_loss: 0.3645 - val_accuracy: 0.8158\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1006 - accuracy: 0.9647 - val_loss: 0.3191 - val_accuracy: 0.8570\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9599 - val_loss: 0.3195 - val_accuracy: 0.8580\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1046 - accuracy: 0.9656 - val_loss: 0.4895 - val_accuracy: 0.8128\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0820 - accuracy: 0.9660 - val_loss: 0.2385 - val_accuracy: 0.8817\n","Score: 0.8816872239112854 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 87398.6016 - accuracy: 0.8898 - val_loss: 0.7949 - val_accuracy: 0.5195\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1820 - accuracy: 0.9127 - val_loss: 0.6933 - val_accuracy: 0.4702\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9149 - val_loss: 0.6994 - val_accuracy: 0.5021\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2043 - accuracy: 0.9109 - val_loss: 0.6965 - val_accuracy: 0.5237\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9206 - val_loss: 0.6968 - val_accuracy: 0.5021\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9206 - val_loss: 0.7176 - val_accuracy: 0.4877\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2132 - accuracy: 0.9092 - val_loss: 0.7231 - val_accuracy: 0.4938\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2058 - accuracy: 0.9127 - val_loss: 0.7126 - val_accuracy: 0.4702\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2109 - accuracy: 0.9043 - val_loss: 0.6945 - val_accuracy: 0.4774\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9070 - val_loss: 0.6964 - val_accuracy: 0.5154\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9167 - val_loss: 0.6949 - val_accuracy: 0.4979\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9065 - val_loss: 0.6944 - val_accuracy: 0.4907\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9012 - val_loss: 0.6942 - val_accuracy: 0.5123\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2174 - accuracy: 0.9118 - val_loss: 0.7126 - val_accuracy: 0.4784\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2183 - accuracy: 0.8951 - val_loss: 0.7108 - val_accuracy: 0.4815\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2165 - accuracy: 0.9070 - val_loss: 0.7011 - val_accuracy: 0.4805\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2055 - accuracy: 0.9052 - val_loss: 0.6928 - val_accuracy: 0.5123\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9206 - val_loss: 0.7011 - val_accuracy: 0.4979\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9078 - val_loss: 0.7043 - val_accuracy: 0.5041\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2003 - accuracy: 0.9096 - val_loss: 0.6942 - val_accuracy: 0.5082\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2140 - accuracy: 0.9114 - val_loss: 0.7065 - val_accuracy: 0.4897\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2121 - accuracy: 0.9039 - val_loss: 0.7146 - val_accuracy: 0.4825\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9030 - val_loss: 0.6972 - val_accuracy: 0.4887\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2128 - accuracy: 0.9039 - val_loss: 0.6933 - val_accuracy: 0.4877\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2143 - accuracy: 0.9039 - val_loss: 0.7152 - val_accuracy: 0.5165\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9083 - val_loss: 0.6954 - val_accuracy: 0.5144\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2050 - accuracy: 0.9078 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2123 - accuracy: 0.9136 - val_loss: 0.6974 - val_accuracy: 0.4835\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.9074 - val_loss: 0.6932 - val_accuracy: 0.5185\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9118 - val_loss: 0.6965 - val_accuracy: 0.5072\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9114 - val_loss: 0.7063 - val_accuracy: 0.4825\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9083 - val_loss: 0.7316 - val_accuracy: 0.4630\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9034 - val_loss: 0.6997 - val_accuracy: 0.5041\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2033 - accuracy: 0.9127 - val_loss: 0.6963 - val_accuracy: 0.5175\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9189 - val_loss: 0.6939 - val_accuracy: 0.4825\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.7006 - val_accuracy: 0.4784\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9087 - val_loss: 0.7127 - val_accuracy: 0.5031\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9140 - val_loss: 0.6962 - val_accuracy: 0.5082\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9180 - val_loss: 0.7097 - val_accuracy: 0.5062\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9096 - val_loss: 0.6927 - val_accuracy: 0.5165\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2103 - accuracy: 0.9074 - val_loss: 0.6915 - val_accuracy: 0.5298\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9061 - val_loss: 0.6949 - val_accuracy: 0.4887\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.9056 - val_loss: 0.7157 - val_accuracy: 0.5257\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9167 - val_loss: 0.6959 - val_accuracy: 0.5123\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2054 - accuracy: 0.9109 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9162 - val_loss: 0.6995 - val_accuracy: 0.4949\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2010 - accuracy: 0.9092 - val_loss: 0.6939 - val_accuracy: 0.4877\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.9074 - val_loss: 0.6964 - val_accuracy: 0.4825\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9083 - val_loss: 0.6941 - val_accuracy: 0.4825\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9105 - val_loss: 0.7003 - val_accuracy: 0.4815\n","Score: 0.48148149251937866 \n","Parameters:  {'learning_rate': 0.08145603414586632, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6022 - accuracy: 0.9158 - val_loss: 0.5510 - val_accuracy: 0.7418\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2303 - accuracy: 0.9347 - val_loss: 0.5246 - val_accuracy: 0.7541\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9352 - val_loss: 0.5445 - val_accuracy: 0.7644\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.9330 - val_loss: 0.5171 - val_accuracy: 0.7521\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9343 - val_loss: 0.5092 - val_accuracy: 0.7778\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1470 - accuracy: 0.9405 - val_loss: 0.4918 - val_accuracy: 0.7840\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1584 - accuracy: 0.9325 - val_loss: 0.4831 - val_accuracy: 0.7984\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6798 - accuracy: 0.9392 - val_loss: 0.4851 - val_accuracy: 0.7603\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2703 - accuracy: 0.9466 - val_loss: 0.4195 - val_accuracy: 0.8045\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1361 - accuracy: 0.9427 - val_loss: 0.4763 - val_accuracy: 0.7870\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9436 - val_loss: 0.4379 - val_accuracy: 0.8025\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1298 - accuracy: 0.9555 - val_loss: 0.4690 - val_accuracy: 0.7582\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9519 - val_loss: 0.3973 - val_accuracy: 0.8148\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1103 - accuracy: 0.9581 - val_loss: 0.4164 - val_accuracy: 0.8025\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1396 - accuracy: 0.9533 - val_loss: 0.4207 - val_accuracy: 0.8179\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9462 - val_loss: 0.3704 - val_accuracy: 0.8323\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1049 - accuracy: 0.9586 - val_loss: 0.3306 - val_accuracy: 0.8549\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0973 - accuracy: 0.9616 - val_loss: 0.3284 - val_accuracy: 0.8416\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1060 - accuracy: 0.9603 - val_loss: 0.2926 - val_accuracy: 0.8652\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1082 - accuracy: 0.9616 - val_loss: 0.2807 - val_accuracy: 0.8601\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1173 - accuracy: 0.9546 - val_loss: 0.3346 - val_accuracy: 0.8302\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0843 - accuracy: 0.9731 - val_loss: 0.2625 - val_accuracy: 0.8755\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9497 - val_loss: 0.3343 - val_accuracy: 0.8519\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1061 - accuracy: 0.9647 - val_loss: 0.3775 - val_accuracy: 0.8426\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0952 - accuracy: 0.9616 - val_loss: 0.3438 - val_accuracy: 0.8364\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0968 - accuracy: 0.9621 - val_loss: 0.2558 - val_accuracy: 0.8899\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0820 - accuracy: 0.9683 - val_loss: 0.3186 - val_accuracy: 0.8549\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0843 - accuracy: 0.9669 - val_loss: 0.2395 - val_accuracy: 0.8889\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0934 - accuracy: 0.9674 - val_loss: 0.2510 - val_accuracy: 0.8848\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0686 - accuracy: 0.9696 - val_loss: 0.2594 - val_accuracy: 0.8786\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0839 - accuracy: 0.9718 - val_loss: 0.1997 - val_accuracy: 0.9187\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0762 - accuracy: 0.9766 - val_loss: 0.2182 - val_accuracy: 0.9136\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0634 - accuracy: 0.9780 - val_loss: 0.2065 - val_accuracy: 0.9177\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 0.2284 - val_accuracy: 0.8909\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0580 - accuracy: 0.9832 - val_loss: 0.2298 - val_accuracy: 0.9043\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0492 - accuracy: 0.9824 - val_loss: 0.1939 - val_accuracy: 0.9259\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0659 - accuracy: 0.9766 - val_loss: 0.2083 - val_accuracy: 0.9177\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1004 - accuracy: 0.9669 - val_loss: 0.2120 - val_accuracy: 0.9208\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0732 - accuracy: 0.9735 - val_loss: 0.1935 - val_accuracy: 0.9218\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0825 - accuracy: 0.9735 - val_loss: 0.3512 - val_accuracy: 0.8683\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0534 - accuracy: 0.9850 - val_loss: 0.1538 - val_accuracy: 0.9352\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0702 - accuracy: 0.9824 - val_loss: 0.2276 - val_accuracy: 0.9146\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0416 - accuracy: 0.9881 - val_loss: 0.1561 - val_accuracy: 0.9496\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0542 - accuracy: 0.9841 - val_loss: 0.1496 - val_accuracy: 0.9414\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0955 - accuracy: 0.9696 - val_loss: 0.1655 - val_accuracy: 0.9444\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9568\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.1207 - val_accuracy: 0.9537\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.1355 - val_accuracy: 0.9537\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0796 - accuracy: 0.9850 - val_loss: 0.1251 - val_accuracy: 0.9640\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0276 - accuracy: 0.9890 - val_loss: 0.1520 - val_accuracy: 0.9516\n","Score: 0.951646089553833 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Global:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1662163.6250 - accuracy: 0.8805 - val_loss: 0.8526 - val_accuracy: 0.4907\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2270 - accuracy: 0.8907 - val_loss: 0.7466 - val_accuracy: 0.5072\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2350 - accuracy: 0.8995 - val_loss: 0.9533 - val_accuracy: 0.5195\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.8999 - val_loss: 1.0246 - val_accuracy: 0.5041\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2192 - accuracy: 0.9061 - val_loss: 1.7148 - val_accuracy: 0.4846\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3227 - accuracy: 0.8880 - val_loss: 0.7893 - val_accuracy: 0.5185\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2269 - accuracy: 0.8995 - val_loss: 0.7335 - val_accuracy: 0.5154\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2321 - accuracy: 0.8871 - val_loss: 0.9078 - val_accuracy: 0.4846\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2737 - accuracy: 0.8946 - val_loss: 0.7848 - val_accuracy: 0.4753\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2735 - accuracy: 0.8968 - val_loss: 0.7033 - val_accuracy: 0.5000\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2422 - accuracy: 0.8836 - val_loss: 0.6926 - val_accuracy: 0.5195\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2071 - accuracy: 0.9087 - val_loss: 1.1895 - val_accuracy: 0.4794\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2803 - accuracy: 0.8867 - val_loss: 1.0577 - val_accuracy: 0.5185\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9074 - val_loss: 0.7192 - val_accuracy: 0.4877\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2113 - accuracy: 0.8977 - val_loss: 0.8810 - val_accuracy: 0.5154\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9030 - val_loss: 0.8893 - val_accuracy: 0.4856\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2181 - accuracy: 0.8981 - val_loss: 0.8017 - val_accuracy: 0.4969\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9012 - val_loss: 0.6950 - val_accuracy: 0.4887\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1816 - accuracy: 0.9171 - val_loss: 0.6930 - val_accuracy: 0.5113\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1861 - accuracy: 0.9109 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1881 - accuracy: 0.9162 - val_loss: 0.7480 - val_accuracy: 0.4825\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9074 - val_loss: 0.6925 - val_accuracy: 0.5226\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9087 - val_loss: 0.7137 - val_accuracy: 0.5298\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9052 - val_loss: 0.7274 - val_accuracy: 0.4691\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9017 - val_loss: 0.7646 - val_accuracy: 0.4846\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1911 - accuracy: 0.9043 - val_loss: 0.6932 - val_accuracy: 0.5134\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1895 - accuracy: 0.9136 - val_loss: 0.6927 - val_accuracy: 0.5165\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9052 - val_loss: 0.6973 - val_accuracy: 0.5195\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9101 - val_loss: 0.7105 - val_accuracy: 0.5093\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1894 - accuracy: 0.8995 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9153 - val_loss: 0.7212 - val_accuracy: 0.5000\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9096 - val_loss: 0.7411 - val_accuracy: 0.5051\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1978 - accuracy: 0.9021 - val_loss: 0.7176 - val_accuracy: 0.4856\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9101 - val_loss: 0.6932 - val_accuracy: 0.4990\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9012 - val_loss: 0.6969 - val_accuracy: 0.4763\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9048 - val_loss: 0.6964 - val_accuracy: 0.4784\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1810 - accuracy: 0.9127 - val_loss: 0.7103 - val_accuracy: 0.5031\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1821 - accuracy: 0.9118 - val_loss: 0.6965 - val_accuracy: 0.4835\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9078 - val_loss: 0.6967 - val_accuracy: 0.4938\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9056 - val_loss: 0.6964 - val_accuracy: 0.4897\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9056 - val_loss: 0.6931 - val_accuracy: 0.5103\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9087 - val_loss: 0.6934 - val_accuracy: 0.4928\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9056 - val_loss: 0.6958 - val_accuracy: 0.5216\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9048 - val_loss: 0.7394 - val_accuracy: 0.4825\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.8955 - val_loss: 0.7025 - val_accuracy: 0.5257\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1873 - accuracy: 0.9131 - val_loss: 0.6962 - val_accuracy: 0.4990\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9096 - val_loss: 0.6968 - val_accuracy: 0.5237\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1814 - accuracy: 0.9131 - val_loss: 0.7497 - val_accuracy: 0.5134\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1941 - accuracy: 0.9101 - val_loss: 0.7431 - val_accuracy: 0.5185\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9048 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Score: 0.5061728358268738 \n","Parameters:  {'learning_rate': 0.19574378717664417, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.8191 - accuracy: 0.9056 - val_loss: 0.6756 - val_accuracy: 0.5504\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2274 - accuracy: 0.9237 - val_loss: 0.6441 - val_accuracy: 0.6626\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2121 - accuracy: 0.9118 - val_loss: 0.6342 - val_accuracy: 0.6163\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2660 - accuracy: 0.9268 - val_loss: 0.6420 - val_accuracy: 0.6461\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1958 - accuracy: 0.9215 - val_loss: 0.6378 - val_accuracy: 0.6934\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1962 - accuracy: 0.9153 - val_loss: 0.5937 - val_accuracy: 0.6883\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2698 - accuracy: 0.9308 - val_loss: 0.5905 - val_accuracy: 0.6883\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1878 - accuracy: 0.9330 - val_loss: 0.5616 - val_accuracy: 0.7078\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.6363 - accuracy: 0.9321 - val_loss: 0.5711 - val_accuracy: 0.7068\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1716 - accuracy: 0.9365 - val_loss: 0.5275 - val_accuracy: 0.7119\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1758 - accuracy: 0.9303 - val_loss: 0.5863 - val_accuracy: 0.7109\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1730 - accuracy: 0.9330 - val_loss: 0.5142 - val_accuracy: 0.7418\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2793 - accuracy: 0.9299 - val_loss: 0.5052 - val_accuracy: 0.7490\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2802 - accuracy: 0.9396 - val_loss: 0.4827 - val_accuracy: 0.7603\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1426 - accuracy: 0.9458 - val_loss: 0.4482 - val_accuracy: 0.7788\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1473 - accuracy: 0.9484 - val_loss: 0.4653 - val_accuracy: 0.7737\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1312 - accuracy: 0.9493 - val_loss: 0.5601 - val_accuracy: 0.7685\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.9484 - val_loss: 0.3880 - val_accuracy: 0.8251\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1969 - accuracy: 0.9493 - val_loss: 0.4133 - val_accuracy: 0.8014\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1617 - accuracy: 0.9563 - val_loss: 0.3461 - val_accuracy: 0.8374\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9502 - val_loss: 0.3583 - val_accuracy: 0.8426\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0947 - accuracy: 0.9656 - val_loss: 0.3019 - val_accuracy: 0.8580\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0992 - accuracy: 0.9616 - val_loss: 0.3329 - val_accuracy: 0.8498\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0809 - accuracy: 0.9727 - val_loss: 0.3264 - val_accuracy: 0.8611\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.9674 - val_loss: 0.2529 - val_accuracy: 0.8961\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1007 - accuracy: 0.9634 - val_loss: 0.2562 - val_accuracy: 0.8951\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0927 - accuracy: 0.9735 - val_loss: 0.2387 - val_accuracy: 0.9074\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0758 - accuracy: 0.9749 - val_loss: 0.2155 - val_accuracy: 0.9167\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0691 - accuracy: 0.9744 - val_loss: 0.2549 - val_accuracy: 0.9074\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0718 - accuracy: 0.9740 - val_loss: 0.2395 - val_accuracy: 0.8971\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.2183 - val_accuracy: 0.9115\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0638 - accuracy: 0.9762 - val_loss: 0.4040 - val_accuracy: 0.8560\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0621 - accuracy: 0.9762 - val_loss: 0.2428 - val_accuracy: 0.9002\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0689 - accuracy: 0.9766 - val_loss: 0.2178 - val_accuracy: 0.9167\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0459 - accuracy: 0.9824 - val_loss: 0.2578 - val_accuracy: 0.8909\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0749 - accuracy: 0.9802 - val_loss: 0.1715 - val_accuracy: 0.9321\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.2424 - val_accuracy: 0.9043\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0337 - accuracy: 0.9907 - val_loss: 0.1620 - val_accuracy: 0.9496\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0510 - accuracy: 0.9877 - val_loss: 0.1425 - val_accuracy: 0.9486\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0545 - accuracy: 0.9832 - val_loss: 0.1974 - val_accuracy: 0.9290\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0438 - accuracy: 0.9890 - val_loss: 0.1682 - val_accuracy: 0.9414\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0546 - accuracy: 0.9859 - val_loss: 0.1471 - val_accuracy: 0.9527\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0381 - accuracy: 0.9863 - val_loss: 0.1511 - val_accuracy: 0.9455\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.1524 - val_accuracy: 0.9424\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0252 - accuracy: 0.9903 - val_loss: 0.1120 - val_accuracy: 0.9650\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1607 - accuracy: 0.9921 - val_loss: 0.1251 - val_accuracy: 0.9588\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0864 - val_accuracy: 0.9774\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.1253 - val_accuracy: 0.9537\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1840 - accuracy: 0.9735 - val_loss: 0.1854 - val_accuracy: 0.9239\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.1158 - val_accuracy: 0.9681\n","Score: 0.9681069850921631 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Global:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 156389.2031 - accuracy: 0.8981 - val_loss: 0.7074 - val_accuracy: 0.5093\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2039 - accuracy: 0.9140 - val_loss: 0.6899 - val_accuracy: 0.5329\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2036 - accuracy: 0.9127 - val_loss: 0.6916 - val_accuracy: 0.5072\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2131 - accuracy: 0.9118 - val_loss: 0.6920 - val_accuracy: 0.5226\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1933 - accuracy: 0.9109 - val_loss: 0.6924 - val_accuracy: 0.5062\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9074 - val_loss: 0.6917 - val_accuracy: 0.4856\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2087 - accuracy: 0.9127 - val_loss: 0.7047 - val_accuracy: 0.5062\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2033 - accuracy: 0.9198 - val_loss: 0.7108 - val_accuracy: 0.5134\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9149 - val_loss: 0.6927 - val_accuracy: 0.5082\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2087 - accuracy: 0.9109 - val_loss: 0.7078 - val_accuracy: 0.4969\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9074 - val_loss: 0.6924 - val_accuracy: 0.5051\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2059 - accuracy: 0.9118 - val_loss: 0.7169 - val_accuracy: 0.4763\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.8995 - val_loss: 0.6903 - val_accuracy: 0.5329\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2056 - accuracy: 0.9189 - val_loss: 0.7263 - val_accuracy: 0.5072\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9127 - val_loss: 0.6950 - val_accuracy: 0.5051\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.9096 - val_loss: 0.6921 - val_accuracy: 0.5082\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9198 - val_loss: 0.7064 - val_accuracy: 0.5257\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2051 - accuracy: 0.9078 - val_loss: 0.7013 - val_accuracy: 0.4835\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2195 - accuracy: 0.8964 - val_loss: 0.7240 - val_accuracy: 0.5123\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9034 - val_loss: 0.6971 - val_accuracy: 0.4918\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1994 - accuracy: 0.9056 - val_loss: 0.6928 - val_accuracy: 0.5031\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9136 - val_loss: 0.7001 - val_accuracy: 0.4928\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.9056 - val_loss: 0.6942 - val_accuracy: 0.4825\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9087 - val_loss: 0.6962 - val_accuracy: 0.4969\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9096 - val_loss: 0.6945 - val_accuracy: 0.4866\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9030 - val_loss: 0.6970 - val_accuracy: 0.4784\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2152 - accuracy: 0.9056 - val_loss: 0.6929 - val_accuracy: 0.5195\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9158 - val_loss: 0.6950 - val_accuracy: 0.4907\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2002 - accuracy: 0.9123 - val_loss: 0.6954 - val_accuracy: 0.4938\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.9140 - val_loss: 0.6939 - val_accuracy: 0.4856\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9158 - val_loss: 0.6961 - val_accuracy: 0.5195\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9145 - val_loss: 0.7051 - val_accuracy: 0.5062\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2072 - accuracy: 0.9118 - val_loss: 0.6914 - val_accuracy: 0.5195\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9136 - val_loss: 0.7064 - val_accuracy: 0.5206\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.9171 - val_loss: 0.6972 - val_accuracy: 0.4825\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9078 - val_loss: 0.6922 - val_accuracy: 0.5154\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9246 - val_loss: 0.6907 - val_accuracy: 0.5237\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9158 - val_loss: 0.6934 - val_accuracy: 0.4907\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2047 - accuracy: 0.9114 - val_loss: 0.7075 - val_accuracy: 0.5093\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9101 - val_loss: 0.6991 - val_accuracy: 0.5123\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9092 - val_loss: 0.7318 - val_accuracy: 0.5309\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9096 - val_loss: 0.7039 - val_accuracy: 0.4887\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2137 - accuracy: 0.9065 - val_loss: 0.6914 - val_accuracy: 0.5247\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2072 - accuracy: 0.9180 - val_loss: 0.6940 - val_accuracy: 0.5267\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9087 - val_loss: 0.6952 - val_accuracy: 0.4805\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9114 - val_loss: 0.6982 - val_accuracy: 0.5350\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2055 - accuracy: 0.9158 - val_loss: 0.6970 - val_accuracy: 0.5165\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9162 - val_loss: 0.6944 - val_accuracy: 0.4815\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9052 - val_loss: 0.6950 - val_accuracy: 0.5062\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9149 - val_loss: 0.7044 - val_accuracy: 0.4722\n","Score: 0.4722222089767456 \n","Parameters:  {'learning_rate': 0.08174774207261225, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5218 - accuracy: 0.9198 - val_loss: 0.6454 - val_accuracy: 0.7109\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9228 - val_loss: 0.5819 - val_accuracy: 0.6934\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5140 - accuracy: 0.9224 - val_loss: 0.5460 - val_accuracy: 0.7377\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1568 - accuracy: 0.9330 - val_loss: 0.5010 - val_accuracy: 0.7654\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1535 - accuracy: 0.9436 - val_loss: 0.5183 - val_accuracy: 0.7335\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9272 - val_loss: 0.4801 - val_accuracy: 0.7582\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9444 - val_loss: 0.4952 - val_accuracy: 0.7644\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2757 - accuracy: 0.9462 - val_loss: 0.3754 - val_accuracy: 0.8169\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1426 - accuracy: 0.9493 - val_loss: 0.3751 - val_accuracy: 0.8251\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1314 - accuracy: 0.9471 - val_loss: 0.3983 - val_accuracy: 0.7973\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1263 - accuracy: 0.9466 - val_loss: 0.3555 - val_accuracy: 0.8292\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2124 - accuracy: 0.9515 - val_loss: 0.3775 - val_accuracy: 0.8158\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1174 - accuracy: 0.9471 - val_loss: 0.3872 - val_accuracy: 0.7984\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1802 - accuracy: 0.9453 - val_loss: 0.3548 - val_accuracy: 0.8272\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1184 - accuracy: 0.9524 - val_loss: 0.3231 - val_accuracy: 0.8447\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1095 - accuracy: 0.9559 - val_loss: 0.3583 - val_accuracy: 0.8169\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9563 - val_loss: 0.3877 - val_accuracy: 0.8241\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1047 - accuracy: 0.9616 - val_loss: 0.4145 - val_accuracy: 0.8282\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9616 - val_loss: 0.3488 - val_accuracy: 0.8591\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1077 - accuracy: 0.9590 - val_loss: 0.4110 - val_accuracy: 0.8086\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0881 - accuracy: 0.9691 - val_loss: 0.9464 - val_accuracy: 0.7922\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1079 - accuracy: 0.9559 - val_loss: 0.3032 - val_accuracy: 0.8580\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1147 - accuracy: 0.9533 - val_loss: 0.3060 - val_accuracy: 0.8611\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1000 - accuracy: 0.9674 - val_loss: 0.2738 - val_accuracy: 0.8807\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9594 - val_loss: 0.3374 - val_accuracy: 0.8354\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0919 - accuracy: 0.9696 - val_loss: 0.2909 - val_accuracy: 0.8673\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1028 - accuracy: 0.9612 - val_loss: 0.3204 - val_accuracy: 0.8663\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0889 - accuracy: 0.9687 - val_loss: 0.2449 - val_accuracy: 0.8879\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0971 - accuracy: 0.9616 - val_loss: 0.3502 - val_accuracy: 0.8282\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0900 - accuracy: 0.9652 - val_loss: 0.2760 - val_accuracy: 0.8796\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0958 - accuracy: 0.9687 - val_loss: 0.2712 - val_accuracy: 0.8642\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0967 - accuracy: 0.9652 - val_loss: 0.2610 - val_accuracy: 0.8837\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9740 - val_loss: 0.2774 - val_accuracy: 0.8837\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1009 - accuracy: 0.9762 - val_loss: 0.2832 - val_accuracy: 0.8889\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0899 - accuracy: 0.9683 - val_loss: 0.2287 - val_accuracy: 0.8961\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0752 - accuracy: 0.9735 - val_loss: 0.2611 - val_accuracy: 0.8837\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0867 - accuracy: 0.9652 - val_loss: 0.2631 - val_accuracy: 0.8837\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1402 - accuracy: 0.9669 - val_loss: 0.2928 - val_accuracy: 0.8817\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 0.3486 - val_accuracy: 0.8570\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1104 - accuracy: 0.9713 - val_loss: 0.2446 - val_accuracy: 0.8909\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0682 - accuracy: 0.9766 - val_loss: 0.2700 - val_accuracy: 0.8807\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0634 - accuracy: 0.9762 - val_loss: 0.1759 - val_accuracy: 0.9259\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0648 - accuracy: 0.9753 - val_loss: 0.2142 - val_accuracy: 0.9115\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0632 - accuracy: 0.9753 - val_loss: 0.2132 - val_accuracy: 0.8971\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0499 - accuracy: 0.9793 - val_loss: 0.1835 - val_accuracy: 0.9208\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0771 - accuracy: 0.9749 - val_loss: 0.1896 - val_accuracy: 0.9105\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0484 - accuracy: 0.9819 - val_loss: 0.1910 - val_accuracy: 0.9300\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0433 - accuracy: 0.9841 - val_loss: 0.1609 - val_accuracy: 0.9311\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.2546 - val_accuracy: 0.9084\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.2445 - val_accuracy: 0.9146\n","Score: 0.9146090745925903 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.5677 - accuracy: 0.9220 - val_loss: 0.6111 - val_accuracy: 0.7058\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9325 - val_loss: 0.5647 - val_accuracy: 0.6996\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1515 - accuracy: 0.9396 - val_loss: 0.5190 - val_accuracy: 0.7222\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1531 - accuracy: 0.9378 - val_loss: 0.5408 - val_accuracy: 0.7212\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1526 - accuracy: 0.9409 - val_loss: 0.5246 - val_accuracy: 0.7490\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9387 - val_loss: 0.5374 - val_accuracy: 0.7428\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2285 - accuracy: 0.9101 - val_loss: 0.7061 - val_accuracy: 0.5195\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9162 - val_loss: 0.6506 - val_accuracy: 0.5381\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2340 - accuracy: 0.9224 - val_loss: 0.5889 - val_accuracy: 0.7088\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1814 - accuracy: 0.9211 - val_loss: 0.5505 - val_accuracy: 0.7418\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1777 - accuracy: 0.9167 - val_loss: 0.5944 - val_accuracy: 0.6399\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9215 - val_loss: 0.5482 - val_accuracy: 0.7181\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9321 - val_loss: 0.5631 - val_accuracy: 0.7160\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1708 - accuracy: 0.9312 - val_loss: 0.5077 - val_accuracy: 0.7541\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1727 - accuracy: 0.9233 - val_loss: 0.5294 - val_accuracy: 0.7325\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1585 - accuracy: 0.9317 - val_loss: 0.4874 - val_accuracy: 0.7562\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2087 - accuracy: 0.9378 - val_loss: 0.5103 - val_accuracy: 0.7449\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1479 - accuracy: 0.9444 - val_loss: 0.4830 - val_accuracy: 0.7798\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4843 - accuracy: 0.9369 - val_loss: 0.4945 - val_accuracy: 0.7490\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1392 - accuracy: 0.9506 - val_loss: 0.4761 - val_accuracy: 0.7582\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1611 - accuracy: 0.9444 - val_loss: 0.4379 - val_accuracy: 0.7953\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1757 - accuracy: 0.9312 - val_loss: 0.5187 - val_accuracy: 0.7356\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1634 - accuracy: 0.9449 - val_loss: 0.4652 - val_accuracy: 0.7994\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3308 - accuracy: 0.9528 - val_loss: 0.5286 - val_accuracy: 0.7418\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1275 - accuracy: 0.9497 - val_loss: 0.4465 - val_accuracy: 0.7860\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9471 - val_loss: 0.4655 - val_accuracy: 0.7788\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9506 - val_loss: 0.4744 - val_accuracy: 0.7757\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9493 - val_loss: 0.4147 - val_accuracy: 0.8148\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1338 - accuracy: 0.9524 - val_loss: 0.4534 - val_accuracy: 0.7788\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1279 - accuracy: 0.9563 - val_loss: 0.4097 - val_accuracy: 0.8066\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1355 - accuracy: 0.9453 - val_loss: 0.4276 - val_accuracy: 0.8014\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.9506 - val_loss: 0.4076 - val_accuracy: 0.8035\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1260 - accuracy: 0.9541 - val_loss: 0.4058 - val_accuracy: 0.8210\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1269 - accuracy: 0.9480 - val_loss: 0.4351 - val_accuracy: 0.7984\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1729 - accuracy: 0.9519 - val_loss: 0.4015 - val_accuracy: 0.8117\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1723 - accuracy: 0.9550 - val_loss: 0.4065 - val_accuracy: 0.8025\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3865 - accuracy: 0.9405 - val_loss: 0.4279 - val_accuracy: 0.8066\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1424 - accuracy: 0.9436 - val_loss: 0.3980 - val_accuracy: 0.8128\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1356 - accuracy: 0.9511 - val_loss: 0.4120 - val_accuracy: 0.8097\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1314 - accuracy: 0.9519 - val_loss: 0.4473 - val_accuracy: 0.7840\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9555 - val_loss: 0.4149 - val_accuracy: 0.8097\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9568 - val_loss: 0.3899 - val_accuracy: 0.8097\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1136 - accuracy: 0.9603 - val_loss: 0.4183 - val_accuracy: 0.7912\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.9555 - val_loss: 0.3861 - val_accuracy: 0.8251\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9581 - val_loss: 0.3635 - val_accuracy: 0.8364\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1167 - accuracy: 0.9511 - val_loss: 0.3677 - val_accuracy: 0.8344\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1135 - accuracy: 0.9625 - val_loss: 0.3376 - val_accuracy: 0.8395\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9528 - val_loss: 0.4319 - val_accuracy: 0.8004\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9484 - val_loss: 0.3522 - val_accuracy: 0.8313\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1169 - accuracy: 0.9586 - val_loss: 0.3621 - val_accuracy: 0.8344\n","Score: 0.8343621492385864 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1530 - accuracy: 0.9237 - val_loss: 0.6618 - val_accuracy: 0.5617\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1508 - accuracy: 0.9286 - val_loss: 0.6082 - val_accuracy: 0.6924\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1568 - accuracy: 0.9281 - val_loss: 0.5821 - val_accuracy: 0.6965\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1575 - accuracy: 0.9369 - val_loss: 0.5439 - val_accuracy: 0.7500\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1425 - accuracy: 0.9383 - val_loss: 0.5492 - val_accuracy: 0.7428\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1709 - accuracy: 0.9378 - val_loss: 0.5291 - val_accuracy: 0.7233\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1743 - accuracy: 0.9414 - val_loss: 0.5459 - val_accuracy: 0.7140\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9361 - val_loss: 0.5412 - val_accuracy: 0.7294\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1435 - accuracy: 0.9422 - val_loss: 0.5293 - val_accuracy: 0.7541\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9418 - val_loss: 0.5086 - val_accuracy: 0.7644\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1699 - accuracy: 0.9405 - val_loss: 0.5112 - val_accuracy: 0.7634\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9418 - val_loss: 0.5222 - val_accuracy: 0.7562\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1402 - accuracy: 0.9449 - val_loss: 0.4509 - val_accuracy: 0.7809\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1299 - accuracy: 0.9506 - val_loss: 0.4456 - val_accuracy: 0.7984\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1817 - accuracy: 0.9387 - val_loss: 0.4368 - val_accuracy: 0.8004\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1512 - accuracy: 0.9392 - val_loss: 0.4630 - val_accuracy: 0.7695\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1481 - accuracy: 0.9422 - val_loss: 0.4883 - val_accuracy: 0.7623\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1527 - accuracy: 0.9427 - val_loss: 0.6042 - val_accuracy: 0.7150\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4043 - accuracy: 0.9436 - val_loss: 0.4414 - val_accuracy: 0.8148\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1462 - accuracy: 0.9387 - val_loss: 0.4529 - val_accuracy: 0.7901\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9484 - val_loss: 0.4267 - val_accuracy: 0.7994\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9533 - val_loss: 0.4205 - val_accuracy: 0.7942\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1271 - accuracy: 0.9489 - val_loss: 0.4184 - val_accuracy: 0.8025\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9502 - val_loss: 0.4426 - val_accuracy: 0.7912\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1326 - accuracy: 0.9515 - val_loss: 0.4436 - val_accuracy: 0.7870\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.9484 - val_loss: 0.3837 - val_accuracy: 0.8148\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1389 - accuracy: 0.9528 - val_loss: 0.4178 - val_accuracy: 0.7850\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1150 - accuracy: 0.9555 - val_loss: 0.3824 - val_accuracy: 0.8117\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.9524 - val_loss: 0.4199 - val_accuracy: 0.7973\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1166 - accuracy: 0.9559 - val_loss: 0.3964 - val_accuracy: 0.8056\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1214 - accuracy: 0.9524 - val_loss: 0.3702 - val_accuracy: 0.8374\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9471 - val_loss: 0.3938 - val_accuracy: 0.8117\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2895 - accuracy: 0.9506 - val_loss: 0.3871 - val_accuracy: 0.8138\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1272 - accuracy: 0.9519 - val_loss: 0.3654 - val_accuracy: 0.8354\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1276 - accuracy: 0.9541 - val_loss: 0.4796 - val_accuracy: 0.8200\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1325 - accuracy: 0.9599 - val_loss: 0.3555 - val_accuracy: 0.8344\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1370 - accuracy: 0.9581 - val_loss: 0.3555 - val_accuracy: 0.8241\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9524 - val_loss: 0.3703 - val_accuracy: 0.8169\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1188 - accuracy: 0.9581 - val_loss: 0.3578 - val_accuracy: 0.8272\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9528 - val_loss: 0.3579 - val_accuracy: 0.8333\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1239 - accuracy: 0.9625 - val_loss: 0.4057 - val_accuracy: 0.8220\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0975 - accuracy: 0.9634 - val_loss: 0.3474 - val_accuracy: 0.8261\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1086 - accuracy: 0.9590 - val_loss: 0.3469 - val_accuracy: 0.8416\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1068 - accuracy: 0.9586 - val_loss: 0.3393 - val_accuracy: 0.8416\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.9563 - val_loss: 0.4115 - val_accuracy: 0.8344\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1133 - accuracy: 0.9603 - val_loss: 0.3454 - val_accuracy: 0.8374\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1034 - accuracy: 0.9608 - val_loss: 0.3574 - val_accuracy: 0.8323\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1078 - accuracy: 0.9621 - val_loss: 0.3128 - val_accuracy: 0.8652\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0816 - accuracy: 0.9674 - val_loss: 0.3078 - val_accuracy: 0.8724\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0849 - accuracy: 0.9660 - val_loss: 0.3167 - val_accuracy: 0.8652\n","Score: 0.8652263283729553 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 846439.6875 - accuracy: 0.9026 - val_loss: 0.6971 - val_accuracy: 0.4907\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1878 - accuracy: 0.9114 - val_loss: 0.6928 - val_accuracy: 0.5165\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2058 - accuracy: 0.9118 - val_loss: 0.7195 - val_accuracy: 0.4949\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9145 - val_loss: 0.7346 - val_accuracy: 0.5144\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9140 - val_loss: 0.6918 - val_accuracy: 0.5319\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9131 - val_loss: 0.6959 - val_accuracy: 0.4805\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9078 - val_loss: 0.6962 - val_accuracy: 0.5185\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.9065 - val_loss: 0.6980 - val_accuracy: 0.4774\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9061 - val_loss: 0.6996 - val_accuracy: 0.5123\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9211 - val_loss: 0.6929 - val_accuracy: 0.5195\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9131 - val_loss: 0.7107 - val_accuracy: 0.4928\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2135 - accuracy: 0.8955 - val_loss: 0.7045 - val_accuracy: 0.5072\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9175 - val_loss: 0.6948 - val_accuracy: 0.5051\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2007 - accuracy: 0.9211 - val_loss: 0.7236 - val_accuracy: 0.5185\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1994 - accuracy: 0.9167 - val_loss: 0.7025 - val_accuracy: 0.5216\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1971 - accuracy: 0.9109 - val_loss: 0.7039 - val_accuracy: 0.5144\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2052 - accuracy: 0.9017 - val_loss: 0.6928 - val_accuracy: 0.5154\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9109 - val_loss: 0.6954 - val_accuracy: 0.5062\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1970 - accuracy: 0.9167 - val_loss: 0.6963 - val_accuracy: 0.5082\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2003 - accuracy: 0.9092 - val_loss: 0.7028 - val_accuracy: 0.4938\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9039 - val_loss: 0.6986 - val_accuracy: 0.4907\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9105 - val_loss: 0.7135 - val_accuracy: 0.5062\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9153 - val_loss: 0.7121 - val_accuracy: 0.5195\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2062 - accuracy: 0.9017 - val_loss: 0.7191 - val_accuracy: 0.5103\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1978 - accuracy: 0.9131 - val_loss: 0.6931 - val_accuracy: 0.5144\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9136 - val_loss: 0.6941 - val_accuracy: 0.4856\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9145 - val_loss: 0.6988 - val_accuracy: 0.4702\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.9056 - val_loss: 0.6935 - val_accuracy: 0.5185\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9198 - val_loss: 0.6991 - val_accuracy: 0.4753\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9065 - val_loss: 0.7066 - val_accuracy: 0.5041\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2042 - accuracy: 0.9026 - val_loss: 0.7253 - val_accuracy: 0.5216\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2006 - accuracy: 0.9136 - val_loss: 0.6933 - val_accuracy: 0.5093\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9004 - val_loss: 0.6919 - val_accuracy: 0.5247\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9198 - val_loss: 0.7119 - val_accuracy: 0.4784\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9136 - val_loss: 0.6995 - val_accuracy: 0.5134\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9118 - val_loss: 0.6933 - val_accuracy: 0.4866\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2003 - accuracy: 0.9149 - val_loss: 0.6941 - val_accuracy: 0.5072\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9140 - val_loss: 0.6924 - val_accuracy: 0.5247\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9162 - val_loss: 0.7056 - val_accuracy: 0.4743\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9140 - val_loss: 0.6941 - val_accuracy: 0.5031\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2078 - accuracy: 0.9123 - val_loss: 0.6992 - val_accuracy: 0.5093\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.9145 - val_loss: 0.7061 - val_accuracy: 0.4897\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9061 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9180 - val_loss: 0.6963 - val_accuracy: 0.4990\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2036 - accuracy: 0.9021 - val_loss: 0.7021 - val_accuracy: 0.4753\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.8995 - val_loss: 0.6958 - val_accuracy: 0.4774\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9153 - val_loss: 0.7112 - val_accuracy: 0.4907\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2118 - accuracy: 0.8986 - val_loss: 0.6937 - val_accuracy: 0.5154\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2005 - accuracy: 0.9145 - val_loss: 0.6930 - val_accuracy: 0.5257\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1952 - accuracy: 0.9131 - val_loss: 0.6938 - val_accuracy: 0.4846\n","Score: 0.48456791043281555 \n","Parameters:  {'learning_rate': 0.10121326952941792, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 2686.4304 - accuracy: 0.9052 - val_loss: 0.7058 - val_accuracy: 0.4959\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2207 - accuracy: 0.8964 - val_loss: 0.6926 - val_accuracy: 0.5195\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2330 - accuracy: 0.9131 - val_loss: 0.6927 - val_accuracy: 0.5144\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2324 - accuracy: 0.9131 - val_loss: 0.6928 - val_accuracy: 0.5165\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2250 - accuracy: 0.9193 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2365 - accuracy: 0.9109 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2362 - accuracy: 0.9109 - val_loss: 0.6964 - val_accuracy: 0.5134\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2288 - accuracy: 0.9193 - val_loss: 0.6998 - val_accuracy: 0.5093\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2344 - accuracy: 0.9109 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2329 - accuracy: 0.9180 - val_loss: 0.6960 - val_accuracy: 0.5206\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2415 - accuracy: 0.9131 - val_loss: 0.7064 - val_accuracy: 0.5175\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2346 - accuracy: 0.9158 - val_loss: 0.6938 - val_accuracy: 0.5154\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2407 - accuracy: 0.9180 - val_loss: 0.6946 - val_accuracy: 0.5226\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2403 - accuracy: 0.9153 - val_loss: 0.6957 - val_accuracy: 0.5226\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2441 - accuracy: 0.9118 - val_loss: 0.6933 - val_accuracy: 0.5051\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2455 - accuracy: 0.9070 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2518 - accuracy: 0.9123 - val_loss: 0.7061 - val_accuracy: 0.5082\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2362 - accuracy: 0.9180 - val_loss: 0.6959 - val_accuracy: 0.5062\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2341 - accuracy: 0.9202 - val_loss: 0.6986 - val_accuracy: 0.4938\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2493 - accuracy: 0.9087 - val_loss: 0.6935 - val_accuracy: 0.5103\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2360 - accuracy: 0.9193 - val_loss: 0.6949 - val_accuracy: 0.5010\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2375 - accuracy: 0.9105 - val_loss: 0.6955 - val_accuracy: 0.4928\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2481 - accuracy: 0.9004 - val_loss: 0.6975 - val_accuracy: 0.4825\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2508 - accuracy: 0.9026 - val_loss: 0.7002 - val_accuracy: 0.5134\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2516 - accuracy: 0.9092 - val_loss: 0.6975 - val_accuracy: 0.5093\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2414 - accuracy: 0.9175 - val_loss: 0.7044 - val_accuracy: 0.5051\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2403 - accuracy: 0.9149 - val_loss: 0.6953 - val_accuracy: 0.5247\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9127 - val_loss: 0.6962 - val_accuracy: 0.5247\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2419 - accuracy: 0.9092 - val_loss: 0.6975 - val_accuracy: 0.4877\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2444 - accuracy: 0.9105 - val_loss: 0.7152 - val_accuracy: 0.5288\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2351 - accuracy: 0.9131 - val_loss: 0.6931 - val_accuracy: 0.5154\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2456 - accuracy: 0.9167 - val_loss: 0.7035 - val_accuracy: 0.5175\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2338 - accuracy: 0.9171 - val_loss: 0.6971 - val_accuracy: 0.5031\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2371 - accuracy: 0.9162 - val_loss: 0.6940 - val_accuracy: 0.5144\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2475 - accuracy: 0.9070 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2477 - accuracy: 0.9096 - val_loss: 0.6965 - val_accuracy: 0.5010\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2409 - accuracy: 0.9167 - val_loss: 0.6955 - val_accuracy: 0.5185\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2356 - accuracy: 0.9145 - val_loss: 0.6939 - val_accuracy: 0.4990\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2413 - accuracy: 0.9140 - val_loss: 0.6938 - val_accuracy: 0.4938\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2407 - accuracy: 0.9105 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2336 - accuracy: 0.9162 - val_loss: 0.6980 - val_accuracy: 0.4794\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2521 - accuracy: 0.9034 - val_loss: 0.6993 - val_accuracy: 0.5216\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2384 - accuracy: 0.9101 - val_loss: 0.6938 - val_accuracy: 0.5051\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2400 - accuracy: 0.9175 - val_loss: 0.6996 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2387 - accuracy: 0.9193 - val_loss: 0.6941 - val_accuracy: 0.5278\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2485 - accuracy: 0.9105 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2503 - accuracy: 0.9061 - val_loss: 0.6981 - val_accuracy: 0.4794\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2423 - accuracy: 0.9052 - val_loss: 0.6932 - val_accuracy: 0.4969\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2517 - accuracy: 0.9083 - val_loss: 0.7040 - val_accuracy: 0.5134\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2376 - accuracy: 0.9101 - val_loss: 0.6930 - val_accuracy: 0.5309\n","Score: 0.5308641791343689 \n","Parameters:  {'learning_rate': 0.03341710635479887, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1527.8883 - accuracy: 0.9109 - val_loss: 0.7006 - val_accuracy: 0.5041\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2476 - accuracy: 0.9136 - val_loss: 0.7005 - val_accuracy: 0.5144\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2402 - accuracy: 0.9237 - val_loss: 0.7192 - val_accuracy: 0.5082\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2395 - accuracy: 0.9158 - val_loss: 0.6932 - val_accuracy: 0.5216\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2446 - accuracy: 0.9167 - val_loss: 0.6936 - val_accuracy: 0.4887\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2618 - accuracy: 0.9012 - val_loss: 0.6940 - val_accuracy: 0.5154\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2507 - accuracy: 0.9167 - val_loss: 0.7019 - val_accuracy: 0.5175\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2505 - accuracy: 0.9105 - val_loss: 0.6941 - val_accuracy: 0.5041\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2453 - accuracy: 0.9193 - val_loss: 0.6981 - val_accuracy: 0.5309\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2483 - accuracy: 0.9153 - val_loss: 0.6961 - val_accuracy: 0.5093\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2542 - accuracy: 0.9118 - val_loss: 0.6936 - val_accuracy: 0.5165\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2491 - accuracy: 0.9180 - val_loss: 0.7045 - val_accuracy: 0.5123\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.9153 - val_loss: 0.6917 - val_accuracy: 0.5278\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2515 - accuracy: 0.9158 - val_loss: 0.7023 - val_accuracy: 0.5051\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2494 - accuracy: 0.9118 - val_loss: 0.6937 - val_accuracy: 0.5072\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2511 - accuracy: 0.9220 - val_loss: 0.7376 - val_accuracy: 0.5165\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2468 - accuracy: 0.9158 - val_loss: 0.7060 - val_accuracy: 0.5062\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2551 - accuracy: 0.9083 - val_loss: 0.6966 - val_accuracy: 0.5175\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2564 - accuracy: 0.9048 - val_loss: 0.6958 - val_accuracy: 0.4897\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2607 - accuracy: 0.8990 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2577 - accuracy: 0.9140 - val_loss: 0.6984 - val_accuracy: 0.5123\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2503 - accuracy: 0.9127 - val_loss: 0.6934 - val_accuracy: 0.5134\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2539 - accuracy: 0.9189 - val_loss: 0.7100 - val_accuracy: 0.5226\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2508 - accuracy: 0.9114 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2585 - accuracy: 0.9118 - val_loss: 0.6954 - val_accuracy: 0.5195\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2526 - accuracy: 0.9118 - val_loss: 0.6972 - val_accuracy: 0.5051\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2536 - accuracy: 0.9118 - val_loss: 0.7002 - val_accuracy: 0.5113\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2485 - accuracy: 0.9158 - val_loss: 0.6990 - val_accuracy: 0.5226\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2441 - accuracy: 0.9198 - val_loss: 0.6993 - val_accuracy: 0.5206\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2505 - accuracy: 0.9158 - val_loss: 0.7045 - val_accuracy: 0.5134\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2482 - accuracy: 0.9101 - val_loss: 0.6931 - val_accuracy: 0.5093\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2532 - accuracy: 0.9171 - val_loss: 0.7088 - val_accuracy: 0.5134\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2518 - accuracy: 0.9109 - val_loss: 0.6951 - val_accuracy: 0.5021\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2459 - accuracy: 0.9136 - val_loss: 0.6936 - val_accuracy: 0.4794\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2511 - accuracy: 0.9153 - val_loss: 0.7123 - val_accuracy: 0.5165\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2504 - accuracy: 0.9083 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2582 - accuracy: 0.9118 - val_loss: 0.6953 - val_accuracy: 0.5195\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2564 - accuracy: 0.9118 - val_loss: 0.6976 - val_accuracy: 0.5072\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2441 - accuracy: 0.9211 - val_loss: 0.7030 - val_accuracy: 0.5247\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2435 - accuracy: 0.9171 - val_loss: 0.6995 - val_accuracy: 0.5134\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2457 - accuracy: 0.9149 - val_loss: 0.6951 - val_accuracy: 0.4938\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2589 - accuracy: 0.9101 - val_loss: 0.7009 - val_accuracy: 0.5123\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2498 - accuracy: 0.9096 - val_loss: 0.6931 - val_accuracy: 0.4743\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2547 - accuracy: 0.9070 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2515 - accuracy: 0.9162 - val_loss: 0.6952 - val_accuracy: 0.5051\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2535 - accuracy: 0.9118 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2467 - accuracy: 0.9184 - val_loss: 0.6992 - val_accuracy: 0.5021\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2464 - accuracy: 0.9167 - val_loss: 0.6955 - val_accuracy: 0.5123\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2435 - accuracy: 0.9171 - val_loss: 0.6941 - val_accuracy: 0.5113\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2532 - accuracy: 0.9109 - val_loss: 0.6954 - val_accuracy: 0.5134\n","Score: 0.5133745074272156 \n","Parameters:  {'learning_rate': 0.029681486073888305, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.9104 - accuracy: 0.9127 - val_loss: 0.6813 - val_accuracy: 0.5648\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9092 - val_loss: 0.6261 - val_accuracy: 0.6811\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2550 - accuracy: 0.9193 - val_loss: 0.6387 - val_accuracy: 0.6368\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1721 - accuracy: 0.9237 - val_loss: 0.6146 - val_accuracy: 0.6862\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1875 - accuracy: 0.9140 - val_loss: 0.6296 - val_accuracy: 0.6543\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1809 - accuracy: 0.9264 - val_loss: 0.5791 - val_accuracy: 0.6914\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2586 - accuracy: 0.9259 - val_loss: 0.5855 - val_accuracy: 0.7058\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9286 - val_loss: 0.5096 - val_accuracy: 0.7459\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1671 - accuracy: 0.9339 - val_loss: 0.5207 - val_accuracy: 0.7479\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1666 - accuracy: 0.9409 - val_loss: 0.5325 - val_accuracy: 0.7726\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9308 - val_loss: 0.5348 - val_accuracy: 0.7346\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9458 - val_loss: 0.4759 - val_accuracy: 0.7582\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2373 - accuracy: 0.9466 - val_loss: 0.4588 - val_accuracy: 0.7757\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1663 - accuracy: 0.9422 - val_loss: 0.4735 - val_accuracy: 0.7994\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9471 - val_loss: 0.4494 - val_accuracy: 0.7922\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1427 - accuracy: 0.9414 - val_loss: 0.4839 - val_accuracy: 0.7675\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1438 - accuracy: 0.9519 - val_loss: 0.4791 - val_accuracy: 0.7891\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9387 - val_loss: 0.4349 - val_accuracy: 0.8045\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1834 - accuracy: 0.9361 - val_loss: 0.5014 - val_accuracy: 0.7531\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1648 - accuracy: 0.9405 - val_loss: 0.4348 - val_accuracy: 0.7984\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9409 - val_loss: 0.4421 - val_accuracy: 0.8117\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1501 - accuracy: 0.9568 - val_loss: 0.4661 - val_accuracy: 0.7860\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1422 - accuracy: 0.9475 - val_loss: 0.4287 - val_accuracy: 0.8035\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9444 - val_loss: 0.4186 - val_accuracy: 0.8272\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1470 - accuracy: 0.9431 - val_loss: 0.4262 - val_accuracy: 0.8025\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1181 - accuracy: 0.9537 - val_loss: 0.4053 - val_accuracy: 0.8189\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1296 - accuracy: 0.9475 - val_loss: 0.4286 - val_accuracy: 0.8086\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1830 - accuracy: 0.9489 - val_loss: 0.4371 - val_accuracy: 0.7881\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1294 - accuracy: 0.9506 - val_loss: 0.4373 - val_accuracy: 0.7891\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1394 - accuracy: 0.9453 - val_loss: 0.4305 - val_accuracy: 0.7984\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1634 - accuracy: 0.9440 - val_loss: 0.4440 - val_accuracy: 0.7747\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1659 - accuracy: 0.9489 - val_loss: 0.4245 - val_accuracy: 0.8025\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1467 - accuracy: 0.9449 - val_loss: 0.4206 - val_accuracy: 0.7984\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1275 - accuracy: 0.9559 - val_loss: 0.5062 - val_accuracy: 0.7582\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1524 - accuracy: 0.9427 - val_loss: 0.4216 - val_accuracy: 0.7953\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1335 - accuracy: 0.9515 - val_loss: 0.4346 - val_accuracy: 0.7922\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1380 - accuracy: 0.9453 - val_loss: 0.4323 - val_accuracy: 0.7922\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.9484 - val_loss: 0.4366 - val_accuracy: 0.7973\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1663 - accuracy: 0.9519 - val_loss: 0.4153 - val_accuracy: 0.8230\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1296 - accuracy: 0.9502 - val_loss: 0.4051 - val_accuracy: 0.8138\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1304 - accuracy: 0.9453 - val_loss: 0.4388 - val_accuracy: 0.7819\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1186 - accuracy: 0.9586 - val_loss: 0.4079 - val_accuracy: 0.8035\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1270 - accuracy: 0.9489 - val_loss: 0.4144 - val_accuracy: 0.8169\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1255 - accuracy: 0.9511 - val_loss: 0.4468 - val_accuracy: 0.7819\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1172 - accuracy: 0.9599 - val_loss: 0.4175 - val_accuracy: 0.8056\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1365 - accuracy: 0.9480 - val_loss: 0.4472 - val_accuracy: 0.7881\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1254 - accuracy: 0.9497 - val_loss: 0.4062 - val_accuracy: 0.8158\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1434 - accuracy: 0.9462 - val_loss: 0.4214 - val_accuracy: 0.8056\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9471 - val_loss: 0.4178 - val_accuracy: 0.8354\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2357 - accuracy: 0.9489 - val_loss: 0.4091 - val_accuracy: 0.8066\n","Score: 0.806584358215332 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7145 - accuracy: 0.9224 - val_loss: 0.6193 - val_accuracy: 0.6564\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1857 - accuracy: 0.9189 - val_loss: 0.6175 - val_accuracy: 0.6245\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1724 - accuracy: 0.9224 - val_loss: 0.6469 - val_accuracy: 0.6687\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2122 - accuracy: 0.9167 - val_loss: 0.5982 - val_accuracy: 0.6595\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1746 - accuracy: 0.9180 - val_loss: 0.6439 - val_accuracy: 0.6574\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1790 - accuracy: 0.9246 - val_loss: 0.5587 - val_accuracy: 0.6862\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1891 - accuracy: 0.9246 - val_loss: 0.5843 - val_accuracy: 0.6821\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1584 - accuracy: 0.9356 - val_loss: 0.5413 - val_accuracy: 0.6852\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1675 - accuracy: 0.9347 - val_loss: 0.5715 - val_accuracy: 0.6944\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1833 - accuracy: 0.9325 - val_loss: 0.5455 - val_accuracy: 0.7181\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.9325 - val_loss: 0.5420 - val_accuracy: 0.7119\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1638 - accuracy: 0.9290 - val_loss: 0.6206 - val_accuracy: 0.6543\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1674 - accuracy: 0.9277 - val_loss: 0.5424 - val_accuracy: 0.7356\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1419 - accuracy: 0.9427 - val_loss: 0.5358 - val_accuracy: 0.7130\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9347 - val_loss: 0.5168 - val_accuracy: 0.7490\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1525 - accuracy: 0.9440 - val_loss: 0.4804 - val_accuracy: 0.7716\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1803 - accuracy: 0.9409 - val_loss: 0.4927 - val_accuracy: 0.7541\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1477 - accuracy: 0.9396 - val_loss: 0.4689 - val_accuracy: 0.7675\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1503 - accuracy: 0.9422 - val_loss: 0.4990 - val_accuracy: 0.7397\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1603 - accuracy: 0.9414 - val_loss: 0.4816 - val_accuracy: 0.7840\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1907 - accuracy: 0.9431 - val_loss: 0.5778 - val_accuracy: 0.7191\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1517 - accuracy: 0.9431 - val_loss: 0.4458 - val_accuracy: 0.7953\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1361 - accuracy: 0.9458 - val_loss: 0.4530 - val_accuracy: 0.7860\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1356 - accuracy: 0.9440 - val_loss: 0.4586 - val_accuracy: 0.7716\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1654 - accuracy: 0.9422 - val_loss: 0.4652 - val_accuracy: 0.7932\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1485 - accuracy: 0.9436 - val_loss: 0.4441 - val_accuracy: 0.8045\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1561 - accuracy: 0.9449 - val_loss: 0.4471 - val_accuracy: 0.8045\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1376 - accuracy: 0.9449 - val_loss: 0.4564 - val_accuracy: 0.7819\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1502 - accuracy: 0.9440 - val_loss: 0.4386 - val_accuracy: 0.7953\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1409 - accuracy: 0.9484 - val_loss: 0.4780 - val_accuracy: 0.7695\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1560 - accuracy: 0.9387 - val_loss: 0.5609 - val_accuracy: 0.7335\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9383 - val_loss: 0.4969 - val_accuracy: 0.7582\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1503 - accuracy: 0.9400 - val_loss: 0.5133 - val_accuracy: 0.7459\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1354 - accuracy: 0.9524 - val_loss: 0.4504 - val_accuracy: 0.7870\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1442 - accuracy: 0.9444 - val_loss: 0.4451 - val_accuracy: 0.7912\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1412 - accuracy: 0.9458 - val_loss: 0.4570 - val_accuracy: 0.7870\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1641 - accuracy: 0.9506 - val_loss: 0.4334 - val_accuracy: 0.7840\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1396 - accuracy: 0.9453 - val_loss: 0.4453 - val_accuracy: 0.8025\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1621 - accuracy: 0.9383 - val_loss: 0.4517 - val_accuracy: 0.7665\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1456 - accuracy: 0.9466 - val_loss: 0.4537 - val_accuracy: 0.7757\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1808 - accuracy: 0.9502 - val_loss: 0.4512 - val_accuracy: 0.7767\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1517 - accuracy: 0.9436 - val_loss: 0.4410 - val_accuracy: 0.7860\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1576 - accuracy: 0.9436 - val_loss: 0.4137 - val_accuracy: 0.8014\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1677 - accuracy: 0.9440 - val_loss: 0.4538 - val_accuracy: 0.7850\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1617 - accuracy: 0.9378 - val_loss: 0.4428 - val_accuracy: 0.8025\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1290 - accuracy: 0.9506 - val_loss: 0.4588 - val_accuracy: 0.7819\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1532 - accuracy: 0.9383 - val_loss: 0.4259 - val_accuracy: 0.8025\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1479 - accuracy: 0.9449 - val_loss: 0.4175 - val_accuracy: 0.8107\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1506 - accuracy: 0.9462 - val_loss: 0.4462 - val_accuracy: 0.7932\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1630 - accuracy: 0.9484 - val_loss: 0.4448 - val_accuracy: 0.7809\n","Score: 0.7808641791343689 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 480.5523 - accuracy: 0.9083 - val_loss: 0.6911 - val_accuracy: 0.5319\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2063 - accuracy: 0.9211 - val_loss: 0.6932 - val_accuracy: 0.5021\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2600 - accuracy: 0.9184 - val_loss: 0.7162 - val_accuracy: 0.5082\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2572 - accuracy: 0.9145 - val_loss: 0.7026 - val_accuracy: 0.5195\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2672 - accuracy: 0.9131 - val_loss: 0.7105 - val_accuracy: 0.5062\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2695 - accuracy: 0.9140 - val_loss: 0.7217 - val_accuracy: 0.5144\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2676 - accuracy: 0.9105 - val_loss: 0.7110 - val_accuracy: 0.5031\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2658 - accuracy: 0.9149 - val_loss: 0.7137 - val_accuracy: 0.5216\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2731 - accuracy: 0.9105 - val_loss: 0.7164 - val_accuracy: 0.5041\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2659 - accuracy: 0.9078 - val_loss: 0.6948 - val_accuracy: 0.5103\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2795 - accuracy: 0.9123 - val_loss: 0.7027 - val_accuracy: 0.5154\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2733 - accuracy: 0.9114 - val_loss: 0.7075 - val_accuracy: 0.5226\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2627 - accuracy: 0.9184 - val_loss: 0.7177 - val_accuracy: 0.5278\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2661 - accuracy: 0.9131 - val_loss: 0.7094 - val_accuracy: 0.5206\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2660 - accuracy: 0.9123 - val_loss: 0.7090 - val_accuracy: 0.5082\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2677 - accuracy: 0.9136 - val_loss: 0.7115 - val_accuracy: 0.5000\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2684 - accuracy: 0.9109 - val_loss: 0.7047 - val_accuracy: 0.5144\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2680 - accuracy: 0.9145 - val_loss: 0.7057 - val_accuracy: 0.5237\n","Epoch 19/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2718 - accuracy: 0.9096 - val_loss: 0.6982 - val_accuracy: 0.5154\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2667 - accuracy: 0.9193 - val_loss: 0.7150 - val_accuracy: 0.5288\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2572 - accuracy: 0.9198 - val_loss: 0.7205 - val_accuracy: 0.5165\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2648 - accuracy: 0.9131 - val_loss: 0.7124 - val_accuracy: 0.5103\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2669 - accuracy: 0.9140 - val_loss: 0.6991 - val_accuracy: 0.5247\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2660 - accuracy: 0.9140 - val_loss: 0.7085 - val_accuracy: 0.5154\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2608 - accuracy: 0.9206 - val_loss: 0.7493 - val_accuracy: 0.5031\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2582 - accuracy: 0.9167 - val_loss: 0.7182 - val_accuracy: 0.5021\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2591 - accuracy: 0.9158 - val_loss: 0.6972 - val_accuracy: 0.5267\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2741 - accuracy: 0.9123 - val_loss: 0.7097 - val_accuracy: 0.5195\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2701 - accuracy: 0.9131 - val_loss: 0.7061 - val_accuracy: 0.5237\n","Epoch 30/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2616 - accuracy: 0.9171 - val_loss: 0.7237 - val_accuracy: 0.5123\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2637 - accuracy: 0.9162 - val_loss: 0.7164 - val_accuracy: 0.5175\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2651 - accuracy: 0.9101 - val_loss: 0.6958 - val_accuracy: 0.5093\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2712 - accuracy: 0.9153 - val_loss: 0.7153 - val_accuracy: 0.5216\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2597 - accuracy: 0.9153 - val_loss: 0.7031 - val_accuracy: 0.5185\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2670 - accuracy: 0.9171 - val_loss: 0.7190 - val_accuracy: 0.5175\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2553 - accuracy: 0.9189 - val_loss: 0.7031 - val_accuracy: 0.5257\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2573 - accuracy: 0.9211 - val_loss: 0.7215 - val_accuracy: 0.5175\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2607 - accuracy: 0.9149 - val_loss: 0.7133 - val_accuracy: 0.4959\n","Epoch 39/50\n","567/567 [==============================] - 4s 7ms/step - loss: 0.2594 - accuracy: 0.9158 - val_loss: 0.7033 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2690 - accuracy: 0.9167 - val_loss: 0.7222 - val_accuracy: 0.5216\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2618 - accuracy: 0.9145 - val_loss: 0.7079 - val_accuracy: 0.5185\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2628 - accuracy: 0.9189 - val_loss: 0.7200 - val_accuracy: 0.5226\n","Epoch 43/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2679 - accuracy: 0.9127 - val_loss: 0.7178 - val_accuracy: 0.5144\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2655 - accuracy: 0.9118 - val_loss: 0.7081 - val_accuracy: 0.4979\n","Epoch 45/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2676 - accuracy: 0.9131 - val_loss: 0.7036 - val_accuracy: 0.5123\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2743 - accuracy: 0.9078 - val_loss: 0.6967 - val_accuracy: 0.5257\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2683 - accuracy: 0.9123 - val_loss: 0.6978 - val_accuracy: 0.5175\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2647 - accuracy: 0.9220 - val_loss: 0.7510 - val_accuracy: 0.5082\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2629 - accuracy: 0.9123 - val_loss: 0.7089 - val_accuracy: 0.4959\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2656 - accuracy: 0.9167 - val_loss: 0.7140 - val_accuracy: 0.5185\n","Score: 0.5185185074806213 \n","Parameters:  {'learning_rate': 0.022818217350525978, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.9591 - accuracy: 0.9153 - val_loss: 0.6419 - val_accuracy: 0.7037\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1826 - accuracy: 0.9153 - val_loss: 0.6199 - val_accuracy: 0.6512\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1758 - accuracy: 0.9096 - val_loss: 0.6274 - val_accuracy: 0.6574\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2080 - accuracy: 0.9202 - val_loss: 0.6262 - val_accuracy: 0.6163\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1628 - accuracy: 0.9228 - val_loss: 0.5915 - val_accuracy: 0.7037\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2379 - accuracy: 0.9140 - val_loss: 0.5932 - val_accuracy: 0.6749\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9299 - val_loss: 0.6105 - val_accuracy: 0.6389\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1624 - accuracy: 0.9206 - val_loss: 0.5656 - val_accuracy: 0.6914\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1833 - accuracy: 0.9242 - val_loss: 0.5662 - val_accuracy: 0.7130\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3002 - accuracy: 0.9325 - val_loss: 0.5565 - val_accuracy: 0.6934\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2158 - accuracy: 0.9303 - val_loss: 0.5738 - val_accuracy: 0.6903\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1584 - accuracy: 0.9339 - val_loss: 0.5179 - val_accuracy: 0.7150\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1962 - accuracy: 0.9334 - val_loss: 0.5052 - val_accuracy: 0.7191\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1745 - accuracy: 0.9361 - val_loss: 0.5413 - val_accuracy: 0.7253\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1625 - accuracy: 0.9365 - val_loss: 0.5535 - val_accuracy: 0.7665\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2034 - accuracy: 0.9352 - val_loss: 0.5328 - val_accuracy: 0.7284\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1554 - accuracy: 0.9378 - val_loss: 0.5464 - val_accuracy: 0.7130\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1706 - accuracy: 0.9259 - val_loss: 0.5204 - val_accuracy: 0.7150\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1534 - accuracy: 0.9352 - val_loss: 0.5421 - val_accuracy: 0.7490\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2543 - accuracy: 0.9334 - val_loss: 0.5302 - val_accuracy: 0.7418\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1447 - accuracy: 0.9400 - val_loss: 0.5202 - val_accuracy: 0.7356\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1679 - accuracy: 0.9308 - val_loss: 0.5232 - val_accuracy: 0.7294\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1537 - accuracy: 0.9378 - val_loss: 0.4934 - val_accuracy: 0.7469\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1554 - accuracy: 0.9444 - val_loss: 0.5089 - val_accuracy: 0.7428\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1732 - accuracy: 0.9361 - val_loss: 0.4704 - val_accuracy: 0.7788\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1977 - accuracy: 0.9325 - val_loss: 0.4609 - val_accuracy: 0.7788\n","Epoch 27/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1393 - accuracy: 0.9414 - val_loss: 0.4410 - val_accuracy: 0.7840\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3688 - accuracy: 0.9444 - val_loss: 0.4268 - val_accuracy: 0.7973\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1391 - accuracy: 0.9422 - val_loss: 0.4859 - val_accuracy: 0.7479\n","Epoch 30/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1329 - accuracy: 0.9497 - val_loss: 0.4565 - val_accuracy: 0.7901\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1585 - accuracy: 0.9361 - val_loss: 0.4354 - val_accuracy: 0.8107\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1312 - accuracy: 0.9502 - val_loss: 0.4940 - val_accuracy: 0.7407\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2122 - accuracy: 0.9418 - val_loss: 0.4636 - val_accuracy: 0.7695\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1592 - accuracy: 0.9497 - val_loss: 0.4395 - val_accuracy: 0.7860\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1353 - accuracy: 0.9502 - val_loss: 0.3728 - val_accuracy: 0.8467\n","Epoch 36/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1232 - accuracy: 0.9550 - val_loss: 0.3892 - val_accuracy: 0.8364\n","Epoch 37/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1681 - accuracy: 0.9511 - val_loss: 0.3782 - val_accuracy: 0.8261\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 0.4046 - val_accuracy: 0.8138\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1262 - accuracy: 0.9577 - val_loss: 0.3499 - val_accuracy: 0.8405\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1232 - accuracy: 0.9506 - val_loss: 0.4210 - val_accuracy: 0.8097\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1416 - accuracy: 0.9524 - val_loss: 0.3745 - val_accuracy: 0.8344\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1305 - accuracy: 0.9506 - val_loss: 0.3438 - val_accuracy: 0.8447\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9625 - val_loss: 0.2972 - val_accuracy: 0.8724\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1106 - accuracy: 0.9683 - val_loss: 0.3555 - val_accuracy: 0.8261\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0873 - accuracy: 0.9691 - val_loss: 0.2708 - val_accuracy: 0.8807\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0970 - accuracy: 0.9687 - val_loss: 0.2758 - val_accuracy: 0.8920\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0996 - accuracy: 0.9656 - val_loss: 0.3756 - val_accuracy: 0.8488\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0839 - accuracy: 0.9744 - val_loss: 0.2243 - val_accuracy: 0.9033\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0903 - accuracy: 0.9705 - val_loss: 0.2887 - val_accuracy: 0.8601\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0578 - accuracy: 0.9780 - val_loss: 0.2465 - val_accuracy: 0.9002\n","Score: 0.9002057909965515 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.6574 - accuracy: 0.9167 - val_loss: 0.6381 - val_accuracy: 0.6986\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1830 - accuracy: 0.9308 - val_loss: 0.5764 - val_accuracy: 0.7068\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2032 - accuracy: 0.9365 - val_loss: 0.6166 - val_accuracy: 0.6543\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1572 - accuracy: 0.9365 - val_loss: 0.5074 - val_accuracy: 0.7500\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1559 - accuracy: 0.9396 - val_loss: 0.4841 - val_accuracy: 0.7922\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1509 - accuracy: 0.9431 - val_loss: 0.4634 - val_accuracy: 0.7726\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1419 - accuracy: 0.9466 - val_loss: 0.4359 - val_accuracy: 0.8035\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1430 - accuracy: 0.9444 - val_loss: 0.4504 - val_accuracy: 0.7994\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1556 - accuracy: 0.9515 - val_loss: 0.4434 - val_accuracy: 0.8004\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1780 - accuracy: 0.9475 - val_loss: 0.4298 - val_accuracy: 0.7922\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1432 - accuracy: 0.9453 - val_loss: 0.4365 - val_accuracy: 0.7932\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9519 - val_loss: 0.4597 - val_accuracy: 0.7819\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1501 - accuracy: 0.9484 - val_loss: 0.4126 - val_accuracy: 0.7953\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1786 - accuracy: 0.9484 - val_loss: 0.4206 - val_accuracy: 0.8169\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9515 - val_loss: 0.4277 - val_accuracy: 0.7850\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1555 - accuracy: 0.9608 - val_loss: 0.3967 - val_accuracy: 0.8405\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9506 - val_loss: 0.4078 - val_accuracy: 0.8416\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1194 - accuracy: 0.9563 - val_loss: 0.3580 - val_accuracy: 0.8323\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1234 - accuracy: 0.9524 - val_loss: 0.3306 - val_accuracy: 0.8539\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1219 - accuracy: 0.9533 - val_loss: 0.3401 - val_accuracy: 0.8560\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0930 - accuracy: 0.9625 - val_loss: 0.3137 - val_accuracy: 0.8632\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9643 - val_loss: 0.4273 - val_accuracy: 0.8333\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0954 - accuracy: 0.9665 - val_loss: 0.3140 - val_accuracy: 0.8539\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1226 - accuracy: 0.9594 - val_loss: 0.3508 - val_accuracy: 0.8333\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1097 - accuracy: 0.9634 - val_loss: 0.3042 - val_accuracy: 0.8724\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0898 - accuracy: 0.9709 - val_loss: 0.4287 - val_accuracy: 0.8148\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0967 - accuracy: 0.9669 - val_loss: 0.3567 - val_accuracy: 0.8673\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1052 - accuracy: 0.9634 - val_loss: 0.2956 - val_accuracy: 0.8621\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.2726 - val_accuracy: 0.8879\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1019 - accuracy: 0.9647 - val_loss: 0.2714 - val_accuracy: 0.8745\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9643 - val_loss: 0.3197 - val_accuracy: 0.8591\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1560 - accuracy: 0.9563 - val_loss: 0.3326 - val_accuracy: 0.8539\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1137 - accuracy: 0.9612 - val_loss: 0.3094 - val_accuracy: 0.8807\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1025 - accuracy: 0.9665 - val_loss: 0.2535 - val_accuracy: 0.9023\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1003 - accuracy: 0.9660 - val_loss: 0.2483 - val_accuracy: 0.8930\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0944 - accuracy: 0.9687 - val_loss: 0.2907 - val_accuracy: 0.8868\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0730 - accuracy: 0.9771 - val_loss: 0.2618 - val_accuracy: 0.8868\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0914 - accuracy: 0.9669 - val_loss: 0.2519 - val_accuracy: 0.8879\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0844 - accuracy: 0.9696 - val_loss: 0.2404 - val_accuracy: 0.9043\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0817 - accuracy: 0.9744 - val_loss: 0.2409 - val_accuracy: 0.9012\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1806 - accuracy: 0.9740 - val_loss: 0.2449 - val_accuracy: 0.9095\n","Epoch 42/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.3838 - accuracy: 0.9594 - val_loss: 0.3232 - val_accuracy: 0.8549\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0897 - accuracy: 0.9718 - val_loss: 0.2907 - val_accuracy: 0.8704\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1035 - accuracy: 0.9660 - val_loss: 0.2086 - val_accuracy: 0.9023\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0849 - accuracy: 0.9727 - val_loss: 0.2348 - val_accuracy: 0.9095\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0900 - accuracy: 0.9727 - val_loss: 0.2448 - val_accuracy: 0.8930\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0614 - accuracy: 0.9771 - val_loss: 0.2263 - val_accuracy: 0.9033\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0596 - accuracy: 0.9771 - val_loss: 0.2134 - val_accuracy: 0.9156\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0596 - accuracy: 0.9771 - val_loss: 0.1980 - val_accuracy: 0.9228\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0658 - accuracy: 0.9824 - val_loss: 0.2136 - val_accuracy: 0.9156\n","Score: 0.9156378507614136 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 278173.4688 - accuracy: 0.8889 - val_loss: 1.1973 - val_accuracy: 0.5195\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.4638 - accuracy: 0.8889 - val_loss: 1.2219 - val_accuracy: 0.4887\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2778 - accuracy: 0.9012 - val_loss: 0.7062 - val_accuracy: 0.4877\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2678 - accuracy: 0.8990 - val_loss: 2.5282 - val_accuracy: 0.5072\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2749 - accuracy: 0.8951 - val_loss: 1.0005 - val_accuracy: 0.4691\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3793 - accuracy: 0.8955 - val_loss: 1.9461 - val_accuracy: 0.5134\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2872 - accuracy: 0.8942 - val_loss: 0.8726 - val_accuracy: 0.4856\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2427 - accuracy: 0.8999 - val_loss: 0.6925 - val_accuracy: 0.5206\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2384 - accuracy: 0.9074 - val_loss: 2.0013 - val_accuracy: 0.4825\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3190 - accuracy: 0.8849 - val_loss: 0.7848 - val_accuracy: 0.4763\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2547 - accuracy: 0.8929 - val_loss: 0.6977 - val_accuracy: 0.4733\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2497 - accuracy: 0.8959 - val_loss: 0.8370 - val_accuracy: 0.5267\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.8929 - val_loss: 0.8181 - val_accuracy: 0.5288\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2489 - accuracy: 0.8951 - val_loss: 0.7247 - val_accuracy: 0.4856\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2437 - accuracy: 0.8990 - val_loss: 0.8838 - val_accuracy: 0.4825\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2004 - accuracy: 0.9074 - val_loss: 0.7177 - val_accuracy: 0.4815\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2112 - accuracy: 0.8942 - val_loss: 0.6947 - val_accuracy: 0.4959\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9043 - val_loss: 0.6921 - val_accuracy: 0.5298\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2013 - accuracy: 0.9167 - val_loss: 0.7116 - val_accuracy: 0.5051\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.8990 - val_loss: 0.6963 - val_accuracy: 0.5072\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9149 - val_loss: 0.6970 - val_accuracy: 0.4835\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9078 - val_loss: 0.7026 - val_accuracy: 0.5082\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9096 - val_loss: 0.6993 - val_accuracy: 0.4763\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.9026 - val_loss: 0.6920 - val_accuracy: 0.5237\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9167 - val_loss: 0.7028 - val_accuracy: 0.5144\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1924 - accuracy: 0.9140 - val_loss: 0.7045 - val_accuracy: 0.5226\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9162 - val_loss: 0.7030 - val_accuracy: 0.4928\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2057 - accuracy: 0.8964 - val_loss: 0.7087 - val_accuracy: 0.4763\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2047 - accuracy: 0.8995 - val_loss: 0.7150 - val_accuracy: 0.5062\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2001 - accuracy: 0.9167 - val_loss: 0.7135 - val_accuracy: 0.5062\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9193 - val_loss: 0.7202 - val_accuracy: 0.5031\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9123 - val_loss: 0.7010 - val_accuracy: 0.4722\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2031 - accuracy: 0.9083 - val_loss: 0.7124 - val_accuracy: 0.5278\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1960 - accuracy: 0.9140 - val_loss: 0.6935 - val_accuracy: 0.5072\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2075 - accuracy: 0.9167 - val_loss: 0.6943 - val_accuracy: 0.5062\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2063 - accuracy: 0.9118 - val_loss: 0.7136 - val_accuracy: 0.4887\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2013 - accuracy: 0.8995 - val_loss: 0.6966 - val_accuracy: 0.4733\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9123 - val_loss: 0.7112 - val_accuracy: 0.4753\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9083 - val_loss: 0.6967 - val_accuracy: 0.5154\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9123 - val_loss: 0.7353 - val_accuracy: 0.5082\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9118 - val_loss: 0.6940 - val_accuracy: 0.4846\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9171 - val_loss: 0.6919 - val_accuracy: 0.5247\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9206 - val_loss: 0.6916 - val_accuracy: 0.5298\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2000 - accuracy: 0.9136 - val_loss: 0.6930 - val_accuracy: 0.5093\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9105 - val_loss: 0.6985 - val_accuracy: 0.4825\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9065 - val_loss: 0.7237 - val_accuracy: 0.4887\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1992 - accuracy: 0.9043 - val_loss: 0.6922 - val_accuracy: 0.5216\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1948 - accuracy: 0.9153 - val_loss: 0.6933 - val_accuracy: 0.4928\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1965 - accuracy: 0.9096 - val_loss: 0.6980 - val_accuracy: 0.4805\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2081 - accuracy: 0.9034 - val_loss: 0.6947 - val_accuracy: 0.4887\n","Score: 0.48868313431739807 \n","Parameters:  {'learning_rate': 0.1141409411536749, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 1.0368 - accuracy: 0.9158 - val_loss: 0.6415 - val_accuracy: 0.6749\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1622 - accuracy: 0.9220 - val_loss: 0.6249 - val_accuracy: 0.6183\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.4258 - accuracy: 0.9281 - val_loss: 0.6645 - val_accuracy: 0.5936\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1779 - accuracy: 0.9118 - val_loss: 0.6243 - val_accuracy: 0.6903\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1850 - accuracy: 0.9083 - val_loss: 0.6708 - val_accuracy: 0.5278\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1825 - accuracy: 0.9180 - val_loss: 0.6022 - val_accuracy: 0.6595\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9039 - val_loss: 0.6164 - val_accuracy: 0.5525\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2056 - accuracy: 0.9074 - val_loss: 0.6233 - val_accuracy: 0.5237\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1704 - accuracy: 0.9220 - val_loss: 0.5604 - val_accuracy: 0.6780\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1533 - accuracy: 0.9387 - val_loss: 0.5498 - val_accuracy: 0.6996\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1736 - accuracy: 0.9228 - val_loss: 0.5589 - val_accuracy: 0.7212\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1693 - accuracy: 0.9202 - val_loss: 0.5486 - val_accuracy: 0.7263\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1617 - accuracy: 0.9343 - val_loss: 0.5084 - val_accuracy: 0.7572\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1683 - accuracy: 0.9321 - val_loss: 0.5262 - val_accuracy: 0.7510\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1603 - accuracy: 0.9400 - val_loss: 0.5191 - val_accuracy: 0.7428\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2968 - accuracy: 0.9325 - val_loss: 0.4751 - val_accuracy: 0.7716\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1651 - accuracy: 0.9475 - val_loss: 0.4760 - val_accuracy: 0.7716\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9440 - val_loss: 0.4586 - val_accuracy: 0.7572\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9422 - val_loss: 0.4568 - val_accuracy: 0.7829\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1531 - accuracy: 0.9383 - val_loss: 0.5084 - val_accuracy: 0.7634\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1533 - accuracy: 0.9374 - val_loss: 0.4806 - val_accuracy: 0.7788\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1516 - accuracy: 0.9422 - val_loss: 0.4632 - val_accuracy: 0.7901\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1548 - accuracy: 0.9374 - val_loss: 0.4411 - val_accuracy: 0.7922\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9528 - val_loss: 0.4235 - val_accuracy: 0.8025\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1486 - accuracy: 0.9480 - val_loss: 0.4435 - val_accuracy: 0.7819\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1621 - accuracy: 0.9449 - val_loss: 0.4417 - val_accuracy: 0.7860\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9427 - val_loss: 0.5019 - val_accuracy: 0.7459\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1544 - accuracy: 0.9444 - val_loss: 0.4906 - val_accuracy: 0.7593\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9480 - val_loss: 0.4409 - val_accuracy: 0.7840\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1507 - accuracy: 0.9466 - val_loss: 0.4707 - val_accuracy: 0.7829\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3061 - accuracy: 0.9290 - val_loss: 0.4770 - val_accuracy: 0.7737\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1596 - accuracy: 0.9418 - val_loss: 0.4296 - val_accuracy: 0.8004\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1288 - accuracy: 0.9533 - val_loss: 0.4563 - val_accuracy: 0.7953\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1506 - accuracy: 0.9414 - val_loss: 0.4516 - val_accuracy: 0.7819\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1896 - accuracy: 0.9475 - val_loss: 0.4103 - val_accuracy: 0.7963\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1304 - accuracy: 0.9484 - val_loss: 0.4264 - val_accuracy: 0.8158\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9489 - val_loss: 0.4100 - val_accuracy: 0.8097\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1908 - accuracy: 0.9493 - val_loss: 0.4318 - val_accuracy: 0.7901\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9515 - val_loss: 0.4402 - val_accuracy: 0.7922\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1367 - accuracy: 0.9519 - val_loss: 0.4098 - val_accuracy: 0.8025\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9497 - val_loss: 0.4249 - val_accuracy: 0.7994\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1545 - accuracy: 0.9365 - val_loss: 0.4072 - val_accuracy: 0.7994\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1511 - accuracy: 0.9409 - val_loss: 0.4390 - val_accuracy: 0.7963\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1234 - accuracy: 0.9515 - val_loss: 0.4124 - val_accuracy: 0.8086\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1406 - accuracy: 0.9480 - val_loss: 0.4208 - val_accuracy: 0.8025\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9431 - val_loss: 0.4190 - val_accuracy: 0.7901\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1380 - accuracy: 0.9502 - val_loss: 0.4231 - val_accuracy: 0.8066\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1298 - accuracy: 0.9524 - val_loss: 0.4065 - val_accuracy: 0.8117\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1578 - accuracy: 0.9462 - val_loss: 0.3891 - val_accuracy: 0.8230\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1420 - accuracy: 0.9444 - val_loss: 0.3883 - val_accuracy: 0.8169\n","Score: 0.8168724179267883 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.6943 - accuracy: 0.9118 - val_loss: 0.6528 - val_accuracy: 0.6111\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1847 - accuracy: 0.9127 - val_loss: 0.6631 - val_accuracy: 0.5288\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1868 - accuracy: 0.9220 - val_loss: 0.6165 - val_accuracy: 0.6379\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1785 - accuracy: 0.9325 - val_loss: 0.5916 - val_accuracy: 0.6698\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1516 - accuracy: 0.9400 - val_loss: 0.5269 - val_accuracy: 0.7449\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2011 - accuracy: 0.9374 - val_loss: 0.5565 - val_accuracy: 0.7099\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1635 - accuracy: 0.9440 - val_loss: 0.5068 - val_accuracy: 0.7377\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2044 - accuracy: 0.9347 - val_loss: 0.6139 - val_accuracy: 0.6862\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1494 - accuracy: 0.9396 - val_loss: 0.5301 - val_accuracy: 0.7233\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1612 - accuracy: 0.9330 - val_loss: 0.5026 - val_accuracy: 0.7407\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1506 - accuracy: 0.9392 - val_loss: 0.5107 - val_accuracy: 0.7479\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1348 - accuracy: 0.9524 - val_loss: 0.4566 - val_accuracy: 0.7706\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9347 - val_loss: 0.4685 - val_accuracy: 0.7767\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1433 - accuracy: 0.9418 - val_loss: 0.4625 - val_accuracy: 0.7716\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1422 - accuracy: 0.9466 - val_loss: 0.4582 - val_accuracy: 0.7706\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1352 - accuracy: 0.9471 - val_loss: 0.4898 - val_accuracy: 0.7634\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1829 - accuracy: 0.9387 - val_loss: 0.5357 - val_accuracy: 0.7377\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1605 - accuracy: 0.9361 - val_loss: 0.4704 - val_accuracy: 0.7829\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0011 - accuracy: 0.9334 - val_loss: 0.4883 - val_accuracy: 0.7716\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1420 - accuracy: 0.9453 - val_loss: 0.4494 - val_accuracy: 0.7747\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1540 - accuracy: 0.9418 - val_loss: 0.5054 - val_accuracy: 0.7407\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1481 - accuracy: 0.9462 - val_loss: 0.4564 - val_accuracy: 0.7860\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1409 - accuracy: 0.9480 - val_loss: 0.4080 - val_accuracy: 0.8148\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1325 - accuracy: 0.9497 - val_loss: 0.4538 - val_accuracy: 0.7912\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1437 - accuracy: 0.9405 - val_loss: 0.4310 - val_accuracy: 0.8056\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1509 - accuracy: 0.9436 - val_loss: 0.4166 - val_accuracy: 0.8066\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.9515 - val_loss: 0.4690 - val_accuracy: 0.7819\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2312 - accuracy: 0.9409 - val_loss: 0.4185 - val_accuracy: 0.8107\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1448 - accuracy: 0.9533 - val_loss: 0.4348 - val_accuracy: 0.8035\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1786 - accuracy: 0.9409 - val_loss: 0.4511 - val_accuracy: 0.7870\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1560 - accuracy: 0.9378 - val_loss: 0.4063 - val_accuracy: 0.8117\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1457 - accuracy: 0.9392 - val_loss: 0.5076 - val_accuracy: 0.7510\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1272 - accuracy: 0.9541 - val_loss: 0.5109 - val_accuracy: 0.7613\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1563 - accuracy: 0.9387 - val_loss: 0.4005 - val_accuracy: 0.7973\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1600 - accuracy: 0.9369 - val_loss: 0.4188 - val_accuracy: 0.8025\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1477 - accuracy: 0.9489 - val_loss: 0.4153 - val_accuracy: 0.8097\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1632 - accuracy: 0.9440 - val_loss: 0.4074 - val_accuracy: 0.8128\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1454 - accuracy: 0.9515 - val_loss: 0.4759 - val_accuracy: 0.7603\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9484 - val_loss: 0.4082 - val_accuracy: 0.8076\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9590 - val_loss: 0.3926 - val_accuracy: 0.8210\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2251 - accuracy: 0.9528 - val_loss: 0.4233 - val_accuracy: 0.8004\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1500 - accuracy: 0.9506 - val_loss: 0.3843 - val_accuracy: 0.8251\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1403 - accuracy: 0.9519 - val_loss: 0.3843 - val_accuracy: 0.8323\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1265 - accuracy: 0.9559 - val_loss: 0.4232 - val_accuracy: 0.8128\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9489 - val_loss: 0.3925 - val_accuracy: 0.8282\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9489 - val_loss: 0.3898 - val_accuracy: 0.8148\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1271 - accuracy: 0.9497 - val_loss: 0.3803 - val_accuracy: 0.8230\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1232 - accuracy: 0.9555 - val_loss: 0.3697 - val_accuracy: 0.8200\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1493 - accuracy: 0.9555 - val_loss: 0.4280 - val_accuracy: 0.8004\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1337 - accuracy: 0.9533 - val_loss: 0.4258 - val_accuracy: 0.7912\n","Score: 0.7911522388458252 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6819 - accuracy: 0.9268 - val_loss: 0.6231 - val_accuracy: 0.6708\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1752 - accuracy: 0.9224 - val_loss: 0.6118 - val_accuracy: 0.6965\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1623 - accuracy: 0.9189 - val_loss: 0.5413 - val_accuracy: 0.7222\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1508 - accuracy: 0.9325 - val_loss: 0.5610 - val_accuracy: 0.7150\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1621 - accuracy: 0.9246 - val_loss: 0.5294 - val_accuracy: 0.7654\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1591 - accuracy: 0.9246 - val_loss: 0.5693 - val_accuracy: 0.7449\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2382 - accuracy: 0.9246 - val_loss: 0.5539 - val_accuracy: 0.7449\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1533 - accuracy: 0.9339 - val_loss: 0.5157 - val_accuracy: 0.7541\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1507 - accuracy: 0.9303 - val_loss: 0.5168 - val_accuracy: 0.7305\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2752 - accuracy: 0.9299 - val_loss: 0.4796 - val_accuracy: 0.7562\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9427 - val_loss: 0.4656 - val_accuracy: 0.7562\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1584 - accuracy: 0.9405 - val_loss: 0.4488 - val_accuracy: 0.7809\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1398 - accuracy: 0.9436 - val_loss: 0.4159 - val_accuracy: 0.8169\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1807 - accuracy: 0.9427 - val_loss: 0.4791 - val_accuracy: 0.7881\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9400 - val_loss: 0.4563 - val_accuracy: 0.7891\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1477 - accuracy: 0.9480 - val_loss: 0.3976 - val_accuracy: 0.8035\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1429 - accuracy: 0.9466 - val_loss: 0.4399 - val_accuracy: 0.8035\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.9440 - val_loss: 0.4568 - val_accuracy: 0.7767\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1224 - accuracy: 0.9568 - val_loss: 0.4585 - val_accuracy: 0.7778\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1137 - accuracy: 0.9546 - val_loss: 0.3992 - val_accuracy: 0.8158\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4858 - accuracy: 0.9303 - val_loss: 0.4483 - val_accuracy: 0.7973\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1534 - accuracy: 0.9489 - val_loss: 0.3982 - val_accuracy: 0.8251\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1414 - accuracy: 0.9449 - val_loss: 0.3922 - val_accuracy: 0.8261\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1608 - accuracy: 0.9537 - val_loss: 0.3482 - val_accuracy: 0.8374\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2481 - accuracy: 0.9449 - val_loss: 0.4330 - val_accuracy: 0.7788\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1193 - accuracy: 0.9555 - val_loss: 0.3646 - val_accuracy: 0.8200\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1027 - accuracy: 0.9630 - val_loss: 0.3926 - val_accuracy: 0.8272\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9630 - val_loss: 0.3395 - val_accuracy: 0.8467\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0885 - accuracy: 0.9669 - val_loss: 0.3442 - val_accuracy: 0.8549\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9586 - val_loss: 0.3697 - val_accuracy: 0.8272\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1028 - accuracy: 0.9590 - val_loss: 0.3842 - val_accuracy: 0.8076\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1158 - accuracy: 0.9568 - val_loss: 0.4133 - val_accuracy: 0.8302\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1721 - accuracy: 0.9550 - val_loss: 0.2912 - val_accuracy: 0.8735\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0948 - accuracy: 0.9678 - val_loss: 0.3314 - val_accuracy: 0.8467\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1282 - accuracy: 0.9568 - val_loss: 0.3588 - val_accuracy: 0.8364\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.9577 - val_loss: 0.3654 - val_accuracy: 0.8426\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1884 - accuracy: 0.9533 - val_loss: 0.3145 - val_accuracy: 0.8580\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1197 - accuracy: 0.9594 - val_loss: 0.3389 - val_accuracy: 0.8477\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2104 - accuracy: 0.9590 - val_loss: 0.3851 - val_accuracy: 0.7994\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0865 - accuracy: 0.9674 - val_loss: 0.3525 - val_accuracy: 0.8272\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0869 - accuracy: 0.9678 - val_loss: 0.3252 - val_accuracy: 0.8426\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0939 - accuracy: 0.9647 - val_loss: 0.2833 - val_accuracy: 0.8621\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1030 - accuracy: 0.9608 - val_loss: 0.2827 - val_accuracy: 0.8848\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9638 - val_loss: 0.3245 - val_accuracy: 0.8447\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0876 - accuracy: 0.9669 - val_loss: 0.2792 - val_accuracy: 0.8683\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0886 - accuracy: 0.9713 - val_loss: 0.4129 - val_accuracy: 0.8457\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0725 - accuracy: 0.9762 - val_loss: 0.2623 - val_accuracy: 0.8837\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0853 - accuracy: 0.9643 - val_loss: 0.3483 - val_accuracy: 0.8796\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1529 - accuracy: 0.9590 - val_loss: 0.2779 - val_accuracy: 0.8591\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1504 - accuracy: 0.9625 - val_loss: 0.2753 - val_accuracy: 0.8570\n","Score: 0.8569958806037903 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 8284.7705 - accuracy: 0.9070 - val_loss: 0.7047 - val_accuracy: 0.5195\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9171 - val_loss: 0.7005 - val_accuracy: 0.5185\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.9083 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2482 - accuracy: 0.9101 - val_loss: 0.6955 - val_accuracy: 0.5093\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2280 - accuracy: 0.9149 - val_loss: 0.6936 - val_accuracy: 0.4784\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2401 - accuracy: 0.9070 - val_loss: 0.6958 - val_accuracy: 0.4918\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2387 - accuracy: 0.9070 - val_loss: 0.6955 - val_accuracy: 0.5000\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2511 - accuracy: 0.9008 - val_loss: 0.6969 - val_accuracy: 0.5082\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2377 - accuracy: 0.9101 - val_loss: 0.6998 - val_accuracy: 0.4743\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2463 - accuracy: 0.9004 - val_loss: 0.6934 - val_accuracy: 0.5154\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2369 - accuracy: 0.9206 - val_loss: 0.7109 - val_accuracy: 0.5123\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2432 - accuracy: 0.9109 - val_loss: 0.7021 - val_accuracy: 0.5113\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2296 - accuracy: 0.9228 - val_loss: 0.7104 - val_accuracy: 0.4969\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2378 - accuracy: 0.9171 - val_loss: 0.7051 - val_accuracy: 0.5082\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2365 - accuracy: 0.9127 - val_loss: 0.6925 - val_accuracy: 0.5257\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2265 - accuracy: 0.9233 - val_loss: 0.6949 - val_accuracy: 0.5144\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2335 - accuracy: 0.9220 - val_loss: 0.7094 - val_accuracy: 0.5041\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2293 - accuracy: 0.9167 - val_loss: 0.6937 - val_accuracy: 0.5165\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2447 - accuracy: 0.9118 - val_loss: 0.6941 - val_accuracy: 0.5103\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2407 - accuracy: 0.9127 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2420 - accuracy: 0.9096 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2334 - accuracy: 0.9149 - val_loss: 0.6944 - val_accuracy: 0.5031\n","Epoch 23/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2416 - accuracy: 0.9153 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2477 - accuracy: 0.9074 - val_loss: 0.6939 - val_accuracy: 0.4928\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2473 - accuracy: 0.9065 - val_loss: 0.7190 - val_accuracy: 0.5072\n","Epoch 26/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.2315 - accuracy: 0.9211 - val_loss: 0.7142 - val_accuracy: 0.5031\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2347 - accuracy: 0.9123 - val_loss: 0.6930 - val_accuracy: 0.5165\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2453 - accuracy: 0.9136 - val_loss: 0.6938 - val_accuracy: 0.5216\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2337 - accuracy: 0.9145 - val_loss: 0.6958 - val_accuracy: 0.4979\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2385 - accuracy: 0.9153 - val_loss: 0.6978 - val_accuracy: 0.4990\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2289 - accuracy: 0.9220 - val_loss: 0.6982 - val_accuracy: 0.5226\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2263 - accuracy: 0.9180 - val_loss: 0.6944 - val_accuracy: 0.4887\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2409 - accuracy: 0.9078 - val_loss: 0.6975 - val_accuracy: 0.5072\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2372 - accuracy: 0.9118 - val_loss: 0.6927 - val_accuracy: 0.5237\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2362 - accuracy: 0.9184 - val_loss: 0.6954 - val_accuracy: 0.5216\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2331 - accuracy: 0.9153 - val_loss: 0.6990 - val_accuracy: 0.4815\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2464 - accuracy: 0.9017 - val_loss: 0.6937 - val_accuracy: 0.5226\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2355 - accuracy: 0.9153 - val_loss: 0.6957 - val_accuracy: 0.5082\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2370 - accuracy: 0.9189 - val_loss: 0.6967 - val_accuracy: 0.5134\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2320 - accuracy: 0.9153 - val_loss: 0.6953 - val_accuracy: 0.4918\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2454 - accuracy: 0.9039 - val_loss: 0.7042 - val_accuracy: 0.5103\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2373 - accuracy: 0.9149 - val_loss: 0.6958 - val_accuracy: 0.5103\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2294 - accuracy: 0.9202 - val_loss: 0.6971 - val_accuracy: 0.5134\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2329 - accuracy: 0.9193 - val_loss: 0.6948 - val_accuracy: 0.5165\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2343 - accuracy: 0.9171 - val_loss: 0.6929 - val_accuracy: 0.5216\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2380 - accuracy: 0.9105 - val_loss: 0.6997 - val_accuracy: 0.5041\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2481 - accuracy: 0.8990 - val_loss: 0.6930 - val_accuracy: 0.5247\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2361 - accuracy: 0.9171 - val_loss: 0.6931 - val_accuracy: 0.5082\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2409 - accuracy: 0.9140 - val_loss: 0.6962 - val_accuracy: 0.4959\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2369 - accuracy: 0.9158 - val_loss: 0.6937 - val_accuracy: 0.4846\n","Score: 0.48456791043281555 \n","Parameters:  {'learning_rate': 0.035501108379805676, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 2255498.0000 - accuracy: 0.9052 - val_loss: 0.6961 - val_accuracy: 0.5165\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2214 - accuracy: 0.8942 - val_loss: 0.7135 - val_accuracy: 0.4815\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2621 - accuracy: 0.8907 - val_loss: 1.1304 - val_accuracy: 0.4835\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2453 - accuracy: 0.8884 - val_loss: 0.7068 - val_accuracy: 0.5154\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2156 - accuracy: 0.8981 - val_loss: 0.6987 - val_accuracy: 0.5144\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2163 - accuracy: 0.9039 - val_loss: 0.7124 - val_accuracy: 0.4959\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1889 - accuracy: 0.9092 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9105 - val_loss: 0.7152 - val_accuracy: 0.5278\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.9078 - val_loss: 0.7282 - val_accuracy: 0.4856\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9101 - val_loss: 0.7004 - val_accuracy: 0.4743\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9092 - val_loss: 0.7240 - val_accuracy: 0.4671\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9105 - val_loss: 0.6952 - val_accuracy: 0.5237\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1867 - accuracy: 0.9105 - val_loss: 0.6942 - val_accuracy: 0.4990\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1818 - accuracy: 0.9123 - val_loss: 0.7049 - val_accuracy: 0.5093\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9127 - val_loss: 0.7182 - val_accuracy: 0.5175\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1932 - accuracy: 0.9145 - val_loss: 0.6915 - val_accuracy: 0.5288\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1816 - accuracy: 0.9175 - val_loss: 0.7051 - val_accuracy: 0.5206\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1848 - accuracy: 0.9171 - val_loss: 0.6936 - val_accuracy: 0.5113\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1822 - accuracy: 0.9153 - val_loss: 0.7560 - val_accuracy: 0.4835\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1962 - accuracy: 0.9026 - val_loss: 0.7025 - val_accuracy: 0.5216\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1939 - accuracy: 0.9092 - val_loss: 0.6994 - val_accuracy: 0.5000\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1942 - accuracy: 0.9021 - val_loss: 0.6920 - val_accuracy: 0.5298\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1903 - accuracy: 0.9092 - val_loss: 0.7056 - val_accuracy: 0.4969\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1769 - accuracy: 0.9171 - val_loss: 0.7014 - val_accuracy: 0.5154\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1858 - accuracy: 0.9184 - val_loss: 0.6952 - val_accuracy: 0.4979\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1941 - accuracy: 0.9136 - val_loss: 0.6939 - val_accuracy: 0.4969\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2002 - accuracy: 0.9021 - val_loss: 0.6953 - val_accuracy: 0.4938\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1966 - accuracy: 0.9039 - val_loss: 0.7025 - val_accuracy: 0.4774\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1904 - accuracy: 0.9052 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2012 - accuracy: 0.9056 - val_loss: 0.6931 - val_accuracy: 0.5072\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1904 - accuracy: 0.9158 - val_loss: 0.7596 - val_accuracy: 0.4835\n","Epoch 32/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1931 - accuracy: 0.9118 - val_loss: 0.7638 - val_accuracy: 0.5144\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1913 - accuracy: 0.9101 - val_loss: 0.7299 - val_accuracy: 0.4815\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1983 - accuracy: 0.8995 - val_loss: 0.7258 - val_accuracy: 0.4887\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1986 - accuracy: 0.9026 - val_loss: 0.7045 - val_accuracy: 0.4763\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1914 - accuracy: 0.9136 - val_loss: 0.6929 - val_accuracy: 0.5144\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1914 - accuracy: 0.9078 - val_loss: 0.6930 - val_accuracy: 0.5154\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1902 - accuracy: 0.9158 - val_loss: 0.7014 - val_accuracy: 0.4866\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1929 - accuracy: 0.9043 - val_loss: 0.7102 - val_accuracy: 0.4866\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1929 - accuracy: 0.9061 - val_loss: 0.7977 - val_accuracy: 0.4959\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1860 - accuracy: 0.9083 - val_loss: 0.6936 - val_accuracy: 0.4877\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1974 - accuracy: 0.9030 - val_loss: 0.7741 - val_accuracy: 0.4990\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1833 - accuracy: 0.9162 - val_loss: 0.6976 - val_accuracy: 0.4949\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9162 - val_loss: 0.7045 - val_accuracy: 0.5010\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9153 - val_loss: 0.7067 - val_accuracy: 0.4897\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1872 - accuracy: 0.9092 - val_loss: 0.7185 - val_accuracy: 0.4846\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1913 - accuracy: 0.9017 - val_loss: 0.6950 - val_accuracy: 0.4815\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1863 - accuracy: 0.9136 - val_loss: 0.6939 - val_accuracy: 0.4846\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9162 - val_loss: 0.7036 - val_accuracy: 0.5051\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9123 - val_loss: 0.6930 - val_accuracy: 0.5257\n","Score: 0.5257201790809631 \n","Parameters:  {'learning_rate': 0.19388059377552258, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.5123 - accuracy: 0.9123 - val_loss: 0.6786 - val_accuracy: 0.5370\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3102 - accuracy: 0.9167 - val_loss: 0.6136 - val_accuracy: 0.6924\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7920 - accuracy: 0.9052 - val_loss: 0.6373 - val_accuracy: 0.6893\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1671 - accuracy: 0.9339 - val_loss: 0.5944 - val_accuracy: 0.7490\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1717 - accuracy: 0.9321 - val_loss: 0.6215 - val_accuracy: 0.7294\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4376 - accuracy: 0.9145 - val_loss: 0.5807 - val_accuracy: 0.7016\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2453 - accuracy: 0.9365 - val_loss: 0.5994 - val_accuracy: 0.7212\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1530 - accuracy: 0.9356 - val_loss: 0.6772 - val_accuracy: 0.6687\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2156 - accuracy: 0.9286 - val_loss: 0.6172 - val_accuracy: 0.7119\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1688 - accuracy: 0.9281 - val_loss: 0.5826 - val_accuracy: 0.7325\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3855 - accuracy: 0.9361 - val_loss: 0.5848 - val_accuracy: 0.7438\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1551 - accuracy: 0.9361 - val_loss: 0.5350 - val_accuracy: 0.7346\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9321 - val_loss: 0.5276 - val_accuracy: 0.7572\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1745 - accuracy: 0.9325 - val_loss: 0.4929 - val_accuracy: 0.7819\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1606 - accuracy: 0.9361 - val_loss: 0.5285 - val_accuracy: 0.7377\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1526 - accuracy: 0.9409 - val_loss: 0.5049 - val_accuracy: 0.7654\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1472 - accuracy: 0.9440 - val_loss: 0.5172 - val_accuracy: 0.7613\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2527 - accuracy: 0.9250 - val_loss: 0.4933 - val_accuracy: 0.7767\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2162 - accuracy: 0.9444 - val_loss: 0.4545 - val_accuracy: 0.7829\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3112 - accuracy: 0.9387 - val_loss: 0.4805 - val_accuracy: 0.7737\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1702 - accuracy: 0.9462 - val_loss: 0.4650 - val_accuracy: 0.7716\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1297 - accuracy: 0.9480 - val_loss: 0.4489 - val_accuracy: 0.7840\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9475 - val_loss: 0.4864 - val_accuracy: 0.7850\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1580 - accuracy: 0.9369 - val_loss: 0.4619 - val_accuracy: 0.7809\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9484 - val_loss: 0.4516 - val_accuracy: 0.7819\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9550 - val_loss: 0.4685 - val_accuracy: 0.7747\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1425 - accuracy: 0.9422 - val_loss: 0.4305 - val_accuracy: 0.7850\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1642 - accuracy: 0.9453 - val_loss: 0.4775 - val_accuracy: 0.7706\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1404 - accuracy: 0.9444 - val_loss: 0.4349 - val_accuracy: 0.7932\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1535 - accuracy: 0.9484 - val_loss: 0.3904 - val_accuracy: 0.8148\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1369 - accuracy: 0.9436 - val_loss: 0.4189 - val_accuracy: 0.8066\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1625 - accuracy: 0.9440 - val_loss: 0.4381 - val_accuracy: 0.7922\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9361 - val_loss: 0.4350 - val_accuracy: 0.7778\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4426 - accuracy: 0.9493 - val_loss: 0.4254 - val_accuracy: 0.8086\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1373 - accuracy: 0.9409 - val_loss: 0.4321 - val_accuracy: 0.8128\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9449 - val_loss: 0.4206 - val_accuracy: 0.8158\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9422 - val_loss: 0.4213 - val_accuracy: 0.8086\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3596 - accuracy: 0.9422 - val_loss: 0.4260 - val_accuracy: 0.8097\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9444 - val_loss: 0.4447 - val_accuracy: 0.8076\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1417 - accuracy: 0.9471 - val_loss: 0.4098 - val_accuracy: 0.8014\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1265 - accuracy: 0.9502 - val_loss: 0.4015 - val_accuracy: 0.8138\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1513 - accuracy: 0.9511 - val_loss: 0.4079 - val_accuracy: 0.8128\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1706 - accuracy: 0.9409 - val_loss: 0.4638 - val_accuracy: 0.7623\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1260 - accuracy: 0.9489 - val_loss: 0.3884 - val_accuracy: 0.8333\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1423 - accuracy: 0.9440 - val_loss: 0.3893 - val_accuracy: 0.8230\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1361 - accuracy: 0.9484 - val_loss: 0.4019 - val_accuracy: 0.8128\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1410 - accuracy: 0.9466 - val_loss: 0.4443 - val_accuracy: 0.7788\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1355 - accuracy: 0.9458 - val_loss: 0.4110 - val_accuracy: 0.8045\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1211 - accuracy: 0.9559 - val_loss: 0.4816 - val_accuracy: 0.7737\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1263 - accuracy: 0.9475 - val_loss: 0.4038 - val_accuracy: 0.8148\n","Score: 0.8148148059844971 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 17263.2266 - accuracy: 0.8955 - val_loss: 0.7061 - val_accuracy: 0.4835\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9061 - val_loss: 0.7723 - val_accuracy: 0.4784\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9004 - val_loss: 0.7016 - val_accuracy: 0.5175\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9078 - val_loss: 0.6981 - val_accuracy: 0.5093\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9021 - val_loss: 0.6940 - val_accuracy: 0.5041\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1893 - accuracy: 0.9118 - val_loss: 0.7026 - val_accuracy: 0.5247\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9078 - val_loss: 0.6956 - val_accuracy: 0.5206\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9043 - val_loss: 0.7370 - val_accuracy: 0.4928\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9030 - val_loss: 0.7170 - val_accuracy: 0.5113\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2007 - accuracy: 0.9145 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2140 - accuracy: 0.9175 - val_loss: 0.6926 - val_accuracy: 0.5247\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2124 - accuracy: 0.9175 - val_loss: 0.6967 - val_accuracy: 0.5010\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9180 - val_loss: 0.7034 - val_accuracy: 0.4743\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2208 - accuracy: 0.9052 - val_loss: 0.6926 - val_accuracy: 0.5185\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2141 - accuracy: 0.9171 - val_loss: 0.6948 - val_accuracy: 0.5062\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2107 - accuracy: 0.9193 - val_loss: 0.7481 - val_accuracy: 0.5103\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2087 - accuracy: 0.9065 - val_loss: 0.6948 - val_accuracy: 0.5010\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2127 - accuracy: 0.9167 - val_loss: 0.6930 - val_accuracy: 0.5206\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9118 - val_loss: 0.6935 - val_accuracy: 0.4846\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2162 - accuracy: 0.9131 - val_loss: 0.6932 - val_accuracy: 0.5072\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2092 - accuracy: 0.9206 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2138 - accuracy: 0.9167 - val_loss: 0.7285 - val_accuracy: 0.4794\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2071 - accuracy: 0.9114 - val_loss: 0.7227 - val_accuracy: 0.4835\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2210 - accuracy: 0.9030 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2165 - accuracy: 0.9180 - val_loss: 0.7012 - val_accuracy: 0.5278\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2046 - accuracy: 0.9153 - val_loss: 0.6975 - val_accuracy: 0.5123\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2098 - accuracy: 0.9184 - val_loss: 0.6957 - val_accuracy: 0.4928\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2216 - accuracy: 0.9004 - val_loss: 0.7015 - val_accuracy: 0.5226\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2109 - accuracy: 0.9101 - val_loss: 0.6931 - val_accuracy: 0.5237\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9123 - val_loss: 0.6938 - val_accuracy: 0.4846\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2130 - accuracy: 0.9074 - val_loss: 0.6954 - val_accuracy: 0.4805\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2174 - accuracy: 0.9114 - val_loss: 0.7018 - val_accuracy: 0.4949\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2191 - accuracy: 0.8981 - val_loss: 0.6945 - val_accuracy: 0.5093\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.9145 - val_loss: 0.6949 - val_accuracy: 0.5021\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2157 - accuracy: 0.8946 - val_loss: 0.6930 - val_accuracy: 0.5123\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2123 - accuracy: 0.9114 - val_loss: 0.6942 - val_accuracy: 0.5093\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2040 - accuracy: 0.9184 - val_loss: 0.6931 - val_accuracy: 0.5165\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9092 - val_loss: 0.6935 - val_accuracy: 0.5113\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.9198 - val_loss: 0.6931 - val_accuracy: 0.5051\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2087 - accuracy: 0.9171 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2063 - accuracy: 0.9193 - val_loss: 0.7059 - val_accuracy: 0.5082\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2155 - accuracy: 0.9078 - val_loss: 0.6927 - val_accuracy: 0.5144\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2139 - accuracy: 0.9171 - val_loss: 0.7153 - val_accuracy: 0.5144\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2000 - accuracy: 0.9189 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2143 - accuracy: 0.9105 - val_loss: 0.6993 - val_accuracy: 0.4846\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2107 - accuracy: 0.9145 - val_loss: 0.7207 - val_accuracy: 0.5041\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2159 - accuracy: 0.9096 - val_loss: 0.6935 - val_accuracy: 0.4815\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2104 - accuracy: 0.9153 - val_loss: 0.6952 - val_accuracy: 0.5185\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2203 - accuracy: 0.9039 - val_loss: 0.6932 - val_accuracy: 0.5093\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2223 - accuracy: 0.8995 - val_loss: 0.6932 - val_accuracy: 0.5206\n","Score: 0.5205761194229126 \n","Parameters:  {'learning_rate': 0.06122478725455912, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 1.3707 - accuracy: 0.9259 - val_loss: 0.6620 - val_accuracy: 0.6091\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6046 - accuracy: 0.9087 - val_loss: 0.6641 - val_accuracy: 0.5905\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4964 - accuracy: 0.9189 - val_loss: 0.5576 - val_accuracy: 0.7047\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9281 - val_loss: 0.5668 - val_accuracy: 0.6975\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7225 - accuracy: 0.9140 - val_loss: 0.6361 - val_accuracy: 0.6039\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2513 - accuracy: 0.9233 - val_loss: 1.0025 - val_accuracy: 0.6728\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1727 - accuracy: 0.9444 - val_loss: 0.5149 - val_accuracy: 0.7418\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1788 - accuracy: 0.9281 - val_loss: 0.4975 - val_accuracy: 0.7562\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1609 - accuracy: 0.9458 - val_loss: 0.3936 - val_accuracy: 0.7973\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9511 - val_loss: 0.4062 - val_accuracy: 0.8066\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9497 - val_loss: 0.3461 - val_accuracy: 0.8344\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1221 - accuracy: 0.9555 - val_loss: 0.4574 - val_accuracy: 0.7603\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9638 - val_loss: 0.3224 - val_accuracy: 0.8385\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9625 - val_loss: 0.3479 - val_accuracy: 0.8416\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1314 - accuracy: 0.9489 - val_loss: 0.3914 - val_accuracy: 0.7984\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1074 - accuracy: 0.9590 - val_loss: 0.3504 - val_accuracy: 0.8405\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1261 - accuracy: 0.9493 - val_loss: 0.3116 - val_accuracy: 0.8539\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0941 - accuracy: 0.9643 - val_loss: 0.3333 - val_accuracy: 0.8642\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1175 - accuracy: 0.9572 - val_loss: 0.3168 - val_accuracy: 0.8447\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1134 - accuracy: 0.9572 - val_loss: 0.3484 - val_accuracy: 0.8302\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1060 - accuracy: 0.9581 - val_loss: 0.3249 - val_accuracy: 0.8416\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1688 - accuracy: 0.9581 - val_loss: 0.3006 - val_accuracy: 0.8642\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1314 - accuracy: 0.9656 - val_loss: 0.3495 - val_accuracy: 0.8508\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1136 - accuracy: 0.9594 - val_loss: 0.3180 - val_accuracy: 0.8477\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1130 - accuracy: 0.9665 - val_loss: 0.2744 - val_accuracy: 0.8663\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0930 - accuracy: 0.9744 - val_loss: 0.2826 - val_accuracy: 0.8642\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0898 - accuracy: 0.9669 - val_loss: 0.2618 - val_accuracy: 0.8755\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0812 - accuracy: 0.9674 - val_loss: 0.2435 - val_accuracy: 0.8879\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0924 - accuracy: 0.9665 - val_loss: 0.2348 - val_accuracy: 0.8920\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0762 - accuracy: 0.9718 - val_loss: 0.4326 - val_accuracy: 0.8488\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 0.2251 - val_accuracy: 0.8940\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1195 - accuracy: 0.9603 - val_loss: 0.3662 - val_accuracy: 0.8498\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9621 - val_loss: 0.2748 - val_accuracy: 0.8807\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0989 - accuracy: 0.9638 - val_loss: 0.3463 - val_accuracy: 0.8529\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0914 - accuracy: 0.9709 - val_loss: 0.2843 - val_accuracy: 0.8786\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0830 - accuracy: 0.9718 - val_loss: 0.2878 - val_accuracy: 0.8735\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0701 - accuracy: 0.9709 - val_loss: 0.2426 - val_accuracy: 0.8951\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0659 - accuracy: 0.9749 - val_loss: 0.2313 - val_accuracy: 0.9033\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0525 - accuracy: 0.9815 - val_loss: 0.2811 - val_accuracy: 0.9053\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0866 - accuracy: 0.9709 - val_loss: 0.3220 - val_accuracy: 0.8539\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0837 - accuracy: 0.9705 - val_loss: 0.2244 - val_accuracy: 0.9167\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0923 - accuracy: 0.9740 - val_loss: 0.2585 - val_accuracy: 0.8909\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0777 - accuracy: 0.9735 - val_loss: 0.2945 - val_accuracy: 0.8632\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0860 - accuracy: 0.9705 - val_loss: 0.2578 - val_accuracy: 0.8807\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0725 - accuracy: 0.9727 - val_loss: 0.2171 - val_accuracy: 0.9115\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0559 - accuracy: 0.9784 - val_loss: 0.1913 - val_accuracy: 0.9198\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0736 - accuracy: 0.9757 - val_loss: 0.2646 - val_accuracy: 0.8889\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0499 - accuracy: 0.9797 - val_loss: 0.2479 - val_accuracy: 0.8951\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 0.2224 - val_accuracy: 0.9023\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0881 - accuracy: 0.9718 - val_loss: 0.2405 - val_accuracy: 0.8889\n","Score: 0.8888888955116272 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 770816.6250 - accuracy: 0.9012 - val_loss: 0.6921 - val_accuracy: 0.5267\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9171 - val_loss: 0.7317 - val_accuracy: 0.5134\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9118 - val_loss: 0.6950 - val_accuracy: 0.5113\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9184 - val_loss: 0.7006 - val_accuracy: 0.5165\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9092 - val_loss: 0.6966 - val_accuracy: 0.4918\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9048 - val_loss: 0.6985 - val_accuracy: 0.5051\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1863 - accuracy: 0.9167 - val_loss: 0.6997 - val_accuracy: 0.4774\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1869 - accuracy: 0.9145 - val_loss: 0.6976 - val_accuracy: 0.5154\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1992 - accuracy: 0.9096 - val_loss: 0.6966 - val_accuracy: 0.4907\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1852 - accuracy: 0.9140 - val_loss: 0.6993 - val_accuracy: 0.4753\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1946 - accuracy: 0.9083 - val_loss: 0.7118 - val_accuracy: 0.5051\n","Epoch 12/50\n","567/567 [==============================] - 4s 7ms/step - loss: 0.1916 - accuracy: 0.9189 - val_loss: 0.6948 - val_accuracy: 0.5123\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1873 - accuracy: 0.9153 - val_loss: 0.6970 - val_accuracy: 0.4856\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9101 - val_loss: 0.7264 - val_accuracy: 0.4784\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2029 - accuracy: 0.9017 - val_loss: 0.6973 - val_accuracy: 0.5206\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9118 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1832 - accuracy: 0.9211 - val_loss: 0.7109 - val_accuracy: 0.5412\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1910 - accuracy: 0.9140 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1939 - accuracy: 0.9131 - val_loss: 0.7405 - val_accuracy: 0.5154\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1923 - accuracy: 0.9109 - val_loss: 0.7436 - val_accuracy: 0.4928\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.8959 - val_loss: 0.6934 - val_accuracy: 0.4877\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9087 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2026 - accuracy: 0.9123 - val_loss: 0.6954 - val_accuracy: 0.5237\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9131 - val_loss: 0.6968 - val_accuracy: 0.5165\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1858 - accuracy: 0.9198 - val_loss: 0.6959 - val_accuracy: 0.5165\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1893 - accuracy: 0.9153 - val_loss: 0.7178 - val_accuracy: 0.5031\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1864 - accuracy: 0.9140 - val_loss: 0.7108 - val_accuracy: 0.4805\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1988 - accuracy: 0.9012 - val_loss: 0.6985 - val_accuracy: 0.5062\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9158 - val_loss: 0.7030 - val_accuracy: 0.4805\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1830 - accuracy: 0.9105 - val_loss: 0.6932 - val_accuracy: 0.4949\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9048 - val_loss: 0.6936 - val_accuracy: 0.4897\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9074 - val_loss: 0.6927 - val_accuracy: 0.5185\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1921 - accuracy: 0.9175 - val_loss: 0.7084 - val_accuracy: 0.4846\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9070 - val_loss: 0.6941 - val_accuracy: 0.5216\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9136 - val_loss: 0.6924 - val_accuracy: 0.5247\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9118 - val_loss: 0.6910 - val_accuracy: 0.5350\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9078 - val_loss: 0.7047 - val_accuracy: 0.5216\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1975 - accuracy: 0.9061 - val_loss: 0.6973 - val_accuracy: 0.5041\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9096 - val_loss: 0.7043 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1905 - accuracy: 0.9136 - val_loss: 0.7009 - val_accuracy: 0.4990\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1962 - accuracy: 0.8942 - val_loss: 0.6920 - val_accuracy: 0.5247\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1878 - accuracy: 0.9118 - val_loss: 0.6925 - val_accuracy: 0.5175\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9096 - val_loss: 0.7106 - val_accuracy: 0.4722\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.8959 - val_loss: 0.7234 - val_accuracy: 0.5278\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1851 - accuracy: 0.9171 - val_loss: 0.7012 - val_accuracy: 0.5031\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1951 - accuracy: 0.9092 - val_loss: 0.6933 - val_accuracy: 0.4866\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9184 - val_loss: 0.6917 - val_accuracy: 0.5267\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9061 - val_loss: 0.7120 - val_accuracy: 0.4846\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9087 - val_loss: 0.7009 - val_accuracy: 0.4897\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1929 - accuracy: 0.9039 - val_loss: 0.7056 - val_accuracy: 0.5103\n","Score: 0.5102880597114563 \n","Parameters:  {'learning_rate': 0.13741743254142083, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1097337.5000 - accuracy: 0.8915 - val_loss: 0.7155 - val_accuracy: 0.5021\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9074 - val_loss: 0.8482 - val_accuracy: 0.4774\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1980 - accuracy: 0.9034 - val_loss: 0.7387 - val_accuracy: 0.5051\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9012 - val_loss: 0.6935 - val_accuracy: 0.4866\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1871 - accuracy: 0.9017 - val_loss: 0.6935 - val_accuracy: 0.5072\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9061 - val_loss: 0.7019 - val_accuracy: 0.5010\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9118 - val_loss: 0.7246 - val_accuracy: 0.5195\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1840 - accuracy: 0.9140 - val_loss: 0.7437 - val_accuracy: 0.4979\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1912 - accuracy: 0.9101 - val_loss: 0.6966 - val_accuracy: 0.4784\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1839 - accuracy: 0.9123 - val_loss: 0.6957 - val_accuracy: 0.4877\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1837 - accuracy: 0.9105 - val_loss: 0.7266 - val_accuracy: 0.5031\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1981 - accuracy: 0.9012 - val_loss: 0.6931 - val_accuracy: 0.5237\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1842 - accuracy: 0.9078 - val_loss: 0.7030 - val_accuracy: 0.4805\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1937 - accuracy: 0.9052 - val_loss: 0.7450 - val_accuracy: 0.4825\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1972 - accuracy: 0.8973 - val_loss: 0.6977 - val_accuracy: 0.4846\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1888 - accuracy: 0.8995 - val_loss: 0.7088 - val_accuracy: 0.4835\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1902 - accuracy: 0.9052 - val_loss: 0.6980 - val_accuracy: 0.4856\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9105 - val_loss: 0.7001 - val_accuracy: 0.5165\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1879 - accuracy: 0.9136 - val_loss: 0.7264 - val_accuracy: 0.5000\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1865 - accuracy: 0.9048 - val_loss: 0.7050 - val_accuracy: 0.5123\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1835 - accuracy: 0.9123 - val_loss: 0.6936 - val_accuracy: 0.4835\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1945 - accuracy: 0.9096 - val_loss: 0.6987 - val_accuracy: 0.4990\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1841 - accuracy: 0.9087 - val_loss: 0.6968 - val_accuracy: 0.4866\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1972 - accuracy: 0.9136 - val_loss: 0.7021 - val_accuracy: 0.5113\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1931 - accuracy: 0.9167 - val_loss: 0.6933 - val_accuracy: 0.5031\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9008 - val_loss: 0.7141 - val_accuracy: 0.4784\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9039 - val_loss: 0.6958 - val_accuracy: 0.4897\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1938 - accuracy: 0.9083 - val_loss: 0.7126 - val_accuracy: 0.5093\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1931 - accuracy: 0.9153 - val_loss: 0.7019 - val_accuracy: 0.5175\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9065 - val_loss: 0.7248 - val_accuracy: 0.5278\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1809 - accuracy: 0.9109 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1960 - accuracy: 0.9109 - val_loss: 0.6949 - val_accuracy: 0.4835\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9017 - val_loss: 0.7002 - val_accuracy: 0.4846\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9118 - val_loss: 0.6950 - val_accuracy: 0.4887\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.8977 - val_loss: 0.7053 - val_accuracy: 0.4753\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1864 - accuracy: 0.9123 - val_loss: 0.6920 - val_accuracy: 0.5360\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9114 - val_loss: 0.7210 - val_accuracy: 0.4938\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9026 - val_loss: 0.7157 - val_accuracy: 0.5257\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9118 - val_loss: 0.6979 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1819 - accuracy: 0.9153 - val_loss: 0.6963 - val_accuracy: 0.4979\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9131 - val_loss: 0.7159 - val_accuracy: 0.5113\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9136 - val_loss: 0.6941 - val_accuracy: 0.4907\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9074 - val_loss: 0.6925 - val_accuracy: 0.5216\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9083 - val_loss: 0.6954 - val_accuracy: 0.4835\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1981 - accuracy: 0.9149 - val_loss: 0.7195 - val_accuracy: 0.5072\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1858 - accuracy: 0.9202 - val_loss: 0.7066 - val_accuracy: 0.4856\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1992 - accuracy: 0.9092 - val_loss: 0.7317 - val_accuracy: 0.5021\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1791 - accuracy: 0.9202 - val_loss: 0.7024 - val_accuracy: 0.5165\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9131 - val_loss: 0.6991 - val_accuracy: 0.5267\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1832 - accuracy: 0.9180 - val_loss: 0.7057 - val_accuracy: 0.4743\n","Score: 0.47427982091903687 \n","Parameters:  {'learning_rate': 0.1623923320349029, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 741636.5625 - accuracy: 0.8858 - val_loss: 4.7998 - val_accuracy: 0.4959\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 10.9057 - accuracy: 0.8937 - val_loss: 0.7297 - val_accuracy: 0.4835\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2365 - accuracy: 0.8902 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2228 - accuracy: 0.9008 - val_loss: 0.6978 - val_accuracy: 0.5051\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2712 - accuracy: 0.8884 - val_loss: 0.9644 - val_accuracy: 0.4959\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2721 - accuracy: 0.8977 - val_loss: 0.8302 - val_accuracy: 0.5144\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2534 - accuracy: 0.8929 - val_loss: 0.7091 - val_accuracy: 0.5154\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9021 - val_loss: 0.7144 - val_accuracy: 0.5175\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9012 - val_loss: 0.8793 - val_accuracy: 0.5195\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2145 - accuracy: 0.8986 - val_loss: 0.7060 - val_accuracy: 0.4815\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2717 - accuracy: 0.8867 - val_loss: 0.8653 - val_accuracy: 0.5165\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2494 - accuracy: 0.9034 - val_loss: 0.8352 - val_accuracy: 0.4794\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2306 - accuracy: 0.8946 - val_loss: 0.6978 - val_accuracy: 0.4846\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2484 - accuracy: 0.8977 - val_loss: 1.6005 - val_accuracy: 0.4712\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2616 - accuracy: 0.9026 - val_loss: 0.7474 - val_accuracy: 0.4918\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2302 - accuracy: 0.9030 - val_loss: 0.6941 - val_accuracy: 0.4959\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2023 - accuracy: 0.8929 - val_loss: 0.6958 - val_accuracy: 0.4949\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1876 - accuracy: 0.9078 - val_loss: 0.7145 - val_accuracy: 0.5144\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9101 - val_loss: 0.7739 - val_accuracy: 0.5247\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1867 - accuracy: 0.9136 - val_loss: 0.6957 - val_accuracy: 0.4815\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9096 - val_loss: 0.6977 - val_accuracy: 0.4753\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9043 - val_loss: 0.6973 - val_accuracy: 0.5257\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9131 - val_loss: 0.6948 - val_accuracy: 0.5298\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9008 - val_loss: 0.6942 - val_accuracy: 0.4959\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9101 - val_loss: 0.6920 - val_accuracy: 0.5257\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1795 - accuracy: 0.9175 - val_loss: 0.6940 - val_accuracy: 0.5021\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9175 - val_loss: 0.7107 - val_accuracy: 0.5144\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9149 - val_loss: 0.7209 - val_accuracy: 0.5165\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9092 - val_loss: 0.6948 - val_accuracy: 0.5010\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1813 - accuracy: 0.9149 - val_loss: 0.7375 - val_accuracy: 0.5123\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1973 - accuracy: 0.9109 - val_loss: 0.7069 - val_accuracy: 0.5267\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.9224 - val_loss: 0.7636 - val_accuracy: 0.4784\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.8933 - val_loss: 0.6926 - val_accuracy: 0.5206\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9056 - val_loss: 0.6933 - val_accuracy: 0.4897\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9105 - val_loss: 0.6918 - val_accuracy: 0.5267\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9206 - val_loss: 0.7177 - val_accuracy: 0.4763\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9109 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9149 - val_loss: 0.7155 - val_accuracy: 0.4969\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.8999 - val_loss: 0.7030 - val_accuracy: 0.4928\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9039 - val_loss: 0.6939 - val_accuracy: 0.4907\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9189 - val_loss: 0.6985 - val_accuracy: 0.4877\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9061 - val_loss: 0.7207 - val_accuracy: 0.5185\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9021 - val_loss: 0.7133 - val_accuracy: 0.5010\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9171 - val_loss: 0.6994 - val_accuracy: 0.4918\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1932 - accuracy: 0.9034 - val_loss: 0.7022 - val_accuracy: 0.4805\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1810 - accuracy: 0.9127 - val_loss: 0.7524 - val_accuracy: 0.4835\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9136 - val_loss: 0.7140 - val_accuracy: 0.5144\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1894 - accuracy: 0.9127 - val_loss: 0.7257 - val_accuracy: 0.5175\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9048 - val_loss: 0.7453 - val_accuracy: 0.5237\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9193 - val_loss: 0.7096 - val_accuracy: 0.5072\n","Score: 0.5072016716003418 \n","Parameters:  {'learning_rate': 0.15282102174697226, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2535 - accuracy: 0.9277 - val_loss: 0.5816 - val_accuracy: 0.7294\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5203 - accuracy: 0.9193 - val_loss: 0.6493 - val_accuracy: 0.6368\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2220 - accuracy: 0.9321 - val_loss: 0.5287 - val_accuracy: 0.7160\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1405 - accuracy: 0.9409 - val_loss: 0.5097 - val_accuracy: 0.7356\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1514 - accuracy: 0.9365 - val_loss: 0.4838 - val_accuracy: 0.7675\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1348 - accuracy: 0.9466 - val_loss: 0.4948 - val_accuracy: 0.7757\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1744 - accuracy: 0.9466 - val_loss: 0.4753 - val_accuracy: 0.7634\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9466 - val_loss: 0.4386 - val_accuracy: 0.7891\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4023 - accuracy: 0.9343 - val_loss: 0.5220 - val_accuracy: 0.7757\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1520 - accuracy: 0.9436 - val_loss: 0.4727 - val_accuracy: 0.7901\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1304 - accuracy: 0.9484 - val_loss: 0.4309 - val_accuracy: 0.7891\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1565 - accuracy: 0.9466 - val_loss: 0.4530 - val_accuracy: 0.7716\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3928 - accuracy: 0.9405 - val_loss: 0.4507 - val_accuracy: 0.7840\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1301 - accuracy: 0.9528 - val_loss: 0.4110 - val_accuracy: 0.8076\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1370 - accuracy: 0.9480 - val_loss: 0.4331 - val_accuracy: 0.7942\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1272 - accuracy: 0.9453 - val_loss: 0.4028 - val_accuracy: 0.8076\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1425 - accuracy: 0.9462 - val_loss: 0.3934 - val_accuracy: 0.8210\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9444 - val_loss: 0.4598 - val_accuracy: 0.7850\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9484 - val_loss: 0.4375 - val_accuracy: 0.8076\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1387 - accuracy: 0.9550 - val_loss: 0.3844 - val_accuracy: 0.8261\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1213 - accuracy: 0.9506 - val_loss: 0.3839 - val_accuracy: 0.8179\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1227 - accuracy: 0.9511 - val_loss: 0.4270 - val_accuracy: 0.8035\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.9533 - val_loss: 0.3844 - val_accuracy: 0.8179\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1179 - accuracy: 0.9555 - val_loss: 0.3966 - val_accuracy: 0.8148\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0926 - accuracy: 0.9630 - val_loss: 0.3913 - val_accuracy: 0.8313\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2339 - accuracy: 0.9330 - val_loss: 0.4231 - val_accuracy: 0.7891\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1978 - accuracy: 0.9511 - val_loss: 0.4133 - val_accuracy: 0.8025\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0996 - accuracy: 0.9594 - val_loss: 0.4052 - val_accuracy: 0.8056\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1332 - accuracy: 0.9546 - val_loss: 0.4168 - val_accuracy: 0.8056\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1192 - accuracy: 0.9612 - val_loss: 0.4027 - val_accuracy: 0.8189\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1032 - accuracy: 0.9590 - val_loss: 0.3763 - val_accuracy: 0.8261\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1082 - accuracy: 0.9586 - val_loss: 0.3719 - val_accuracy: 0.8405\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1109 - accuracy: 0.9608 - val_loss: 0.3907 - val_accuracy: 0.8220\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1106 - accuracy: 0.9546 - val_loss: 0.3474 - val_accuracy: 0.8374\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1909 - accuracy: 0.9471 - val_loss: 0.3242 - val_accuracy: 0.8405\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0964 - accuracy: 0.9674 - val_loss: 0.2964 - val_accuracy: 0.8519\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0796 - accuracy: 0.9647 - val_loss: 0.3312 - val_accuracy: 0.8292\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1107 - accuracy: 0.9555 - val_loss: 0.3516 - val_accuracy: 0.8272\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1135 - accuracy: 0.9660 - val_loss: 0.3091 - val_accuracy: 0.8498\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.2761 - val_accuracy: 0.8519\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0951 - accuracy: 0.9674 - val_loss: 0.3272 - val_accuracy: 0.8447\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0734 - accuracy: 0.9740 - val_loss: 0.2835 - val_accuracy: 0.8745\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9691 - val_loss: 0.2583 - val_accuracy: 0.8868\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0858 - accuracy: 0.9660 - val_loss: 0.2523 - val_accuracy: 0.8889\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9713 - val_loss: 0.2592 - val_accuracy: 0.8848\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0748 - accuracy: 0.9705 - val_loss: 0.3388 - val_accuracy: 0.8837\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0757 - accuracy: 0.9687 - val_loss: 0.2725 - val_accuracy: 0.8693\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0682 - accuracy: 0.9727 - val_loss: 0.2606 - val_accuracy: 0.8663\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0719 - accuracy: 0.9740 - val_loss: 0.2378 - val_accuracy: 0.8971\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0722 - accuracy: 0.9780 - val_loss: 0.2175 - val_accuracy: 0.8992\n","Score: 0.8991769552230835 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 6072715.5000 - accuracy: 0.9004 - val_loss: 0.6974 - val_accuracy: 0.4743\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1832 - accuracy: 0.9131 - val_loss: 0.7096 - val_accuracy: 0.4918\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1975 - accuracy: 0.9083 - val_loss: 0.7257 - val_accuracy: 0.5082\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9092 - val_loss: 0.6966 - val_accuracy: 0.5165\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9109 - val_loss: 0.7492 - val_accuracy: 0.5082\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1927 - accuracy: 0.9087 - val_loss: 0.7613 - val_accuracy: 0.4979\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9043 - val_loss: 0.7501 - val_accuracy: 0.4907\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1894 - accuracy: 0.9136 - val_loss: 0.7164 - val_accuracy: 0.4691\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1996 - accuracy: 0.9078 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1833 - accuracy: 0.9228 - val_loss: 0.7359 - val_accuracy: 0.4949\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.8981 - val_loss: 0.7207 - val_accuracy: 0.4743\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9004 - val_loss: 0.6941 - val_accuracy: 0.5082\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1846 - accuracy: 0.9193 - val_loss: 0.8297 - val_accuracy: 0.5051\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1878 - accuracy: 0.9105 - val_loss: 0.6948 - val_accuracy: 0.5165\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9140 - val_loss: 0.8242 - val_accuracy: 0.4928\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1945 - accuracy: 0.9083 - val_loss: 0.7634 - val_accuracy: 0.4918\n","Epoch 17/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.1940 - accuracy: 0.9101 - val_loss: 0.7816 - val_accuracy: 0.4928\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9131 - val_loss: 0.7122 - val_accuracy: 0.4856\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9065 - val_loss: 0.7684 - val_accuracy: 0.4815\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.8986 - val_loss: 0.7175 - val_accuracy: 0.4856\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9092 - val_loss: 0.7013 - val_accuracy: 0.4938\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1900 - accuracy: 0.9074 - val_loss: 0.6964 - val_accuracy: 0.4938\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1879 - accuracy: 0.9030 - val_loss: 0.7002 - val_accuracy: 0.4815\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9083 - val_loss: 0.6942 - val_accuracy: 0.4887\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1769 - accuracy: 0.9153 - val_loss: 0.7453 - val_accuracy: 0.5051\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9158 - val_loss: 0.6971 - val_accuracy: 0.4743\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9061 - val_loss: 0.6980 - val_accuracy: 0.4928\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1899 - accuracy: 0.9052 - val_loss: 0.7224 - val_accuracy: 0.4866\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9048 - val_loss: 0.7024 - val_accuracy: 0.5134\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9127 - val_loss: 0.6935 - val_accuracy: 0.4949\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.8964 - val_loss: 0.6983 - val_accuracy: 0.4743\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9048 - val_loss: 0.7313 - val_accuracy: 0.5195\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9118 - val_loss: 0.6954 - val_accuracy: 0.5267\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9092 - val_loss: 0.6939 - val_accuracy: 0.4794\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1873 - accuracy: 0.9105 - val_loss: 0.7223 - val_accuracy: 0.4959\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.8995 - val_loss: 0.6963 - val_accuracy: 0.5175\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9131 - val_loss: 0.7743 - val_accuracy: 0.4887\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.8955 - val_loss: 0.7127 - val_accuracy: 0.5154\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1866 - accuracy: 0.9083 - val_loss: 0.7542 - val_accuracy: 0.4763\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1941 - accuracy: 0.9131 - val_loss: 0.7842 - val_accuracy: 0.5226\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1754 - accuracy: 0.9180 - val_loss: 0.7295 - val_accuracy: 0.5021\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.8999 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1847 - accuracy: 0.9074 - val_loss: 0.7219 - val_accuracy: 0.5093\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9048 - val_loss: 0.6940 - val_accuracy: 0.4712\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9078 - val_loss: 0.6936 - val_accuracy: 0.4733\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9043 - val_loss: 0.6933 - val_accuracy: 0.4835\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1844 - accuracy: 0.9109 - val_loss: 0.7152 - val_accuracy: 0.5144\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9118 - val_loss: 0.7005 - val_accuracy: 0.4763\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1859 - accuracy: 0.9123 - val_loss: 0.6920 - val_accuracy: 0.5267\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1802 - accuracy: 0.9206 - val_loss: 0.6924 - val_accuracy: 0.5278\n","Score: 0.5277777910232544 \n","Parameters:  {'learning_rate': 0.22952849908096234, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 3750.3567 - accuracy: 0.9087 - val_loss: 0.7005 - val_accuracy: 0.4949\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9017 - val_loss: 0.6955 - val_accuracy: 0.4887\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2512 - accuracy: 0.9043 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2482 - accuracy: 0.9211 - val_loss: 0.7032 - val_accuracy: 0.5154\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2519 - accuracy: 0.9127 - val_loss: 0.6941 - val_accuracy: 0.5103\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2581 - accuracy: 0.9118 - val_loss: 0.6984 - val_accuracy: 0.5195\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2544 - accuracy: 0.9180 - val_loss: 0.7103 - val_accuracy: 0.5093\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2573 - accuracy: 0.9118 - val_loss: 0.6980 - val_accuracy: 0.5134\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2622 - accuracy: 0.9118 - val_loss: 0.7026 - val_accuracy: 0.5103\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2496 - accuracy: 0.9193 - val_loss: 0.7092 - val_accuracy: 0.4990\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2482 - accuracy: 0.9118 - val_loss: 0.6941 - val_accuracy: 0.4897\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2514 - accuracy: 0.9145 - val_loss: 0.7154 - val_accuracy: 0.5195\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2490 - accuracy: 0.9136 - val_loss: 0.6950 - val_accuracy: 0.5093\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2632 - accuracy: 0.9123 - val_loss: 0.7005 - val_accuracy: 0.5123\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2601 - accuracy: 0.9101 - val_loss: 0.6939 - val_accuracy: 0.5154\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2612 - accuracy: 0.9101 - val_loss: 0.7031 - val_accuracy: 0.4938\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2513 - accuracy: 0.9180 - val_loss: 0.6990 - val_accuracy: 0.5144\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2509 - accuracy: 0.9198 - val_loss: 0.7014 - val_accuracy: 0.5237\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2487 - accuracy: 0.9171 - val_loss: 0.6965 - val_accuracy: 0.5195\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2488 - accuracy: 0.9162 - val_loss: 0.6956 - val_accuracy: 0.5154\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2447 - accuracy: 0.9198 - val_loss: 0.6940 - val_accuracy: 0.5113\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2657 - accuracy: 0.9096 - val_loss: 0.6966 - val_accuracy: 0.5072\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2568 - accuracy: 0.9162 - val_loss: 0.6999 - val_accuracy: 0.5134\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2553 - accuracy: 0.9158 - val_loss: 0.7028 - val_accuracy: 0.5288\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2499 - accuracy: 0.9167 - val_loss: 0.7004 - val_accuracy: 0.5113\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2512 - accuracy: 0.9167 - val_loss: 0.6969 - val_accuracy: 0.5216\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2492 - accuracy: 0.9224 - val_loss: 0.7138 - val_accuracy: 0.5226\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2484 - accuracy: 0.9175 - val_loss: 0.7058 - val_accuracy: 0.5206\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2476 - accuracy: 0.9171 - val_loss: 0.6920 - val_accuracy: 0.5319\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2568 - accuracy: 0.9127 - val_loss: 0.7069 - val_accuracy: 0.5000\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2623 - accuracy: 0.9078 - val_loss: 0.6932 - val_accuracy: 0.5062\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2603 - accuracy: 0.9127 - val_loss: 0.6958 - val_accuracy: 0.5216\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2583 - accuracy: 0.9153 - val_loss: 0.7052 - val_accuracy: 0.5051\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2528 - accuracy: 0.9184 - val_loss: 0.7078 - val_accuracy: 0.5144\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2555 - accuracy: 0.9136 - val_loss: 0.6926 - val_accuracy: 0.5319\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2582 - accuracy: 0.9109 - val_loss: 0.6939 - val_accuracy: 0.5093\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2676 - accuracy: 0.9118 - val_loss: 0.7063 - val_accuracy: 0.5123\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2549 - accuracy: 0.9158 - val_loss: 0.7034 - val_accuracy: 0.5051\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2539 - accuracy: 0.9193 - val_loss: 0.7290 - val_accuracy: 0.5226\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2479 - accuracy: 0.9162 - val_loss: 0.6972 - val_accuracy: 0.5021\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2396 - accuracy: 0.9211 - val_loss: 0.6935 - val_accuracy: 0.5206\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2571 - accuracy: 0.9184 - val_loss: 0.7059 - val_accuracy: 0.5226\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2498 - accuracy: 0.9140 - val_loss: 0.6936 - val_accuracy: 0.5216\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2522 - accuracy: 0.9171 - val_loss: 0.7006 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2571 - accuracy: 0.9140 - val_loss: 0.6969 - val_accuracy: 0.5154\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2570 - accuracy: 0.9118 - val_loss: 0.6929 - val_accuracy: 0.5237\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2560 - accuracy: 0.9189 - val_loss: 0.7130 - val_accuracy: 0.5185\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2511 - accuracy: 0.9149 - val_loss: 0.7041 - val_accuracy: 0.5185\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2465 - accuracy: 0.9167 - val_loss: 0.6912 - val_accuracy: 0.5319\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2537 - accuracy: 0.9189 - val_loss: 0.7064 - val_accuracy: 0.5195\n","Score: 0.5195473432540894 \n","Parameters:  {'learning_rate': 0.027323524433871507, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3973 - accuracy: 0.9167 - val_loss: 0.6822 - val_accuracy: 0.5391\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1804 - accuracy: 0.9180 - val_loss: 0.6630 - val_accuracy: 0.6091\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9065 - val_loss: 0.6105 - val_accuracy: 0.7305\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1782 - accuracy: 0.9259 - val_loss: 0.6136 - val_accuracy: 0.7243\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4166 - accuracy: 0.9396 - val_loss: 0.4409 - val_accuracy: 0.8045\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1705 - accuracy: 0.9347 - val_loss: 0.6948 - val_accuracy: 0.6986\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9334 - val_loss: 0.4295 - val_accuracy: 0.8097\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9378 - val_loss: 0.4061 - val_accuracy: 0.8025\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1175 - accuracy: 0.9528 - val_loss: 0.4879 - val_accuracy: 0.7706\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1188 - accuracy: 0.9511 - val_loss: 0.3965 - val_accuracy: 0.8261\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1157 - accuracy: 0.9519 - val_loss: 0.3177 - val_accuracy: 0.8498\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1545 - accuracy: 0.9431 - val_loss: 0.4649 - val_accuracy: 0.7912\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1094 - accuracy: 0.9621 - val_loss: 0.3478 - val_accuracy: 0.8333\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1040 - accuracy: 0.9634 - val_loss: 0.3172 - val_accuracy: 0.8663\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1045 - accuracy: 0.9612 - val_loss: 0.2737 - val_accuracy: 0.8796\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1054 - accuracy: 0.9652 - val_loss: 0.2796 - val_accuracy: 0.8693\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0999 - accuracy: 0.9691 - val_loss: 0.2718 - val_accuracy: 0.8827\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0923 - accuracy: 0.9656 - val_loss: 0.2221 - val_accuracy: 0.9115\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1045 - accuracy: 0.9612 - val_loss: 0.2807 - val_accuracy: 0.8879\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9497 - val_loss: 0.2457 - val_accuracy: 0.8755\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 0.2517 - val_accuracy: 0.8837\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0966 - accuracy: 0.9643 - val_loss: 0.2377 - val_accuracy: 0.8961\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0938 - accuracy: 0.9652 - val_loss: 0.2521 - val_accuracy: 0.8920\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0794 - accuracy: 0.9722 - val_loss: 0.2022 - val_accuracy: 0.9126\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0596 - accuracy: 0.9766 - val_loss: 0.2261 - val_accuracy: 0.8961\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0615 - accuracy: 0.9735 - val_loss: 0.2463 - val_accuracy: 0.8920\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0642 - accuracy: 0.9757 - val_loss: 0.2043 - val_accuracy: 0.9239\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0680 - accuracy: 0.9749 - val_loss: 0.2184 - val_accuracy: 0.8889\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0624 - accuracy: 0.9819 - val_loss: 0.1580 - val_accuracy: 0.9270\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0602 - accuracy: 0.9757 - val_loss: 0.1501 - val_accuracy: 0.9177\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.1668 - val_accuracy: 0.9444\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.1349 - val_accuracy: 0.9486\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0654 - accuracy: 0.9740 - val_loss: 0.1890 - val_accuracy: 0.9198\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0647 - accuracy: 0.9841 - val_loss: 0.1481 - val_accuracy: 0.9352\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0438 - accuracy: 0.9832 - val_loss: 0.1884 - val_accuracy: 0.9300\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 0.1517 - val_accuracy: 0.9537\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0760 - accuracy: 0.9802 - val_loss: 0.1977 - val_accuracy: 0.9342\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.1328 - val_accuracy: 0.9486\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0334 - accuracy: 0.9899 - val_loss: 0.1220 - val_accuracy: 0.9578\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.1165 - val_accuracy: 0.9619\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0349 - accuracy: 0.9899 - val_loss: 0.1786 - val_accuracy: 0.9527\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.3101 - val_accuracy: 0.9074\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.1556 - val_accuracy: 0.9516\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.1949 - val_accuracy: 0.9465\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0492 - accuracy: 0.9872 - val_loss: 0.1145 - val_accuracy: 0.9691\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.1088 - val_accuracy: 0.9619\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0187 - accuracy: 0.9956 - val_loss: 0.1355 - val_accuracy: 0.9691\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.1537 - val_accuracy: 0.9547\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0787 - accuracy: 0.9943 - val_loss: 0.1290 - val_accuracy: 0.9568\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.1014 - val_accuracy: 0.9671\n","Score: 0.9670782089233398 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 5ms/step - loss: 0.8732 - accuracy: 0.9162 - val_loss: 0.6676 - val_accuracy: 0.5185\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9250 - val_loss: 0.6816 - val_accuracy: 0.5360\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1709 - accuracy: 0.9202 - val_loss: 0.6041 - val_accuracy: 0.7027\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1755 - accuracy: 0.9308 - val_loss: 0.5633 - val_accuracy: 0.7438\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5096 - accuracy: 0.9303 - val_loss: 0.5636 - val_accuracy: 0.7449\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3691 - accuracy: 0.9286 - val_loss: 0.5436 - val_accuracy: 0.7521\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1626 - accuracy: 0.9444 - val_loss: 0.4942 - val_accuracy: 0.7274\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1831 - accuracy: 0.9431 - val_loss: 0.4907 - val_accuracy: 0.7767\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1541 - accuracy: 0.9317 - val_loss: 0.5138 - val_accuracy: 0.7798\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1597 - accuracy: 0.9475 - val_loss: 0.3651 - val_accuracy: 0.8261\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1156 - accuracy: 0.9506 - val_loss: 0.3242 - val_accuracy: 0.8519\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9537 - val_loss: 0.3551 - val_accuracy: 0.8488\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1018 - accuracy: 0.9638 - val_loss: 0.2911 - val_accuracy: 0.8560\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1012 - accuracy: 0.9603 - val_loss: 0.3086 - val_accuracy: 0.8642\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1023 - accuracy: 0.9590 - val_loss: 0.2377 - val_accuracy: 0.8909\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1053 - accuracy: 0.9656 - val_loss: 0.2541 - val_accuracy: 0.8879\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0866 - accuracy: 0.9674 - val_loss: 0.2426 - val_accuracy: 0.8837\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0728 - accuracy: 0.9705 - val_loss: 0.2544 - val_accuracy: 0.8858\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1758 - accuracy: 0.9519 - val_loss: 0.3218 - val_accuracy: 0.8591\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9784 - val_loss: 0.2212 - val_accuracy: 0.9074\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1129 - accuracy: 0.9599 - val_loss: 0.6084 - val_accuracy: 0.7963\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0861 - accuracy: 0.9669 - val_loss: 0.3335 - val_accuracy: 0.8786\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2219 - accuracy: 0.9568 - val_loss: 0.3203 - val_accuracy: 0.8663\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9727 - val_loss: 0.2199 - val_accuracy: 0.9023\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0655 - accuracy: 0.9731 - val_loss: 0.1914 - val_accuracy: 0.9105\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0899 - accuracy: 0.9647 - val_loss: 0.2065 - val_accuracy: 0.9033\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0613 - accuracy: 0.9775 - val_loss: 0.1893 - val_accuracy: 0.9218\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1023 - accuracy: 0.9727 - val_loss: 0.2502 - val_accuracy: 0.9023\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0774 - accuracy: 0.9744 - val_loss: 0.1895 - val_accuracy: 0.9156\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.1932 - val_accuracy: 0.9239\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0546 - accuracy: 0.9797 - val_loss: 0.1508 - val_accuracy: 0.9393\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.2153 - val_accuracy: 0.9311\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0529 - accuracy: 0.9841 - val_loss: 0.1635 - val_accuracy: 0.9362\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1126 - accuracy: 0.9660 - val_loss: 0.2641 - val_accuracy: 0.8868\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.1538 - val_accuracy: 0.9342\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0441 - accuracy: 0.9841 - val_loss: 0.1646 - val_accuracy: 0.9496\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0704 - accuracy: 0.9797 - val_loss: 0.1667 - val_accuracy: 0.9424\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.1325 - val_accuracy: 0.9475\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0611 - accuracy: 0.9877 - val_loss: 0.1635 - val_accuracy: 0.9352\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0574 - accuracy: 0.9815 - val_loss: 0.1769 - val_accuracy: 0.9372\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0444 - accuracy: 0.9894 - val_loss: 0.1765 - val_accuracy: 0.9239\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.1240 - val_accuracy: 0.9527\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0285 - accuracy: 0.9907 - val_loss: 0.0999 - val_accuracy: 0.9630\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0346 - accuracy: 0.9907 - val_loss: 0.0875 - val_accuracy: 0.9712\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 0.0842 - val_accuracy: 0.9671\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0496 - accuracy: 0.9885 - val_loss: 0.1282 - val_accuracy: 0.9516\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.1090 - val_accuracy: 0.9640\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.1567 - val_accuracy: 0.9496\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 0.0959 - val_accuracy: 0.9702\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0341 - accuracy: 0.9907 - val_loss: 0.0847 - val_accuracy: 0.9681\n","Score: 0.9681069850921631 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 87541.6172 - accuracy: 0.9087 - val_loss: 0.6960 - val_accuracy: 0.5041\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2142 - accuracy: 0.9074 - val_loss: 0.7036 - val_accuracy: 0.5154\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.9162 - val_loss: 0.6949 - val_accuracy: 0.4846\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2022 - accuracy: 0.9175 - val_loss: 0.7238 - val_accuracy: 0.5000\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9153 - val_loss: 0.6937 - val_accuracy: 0.5195\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9215 - val_loss: 0.7000 - val_accuracy: 0.5144\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9171 - val_loss: 0.7103 - val_accuracy: 0.4990\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9167 - val_loss: 0.6983 - val_accuracy: 0.5082\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.9070 - val_loss: 0.7041 - val_accuracy: 0.4907\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2155 - accuracy: 0.9048 - val_loss: 0.7179 - val_accuracy: 0.5103\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2032 - accuracy: 0.9158 - val_loss: 0.7034 - val_accuracy: 0.4815\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9048 - val_loss: 0.6945 - val_accuracy: 0.4897\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9162 - val_loss: 0.7180 - val_accuracy: 0.4856\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2058 - accuracy: 0.9065 - val_loss: 0.6922 - val_accuracy: 0.5278\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1974 - accuracy: 0.9180 - val_loss: 0.7081 - val_accuracy: 0.4846\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9052 - val_loss: 0.6963 - val_accuracy: 0.5165\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9171 - val_loss: 0.6952 - val_accuracy: 0.5257\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2101 - accuracy: 0.9118 - val_loss: 0.6962 - val_accuracy: 0.5226\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2057 - accuracy: 0.9171 - val_loss: 0.7112 - val_accuracy: 0.4866\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9083 - val_loss: 0.6957 - val_accuracy: 0.5062\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9136 - val_loss: 0.6918 - val_accuracy: 0.5257\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1930 - accuracy: 0.9206 - val_loss: 0.7080 - val_accuracy: 0.4609\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2042 - accuracy: 0.9021 - val_loss: 0.6930 - val_accuracy: 0.5093\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2017 - accuracy: 0.9078 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2081 - accuracy: 0.9083 - val_loss: 0.6949 - val_accuracy: 0.5134\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9180 - val_loss: 0.6975 - val_accuracy: 0.4835\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1978 - accuracy: 0.9078 - val_loss: 0.6949 - val_accuracy: 0.4825\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1961 - accuracy: 0.9114 - val_loss: 0.6920 - val_accuracy: 0.5247\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2103 - accuracy: 0.9074 - val_loss: 0.6939 - val_accuracy: 0.5093\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1989 - accuracy: 0.9193 - val_loss: 0.6933 - val_accuracy: 0.4959\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1931 - accuracy: 0.9228 - val_loss: 0.7233 - val_accuracy: 0.4856\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9078 - val_loss: 0.6984 - val_accuracy: 0.4907\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9048 - val_loss: 0.6960 - val_accuracy: 0.5144\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2061 - accuracy: 0.9096 - val_loss: 0.6959 - val_accuracy: 0.5175\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2106 - accuracy: 0.9070 - val_loss: 0.6961 - val_accuracy: 0.5226\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9114 - val_loss: 0.6933 - val_accuracy: 0.4938\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9118 - val_loss: 0.6964 - val_accuracy: 0.5165\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2091 - accuracy: 0.9065 - val_loss: 0.7176 - val_accuracy: 0.5134\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2059 - accuracy: 0.9065 - val_loss: 0.6939 - val_accuracy: 0.4907\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9162 - val_loss: 0.7003 - val_accuracy: 0.5103\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9153 - val_loss: 0.7075 - val_accuracy: 0.4918\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2093 - accuracy: 0.9078 - val_loss: 0.7025 - val_accuracy: 0.5093\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2010 - accuracy: 0.9153 - val_loss: 0.7131 - val_accuracy: 0.5051\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2111 - accuracy: 0.9034 - val_loss: 0.7154 - val_accuracy: 0.4805\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2074 - accuracy: 0.9048 - val_loss: 0.6942 - val_accuracy: 0.4928\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9189 - val_loss: 0.6970 - val_accuracy: 0.4877\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2080 - accuracy: 0.8999 - val_loss: 0.6931 - val_accuracy: 0.5062\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9167 - val_loss: 0.7085 - val_accuracy: 0.5103\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1973 - accuracy: 0.9167 - val_loss: 0.6953 - val_accuracy: 0.5195\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9153 - val_loss: 0.7018 - val_accuracy: 0.4979\n","Score: 0.49794238805770874 \n","Parameters:  {'learning_rate': 0.0888587783020632, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7907 - accuracy: 0.9131 - val_loss: 0.6728 - val_accuracy: 0.6430\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1776 - accuracy: 0.9246 - val_loss: 0.6338 - val_accuracy: 0.7006\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1846 - accuracy: 0.9259 - val_loss: 0.6164 - val_accuracy: 0.7047\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1649 - accuracy: 0.9334 - val_loss: 0.5963 - val_accuracy: 0.7078\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1727 - accuracy: 0.9299 - val_loss: 0.5874 - val_accuracy: 0.7202\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1929 - accuracy: 0.9268 - val_loss: 0.5962 - val_accuracy: 0.7016\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9365 - val_loss: 0.5585 - val_accuracy: 0.7510\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1737 - accuracy: 0.9250 - val_loss: 0.5693 - val_accuracy: 0.7191\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1618 - accuracy: 0.9365 - val_loss: 0.5460 - val_accuracy: 0.7459\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1677 - accuracy: 0.9321 - val_loss: 0.6102 - val_accuracy: 0.6698\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2004 - accuracy: 0.9158 - val_loss: 0.6967 - val_accuracy: 0.5144\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2592 - accuracy: 0.9149 - val_loss: 0.7005 - val_accuracy: 0.5123\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2054 - accuracy: 0.9202 - val_loss: 0.5484 - val_accuracy: 0.7737\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9224 - val_loss: 0.5858 - val_accuracy: 0.7047\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9312 - val_loss: 0.5727 - val_accuracy: 0.7377\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1598 - accuracy: 0.9325 - val_loss: 0.4663 - val_accuracy: 0.7706\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1675 - accuracy: 0.9374 - val_loss: 0.5009 - val_accuracy: 0.7809\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1450 - accuracy: 0.9392 - val_loss: 0.4510 - val_accuracy: 0.8025\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1489 - accuracy: 0.9374 - val_loss: 0.5045 - val_accuracy: 0.7891\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1564 - accuracy: 0.9414 - val_loss: 0.5355 - val_accuracy: 0.7654\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1740 - accuracy: 0.9321 - val_loss: 0.4903 - val_accuracy: 0.7829\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1409 - accuracy: 0.9449 - val_loss: 0.4984 - val_accuracy: 0.7891\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1615 - accuracy: 0.9444 - val_loss: 0.4899 - val_accuracy: 0.7809\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1782 - accuracy: 0.9396 - val_loss: 0.5404 - val_accuracy: 0.7510\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2169 - accuracy: 0.9136 - val_loss: 0.5787 - val_accuracy: 0.7346\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9392 - val_loss: 0.4931 - val_accuracy: 0.7860\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1508 - accuracy: 0.9374 - val_loss: 0.4946 - val_accuracy: 0.7757\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1627 - accuracy: 0.9339 - val_loss: 0.5529 - val_accuracy: 0.7695\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1624 - accuracy: 0.9347 - val_loss: 0.4975 - val_accuracy: 0.7613\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1476 - accuracy: 0.9458 - val_loss: 0.4741 - val_accuracy: 0.7891\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5301 - accuracy: 0.9325 - val_loss: 0.5176 - val_accuracy: 0.7767\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2469 - accuracy: 0.9431 - val_loss: 0.4475 - val_accuracy: 0.7932\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2937 - accuracy: 0.9444 - val_loss: 0.4440 - val_accuracy: 0.7860\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4129 - accuracy: 0.9458 - val_loss: 0.4518 - val_accuracy: 0.7829\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1139 - accuracy: 0.9581 - val_loss: 0.4261 - val_accuracy: 0.8025\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1314 - accuracy: 0.9449 - val_loss: 0.4337 - val_accuracy: 0.7932\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1531 - accuracy: 0.9431 - val_loss: 0.3993 - val_accuracy: 0.8220\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1341 - accuracy: 0.9431 - val_loss: 0.4454 - val_accuracy: 0.8086\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1426 - accuracy: 0.9471 - val_loss: 0.4402 - val_accuracy: 0.7654\n","Epoch 40/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1398 - accuracy: 0.9458 - val_loss: 0.4471 - val_accuracy: 0.7706\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9519 - val_loss: 0.4665 - val_accuracy: 0.7891\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1763 - accuracy: 0.9436 - val_loss: 0.4321 - val_accuracy: 0.8117\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1319 - accuracy: 0.9493 - val_loss: 0.4119 - val_accuracy: 0.8210\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1349 - accuracy: 0.9466 - val_loss: 0.4306 - val_accuracy: 0.7912\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9458 - val_loss: 0.4249 - val_accuracy: 0.7994\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1661 - accuracy: 0.9440 - val_loss: 0.4568 - val_accuracy: 0.7901\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1294 - accuracy: 0.9537 - val_loss: 0.4383 - val_accuracy: 0.7973\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1422 - accuracy: 0.9462 - val_loss: 0.4140 - val_accuracy: 0.8179\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9524 - val_loss: 0.4022 - val_accuracy: 0.8189\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9506 - val_loss: 0.4225 - val_accuracy: 0.8045\n","Score: 0.8045267462730408 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.7116 - accuracy: 0.9211 - val_loss: 0.6002 - val_accuracy: 0.6790\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1787 - accuracy: 0.9325 - val_loss: 0.5845 - val_accuracy: 0.6934\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1715 - accuracy: 0.9339 - val_loss: 0.5485 - val_accuracy: 0.7500\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1879 - accuracy: 0.9277 - val_loss: 0.5330 - val_accuracy: 0.7212\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1477 - accuracy: 0.9497 - val_loss: 0.5161 - val_accuracy: 0.7531\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.9414 - val_loss: 0.4745 - val_accuracy: 0.7685\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9427 - val_loss: 0.4575 - val_accuracy: 0.7726\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1355 - accuracy: 0.9466 - val_loss: 0.5058 - val_accuracy: 0.7582\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1456 - accuracy: 0.9392 - val_loss: 0.4568 - val_accuracy: 0.8004\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1624 - accuracy: 0.9453 - val_loss: 0.4529 - val_accuracy: 0.7891\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1442 - accuracy: 0.9414 - val_loss: 0.4280 - val_accuracy: 0.8035\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9511 - val_loss: 0.4271 - val_accuracy: 0.8107\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1807 - accuracy: 0.9405 - val_loss: 0.4565 - val_accuracy: 0.7963\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9497 - val_loss: 0.4339 - val_accuracy: 0.8148\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1528 - accuracy: 0.9440 - val_loss: 0.4241 - val_accuracy: 0.8107\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1325 - accuracy: 0.9489 - val_loss: 0.3860 - val_accuracy: 0.8282\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9515 - val_loss: 0.3666 - val_accuracy: 0.8385\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9524 - val_loss: 0.3660 - val_accuracy: 0.8189\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1294 - accuracy: 0.9502 - val_loss: 0.4293 - val_accuracy: 0.8025\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9444 - val_loss: 0.5004 - val_accuracy: 0.8025\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1490 - accuracy: 0.9475 - val_loss: 0.3487 - val_accuracy: 0.8374\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1349 - accuracy: 0.9515 - val_loss: 0.4219 - val_accuracy: 0.8107\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1279 - accuracy: 0.9533 - val_loss: 0.4865 - val_accuracy: 0.7747\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9480 - val_loss: 1.2101 - val_accuracy: 0.4938\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1210 - accuracy: 0.9586 - val_loss: 0.3709 - val_accuracy: 0.8158\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2868 - accuracy: 0.9599 - val_loss: 0.4283 - val_accuracy: 0.8117\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1266 - accuracy: 0.9555 - val_loss: 0.3688 - val_accuracy: 0.8241\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1124 - accuracy: 0.9616 - val_loss: 0.3609 - val_accuracy: 0.8189\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1070 - accuracy: 0.9550 - val_loss: 0.3405 - val_accuracy: 0.8426\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9612 - val_loss: 0.3230 - val_accuracy: 0.8539\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.9519 - val_loss: 0.3555 - val_accuracy: 0.8447\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1490 - accuracy: 0.9471 - val_loss: 0.4084 - val_accuracy: 0.8117\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1211 - accuracy: 0.9541 - val_loss: 0.3052 - val_accuracy: 0.8611\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9511 - val_loss: 0.3527 - val_accuracy: 0.8374\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1836 - accuracy: 0.9559 - val_loss: 0.3399 - val_accuracy: 0.8313\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1435 - accuracy: 0.9559 - val_loss: 0.3469 - val_accuracy: 0.8498\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1331 - accuracy: 0.9497 - val_loss: 0.3104 - val_accuracy: 0.8549\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3043 - accuracy: 0.9581 - val_loss: 0.3376 - val_accuracy: 0.8323\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0996 - accuracy: 0.9586 - val_loss: 0.3372 - val_accuracy: 0.8426\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1123 - accuracy: 0.9590 - val_loss: 0.3050 - val_accuracy: 0.8580\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1050 - accuracy: 0.9546 - val_loss: 0.3074 - val_accuracy: 0.8549\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0878 - accuracy: 0.9652 - val_loss: 0.2898 - val_accuracy: 0.8735\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0849 - accuracy: 0.9669 - val_loss: 0.3617 - val_accuracy: 0.8333\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1233 - accuracy: 0.9678 - val_loss: 0.2540 - val_accuracy: 0.8673\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0953 - accuracy: 0.9735 - val_loss: 0.3955 - val_accuracy: 0.8354\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0948 - accuracy: 0.9634 - val_loss: 0.2808 - val_accuracy: 0.8735\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0790 - accuracy: 0.9700 - val_loss: 0.2846 - val_accuracy: 0.8724\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0997 - accuracy: 0.9647 - val_loss: 0.2451 - val_accuracy: 0.8848\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0857 - accuracy: 0.9687 - val_loss: 0.3224 - val_accuracy: 0.8416\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9669 - val_loss: 0.3066 - val_accuracy: 0.8837\n","Score: 0.8837448358535767 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6041 - accuracy: 0.9233 - val_loss: 0.5928 - val_accuracy: 0.6944\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.9272 - val_loss: 0.5940 - val_accuracy: 0.7006\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9162 - val_loss: 0.5570 - val_accuracy: 0.7274\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2397 - accuracy: 0.9321 - val_loss: 0.5415 - val_accuracy: 0.7253\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1721 - accuracy: 0.9352 - val_loss: 0.5382 - val_accuracy: 0.7233\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1691 - accuracy: 0.9418 - val_loss: 0.4947 - val_accuracy: 0.7582\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1495 - accuracy: 0.9361 - val_loss: 0.4459 - val_accuracy: 0.7716\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1464 - accuracy: 0.9405 - val_loss: 0.5100 - val_accuracy: 0.7469\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1227 - accuracy: 0.9537 - val_loss: 0.4603 - val_accuracy: 0.7737\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9506 - val_loss: 0.4710 - val_accuracy: 0.7675\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1660 - accuracy: 0.9480 - val_loss: 0.4075 - val_accuracy: 0.8148\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1409 - accuracy: 0.9427 - val_loss: 0.4506 - val_accuracy: 0.7757\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9533 - val_loss: 0.4752 - val_accuracy: 0.7901\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1430 - accuracy: 0.9480 - val_loss: 0.4738 - val_accuracy: 0.7685\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.9497 - val_loss: 0.4595 - val_accuracy: 0.7891\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1567 - accuracy: 0.9436 - val_loss: 0.4429 - val_accuracy: 0.7912\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1435 - accuracy: 0.9506 - val_loss: 0.4157 - val_accuracy: 0.8014\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1255 - accuracy: 0.9537 - val_loss: 0.4055 - val_accuracy: 0.8148\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1275 - accuracy: 0.9515 - val_loss: 0.4126 - val_accuracy: 0.7922\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1242 - accuracy: 0.9528 - val_loss: 0.4463 - val_accuracy: 0.7953\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1374 - accuracy: 0.9625 - val_loss: 0.3641 - val_accuracy: 0.8344\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1423 - accuracy: 0.9493 - val_loss: 0.4645 - val_accuracy: 0.8261\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1810 - accuracy: 0.9466 - val_loss: 0.4037 - val_accuracy: 0.8158\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1781 - accuracy: 0.9568 - val_loss: 0.4178 - val_accuracy: 0.8097\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1666 - accuracy: 0.9563 - val_loss: 0.3399 - val_accuracy: 0.8488\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1055 - accuracy: 0.9625 - val_loss: 0.3451 - val_accuracy: 0.8426\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1662 - accuracy: 0.9537 - val_loss: 0.3204 - val_accuracy: 0.8724\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1030 - accuracy: 0.9586 - val_loss: 0.3704 - val_accuracy: 0.8272\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1062 - accuracy: 0.9599 - val_loss: 0.3176 - val_accuracy: 0.8519\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1150 - accuracy: 0.9577 - val_loss: 0.3568 - val_accuracy: 0.8508\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.9603 - val_loss: 0.3938 - val_accuracy: 0.8272\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0949 - accuracy: 0.9652 - val_loss: 0.3314 - val_accuracy: 0.8457\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0995 - accuracy: 0.9678 - val_loss: 0.3603 - val_accuracy: 0.8364\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3218 - accuracy: 0.9608 - val_loss: 0.3294 - val_accuracy: 0.8395\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1988 - accuracy: 0.9590 - val_loss: 0.2991 - val_accuracy: 0.8704\n","Epoch 36/50\n","567/567 [==============================] - 4s 7ms/step - loss: 0.0833 - accuracy: 0.9691 - val_loss: 0.2887 - val_accuracy: 0.8755\n","Epoch 37/50\n","567/567 [==============================] - 4s 7ms/step - loss: 0.1129 - accuracy: 0.9656 - val_loss: 0.2774 - val_accuracy: 0.8724\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0952 - accuracy: 0.9691 - val_loss: 0.3156 - val_accuracy: 0.8683\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0893 - accuracy: 0.9696 - val_loss: 0.2702 - val_accuracy: 0.8889\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9722 - val_loss: 0.2862 - val_accuracy: 0.8765\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0900 - accuracy: 0.9744 - val_loss: 0.2662 - val_accuracy: 0.8858\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9687 - val_loss: 0.2777 - val_accuracy: 0.8889\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0994 - accuracy: 0.9687 - val_loss: 0.3159 - val_accuracy: 0.8848\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1385 - accuracy: 0.9581 - val_loss: 0.3141 - val_accuracy: 0.8652\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0842 - accuracy: 0.9687 - val_loss: 0.2575 - val_accuracy: 0.8858\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0947 - accuracy: 0.9735 - val_loss: 0.2450 - val_accuracy: 0.9053\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0807 - accuracy: 0.9727 - val_loss: 0.2184 - val_accuracy: 0.9187\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0906 - accuracy: 0.9709 - val_loss: 0.3285 - val_accuracy: 0.8508\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0704 - accuracy: 0.9705 - val_loss: 0.2513 - val_accuracy: 0.8879\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 0.2020 - val_accuracy: 0.9095\n","Score: 0.9094650149345398 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 11875.4580 - accuracy: 0.9078 - val_loss: 0.7014 - val_accuracy: 0.5103\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9153 - val_loss: 0.6916 - val_accuracy: 0.5298\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2159 - accuracy: 0.9158 - val_loss: 0.7230 - val_accuracy: 0.4794\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2226 - accuracy: 0.9043 - val_loss: 0.6944 - val_accuracy: 0.4887\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2164 - accuracy: 0.9149 - val_loss: 0.6943 - val_accuracy: 0.5175\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2211 - accuracy: 0.9114 - val_loss: 0.6937 - val_accuracy: 0.4784\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2259 - accuracy: 0.9114 - val_loss: 0.6968 - val_accuracy: 0.5123\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2093 - accuracy: 0.9206 - val_loss: 0.7003 - val_accuracy: 0.5082\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2206 - accuracy: 0.9078 - val_loss: 0.6936 - val_accuracy: 0.4918\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2287 - accuracy: 0.9149 - val_loss: 0.6953 - val_accuracy: 0.5123\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2244 - accuracy: 0.9127 - val_loss: 0.6940 - val_accuracy: 0.5113\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2257 - accuracy: 0.9109 - val_loss: 0.6911 - val_accuracy: 0.5329\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9162 - val_loss: 0.6960 - val_accuracy: 0.5237\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2235 - accuracy: 0.9145 - val_loss: 0.6976 - val_accuracy: 0.5051\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2113 - accuracy: 0.9153 - val_loss: 0.6932 - val_accuracy: 0.5072\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2197 - accuracy: 0.9162 - val_loss: 0.6950 - val_accuracy: 0.4722\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2246 - accuracy: 0.9052 - val_loss: 0.6939 - val_accuracy: 0.5175\n","Epoch 18/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2256 - accuracy: 0.9026 - val_loss: 0.6951 - val_accuracy: 0.5185\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2217 - accuracy: 0.9123 - val_loss: 0.7013 - val_accuracy: 0.4846\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2268 - accuracy: 0.9052 - val_loss: 0.7037 - val_accuracy: 0.5103\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2159 - accuracy: 0.9175 - val_loss: 0.6929 - val_accuracy: 0.5237\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2327 - accuracy: 0.9105 - val_loss: 0.6922 - val_accuracy: 0.5278\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2197 - accuracy: 0.9167 - val_loss: 0.6948 - val_accuracy: 0.4979\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2169 - accuracy: 0.9171 - val_loss: 0.7070 - val_accuracy: 0.4835\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2132 - accuracy: 0.9092 - val_loss: 0.6961 - val_accuracy: 0.4650\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2294 - accuracy: 0.9061 - val_loss: 0.6951 - val_accuracy: 0.5237\n","Epoch 27/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2217 - accuracy: 0.9140 - val_loss: 0.6954 - val_accuracy: 0.5165\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2180 - accuracy: 0.9189 - val_loss: 0.6972 - val_accuracy: 0.4815\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2269 - accuracy: 0.9052 - val_loss: 0.6911 - val_accuracy: 0.5319\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2148 - accuracy: 0.9211 - val_loss: 0.6945 - val_accuracy: 0.5257\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2201 - accuracy: 0.9127 - val_loss: 0.6952 - val_accuracy: 0.4733\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2238 - accuracy: 0.9008 - val_loss: 0.6930 - val_accuracy: 0.5072\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2203 - accuracy: 0.9198 - val_loss: 0.6936 - val_accuracy: 0.5195\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2242 - accuracy: 0.9070 - val_loss: 0.6931 - val_accuracy: 0.5041\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2226 - accuracy: 0.9153 - val_loss: 0.6933 - val_accuracy: 0.4938\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2229 - accuracy: 0.9101 - val_loss: 0.6949 - val_accuracy: 0.5278\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2159 - accuracy: 0.9149 - val_loss: 0.6919 - val_accuracy: 0.5267\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2261 - accuracy: 0.9136 - val_loss: 0.7031 - val_accuracy: 0.5031\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2183 - accuracy: 0.9171 - val_loss: 0.6942 - val_accuracy: 0.5237\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.9202 - val_loss: 0.7006 - val_accuracy: 0.5123\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2151 - accuracy: 0.9158 - val_loss: 0.6943 - val_accuracy: 0.4918\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2235 - accuracy: 0.9056 - val_loss: 0.6971 - val_accuracy: 0.4763\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2271 - accuracy: 0.9026 - val_loss: 0.6990 - val_accuracy: 0.4877\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2249 - accuracy: 0.9096 - val_loss: 0.7218 - val_accuracy: 0.5185\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2116 - accuracy: 0.9202 - val_loss: 0.6946 - val_accuracy: 0.5278\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2146 - accuracy: 0.9162 - val_loss: 0.6941 - val_accuracy: 0.4969\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2172 - accuracy: 0.9153 - val_loss: 0.7177 - val_accuracy: 0.5123\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2166 - accuracy: 0.9162 - val_loss: 0.6970 - val_accuracy: 0.5134\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2184 - accuracy: 0.9118 - val_loss: 0.6924 - val_accuracy: 0.5206\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2217 - accuracy: 0.9114 - val_loss: 0.6950 - val_accuracy: 0.4846\n","Score: 0.48456791043281555 \n","Parameters:  {'learning_rate': 0.05033350147910386, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 3096.8398 - accuracy: 0.8942 - val_loss: 0.8009 - val_accuracy: 0.5144\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1885 - accuracy: 0.9096 - val_loss: 0.7827 - val_accuracy: 0.5072\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1760 - accuracy: 0.9056 - val_loss: 0.6967 - val_accuracy: 0.5165\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1926 - accuracy: 0.9131 - val_loss: 0.6981 - val_accuracy: 0.5216\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2410 - accuracy: 0.9078 - val_loss: 0.6933 - val_accuracy: 0.5051\n","Epoch 6/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2528 - accuracy: 0.9026 - val_loss: 0.6954 - val_accuracy: 0.5185\n","Epoch 7/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2434 - accuracy: 0.9153 - val_loss: 0.6957 - val_accuracy: 0.5309\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2439 - accuracy: 0.9140 - val_loss: 0.6930 - val_accuracy: 0.5134\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2424 - accuracy: 0.9180 - val_loss: 0.6918 - val_accuracy: 0.5206\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2533 - accuracy: 0.9109 - val_loss: 0.6919 - val_accuracy: 0.5165\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2254 - accuracy: 0.9078 - val_loss: 0.6978 - val_accuracy: 0.5010\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2254 - accuracy: 0.9030 - val_loss: 0.7211 - val_accuracy: 0.4907\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2311 - accuracy: 0.9167 - val_loss: 0.7097 - val_accuracy: 0.5175\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2393 - accuracy: 0.9114 - val_loss: 0.6917 - val_accuracy: 0.5226\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2482 - accuracy: 0.9118 - val_loss: 0.6943 - val_accuracy: 0.4897\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2569 - accuracy: 0.9030 - val_loss: 0.7052 - val_accuracy: 0.5134\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2380 - accuracy: 0.9123 - val_loss: 0.6953 - val_accuracy: 0.4825\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2517 - accuracy: 0.9012 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2375 - accuracy: 0.9198 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2546 - accuracy: 0.9145 - val_loss: 0.6988 - val_accuracy: 0.5154\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2440 - accuracy: 0.9140 - val_loss: 0.6929 - val_accuracy: 0.5185\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2438 - accuracy: 0.9193 - val_loss: 0.6956 - val_accuracy: 0.5041\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2389 - accuracy: 0.9158 - val_loss: 0.6924 - val_accuracy: 0.5123\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2504 - accuracy: 0.9158 - val_loss: 0.6943 - val_accuracy: 0.5185\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2362 - accuracy: 0.9250 - val_loss: 0.7069 - val_accuracy: 0.5041\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.9149 - val_loss: 0.6917 - val_accuracy: 0.5319\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2557 - accuracy: 0.9109 - val_loss: 0.6956 - val_accuracy: 0.5144\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.9149 - val_loss: 0.6932 - val_accuracy: 0.4671\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6455 - accuracy: 0.9056 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2488 - accuracy: 0.9153 - val_loss: 0.6949 - val_accuracy: 0.5082\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2467 - accuracy: 0.9145 - val_loss: 0.6929 - val_accuracy: 0.5195\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2508 - accuracy: 0.9123 - val_loss: 0.6961 - val_accuracy: 0.5103\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2514 - accuracy: 0.9127 - val_loss: 0.6956 - val_accuracy: 0.5154\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2494 - accuracy: 0.9158 - val_loss: 0.6989 - val_accuracy: 0.5185\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2450 - accuracy: 0.9136 - val_loss: 0.6930 - val_accuracy: 0.5093\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2450 - accuracy: 0.9202 - val_loss: 0.6936 - val_accuracy: 0.5185\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2440 - accuracy: 0.9158 - val_loss: 0.6984 - val_accuracy: 0.5062\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2396 - accuracy: 0.9145 - val_loss: 0.6957 - val_accuracy: 0.4938\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2638 - accuracy: 0.8964 - val_loss: 0.6979 - val_accuracy: 0.5154\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2501 - accuracy: 0.9131 - val_loss: 0.7049 - val_accuracy: 0.5134\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2470 - accuracy: 0.9131 - val_loss: 0.6935 - val_accuracy: 0.5165\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2409 - accuracy: 0.9193 - val_loss: 0.6911 - val_accuracy: 0.5319\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2452 - accuracy: 0.9136 - val_loss: 0.7059 - val_accuracy: 0.4846\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2561 - accuracy: 0.8990 - val_loss: 0.7006 - val_accuracy: 0.5226\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9180 - val_loss: 0.7092 - val_accuracy: 0.5093\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2472 - accuracy: 0.9109 - val_loss: 0.6934 - val_accuracy: 0.5093\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2449 - accuracy: 0.9162 - val_loss: 0.6931 - val_accuracy: 0.5051\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2522 - accuracy: 0.9158 - val_loss: 0.7135 - val_accuracy: 0.5103\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2435 - accuracy: 0.9105 - val_loss: 0.6938 - val_accuracy: 0.4784\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2451 - accuracy: 0.9127 - val_loss: 0.6933 - val_accuracy: 0.5216\n","Score: 0.5216049551963806 \n","Parameters:  {'learning_rate': 0.031122962976905467, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.1285 - accuracy: 0.9026 - val_loss: 0.6762 - val_accuracy: 0.5134\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1977 - accuracy: 0.9220 - val_loss: 0.6431 - val_accuracy: 0.6605\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1937 - accuracy: 0.9140 - val_loss: 0.7088 - val_accuracy: 0.5154\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2359 - accuracy: 0.9118 - val_loss: 0.7244 - val_accuracy: 0.5175\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2501 - accuracy: 0.9189 - val_loss: 0.7610 - val_accuracy: 0.5185\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3702 - accuracy: 0.9118 - val_loss: 0.8091 - val_accuracy: 0.5072\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2622 - accuracy: 0.9189 - val_loss: 0.7768 - val_accuracy: 0.5226\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2382 - accuracy: 0.9242 - val_loss: 0.6560 - val_accuracy: 0.6317\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2160 - accuracy: 0.9202 - val_loss: 0.6374 - val_accuracy: 0.6667\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1738 - accuracy: 0.9202 - val_loss: 0.6150 - val_accuracy: 0.7160\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2149 - accuracy: 0.9259 - val_loss: 0.5721 - val_accuracy: 0.7222\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9233 - val_loss: 0.6077 - val_accuracy: 0.7469\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2303 - accuracy: 0.9140 - val_loss: 0.6958 - val_accuracy: 0.5319\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3806 - accuracy: 0.9189 - val_loss: 0.6128 - val_accuracy: 0.6224\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1630 - accuracy: 0.9361 - val_loss: 0.5666 - val_accuracy: 0.7233\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9347 - val_loss: 0.5651 - val_accuracy: 0.7047\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1825 - accuracy: 0.9259 - val_loss: 0.5060 - val_accuracy: 0.7757\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9250 - val_loss: 0.5992 - val_accuracy: 0.6440\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1434 - accuracy: 0.9392 - val_loss: 0.5009 - val_accuracy: 0.7438\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9317 - val_loss: 0.4589 - val_accuracy: 0.7829\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1578 - accuracy: 0.9396 - val_loss: 0.4476 - val_accuracy: 0.7860\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1421 - accuracy: 0.9396 - val_loss: 0.4490 - val_accuracy: 0.7809\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1495 - accuracy: 0.9365 - val_loss: 0.4911 - val_accuracy: 0.7623\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2495 - accuracy: 0.9361 - val_loss: 0.4522 - val_accuracy: 0.7922\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1454 - accuracy: 0.9400 - val_loss: 0.4591 - val_accuracy: 0.7695\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2531 - accuracy: 0.9378 - val_loss: 0.4246 - val_accuracy: 0.8004\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1553 - accuracy: 0.9436 - val_loss: 0.4736 - val_accuracy: 0.7644\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1302 - accuracy: 0.9440 - val_loss: 0.4516 - val_accuracy: 0.7644\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1404 - accuracy: 0.9449 - val_loss: 0.5335 - val_accuracy: 0.7377\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1599 - accuracy: 0.9422 - val_loss: 0.5041 - val_accuracy: 0.7428\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1756 - accuracy: 0.9312 - val_loss: 0.5067 - val_accuracy: 0.7644\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1546 - accuracy: 0.9325 - val_loss: 0.5310 - val_accuracy: 0.7459\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9334 - val_loss: 0.4643 - val_accuracy: 0.7850\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1232 - accuracy: 0.9475 - val_loss: 0.4414 - val_accuracy: 0.8066\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9471 - val_loss: 0.4383 - val_accuracy: 0.7994\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1590 - accuracy: 0.9458 - val_loss: 0.4304 - val_accuracy: 0.8066\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1653 - accuracy: 0.9414 - val_loss: 0.5037 - val_accuracy: 0.7963\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9308 - val_loss: 0.4965 - val_accuracy: 0.7572\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1404 - accuracy: 0.9418 - val_loss: 0.5044 - val_accuracy: 0.7675\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9387 - val_loss: 0.4619 - val_accuracy: 0.7716\n","Epoch 41/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1327 - accuracy: 0.9533 - val_loss: 0.4283 - val_accuracy: 0.7819\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1642 - accuracy: 0.9427 - val_loss: 0.4187 - val_accuracy: 0.7922\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9462 - val_loss: 0.4428 - val_accuracy: 0.7881\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1377 - accuracy: 0.9466 - val_loss: 0.4674 - val_accuracy: 0.7891\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2136 - accuracy: 0.9418 - val_loss: 0.4098 - val_accuracy: 0.8117\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.9484 - val_loss: 0.4357 - val_accuracy: 0.7850\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9462 - val_loss: 0.4138 - val_accuracy: 0.8107\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1529 - accuracy: 0.9418 - val_loss: 0.4947 - val_accuracy: 0.7644\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1304 - accuracy: 0.9502 - val_loss: 0.4345 - val_accuracy: 0.7932\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1357 - accuracy: 0.9497 - val_loss: 0.3883 - val_accuracy: 0.8210\n","Score: 0.8209876418113708 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 0.8088 - accuracy: 0.9228 - val_loss: 0.6417 - val_accuracy: 0.6749\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2162 - accuracy: 0.9317 - val_loss: 0.5753 - val_accuracy: 0.7212\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1618 - accuracy: 0.9250 - val_loss: 0.5260 - val_accuracy: 0.7593\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9334 - val_loss: 0.5158 - val_accuracy: 0.7490\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1345 - accuracy: 0.9400 - val_loss: 0.4784 - val_accuracy: 0.7788\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1469 - accuracy: 0.9458 - val_loss: 0.4956 - val_accuracy: 0.7840\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9378 - val_loss: 0.4918 - val_accuracy: 0.7469\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9489 - val_loss: 0.4121 - val_accuracy: 0.8148\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1253 - accuracy: 0.9493 - val_loss: 0.3874 - val_accuracy: 0.8210\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1069 - accuracy: 0.9616 - val_loss: 0.3893 - val_accuracy: 0.8148\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1196 - accuracy: 0.9475 - val_loss: 0.3934 - val_accuracy: 0.8117\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1373 - accuracy: 0.9444 - val_loss: 0.3845 - val_accuracy: 0.8158\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.9484 - val_loss: 0.3438 - val_accuracy: 0.8313\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1169 - accuracy: 0.9559 - val_loss: 0.4532 - val_accuracy: 0.7675\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1253 - accuracy: 0.9449 - val_loss: 0.4184 - val_accuracy: 0.7922\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1035 - accuracy: 0.9559 - val_loss: 0.3366 - val_accuracy: 0.8354\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1094 - accuracy: 0.9533 - val_loss: 0.3712 - val_accuracy: 0.8364\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3420 - accuracy: 0.9502 - val_loss: 1.4770 - val_accuracy: 0.7840\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1243 - accuracy: 0.9493 - val_loss: 0.3155 - val_accuracy: 0.8467\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1312 - accuracy: 0.9541 - val_loss: 0.3671 - val_accuracy: 0.8333\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1034 - accuracy: 0.9643 - val_loss: 0.4368 - val_accuracy: 0.8179\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9541 - val_loss: 0.3299 - val_accuracy: 0.8385\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1081 - accuracy: 0.9550 - val_loss: 0.3196 - val_accuracy: 0.8477\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0955 - accuracy: 0.9599 - val_loss: 0.3158 - val_accuracy: 0.8539\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0923 - accuracy: 0.9634 - val_loss: 0.3051 - val_accuracy: 0.8621\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1184 - accuracy: 0.9559 - val_loss: 0.3036 - val_accuracy: 0.8591\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1134 - accuracy: 0.9616 - val_loss: 0.3760 - val_accuracy: 0.8364\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0974 - accuracy: 0.9599 - val_loss: 0.2978 - val_accuracy: 0.8786\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1058 - accuracy: 0.9581 - val_loss: 0.3128 - val_accuracy: 0.8539\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1007 - accuracy: 0.9678 - val_loss: 0.2438 - val_accuracy: 0.8807\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.9590 - val_loss: 0.3056 - val_accuracy: 0.8591\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.9586 - val_loss: 0.3231 - val_accuracy: 0.8374\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1205 - accuracy: 0.9581 - val_loss: 0.3318 - val_accuracy: 0.8282\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0945 - accuracy: 0.9608 - val_loss: 0.2512 - val_accuracy: 0.8807\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0812 - accuracy: 0.9700 - val_loss: 0.2780 - val_accuracy: 0.8683\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0917 - accuracy: 0.9656 - val_loss: 0.2571 - val_accuracy: 0.8858\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1223 - accuracy: 0.9643 - val_loss: 0.3588 - val_accuracy: 0.8570\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0732 - accuracy: 0.9696 - val_loss: 0.3087 - val_accuracy: 0.8591\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9713 - val_loss: 0.3358 - val_accuracy: 0.8364\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0701 - accuracy: 0.9740 - val_loss: 0.2531 - val_accuracy: 0.8868\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0978 - accuracy: 0.9700 - val_loss: 0.2790 - val_accuracy: 0.8765\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0685 - accuracy: 0.9780 - val_loss: 0.2726 - val_accuracy: 0.8673\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0702 - accuracy: 0.9718 - val_loss: 0.2542 - val_accuracy: 0.8879\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9731 - val_loss: 0.2513 - val_accuracy: 0.9023\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0826 - accuracy: 0.9722 - val_loss: 0.2534 - val_accuracy: 0.8951\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0798 - accuracy: 0.9691 - val_loss: 0.2572 - val_accuracy: 0.8735\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 0.2926 - val_accuracy: 0.8714\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0720 - accuracy: 0.9766 - val_loss: 0.1946 - val_accuracy: 0.9187\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0740 - accuracy: 0.9744 - val_loss: 0.1909 - val_accuracy: 0.9167\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0658 - accuracy: 0.9762 - val_loss: 0.2335 - val_accuracy: 0.8951\n","Score: 0.895061731338501 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 361.5400 - accuracy: 0.9030 - val_loss: 0.6931 - val_accuracy: 0.5103\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2782 - accuracy: 0.9180 - val_loss: 0.7721 - val_accuracy: 0.5175\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2644 - accuracy: 0.9215 - val_loss: 0.8035 - val_accuracy: 0.5062\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2722 - accuracy: 0.9131 - val_loss: 0.7403 - val_accuracy: 0.5144\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2881 - accuracy: 0.9105 - val_loss: 0.7518 - val_accuracy: 0.5062\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2841 - accuracy: 0.9140 - val_loss: 0.7747 - val_accuracy: 0.5103\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2793 - accuracy: 0.9149 - val_loss: 0.7789 - val_accuracy: 0.5154\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2782 - accuracy: 0.9171 - val_loss: 0.7700 - val_accuracy: 0.5216\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2769 - accuracy: 0.9175 - val_loss: 0.8026 - val_accuracy: 0.5113\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2768 - accuracy: 0.9158 - val_loss: 0.8010 - val_accuracy: 0.4969\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2779 - accuracy: 0.9153 - val_loss: 0.7937 - val_accuracy: 0.5021\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2755 - accuracy: 0.9175 - val_loss: 0.7979 - val_accuracy: 0.5082\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2687 - accuracy: 0.9206 - val_loss: 0.8055 - val_accuracy: 0.5010\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2761 - accuracy: 0.9158 - val_loss: 0.7774 - val_accuracy: 0.5195\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2699 - accuracy: 0.9198 - val_loss: 0.7585 - val_accuracy: 0.5350\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2768 - accuracy: 0.9136 - val_loss: 0.7444 - val_accuracy: 0.5319\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2883 - accuracy: 0.9083 - val_loss: 0.7592 - val_accuracy: 0.4990\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2644 - accuracy: 0.9268 - val_loss: 0.8279 - val_accuracy: 0.5226\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2695 - accuracy: 0.9167 - val_loss: 0.7896 - val_accuracy: 0.5031\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2761 - accuracy: 0.9158 - val_loss: 0.7894 - val_accuracy: 0.5031\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2939 - accuracy: 0.9043 - val_loss: 0.7241 - val_accuracy: 0.5237\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2839 - accuracy: 0.9149 - val_loss: 0.7787 - val_accuracy: 0.5185\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2794 - accuracy: 0.9145 - val_loss: 0.7795 - val_accuracy: 0.5021\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2877 - accuracy: 0.9105 - val_loss: 0.7681 - val_accuracy: 0.5103\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2783 - accuracy: 0.9153 - val_loss: 0.7870 - val_accuracy: 0.4979\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2774 - accuracy: 0.9184 - val_loss: 0.7810 - val_accuracy: 0.5257\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2740 - accuracy: 0.9158 - val_loss: 0.7696 - val_accuracy: 0.5278\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2825 - accuracy: 0.9118 - val_loss: 0.7707 - val_accuracy: 0.5103\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2775 - accuracy: 0.9180 - val_loss: 0.7832 - val_accuracy: 0.5144\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2709 - accuracy: 0.9198 - val_loss: 0.7869 - val_accuracy: 0.5226\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2737 - accuracy: 0.9158 - val_loss: 0.7704 - val_accuracy: 0.5195\n","Epoch 32/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2780 - accuracy: 0.9167 - val_loss: 0.7877 - val_accuracy: 0.5216\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2758 - accuracy: 0.9158 - val_loss: 0.7754 - val_accuracy: 0.5195\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2657 - accuracy: 0.9224 - val_loss: 0.8185 - val_accuracy: 0.5103\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2701 - accuracy: 0.9175 - val_loss: 0.7850 - val_accuracy: 0.5123\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2811 - accuracy: 0.9118 - val_loss: 0.7461 - val_accuracy: 0.5216\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2925 - accuracy: 0.9096 - val_loss: 0.7555 - val_accuracy: 0.5206\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2786 - accuracy: 0.9171 - val_loss: 0.7897 - val_accuracy: 0.5082\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2775 - accuracy: 0.9158 - val_loss: 0.7975 - val_accuracy: 0.4979\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2796 - accuracy: 0.9127 - val_loss: 0.7652 - val_accuracy: 0.5093\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2863 - accuracy: 0.9109 - val_loss: 0.7491 - val_accuracy: 0.5154\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2935 - accuracy: 0.9061 - val_loss: 0.7428 - val_accuracy: 0.5134\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2804 - accuracy: 0.9175 - val_loss: 0.7966 - val_accuracy: 0.5021\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2730 - accuracy: 0.9180 - val_loss: 0.7983 - val_accuracy: 0.4959\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2810 - accuracy: 0.9127 - val_loss: 0.7736 - val_accuracy: 0.5062\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2772 - accuracy: 0.9180 - val_loss: 0.8089 - val_accuracy: 0.5021\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2754 - accuracy: 0.9167 - val_loss: 0.7712 - val_accuracy: 0.5237\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2753 - accuracy: 0.9158 - val_loss: 0.7730 - val_accuracy: 0.5206\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2745 - accuracy: 0.9180 - val_loss: 0.7870 - val_accuracy: 0.5206\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2725 - accuracy: 0.9158 - val_loss: 0.7603 - val_accuracy: 0.5185\n","Score: 0.5185185074806213 \n","Parameters:  {'learning_rate': 0.016724876578246464, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 908738.7500 - accuracy: 0.9026 - val_loss: 0.6953 - val_accuracy: 0.4846\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9109 - val_loss: 0.7042 - val_accuracy: 0.4805\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.9101 - val_loss: 0.6944 - val_accuracy: 0.5093\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1976 - accuracy: 0.9101 - val_loss: 0.6997 - val_accuracy: 0.4794\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9083 - val_loss: 0.7223 - val_accuracy: 0.5103\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9074 - val_loss: 0.6997 - val_accuracy: 0.4856\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9109 - val_loss: 0.6951 - val_accuracy: 0.4866\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1873 - accuracy: 0.9149 - val_loss: 0.6929 - val_accuracy: 0.5206\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1863 - accuracy: 0.9180 - val_loss: 0.7122 - val_accuracy: 0.4835\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9026 - val_loss: 0.6936 - val_accuracy: 0.4907\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9127 - val_loss: 0.7789 - val_accuracy: 0.5103\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9158 - val_loss: 0.7600 - val_accuracy: 0.4979\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9074 - val_loss: 0.6933 - val_accuracy: 0.4681\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1818 - accuracy: 0.9228 - val_loss: 0.7644 - val_accuracy: 0.4825\n","Epoch 15/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1986 - accuracy: 0.8968 - val_loss: 0.6948 - val_accuracy: 0.4907\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1870 - accuracy: 0.9136 - val_loss: 0.6966 - val_accuracy: 0.5072\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1842 - accuracy: 0.9153 - val_loss: 0.7184 - val_accuracy: 0.5041\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9074 - val_loss: 0.7022 - val_accuracy: 0.5206\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1968 - accuracy: 0.9127 - val_loss: 0.6971 - val_accuracy: 0.4835\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.8915 - val_loss: 0.6962 - val_accuracy: 0.4979\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2025 - accuracy: 0.9065 - val_loss: 0.6933 - val_accuracy: 0.5165\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1926 - accuracy: 0.9083 - val_loss: 0.6927 - val_accuracy: 0.5144\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2044 - accuracy: 0.9101 - val_loss: 0.7715 - val_accuracy: 0.4763\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9074 - val_loss: 0.6958 - val_accuracy: 0.4784\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1906 - accuracy: 0.9074 - val_loss: 0.7318 - val_accuracy: 0.5165\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1879 - accuracy: 0.9206 - val_loss: 0.6950 - val_accuracy: 0.4794\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9131 - val_loss: 0.6982 - val_accuracy: 0.5134\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9184 - val_loss: 0.7239 - val_accuracy: 0.4990\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1963 - accuracy: 0.9140 - val_loss: 0.6949 - val_accuracy: 0.4907\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2018 - accuracy: 0.9114 - val_loss: 0.6950 - val_accuracy: 0.5093\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1965 - accuracy: 0.9127 - val_loss: 0.7134 - val_accuracy: 0.4928\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9123 - val_loss: 0.7025 - val_accuracy: 0.5031\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1802 - accuracy: 0.9206 - val_loss: 0.6958 - val_accuracy: 0.4733\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9092 - val_loss: 0.8062 - val_accuracy: 0.5000\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1959 - accuracy: 0.9118 - val_loss: 0.6971 - val_accuracy: 0.5041\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1988 - accuracy: 0.9136 - val_loss: 0.7147 - val_accuracy: 0.4794\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1949 - accuracy: 0.9083 - val_loss: 0.6928 - val_accuracy: 0.5185\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1939 - accuracy: 0.9114 - val_loss: 0.6982 - val_accuracy: 0.4907\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2011 - accuracy: 0.9114 - val_loss: 0.7118 - val_accuracy: 0.4907\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9131 - val_loss: 0.7122 - val_accuracy: 0.5309\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9149 - val_loss: 0.7087 - val_accuracy: 0.4907\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9074 - val_loss: 0.6933 - val_accuracy: 0.4990\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9083 - val_loss: 0.6956 - val_accuracy: 0.4846\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9175 - val_loss: 0.7960 - val_accuracy: 0.4784\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9056 - val_loss: 0.6965 - val_accuracy: 0.4784\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9039 - val_loss: 0.6935 - val_accuracy: 0.5051\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9109 - val_loss: 0.6930 - val_accuracy: 0.5257\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9202 - val_loss: 0.7098 - val_accuracy: 0.4733\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2005 - accuracy: 0.9056 - val_loss: 0.6917 - val_accuracy: 0.5278\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1950 - accuracy: 0.9145 - val_loss: 0.7141 - val_accuracy: 0.5206\n","Score: 0.5205761194229126 \n","Parameters:  {'learning_rate': 0.13853919018051844, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 4s 6ms/step - loss: 1.0021 - accuracy: 0.9056 - val_loss: 0.6895 - val_accuracy: 0.5093\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9198 - val_loss: 0.6837 - val_accuracy: 0.5298\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2353 - accuracy: 0.9237 - val_loss: 0.6098 - val_accuracy: 0.7109\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1717 - accuracy: 0.9286 - val_loss: 0.5983 - val_accuracy: 0.7191\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.9286 - val_loss: 0.5573 - val_accuracy: 0.7407\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1456 - accuracy: 0.9418 - val_loss: 0.4983 - val_accuracy: 0.7685\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1603 - accuracy: 0.9440 - val_loss: 0.5212 - val_accuracy: 0.7726\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1671 - accuracy: 0.9378 - val_loss: 0.4508 - val_accuracy: 0.7891\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9418 - val_loss: 0.4757 - val_accuracy: 0.7798\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1521 - accuracy: 0.9414 - val_loss: 0.5074 - val_accuracy: 0.7541\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1466 - accuracy: 0.9427 - val_loss: 0.4414 - val_accuracy: 0.7788\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9466 - val_loss: 0.4204 - val_accuracy: 0.8066\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9497 - val_loss: 0.4287 - val_accuracy: 0.7953\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9462 - val_loss: 0.4814 - val_accuracy: 0.7685\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1359 - accuracy: 0.9436 - val_loss: 0.5069 - val_accuracy: 0.7572\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1342 - accuracy: 0.9440 - val_loss: 0.4425 - val_accuracy: 0.8086\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1294 - accuracy: 0.9511 - val_loss: 0.4395 - val_accuracy: 0.7994\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1250 - accuracy: 0.9519 - val_loss: 0.4363 - val_accuracy: 0.7942\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1315 - accuracy: 0.9519 - val_loss: 0.4031 - val_accuracy: 0.8138\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9471 - val_loss: 0.4288 - val_accuracy: 0.7953\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1153 - accuracy: 0.9599 - val_loss: 0.4189 - val_accuracy: 0.8056\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1283 - accuracy: 0.9493 - val_loss: 0.4043 - val_accuracy: 0.8158\n","Epoch 23/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1317 - accuracy: 0.9436 - val_loss: 0.4631 - val_accuracy: 0.8179\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1146 - accuracy: 0.9546 - val_loss: 0.4374 - val_accuracy: 0.7942\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1228 - accuracy: 0.9511 - val_loss: 0.4234 - val_accuracy: 0.8117\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1204 - accuracy: 0.9599 - val_loss: 0.4091 - val_accuracy: 0.8138\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1193 - accuracy: 0.9524 - val_loss: 0.4022 - val_accuracy: 0.8189\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9541 - val_loss: 0.4122 - val_accuracy: 0.7994\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1182 - accuracy: 0.9568 - val_loss: 0.4189 - val_accuracy: 0.8066\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1223 - accuracy: 0.9581 - val_loss: 0.3936 - val_accuracy: 0.8158\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1128 - accuracy: 0.9555 - val_loss: 0.3951 - val_accuracy: 0.8220\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9528 - val_loss: 0.4243 - val_accuracy: 0.8076\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1272 - accuracy: 0.9480 - val_loss: 0.3742 - val_accuracy: 0.8230\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1338 - accuracy: 0.9546 - val_loss: 0.3904 - val_accuracy: 0.8138\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1365 - accuracy: 0.9471 - val_loss: 0.3724 - val_accuracy: 0.8333\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1424 - accuracy: 0.9546 - val_loss: 0.3744 - val_accuracy: 0.8251\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1309 - accuracy: 0.9577 - val_loss: 0.4201 - val_accuracy: 0.8179\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1104 - accuracy: 0.9559 - val_loss: 0.3924 - val_accuracy: 0.8282\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1124 - accuracy: 0.9559 - val_loss: 0.3797 - val_accuracy: 0.8292\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1251 - accuracy: 0.9572 - val_loss: 0.4014 - val_accuracy: 0.8261\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1081 - accuracy: 0.9515 - val_loss: 0.4356 - val_accuracy: 0.7922\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3546 - accuracy: 0.9546 - val_loss: 0.4046 - val_accuracy: 0.8158\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1143 - accuracy: 0.9555 - val_loss: 0.3643 - val_accuracy: 0.8323\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1137 - accuracy: 0.9555 - val_loss: 0.3776 - val_accuracy: 0.8220\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1295 - accuracy: 0.9568 - val_loss: 0.3532 - val_accuracy: 0.8374\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1357 - accuracy: 0.9555 - val_loss: 0.3331 - val_accuracy: 0.8498\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1073 - accuracy: 0.9612 - val_loss: 0.3364 - val_accuracy: 0.8344\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1014 - accuracy: 0.9590 - val_loss: 0.3382 - val_accuracy: 0.8385\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1120 - accuracy: 0.9612 - val_loss: 0.3680 - val_accuracy: 0.8302\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1194 - accuracy: 0.9594 - val_loss: 0.4064 - val_accuracy: 0.8261\n","Score: 0.8261317014694214 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 3744096.2500 - accuracy: 0.8973 - val_loss: 0.6916 - val_accuracy: 0.5123\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1950 - accuracy: 0.9034 - val_loss: 0.6923 - val_accuracy: 0.5010\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2346 - accuracy: 0.8973 - val_loss: 1.2039 - val_accuracy: 0.5216\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4697 - accuracy: 0.8981 - val_loss: 0.7045 - val_accuracy: 0.5113\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9065 - val_loss: 0.7014 - val_accuracy: 0.5093\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2236 - accuracy: 0.8990 - val_loss: 0.7901 - val_accuracy: 0.5031\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9070 - val_loss: 0.9382 - val_accuracy: 0.5185\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1826 - accuracy: 0.9078 - val_loss: 0.7542 - val_accuracy: 0.4897\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2056 - accuracy: 0.9026 - val_loss: 0.7041 - val_accuracy: 0.4928\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2287 - accuracy: 0.9017 - val_loss: 0.7134 - val_accuracy: 0.4753\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2131 - accuracy: 0.9008 - val_loss: 0.7290 - val_accuracy: 0.5021\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2107 - accuracy: 0.9056 - val_loss: 0.7346 - val_accuracy: 0.5144\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2119 - accuracy: 0.9070 - val_loss: 0.6962 - val_accuracy: 0.4805\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2171 - accuracy: 0.9056 - val_loss: 0.7577 - val_accuracy: 0.5154\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2113 - accuracy: 0.8981 - val_loss: 0.8923 - val_accuracy: 0.4897\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2193 - accuracy: 0.9087 - val_loss: 0.9707 - val_accuracy: 0.4897\n","Epoch 17/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2025 - accuracy: 0.9105 - val_loss: 0.7444 - val_accuracy: 0.5154\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9096 - val_loss: 0.9718 - val_accuracy: 0.4743\n","Epoch 19/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2261 - accuracy: 0.8937 - val_loss: 0.6936 - val_accuracy: 0.4959\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2114 - accuracy: 0.8990 - val_loss: 0.7637 - val_accuracy: 0.5113\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.8973 - val_loss: 0.6976 - val_accuracy: 0.5247\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2024 - accuracy: 0.9030 - val_loss: 0.9071 - val_accuracy: 0.5072\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1841 - accuracy: 0.9167 - val_loss: 0.7615 - val_accuracy: 0.4743\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9061 - val_loss: 0.6978 - val_accuracy: 0.5247\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2052 - accuracy: 0.9056 - val_loss: 0.7120 - val_accuracy: 0.4825\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1950 - accuracy: 0.9026 - val_loss: 0.7150 - val_accuracy: 0.5267\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1735 - accuracy: 0.9180 - val_loss: 0.7111 - val_accuracy: 0.5340\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9083 - val_loss: 0.7068 - val_accuracy: 0.4928\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9030 - val_loss: 0.7227 - val_accuracy: 0.4897\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.8968 - val_loss: 0.7039 - val_accuracy: 0.4979\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9127 - val_loss: 0.7258 - val_accuracy: 0.5216\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1861 - accuracy: 0.9114 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9087 - val_loss: 0.7070 - val_accuracy: 0.5257\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1979 - accuracy: 0.9048 - val_loss: 0.7121 - val_accuracy: 0.4733\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1967 - accuracy: 0.9043 - val_loss: 0.7230 - val_accuracy: 0.4702\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9123 - val_loss: 0.7151 - val_accuracy: 0.5113\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9136 - val_loss: 0.6933 - val_accuracy: 0.5175\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1900 - accuracy: 0.9180 - val_loss: 0.7070 - val_accuracy: 0.4763\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2092 - accuracy: 0.9043 - val_loss: 0.7309 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1906 - accuracy: 0.9184 - val_loss: 0.7006 - val_accuracy: 0.5144\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9061 - val_loss: 0.7229 - val_accuracy: 0.5000\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1781 - accuracy: 0.9167 - val_loss: 0.7481 - val_accuracy: 0.4712\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9101 - val_loss: 0.6933 - val_accuracy: 0.5021\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1791 - accuracy: 0.9087 - val_loss: 0.6986 - val_accuracy: 0.5206\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1873 - accuracy: 0.9153 - val_loss: 0.7541 - val_accuracy: 0.5062\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9171 - val_loss: 0.6926 - val_accuracy: 0.5175\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9092 - val_loss: 0.7015 - val_accuracy: 0.4825\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2029 - accuracy: 0.9021 - val_loss: 0.7133 - val_accuracy: 0.4650\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1886 - accuracy: 0.9021 - val_loss: 0.6945 - val_accuracy: 0.5021\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1840 - accuracy: 0.9096 - val_loss: 0.7007 - val_accuracy: 0.5051\n","Score: 0.5051440596580505 \n","Parameters:  {'learning_rate': 0.16759974634382652, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.7007 - accuracy: 0.9061 - val_loss: 0.6732 - val_accuracy: 0.5041\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1889 - accuracy: 0.9224 - val_loss: 0.6009 - val_accuracy: 0.6893\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1875 - accuracy: 0.9078 - val_loss: 0.6113 - val_accuracy: 0.6903\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2276 - accuracy: 0.9281 - val_loss: 0.5699 - val_accuracy: 0.7130\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9352 - val_loss: 0.4992 - val_accuracy: 0.7335\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1775 - accuracy: 0.9308 - val_loss: 0.5297 - val_accuracy: 0.7284\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1549 - accuracy: 0.9392 - val_loss: 0.4985 - val_accuracy: 0.7531\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1878 - accuracy: 0.9418 - val_loss: 0.4869 - val_accuracy: 0.7634\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1713 - accuracy: 0.9453 - val_loss: 0.4881 - val_accuracy: 0.7665\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1436 - accuracy: 0.9471 - val_loss: 0.4698 - val_accuracy: 0.7798\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1887 - accuracy: 0.9427 - val_loss: 0.4379 - val_accuracy: 0.7953\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2000 - accuracy: 0.9444 - val_loss: 0.4393 - val_accuracy: 0.8045\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1766 - accuracy: 0.9405 - val_loss: 0.4640 - val_accuracy: 0.7737\n","Epoch 14/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1285 - accuracy: 0.9555 - val_loss: 0.4357 - val_accuracy: 0.7973\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1323 - accuracy: 0.9506 - val_loss: 0.4192 - val_accuracy: 0.8025\n","Epoch 16/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1437 - accuracy: 0.9519 - val_loss: 0.4105 - val_accuracy: 0.8066\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1574 - accuracy: 0.9528 - val_loss: 0.5237 - val_accuracy: 0.7623\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9466 - val_loss: 0.3956 - val_accuracy: 0.8107\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9537 - val_loss: 0.3824 - val_accuracy: 0.8261\n","Epoch 20/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1123 - accuracy: 0.9568 - val_loss: 0.4035 - val_accuracy: 0.8230\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1301 - accuracy: 0.9577 - val_loss: 0.3580 - val_accuracy: 0.8364\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0995 - accuracy: 0.9638 - val_loss: 0.4075 - val_accuracy: 0.8200\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1108 - accuracy: 0.9528 - val_loss: 0.3757 - val_accuracy: 0.8128\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9541 - val_loss: 0.3852 - val_accuracy: 0.8241\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1275 - accuracy: 0.9493 - val_loss: 0.3407 - val_accuracy: 0.8395\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2578 - accuracy: 0.9586 - val_loss: 0.3237 - val_accuracy: 0.8549\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0912 - accuracy: 0.9630 - val_loss: 0.3762 - val_accuracy: 0.8467\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0962 - accuracy: 0.9643 - val_loss: 0.3121 - val_accuracy: 0.8570\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1058 - accuracy: 0.9603 - val_loss: 0.2702 - val_accuracy: 0.8755\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1189 - accuracy: 0.9586 - val_loss: 0.2940 - val_accuracy: 0.8591\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1053 - accuracy: 0.9630 - val_loss: 0.3276 - val_accuracy: 0.8580\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0877 - accuracy: 0.9652 - val_loss: 0.3324 - val_accuracy: 0.8323\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1171 - accuracy: 0.9674 - val_loss: 0.3221 - val_accuracy: 0.8447\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0877 - accuracy: 0.9687 - val_loss: 0.3163 - val_accuracy: 0.8529\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0908 - accuracy: 0.9603 - val_loss: 0.3039 - val_accuracy: 0.8693\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0990 - accuracy: 0.9630 - val_loss: 0.2865 - val_accuracy: 0.8632\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1417 - accuracy: 0.9638 - val_loss: 0.2950 - val_accuracy: 0.8652\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0697 - accuracy: 0.9713 - val_loss: 0.2978 - val_accuracy: 0.8652\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0827 - accuracy: 0.9634 - val_loss: 0.2587 - val_accuracy: 0.8776\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0989 - accuracy: 0.9638 - val_loss: 0.3018 - val_accuracy: 0.8632\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0647 - accuracy: 0.9731 - val_loss: 0.2571 - val_accuracy: 0.8951\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0716 - accuracy: 0.9731 - val_loss: 0.2429 - val_accuracy: 0.8765\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 0.3106 - val_accuracy: 0.8663\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0746 - accuracy: 0.9709 - val_loss: 0.2478 - val_accuracy: 0.8837\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0837 - accuracy: 0.9696 - val_loss: 0.1995 - val_accuracy: 0.8940\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1081 - accuracy: 0.9727 - val_loss: 0.2975 - val_accuracy: 0.8827\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0718 - accuracy: 0.9740 - val_loss: 0.4220 - val_accuracy: 0.8364\n","Epoch 48/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.0856 - accuracy: 0.9674 - val_loss: 0.2267 - val_accuracy: 0.8827\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2389 - accuracy: 0.9643 - val_loss: 0.3666 - val_accuracy: 0.8457\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1089 - accuracy: 0.9647 - val_loss: 0.3386 - val_accuracy: 0.8374\n","Score: 0.8374485373497009 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 502132.5000 - accuracy: 0.8862 - val_loss: 3.3357 - val_accuracy: 0.5134\n","Epoch 2/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.9494 - accuracy: 0.8942 - val_loss: 0.6921 - val_accuracy: 0.5247\n","Epoch 3/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2538 - accuracy: 0.8924 - val_loss: 0.7038 - val_accuracy: 0.5123\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2789 - accuracy: 0.8884 - val_loss: 0.9010 - val_accuracy: 0.4928\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2410 - accuracy: 0.8977 - val_loss: 1.0993 - val_accuracy: 0.5309\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2069 - accuracy: 0.8986 - val_loss: 0.6945 - val_accuracy: 0.4887\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1843 - accuracy: 0.9206 - val_loss: 0.7133 - val_accuracy: 0.5062\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1916 - accuracy: 0.9158 - val_loss: 0.7274 - val_accuracy: 0.5165\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9118 - val_loss: 0.6942 - val_accuracy: 0.4928\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1915 - accuracy: 0.9056 - val_loss: 0.6985 - val_accuracy: 0.4959\n","Epoch 11/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1980 - accuracy: 0.9039 - val_loss: 0.6936 - val_accuracy: 0.5175\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1882 - accuracy: 0.9175 - val_loss: 0.6956 - val_accuracy: 0.4907\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9092 - val_loss: 0.6971 - val_accuracy: 0.4979\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9198 - val_loss: 0.7025 - val_accuracy: 0.5123\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9145 - val_loss: 0.7335 - val_accuracy: 0.5103\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1943 - accuracy: 0.9087 - val_loss: 0.7042 - val_accuracy: 0.5000\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2056 - accuracy: 0.9052 - val_loss: 0.6945 - val_accuracy: 0.4887\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1849 - accuracy: 0.9123 - val_loss: 0.6927 - val_accuracy: 0.5154\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9193 - val_loss: 0.6967 - val_accuracy: 0.4877\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.9109 - val_loss: 0.6924 - val_accuracy: 0.5216\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1972 - accuracy: 0.9149 - val_loss: 0.7083 - val_accuracy: 0.4805\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1970 - accuracy: 0.9052 - val_loss: 0.7065 - val_accuracy: 0.5237\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1998 - accuracy: 0.9171 - val_loss: 0.7127 - val_accuracy: 0.5123\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9145 - val_loss: 0.6929 - val_accuracy: 0.5175\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9149 - val_loss: 0.6924 - val_accuracy: 0.5226\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9127 - val_loss: 0.6972 - val_accuracy: 0.4835\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2065 - accuracy: 0.9034 - val_loss: 0.6924 - val_accuracy: 0.5195\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2006 - accuracy: 0.9092 - val_loss: 0.6954 - val_accuracy: 0.5093\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9206 - val_loss: 0.7015 - val_accuracy: 0.5113\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1925 - accuracy: 0.9184 - val_loss: 0.7335 - val_accuracy: 0.4918\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.8986 - val_loss: 0.6928 - val_accuracy: 0.5319\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9162 - val_loss: 0.6953 - val_accuracy: 0.5041\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1877 - accuracy: 0.9158 - val_loss: 0.7017 - val_accuracy: 0.4877\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2041 - accuracy: 0.9078 - val_loss: 0.7636 - val_accuracy: 0.4784\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1928 - accuracy: 0.9092 - val_loss: 0.7096 - val_accuracy: 0.4691\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1975 - accuracy: 0.9043 - val_loss: 0.7143 - val_accuracy: 0.5062\n","Epoch 37/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1968 - accuracy: 0.9096 - val_loss: 0.6996 - val_accuracy: 0.4815\n","Epoch 38/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2003 - accuracy: 0.9065 - val_loss: 0.7212 - val_accuracy: 0.4825\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1978 - accuracy: 0.8986 - val_loss: 0.7011 - val_accuracy: 0.4928\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9061 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9171 - val_loss: 0.7089 - val_accuracy: 0.4959\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2052 - accuracy: 0.8968 - val_loss: 0.6950 - val_accuracy: 0.5123\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1873 - accuracy: 0.9158 - val_loss: 0.6963 - val_accuracy: 0.4938\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1982 - accuracy: 0.9078 - val_loss: 0.6966 - val_accuracy: 0.4671\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9101 - val_loss: 0.7101 - val_accuracy: 0.5195\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1858 - accuracy: 0.9118 - val_loss: 0.6930 - val_accuracy: 0.5082\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9131 - val_loss: 0.6944 - val_accuracy: 0.4733\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9162 - val_loss: 0.6957 - val_accuracy: 0.4907\n","Epoch 49/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2100 - accuracy: 0.9048 - val_loss: 0.6932 - val_accuracy: 0.4815\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9131 - val_loss: 0.7322 - val_accuracy: 0.4856\n","Score: 0.4855967164039612 \n","Parameters:  {'learning_rate': 0.12245457464475518, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 11473.2686 - accuracy: 0.9012 - val_loss: 0.7061 - val_accuracy: 0.4846\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9127 - val_loss: 0.7000 - val_accuracy: 0.5206\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1947 - accuracy: 0.9140 - val_loss: 0.7775 - val_accuracy: 0.4856\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1958 - accuracy: 0.9092 - val_loss: 0.7031 - val_accuracy: 0.4897\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9070 - val_loss: 0.7101 - val_accuracy: 0.5216\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1841 - accuracy: 0.9162 - val_loss: 0.6978 - val_accuracy: 0.4979\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9109 - val_loss: 0.6997 - val_accuracy: 0.5103\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1922 - accuracy: 0.9065 - val_loss: 0.6927 - val_accuracy: 0.5267\n","Epoch 9/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1919 - accuracy: 0.9206 - val_loss: 0.7334 - val_accuracy: 0.5226\n","Epoch 10/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1916 - accuracy: 0.9052 - val_loss: 0.7166 - val_accuracy: 0.5165\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9167 - val_loss: 0.7120 - val_accuracy: 0.5113\n","Epoch 12/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1992 - accuracy: 0.9140 - val_loss: 0.6977 - val_accuracy: 0.4846\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2508 - accuracy: 0.9021 - val_loss: 0.7151 - val_accuracy: 0.5010\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2504 - accuracy: 0.9114 - val_loss: 0.7097 - val_accuracy: 0.5062\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2402 - accuracy: 0.9153 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2391 - accuracy: 0.9109 - val_loss: 0.6955 - val_accuracy: 0.4969\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9061 - val_loss: 0.6920 - val_accuracy: 0.5247\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2409 - accuracy: 0.9149 - val_loss: 0.6937 - val_accuracy: 0.5123\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2343 - accuracy: 0.9220 - val_loss: 0.6935 - val_accuracy: 0.5206\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2468 - accuracy: 0.9114 - val_loss: 0.6929 - val_accuracy: 0.5144\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2520 - accuracy: 0.9096 - val_loss: 0.6945 - val_accuracy: 0.5103\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2462 - accuracy: 0.9118 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2531 - accuracy: 0.9083 - val_loss: 0.6921 - val_accuracy: 0.5298\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2498 - accuracy: 0.9118 - val_loss: 0.6941 - val_accuracy: 0.5165\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2467 - accuracy: 0.9123 - val_loss: 0.6941 - val_accuracy: 0.4979\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2570 - accuracy: 0.9030 - val_loss: 0.6943 - val_accuracy: 0.4835\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2457 - accuracy: 0.9109 - val_loss: 0.6914 - val_accuracy: 0.5319\n","Epoch 28/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2589 - accuracy: 0.9048 - val_loss: 0.6978 - val_accuracy: 0.5072\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2463 - accuracy: 0.9131 - val_loss: 0.6948 - val_accuracy: 0.5010\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2375 - accuracy: 0.9189 - val_loss: 0.6934 - val_accuracy: 0.5134\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2457 - accuracy: 0.9140 - val_loss: 0.6942 - val_accuracy: 0.4959\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2393 - accuracy: 0.9211 - val_loss: 0.6950 - val_accuracy: 0.5226\n","Epoch 33/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2376 - accuracy: 0.9171 - val_loss: 0.6981 - val_accuracy: 0.5123\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2418 - accuracy: 0.9171 - val_loss: 0.7011 - val_accuracy: 0.5021\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2430 - accuracy: 0.9118 - val_loss: 0.6944 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9074 - val_loss: 0.6929 - val_accuracy: 0.5185\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2426 - accuracy: 0.9162 - val_loss: 0.6916 - val_accuracy: 0.5288\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2435 - accuracy: 0.9131 - val_loss: 0.6937 - val_accuracy: 0.5010\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2494 - accuracy: 0.9127 - val_loss: 0.6951 - val_accuracy: 0.5123\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2459 - accuracy: 0.9149 - val_loss: 0.6924 - val_accuracy: 0.5226\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2387 - accuracy: 0.9127 - val_loss: 0.6991 - val_accuracy: 0.4763\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2588 - accuracy: 0.8995 - val_loss: 0.6944 - val_accuracy: 0.5195\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2413 - accuracy: 0.9153 - val_loss: 0.6927 - val_accuracy: 0.5165\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2480 - accuracy: 0.9105 - val_loss: 0.6960 - val_accuracy: 0.4815\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2426 - accuracy: 0.9087 - val_loss: 0.6910 - val_accuracy: 0.5329\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2446 - accuracy: 0.9167 - val_loss: 0.7005 - val_accuracy: 0.5237\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2318 - accuracy: 0.9228 - val_loss: 0.7172 - val_accuracy: 0.5082\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2517 - accuracy: 0.8999 - val_loss: 0.6950 - val_accuracy: 0.5031\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2445 - accuracy: 0.9096 - val_loss: 0.6925 - val_accuracy: 0.5185\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2565 - accuracy: 0.9078 - val_loss: 0.6925 - val_accuracy: 0.5195\n","Score: 0.5195473432540894 \n","Parameters:  {'learning_rate': 0.03265632711833218, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3917 - accuracy: 0.9246 - val_loss: 0.6701 - val_accuracy: 0.6451\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2249 - accuracy: 0.9272 - val_loss: 0.5274 - val_accuracy: 0.7510\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1711 - accuracy: 0.9365 - val_loss: 0.4876 - val_accuracy: 0.7510\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1576 - accuracy: 0.9436 - val_loss: 0.4860 - val_accuracy: 0.7531\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1434 - accuracy: 0.9436 - val_loss: 0.5146 - val_accuracy: 0.7407\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2521 - accuracy: 0.9365 - val_loss: 0.6048 - val_accuracy: 0.6646\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1661 - accuracy: 0.9506 - val_loss: 0.4772 - val_accuracy: 0.7726\n","Epoch 8/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1353 - accuracy: 0.9400 - val_loss: 0.4322 - val_accuracy: 0.7819\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1309 - accuracy: 0.9497 - val_loss: 0.4243 - val_accuracy: 0.7850\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9462 - val_loss: 0.4512 - val_accuracy: 0.7757\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9440 - val_loss: 0.4103 - val_accuracy: 0.8056\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1308 - accuracy: 0.9475 - val_loss: 0.4274 - val_accuracy: 0.8004\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1402 - accuracy: 0.9444 - val_loss: 0.4325 - val_accuracy: 0.7984\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1448 - accuracy: 0.9550 - val_loss: 0.4270 - val_accuracy: 0.8014\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1514 - accuracy: 0.9414 - val_loss: 0.4620 - val_accuracy: 0.7901\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2743 - accuracy: 0.9347 - val_loss: 0.4412 - val_accuracy: 0.7963\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.9563 - val_loss: 0.4426 - val_accuracy: 0.8035\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1248 - accuracy: 0.9511 - val_loss: 0.4140 - val_accuracy: 0.8323\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1281 - accuracy: 0.9528 - val_loss: 0.3844 - val_accuracy: 0.8148\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1187 - accuracy: 0.9480 - val_loss: 0.4236 - val_accuracy: 0.7973\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1453 - accuracy: 0.9462 - val_loss: 0.3872 - val_accuracy: 0.8086\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1390 - accuracy: 0.9533 - val_loss: 0.3947 - val_accuracy: 0.8210\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9537 - val_loss: 0.3815 - val_accuracy: 0.8169\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1370 - accuracy: 0.9537 - val_loss: 0.4298 - val_accuracy: 0.8025\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9497 - val_loss: 0.4485 - val_accuracy: 0.8158\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9555 - val_loss: 0.4190 - val_accuracy: 0.8158\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1043 - accuracy: 0.9643 - val_loss: 0.3654 - val_accuracy: 0.8426\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1188 - accuracy: 0.9581 - val_loss: 0.3380 - val_accuracy: 0.8539\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0962 - accuracy: 0.9621 - val_loss: 0.4222 - val_accuracy: 0.8272\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1071 - accuracy: 0.9616 - val_loss: 0.3429 - val_accuracy: 0.8416\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1027 - accuracy: 0.9581 - val_loss: 0.3516 - val_accuracy: 0.8436\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1438 - accuracy: 0.9555 - val_loss: 0.3494 - val_accuracy: 0.8292\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0971 - accuracy: 0.9594 - val_loss: 0.3555 - val_accuracy: 0.8374\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1102 - accuracy: 0.9568 - val_loss: 0.3459 - val_accuracy: 0.8519\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9497 - val_loss: 0.3221 - val_accuracy: 0.8580\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3711 - accuracy: 0.9541 - val_loss: 0.4431 - val_accuracy: 0.8117\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9572 - val_loss: 0.3085 - val_accuracy: 0.8735\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1207 - accuracy: 0.9586 - val_loss: 0.3058 - val_accuracy: 0.8642\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0885 - accuracy: 0.9696 - val_loss: 0.4110 - val_accuracy: 0.8302\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0922 - accuracy: 0.9634 - val_loss: 0.2771 - val_accuracy: 0.8765\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1652 - accuracy: 0.9559 - val_loss: 0.3293 - val_accuracy: 0.8570\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1552 - accuracy: 0.9546 - val_loss: 0.3168 - val_accuracy: 0.8549\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1133 - accuracy: 0.9528 - val_loss: 0.3012 - val_accuracy: 0.8673\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0972 - accuracy: 0.9674 - val_loss: 0.3443 - val_accuracy: 0.8344\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0786 - accuracy: 0.9669 - val_loss: 0.3312 - val_accuracy: 0.8477\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0857 - accuracy: 0.9709 - val_loss: 0.3461 - val_accuracy: 0.8364\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1012 - accuracy: 0.9652 - val_loss: 0.3229 - val_accuracy: 0.8663\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0763 - accuracy: 0.9700 - val_loss: 0.2741 - val_accuracy: 0.8745\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0819 - accuracy: 0.9705 - val_loss: 0.2715 - val_accuracy: 0.8693\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0748 - accuracy: 0.9709 - val_loss: 0.3217 - val_accuracy: 0.8560\n","Score: 0.855967104434967 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.2862 - accuracy: 0.9087 - val_loss: 0.6951 - val_accuracy: 0.5062\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1977 - accuracy: 0.9158 - val_loss: 0.6976 - val_accuracy: 0.5113\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1883 - accuracy: 0.9220 - val_loss: 0.6991 - val_accuracy: 0.5134\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9101 - val_loss: 0.6993 - val_accuracy: 0.5113\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3182 - accuracy: 0.9092 - val_loss: 0.7284 - val_accuracy: 0.4990\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2249 - accuracy: 0.9167 - val_loss: 0.6451 - val_accuracy: 0.6101\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1682 - accuracy: 0.9246 - val_loss: 0.6507 - val_accuracy: 0.6255\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1712 - accuracy: 0.9259 - val_loss: 0.6760 - val_accuracy: 0.6111\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3084 - accuracy: 0.9237 - val_loss: 0.6137 - val_accuracy: 0.7006\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2263 - accuracy: 0.9264 - val_loss: 0.6323 - val_accuracy: 0.6821\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1740 - accuracy: 0.9242 - val_loss: 0.6062 - val_accuracy: 0.7068\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1712 - accuracy: 0.9312 - val_loss: 0.5688 - val_accuracy: 0.7212\n","Epoch 13/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1989 - accuracy: 0.9325 - val_loss: 0.5776 - val_accuracy: 0.7490\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9347 - val_loss: 0.5612 - val_accuracy: 0.7438\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9378 - val_loss: 0.4957 - val_accuracy: 0.7634\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1514 - accuracy: 0.9427 - val_loss: 0.4812 - val_accuracy: 0.7850\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1650 - accuracy: 0.9387 - val_loss: 0.4307 - val_accuracy: 0.7994\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1521 - accuracy: 0.9431 - val_loss: 0.4277 - val_accuracy: 0.8045\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1380 - accuracy: 0.9480 - val_loss: 0.4868 - val_accuracy: 0.7593\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9511 - val_loss: 0.3913 - val_accuracy: 0.8210\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1382 - accuracy: 0.9484 - val_loss: 0.4552 - val_accuracy: 0.7901\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1992 - accuracy: 0.9436 - val_loss: 0.4466 - val_accuracy: 0.8004\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1509 - accuracy: 0.9511 - val_loss: 0.4278 - val_accuracy: 0.8035\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1345 - accuracy: 0.9550 - val_loss: 0.4284 - val_accuracy: 0.8004\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1549 - accuracy: 0.9418 - val_loss: 0.4652 - val_accuracy: 0.7737\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1519 - accuracy: 0.9414 - val_loss: 0.4381 - val_accuracy: 0.7942\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9506 - val_loss: 0.4196 - val_accuracy: 0.8056\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1315 - accuracy: 0.9449 - val_loss: 0.4256 - val_accuracy: 0.7901\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1285 - accuracy: 0.9475 - val_loss: 0.4215 - val_accuracy: 0.7953\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1448 - accuracy: 0.9484 - val_loss: 0.4026 - val_accuracy: 0.8117\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2539 - accuracy: 0.9475 - val_loss: 0.4525 - val_accuracy: 0.8014\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1406 - accuracy: 0.9484 - val_loss: 0.4305 - val_accuracy: 0.8014\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1414 - accuracy: 0.9440 - val_loss: 0.4570 - val_accuracy: 0.7757\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6499 - accuracy: 0.9502 - val_loss: 0.4249 - val_accuracy: 0.8035\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9524 - val_loss: 0.4351 - val_accuracy: 0.7819\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1196 - accuracy: 0.9590 - val_loss: 0.4155 - val_accuracy: 0.8066\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.9497 - val_loss: 0.3900 - val_accuracy: 0.8117\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9515 - val_loss: 0.4310 - val_accuracy: 0.8035\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1250 - accuracy: 0.9511 - val_loss: 0.4206 - val_accuracy: 0.8025\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1235 - accuracy: 0.9511 - val_loss: 0.4100 - val_accuracy: 0.8107\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1452 - accuracy: 0.9489 - val_loss: 0.3643 - val_accuracy: 0.8261\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1229 - accuracy: 0.9541 - val_loss: 0.4138 - val_accuracy: 0.8056\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9533 - val_loss: 0.3665 - val_accuracy: 0.8344\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1086 - accuracy: 0.9603 - val_loss: 0.3530 - val_accuracy: 0.8302\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1368 - accuracy: 0.9497 - val_loss: 0.3919 - val_accuracy: 0.8076\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.9528 - val_loss: 0.3580 - val_accuracy: 0.8272\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9519 - val_loss: 0.3873 - val_accuracy: 0.8107\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1162 - accuracy: 0.9590 - val_loss: 0.3615 - val_accuracy: 0.8323\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9449 - val_loss: 0.3930 - val_accuracy: 0.8220\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1249 - accuracy: 0.9519 - val_loss: 0.3656 - val_accuracy: 0.8313\n","Score: 0.8312757015228271 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 198025.0469 - accuracy: 0.8911 - val_loss: 4.3452 - val_accuracy: 0.4938\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.4296 - accuracy: 0.8946 - val_loss: 0.8224 - val_accuracy: 0.5278\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2099 - accuracy: 0.9052 - val_loss: 0.7440 - val_accuracy: 0.5031\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9034 - val_loss: 0.7614 - val_accuracy: 0.4887\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9074 - val_loss: 0.9403 - val_accuracy: 0.5257\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1785 - accuracy: 0.9193 - val_loss: 0.7036 - val_accuracy: 0.4877\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1794 - accuracy: 0.9061 - val_loss: 0.7178 - val_accuracy: 0.5082\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1767 - accuracy: 0.9118 - val_loss: 0.8026 - val_accuracy: 0.5000\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1801 - accuracy: 0.9140 - val_loss: 0.7021 - val_accuracy: 0.5175\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1891 - accuracy: 0.9083 - val_loss: 0.7182 - val_accuracy: 0.4712\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9096 - val_loss: 0.6943 - val_accuracy: 0.4702\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1862 - accuracy: 0.9070 - val_loss: 0.7800 - val_accuracy: 0.5175\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1870 - accuracy: 0.9096 - val_loss: 0.7570 - val_accuracy: 0.4794\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2012 - accuracy: 0.8995 - val_loss: 0.6953 - val_accuracy: 0.5165\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9052 - val_loss: 0.7562 - val_accuracy: 0.5113\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1795 - accuracy: 0.9145 - val_loss: 0.7017 - val_accuracy: 0.4969\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1920 - accuracy: 0.8995 - val_loss: 0.7010 - val_accuracy: 0.5257\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1917 - accuracy: 0.9123 - val_loss: 0.7489 - val_accuracy: 0.4825\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2095 - accuracy: 0.8933 - val_loss: 0.6931 - val_accuracy: 0.5216\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9153 - val_loss: 0.6926 - val_accuracy: 0.5206\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1849 - accuracy: 0.9131 - val_loss: 0.7540 - val_accuracy: 0.5051\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1838 - accuracy: 0.9056 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9087 - val_loss: 0.6943 - val_accuracy: 0.5113\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1903 - accuracy: 0.9105 - val_loss: 0.6960 - val_accuracy: 0.5123\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2063 - accuracy: 0.9083 - val_loss: 0.6966 - val_accuracy: 0.5031\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2022 - accuracy: 0.9145 - val_loss: 0.7339 - val_accuracy: 0.5093\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1919 - accuracy: 0.9202 - val_loss: 0.7223 - val_accuracy: 0.4887\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.8999 - val_loss: 0.7271 - val_accuracy: 0.4990\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1841 - accuracy: 0.9224 - val_loss: 0.6978 - val_accuracy: 0.5010\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9109 - val_loss: 0.6963 - val_accuracy: 0.5072\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9056 - val_loss: 0.6960 - val_accuracy: 0.4969\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9136 - val_loss: 0.6933 - val_accuracy: 0.4866\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9153 - val_loss: 0.6946 - val_accuracy: 0.5226\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1884 - accuracy: 0.9175 - val_loss: 0.6938 - val_accuracy: 0.4815\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9083 - val_loss: 0.7056 - val_accuracy: 0.5216\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1993 - accuracy: 0.9070 - val_loss: 0.6939 - val_accuracy: 0.5237\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2041 - accuracy: 0.9123 - val_loss: 0.7158 - val_accuracy: 0.5237\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9145 - val_loss: 0.7241 - val_accuracy: 0.4928\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2067 - accuracy: 0.9074 - val_loss: 0.6996 - val_accuracy: 0.4969\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1969 - accuracy: 0.9078 - val_loss: 0.7031 - val_accuracy: 0.4835\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1971 - accuracy: 0.9105 - val_loss: 0.7113 - val_accuracy: 0.4907\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9008 - val_loss: 0.7198 - val_accuracy: 0.4846\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2028 - accuracy: 0.9065 - val_loss: 0.6935 - val_accuracy: 0.5206\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2136 - accuracy: 0.9083 - val_loss: 0.7010 - val_accuracy: 0.5134\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1913 - accuracy: 0.9233 - val_loss: 0.7061 - val_accuracy: 0.5123\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9136 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9198 - val_loss: 0.7006 - val_accuracy: 0.4897\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2048 - accuracy: 0.9065 - val_loss: 0.7003 - val_accuracy: 0.4866\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9021 - val_loss: 0.6934 - val_accuracy: 0.4835\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9127 - val_loss: 0.7157 - val_accuracy: 0.5226\n","Score: 0.5226337313652039 \n","Parameters:  {'learning_rate': 0.09643151513365188, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 136.9991 - accuracy: 0.9061 - val_loss: 0.6958 - val_accuracy: 0.5370\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2541 - accuracy: 0.9184 - val_loss: 0.6968 - val_accuracy: 0.5093\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2303 - accuracy: 0.9048 - val_loss: 0.6943 - val_accuracy: 0.4897\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2415 - accuracy: 0.8999 - val_loss: 0.6927 - val_accuracy: 0.5144\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2442 - accuracy: 0.9087 - val_loss: 0.6920 - val_accuracy: 0.5237\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2423 - accuracy: 0.9065 - val_loss: 0.6937 - val_accuracy: 0.4897\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2540 - accuracy: 0.9096 - val_loss: 0.7006 - val_accuracy: 0.5113\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2555 - accuracy: 0.9158 - val_loss: 0.7209 - val_accuracy: 0.5206\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2648 - accuracy: 0.9162 - val_loss: 0.7445 - val_accuracy: 0.5216\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2589 - accuracy: 0.9136 - val_loss: 0.6995 - val_accuracy: 0.5041\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2609 - accuracy: 0.9136 - val_loss: 0.7134 - val_accuracy: 0.5031\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2592 - accuracy: 0.9175 - val_loss: 0.7114 - val_accuracy: 0.5257\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2467 - accuracy: 0.9140 - val_loss: 0.7031 - val_accuracy: 0.4784\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2259 - accuracy: 0.9065 - val_loss: 0.6983 - val_accuracy: 0.5113\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2286 - accuracy: 0.9039 - val_loss: 0.6938 - val_accuracy: 0.5093\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3101 - accuracy: 0.9171 - val_loss: 0.6986 - val_accuracy: 0.4959\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.9127 - val_loss: 0.7004 - val_accuracy: 0.5051\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2068 - accuracy: 0.9193 - val_loss: 0.7106 - val_accuracy: 0.5237\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2139 - accuracy: 0.9153 - val_loss: 0.6946 - val_accuracy: 0.5103\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2150 - accuracy: 0.9175 - val_loss: 0.6942 - val_accuracy: 0.4825\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2330 - accuracy: 0.9140 - val_loss: 0.7140 - val_accuracy: 0.5144\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2441 - accuracy: 0.9105 - val_loss: 0.6964 - val_accuracy: 0.4805\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2710 - accuracy: 0.9008 - val_loss: 0.6934 - val_accuracy: 0.5195\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2728 - accuracy: 0.9180 - val_loss: 0.7778 - val_accuracy: 0.5165\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2922 - accuracy: 0.9118 - val_loss: 0.8491 - val_accuracy: 0.5021\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2951 - accuracy: 0.9136 - val_loss: 0.8961 - val_accuracy: 0.5031\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2811 - accuracy: 0.9193 - val_loss: 0.9053 - val_accuracy: 0.5165\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2853 - accuracy: 0.9158 - val_loss: 0.8728 - val_accuracy: 0.5278\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2907 - accuracy: 0.9131 - val_loss: 0.8661 - val_accuracy: 0.5226\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2818 - accuracy: 0.9193 - val_loss: 0.9288 - val_accuracy: 0.5103\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2939 - accuracy: 0.9101 - val_loss: 0.8565 - val_accuracy: 0.5175\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2837 - accuracy: 0.9193 - val_loss: 0.9392 - val_accuracy: 0.5000\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2814 - accuracy: 0.9180 - val_loss: 0.9090 - val_accuracy: 0.5041\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2833 - accuracy: 0.9175 - val_loss: 0.8877 - val_accuracy: 0.5257\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2828 - accuracy: 0.9171 - val_loss: 0.9074 - val_accuracy: 0.5185\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2880 - accuracy: 0.9149 - val_loss: 0.8878 - val_accuracy: 0.5185\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2914 - accuracy: 0.9127 - val_loss: 0.8745 - val_accuracy: 0.5165\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3017 - accuracy: 0.9074 - val_loss: 0.8413 - val_accuracy: 0.5206\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2873 - accuracy: 0.9184 - val_loss: 0.9064 - val_accuracy: 0.5144\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2817 - accuracy: 0.9180 - val_loss: 0.9235 - val_accuracy: 0.5144\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2865 - accuracy: 0.9158 - val_loss: 0.8928 - val_accuracy: 0.5154\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2835 - accuracy: 0.9167 - val_loss: 0.8866 - val_accuracy: 0.5237\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2919 - accuracy: 0.9114 - val_loss: 0.8345 - val_accuracy: 0.5298\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3016 - accuracy: 0.9083 - val_loss: 0.8441 - val_accuracy: 0.5195\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2956 - accuracy: 0.9140 - val_loss: 0.8726 - val_accuracy: 0.5226\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2874 - accuracy: 0.9153 - val_loss: 0.8747 - val_accuracy: 0.5319\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2841 - accuracy: 0.9175 - val_loss: 0.9298 - val_accuracy: 0.4990\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2749 - accuracy: 0.9220 - val_loss: 0.9251 - val_accuracy: 0.5154\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2785 - accuracy: 0.9189 - val_loss: 0.9538 - val_accuracy: 0.4928\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2793 - accuracy: 0.9180 - val_loss: 0.9279 - val_accuracy: 0.5072\n","Score: 0.5072016716003418 \n","Parameters:  {'learning_rate': 0.0111463533281304, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.0086 - accuracy: 0.9123 - val_loss: 0.6926 - val_accuracy: 0.5226\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1938 - accuracy: 0.9145 - val_loss: 0.6969 - val_accuracy: 0.5165\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.9958 - accuracy: 0.9242 - val_loss: 0.6653 - val_accuracy: 0.6276\n","Epoch 4/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2263 - accuracy: 0.9295 - val_loss: 0.5903 - val_accuracy: 0.6800\n","Epoch 5/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.4296 - accuracy: 0.9255 - val_loss: 0.5686 - val_accuracy: 0.7202\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2226 - accuracy: 0.9299 - val_loss: 0.9574 - val_accuracy: 0.5905\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1714 - accuracy: 0.9405 - val_loss: 0.5473 - val_accuracy: 0.7418\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1462 - accuracy: 0.9361 - val_loss: 0.5194 - val_accuracy: 0.7181\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2415 - accuracy: 0.9383 - val_loss: 0.5089 - val_accuracy: 0.7706\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1559 - accuracy: 0.9462 - val_loss: 0.4462 - val_accuracy: 0.7798\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1628 - accuracy: 0.9396 - val_loss: 0.4483 - val_accuracy: 0.7778\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1397 - accuracy: 0.9506 - val_loss: 0.4744 - val_accuracy: 0.7675\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1290 - accuracy: 0.9462 - val_loss: 0.4319 - val_accuracy: 0.8035\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2036 - accuracy: 0.9440 - val_loss: 0.4069 - val_accuracy: 0.7901\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.9519 - val_loss: 0.3533 - val_accuracy: 0.8272\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9462 - val_loss: 0.4017 - val_accuracy: 0.8344\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1089 - accuracy: 0.9555 - val_loss: 0.3148 - val_accuracy: 0.8683\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1487 - accuracy: 0.9559 - val_loss: 0.5098 - val_accuracy: 0.7665\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1241 - accuracy: 0.9537 - val_loss: 0.4008 - val_accuracy: 0.8086\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9550 - val_loss: 0.3521 - val_accuracy: 0.8261\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1247 - accuracy: 0.9590 - val_loss: 0.4136 - val_accuracy: 0.8004\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1429 - accuracy: 0.9643 - val_loss: 0.3360 - val_accuracy: 0.8344\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.9581 - val_loss: 0.3371 - val_accuracy: 0.8426\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1088 - accuracy: 0.9581 - val_loss: 0.2817 - val_accuracy: 0.8755\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0830 - accuracy: 0.9700 - val_loss: 0.2522 - val_accuracy: 0.8776\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1008 - accuracy: 0.9665 - val_loss: 0.3508 - val_accuracy: 0.8467\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1260 - accuracy: 0.9524 - val_loss: 0.3584 - val_accuracy: 0.8488\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1141 - accuracy: 0.9528 - val_loss: 0.3336 - val_accuracy: 0.8529\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1419 - accuracy: 0.9581 - val_loss: 0.3881 - val_accuracy: 0.8117\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0880 - accuracy: 0.9700 - val_loss: 0.3577 - val_accuracy: 0.8364\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1016 - accuracy: 0.9638 - val_loss: 0.4826 - val_accuracy: 0.8230\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1457 - accuracy: 0.9572 - val_loss: 0.3938 - val_accuracy: 0.8323\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1478 - accuracy: 0.9586 - val_loss: 0.3450 - val_accuracy: 0.8395\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1305 - accuracy: 0.9616 - val_loss: 0.3415 - val_accuracy: 0.8313\n","Epoch 35/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1045 - accuracy: 0.9656 - val_loss: 0.3187 - val_accuracy: 0.8508\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0949 - accuracy: 0.9647 - val_loss: 0.3677 - val_accuracy: 0.8230\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0922 - accuracy: 0.9753 - val_loss: 0.3456 - val_accuracy: 0.8632\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1267 - accuracy: 0.9700 - val_loss: 0.3358 - val_accuracy: 0.8467\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1057 - accuracy: 0.9652 - val_loss: 0.2426 - val_accuracy: 0.8848\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0830 - accuracy: 0.9722 - val_loss: 0.2568 - val_accuracy: 0.8940\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0831 - accuracy: 0.9753 - val_loss: 0.3663 - val_accuracy: 0.8683\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0860 - accuracy: 0.9727 - val_loss: 0.2304 - val_accuracy: 0.9136\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1295 - accuracy: 0.9669 - val_loss: 0.3662 - val_accuracy: 0.8591\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.2904 - val_accuracy: 0.8930\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0833 - accuracy: 0.9749 - val_loss: 0.2515 - val_accuracy: 0.8961\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0741 - accuracy: 0.9784 - val_loss: 0.2499 - val_accuracy: 0.8909\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.1991 - val_accuracy: 0.9218\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0608 - accuracy: 0.9819 - val_loss: 0.1980 - val_accuracy: 0.9239\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0910 - accuracy: 0.9749 - val_loss: 0.2140 - val_accuracy: 0.9167\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0884 - accuracy: 0.9793 - val_loss: 0.1536 - val_accuracy: 0.9342\n","Score: 0.9341563582420349 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1361.1836 - accuracy: 0.9017 - val_loss: 0.6967 - val_accuracy: 0.4928\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9039 - val_loss: 0.6974 - val_accuracy: 0.5021\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2045 - accuracy: 0.9131 - val_loss: 0.6921 - val_accuracy: 0.5226\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2202 - accuracy: 0.9153 - val_loss: 0.6983 - val_accuracy: 0.5154\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2329 - accuracy: 0.9215 - val_loss: 0.6956 - val_accuracy: 0.5226\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2440 - accuracy: 0.9167 - val_loss: 0.6939 - val_accuracy: 0.5226\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2386 - accuracy: 0.9233 - val_loss: 0.7124 - val_accuracy: 0.5031\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2471 - accuracy: 0.9136 - val_loss: 0.6928 - val_accuracy: 0.5144\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2461 - accuracy: 0.9180 - val_loss: 0.6959 - val_accuracy: 0.5144\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2477 - accuracy: 0.9211 - val_loss: 0.7226 - val_accuracy: 0.5175\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.9167 - val_loss: 0.6972 - val_accuracy: 0.5247\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2490 - accuracy: 0.9162 - val_loss: 0.6993 - val_accuracy: 0.5062\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2452 - accuracy: 0.9180 - val_loss: 0.6979 - val_accuracy: 0.5041\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2509 - accuracy: 0.9149 - val_loss: 0.6925 - val_accuracy: 0.5226\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2449 - accuracy: 0.9220 - val_loss: 0.7115 - val_accuracy: 0.5165\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2500 - accuracy: 0.9105 - val_loss: 0.6922 - val_accuracy: 0.5237\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2625 - accuracy: 0.9101 - val_loss: 0.7003 - val_accuracy: 0.5041\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2510 - accuracy: 0.9153 - val_loss: 0.6969 - val_accuracy: 0.5123\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9131 - val_loss: 0.6930 - val_accuracy: 0.5103\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2563 - accuracy: 0.9175 - val_loss: 0.7046 - val_accuracy: 0.5288\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2471 - accuracy: 0.9180 - val_loss: 0.7013 - val_accuracy: 0.5165\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2438 - accuracy: 0.9211 - val_loss: 0.7092 - val_accuracy: 0.5113\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2407 - accuracy: 0.9184 - val_loss: 0.6950 - val_accuracy: 0.5093\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2574 - accuracy: 0.9109 - val_loss: 0.6936 - val_accuracy: 0.5144\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2524 - accuracy: 0.9171 - val_loss: 0.7108 - val_accuracy: 0.5175\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2475 - accuracy: 0.9140 - val_loss: 0.6929 - val_accuracy: 0.5154\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2587 - accuracy: 0.9078 - val_loss: 0.6940 - val_accuracy: 0.4763\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2638 - accuracy: 0.9052 - val_loss: 0.7120 - val_accuracy: 0.5031\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2458 - accuracy: 0.9167 - val_loss: 0.7003 - val_accuracy: 0.5031\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2520 - accuracy: 0.9158 - val_loss: 0.7040 - val_accuracy: 0.5144\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2504 - accuracy: 0.9167 - val_loss: 0.6933 - val_accuracy: 0.5237\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2475 - accuracy: 0.9158 - val_loss: 0.6922 - val_accuracy: 0.5288\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2514 - accuracy: 0.9175 - val_loss: 0.6964 - val_accuracy: 0.5175\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2420 - accuracy: 0.9228 - val_loss: 0.7230 - val_accuracy: 0.4856\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2492 - accuracy: 0.9109 - val_loss: 0.6947 - val_accuracy: 0.4897\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2663 - accuracy: 0.8946 - val_loss: 0.6925 - val_accuracy: 0.5237\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2582 - accuracy: 0.9140 - val_loss: 0.6919 - val_accuracy: 0.5309\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2469 - accuracy: 0.9193 - val_loss: 0.6967 - val_accuracy: 0.5165\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2613 - accuracy: 0.9127 - val_loss: 0.7181 - val_accuracy: 0.5062\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2451 - accuracy: 0.9158 - val_loss: 0.6960 - val_accuracy: 0.5123\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2398 - accuracy: 0.9220 - val_loss: 0.7030 - val_accuracy: 0.5113\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2520 - accuracy: 0.9136 - val_loss: 0.6941 - val_accuracy: 0.5113\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2497 - accuracy: 0.9158 - val_loss: 0.6915 - val_accuracy: 0.5360\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2519 - accuracy: 0.9145 - val_loss: 0.6937 - val_accuracy: 0.5226\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2595 - accuracy: 0.9127 - val_loss: 0.6958 - val_accuracy: 0.5278\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2427 - accuracy: 0.9202 - val_loss: 0.6977 - val_accuracy: 0.5195\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2565 - accuracy: 0.9096 - val_loss: 0.6920 - val_accuracy: 0.5237\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2498 - accuracy: 0.9184 - val_loss: 0.6928 - val_accuracy: 0.5247\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2557 - accuracy: 0.9149 - val_loss: 0.6989 - val_accuracy: 0.5288\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2511 - accuracy: 0.9162 - val_loss: 0.7085 - val_accuracy: 0.5051\n","Score: 0.5051440596580505 \n","Parameters:  {'learning_rate': 0.028528007733502534, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1091722.3750 - accuracy: 0.8898 - val_loss: 0.6932 - val_accuracy: 0.5154\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1815 - accuracy: 0.9220 - val_loss: 0.7016 - val_accuracy: 0.4949\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1990 - accuracy: 0.9043 - val_loss: 0.6998 - val_accuracy: 0.5134\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1911 - accuracy: 0.9198 - val_loss: 0.6932 - val_accuracy: 0.5010\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1895 - accuracy: 0.9061 - val_loss: 0.6926 - val_accuracy: 0.5165\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1933 - accuracy: 0.9175 - val_loss: 0.7666 - val_accuracy: 0.4887\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.8955 - val_loss: 0.7135 - val_accuracy: 0.5021\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1898 - accuracy: 0.9017 - val_loss: 0.6929 - val_accuracy: 0.5247\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9083 - val_loss: 0.6934 - val_accuracy: 0.4897\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2019 - accuracy: 0.9056 - val_loss: 0.7128 - val_accuracy: 0.4835\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9039 - val_loss: 0.7089 - val_accuracy: 0.5134\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9127 - val_loss: 0.6975 - val_accuracy: 0.4846\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9074 - val_loss: 0.6942 - val_accuracy: 0.5175\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9145 - val_loss: 0.6975 - val_accuracy: 0.5154\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2002 - accuracy: 0.9043 - val_loss: 0.6927 - val_accuracy: 0.5144\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2088 - accuracy: 0.8999 - val_loss: 0.6980 - val_accuracy: 0.5062\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1976 - accuracy: 0.9083 - val_loss: 0.6974 - val_accuracy: 0.5144\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1936 - accuracy: 0.9078 - val_loss: 0.7151 - val_accuracy: 0.5226\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9184 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9061 - val_loss: 0.6960 - val_accuracy: 0.4969\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1999 - accuracy: 0.9061 - val_loss: 0.6940 - val_accuracy: 0.5031\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9118 - val_loss: 0.7431 - val_accuracy: 0.4835\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9048 - val_loss: 0.7064 - val_accuracy: 0.4815\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2084 - accuracy: 0.9026 - val_loss: 0.7028 - val_accuracy: 0.4897\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9056 - val_loss: 0.6980 - val_accuracy: 0.4877\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2008 - accuracy: 0.8937 - val_loss: 0.6956 - val_accuracy: 0.4784\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1953 - accuracy: 0.9136 - val_loss: 0.7193 - val_accuracy: 0.4856\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9096 - val_loss: 0.6945 - val_accuracy: 0.4846\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9118 - val_loss: 0.6954 - val_accuracy: 0.5216\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1845 - accuracy: 0.9175 - val_loss: 0.6937 - val_accuracy: 0.5113\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1915 - accuracy: 0.9078 - val_loss: 0.6943 - val_accuracy: 0.4805\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9118 - val_loss: 0.6944 - val_accuracy: 0.5051\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1914 - accuracy: 0.9153 - val_loss: 0.7031 - val_accuracy: 0.5010\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1923 - accuracy: 0.9175 - val_loss: 0.6928 - val_accuracy: 0.5134\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1985 - accuracy: 0.9118 - val_loss: 0.7169 - val_accuracy: 0.5051\n","Epoch 36/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1957 - accuracy: 0.9048 - val_loss: 0.7041 - val_accuracy: 0.5195\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9193 - val_loss: 0.7010 - val_accuracy: 0.5082\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9127 - val_loss: 0.6978 - val_accuracy: 0.4938\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9070 - val_loss: 0.6929 - val_accuracy: 0.5123\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1890 - accuracy: 0.9193 - val_loss: 0.7505 - val_accuracy: 0.4918\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1991 - accuracy: 0.9074 - val_loss: 0.6931 - val_accuracy: 0.5195\n","Epoch 42/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1974 - accuracy: 0.9149 - val_loss: 0.7088 - val_accuracy: 0.5103\n","Epoch 43/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1875 - accuracy: 0.9211 - val_loss: 0.6927 - val_accuracy: 0.5195\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1933 - accuracy: 0.9052 - val_loss: 0.6935 - val_accuracy: 0.5154\n","Epoch 45/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1920 - accuracy: 0.9118 - val_loss: 0.7456 - val_accuracy: 0.5093\n","Epoch 46/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1947 - accuracy: 0.9127 - val_loss: 0.7123 - val_accuracy: 0.5062\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1954 - accuracy: 0.9070 - val_loss: 0.7070 - val_accuracy: 0.4866\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1924 - accuracy: 0.9074 - val_loss: 0.6933 - val_accuracy: 0.5051\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1944 - accuracy: 0.9105 - val_loss: 0.7065 - val_accuracy: 0.4722\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9021 - val_loss: 0.7134 - val_accuracy: 0.5093\n","Score: 0.5092592835426331 \n","Parameters:  {'learning_rate': 0.13597284464736922, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 494.0386 - accuracy: 0.9101 - val_loss: 22.6191 - val_accuracy: 0.5237\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 139.2295 - accuracy: 0.9030 - val_loss: 0.6926 - val_accuracy: 0.5144\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2860 - accuracy: 0.9175 - val_loss: 0.8110 - val_accuracy: 0.4990\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2611 - accuracy: 0.9242 - val_loss: 0.8179 - val_accuracy: 0.5154\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2279 - accuracy: 0.9065 - val_loss: 0.7030 - val_accuracy: 0.5267\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2164 - accuracy: 0.9105 - val_loss: 0.7034 - val_accuracy: 0.5051\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2276 - accuracy: 0.9149 - val_loss: 0.6923 - val_accuracy: 0.5216\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2549 - accuracy: 0.9096 - val_loss: 0.6945 - val_accuracy: 0.4774\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2676 - accuracy: 0.9118 - val_loss: 0.7593 - val_accuracy: 0.5113\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2758 - accuracy: 0.9136 - val_loss: 0.7428 - val_accuracy: 0.5267\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2846 - accuracy: 0.9127 - val_loss: 0.7575 - val_accuracy: 0.5134\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2797 - accuracy: 0.9171 - val_loss: 0.7834 - val_accuracy: 0.5175\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2861 - accuracy: 0.9083 - val_loss: 0.7384 - val_accuracy: 0.5195\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2791 - accuracy: 0.9184 - val_loss: 0.7793 - val_accuracy: 0.5391\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2714 - accuracy: 0.9171 - val_loss: 0.7731 - val_accuracy: 0.5226\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2806 - accuracy: 0.9127 - val_loss: 0.7532 - val_accuracy: 0.5237\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2886 - accuracy: 0.9105 - val_loss: 0.7509 - val_accuracy: 0.5165\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2829 - accuracy: 0.9145 - val_loss: 0.7618 - val_accuracy: 0.5175\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2733 - accuracy: 0.9189 - val_loss: 0.7779 - val_accuracy: 0.5237\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2797 - accuracy: 0.9153 - val_loss: 0.7790 - val_accuracy: 0.5206\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2733 - accuracy: 0.9193 - val_loss: 0.8002 - val_accuracy: 0.5288\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2755 - accuracy: 0.9145 - val_loss: 0.7763 - val_accuracy: 0.5021\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2783 - accuracy: 0.9153 - val_loss: 0.7589 - val_accuracy: 0.5257\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2751 - accuracy: 0.9184 - val_loss: 0.7730 - val_accuracy: 0.5350\n","Epoch 25/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2827 - accuracy: 0.9127 - val_loss: 0.7720 - val_accuracy: 0.5103\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2795 - accuracy: 0.9162 - val_loss: 0.8097 - val_accuracy: 0.4949\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2737 - accuracy: 0.9158 - val_loss: 0.7517 - val_accuracy: 0.5412\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2804 - accuracy: 0.9118 - val_loss: 0.7528 - val_accuracy: 0.5134\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2879 - accuracy: 0.9127 - val_loss: 0.7774 - val_accuracy: 0.5093\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2848 - accuracy: 0.9109 - val_loss: 0.7685 - val_accuracy: 0.5031\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2852 - accuracy: 0.9140 - val_loss: 0.7799 - val_accuracy: 0.4990\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2715 - accuracy: 0.9215 - val_loss: 0.7933 - val_accuracy: 0.5278\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2876 - accuracy: 0.9034 - val_loss: 0.7235 - val_accuracy: 0.5175\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2976 - accuracy: 0.9078 - val_loss: 0.7568 - val_accuracy: 0.5113\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2829 - accuracy: 0.9162 - val_loss: 0.7831 - val_accuracy: 0.5257\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2787 - accuracy: 0.9162 - val_loss: 0.7957 - val_accuracy: 0.5216\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2728 - accuracy: 0.9198 - val_loss: 0.8051 - val_accuracy: 0.5185\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2721 - accuracy: 0.9180 - val_loss: 0.7849 - val_accuracy: 0.5226\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2774 - accuracy: 0.9162 - val_loss: 0.8044 - val_accuracy: 0.4969\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2733 - accuracy: 0.9171 - val_loss: 0.7811 - val_accuracy: 0.5298\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2806 - accuracy: 0.9140 - val_loss: 0.7889 - val_accuracy: 0.5031\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2887 - accuracy: 0.9083 - val_loss: 0.7596 - val_accuracy: 0.5072\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2844 - accuracy: 0.9140 - val_loss: 0.7884 - val_accuracy: 0.5051\n","Epoch 44/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2731 - accuracy: 0.9198 - val_loss: 0.8171 - val_accuracy: 0.5010\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2685 - accuracy: 0.9198 - val_loss: 0.8072 - val_accuracy: 0.5041\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2781 - accuracy: 0.9140 - val_loss: 0.7686 - val_accuracy: 0.5247\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2643 - accuracy: 0.9268 - val_loss: 0.8441 - val_accuracy: 0.5257\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2741 - accuracy: 0.9118 - val_loss: 0.7688 - val_accuracy: 0.5062\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2810 - accuracy: 0.9140 - val_loss: 0.7705 - val_accuracy: 0.5123\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2855 - accuracy: 0.9127 - val_loss: 0.7765 - val_accuracy: 0.5185\n","Score: 0.5185185074806213 \n","Parameters:  {'learning_rate': 0.0165097611657914, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 1.6714 - accuracy: 0.9096 - val_loss: 0.6514 - val_accuracy: 0.6492\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1764 - accuracy: 0.9193 - val_loss: 0.6373 - val_accuracy: 0.6821\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2164 - accuracy: 0.9074 - val_loss: 0.6950 - val_accuracy: 0.5154\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2035 - accuracy: 0.9211 - val_loss: 0.6256 - val_accuracy: 0.7006\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1702 - accuracy: 0.9343 - val_loss: 0.6394 - val_accuracy: 0.6667\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9264 - val_loss: 0.5639 - val_accuracy: 0.6914\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1892 - accuracy: 0.9396 - val_loss: 0.5825 - val_accuracy: 0.7202\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2421 - accuracy: 0.9136 - val_loss: 0.6695 - val_accuracy: 0.6914\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3538 - accuracy: 0.9184 - val_loss: 0.7119 - val_accuracy: 0.5175\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2548 - accuracy: 0.9255 - val_loss: 0.6224 - val_accuracy: 0.6296\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2306 - accuracy: 0.9220 - val_loss: 0.6174 - val_accuracy: 0.7099\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1834 - accuracy: 0.9272 - val_loss: 0.5689 - val_accuracy: 0.7325\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9312 - val_loss: 0.6672 - val_accuracy: 0.6286\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1707 - accuracy: 0.9356 - val_loss: 0.5532 - val_accuracy: 0.7479\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1885 - accuracy: 0.9339 - val_loss: 0.5845 - val_accuracy: 0.6944\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1642 - accuracy: 0.9312 - val_loss: 0.5432 - val_accuracy: 0.7274\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1748 - accuracy: 0.9321 - val_loss: 0.5573 - val_accuracy: 0.7459\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1622 - accuracy: 0.9330 - val_loss: 0.5372 - val_accuracy: 0.7377\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1887 - accuracy: 0.9396 - val_loss: 0.5117 - val_accuracy: 0.7675\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1541 - accuracy: 0.9277 - val_loss: 0.4956 - val_accuracy: 0.7881\n","Epoch 21/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2369 - accuracy: 0.9339 - val_loss: 0.5224 - val_accuracy: 0.7603\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1502 - accuracy: 0.9299 - val_loss: 0.4686 - val_accuracy: 0.8035\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1659 - accuracy: 0.9325 - val_loss: 0.5007 - val_accuracy: 0.7747\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1546 - accuracy: 0.9444 - val_loss: 0.6158 - val_accuracy: 0.7449\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1443 - accuracy: 0.9414 - val_loss: 0.5549 - val_accuracy: 0.7233\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1663 - accuracy: 0.9334 - val_loss: 0.4966 - val_accuracy: 0.7726\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1666 - accuracy: 0.9365 - val_loss: 0.5337 - val_accuracy: 0.7243\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9418 - val_loss: 0.5049 - val_accuracy: 0.7634\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9466 - val_loss: 0.5082 - val_accuracy: 0.7778\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1626 - accuracy: 0.9405 - val_loss: 0.4666 - val_accuracy: 0.7932\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1705 - accuracy: 0.9356 - val_loss: 0.4723 - val_accuracy: 0.7891\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1415 - accuracy: 0.9356 - val_loss: 0.4765 - val_accuracy: 0.7850\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1470 - accuracy: 0.9378 - val_loss: 0.4518 - val_accuracy: 0.7984\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1510 - accuracy: 0.9352 - val_loss: 0.4599 - val_accuracy: 0.8004\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1471 - accuracy: 0.9321 - val_loss: 0.5042 - val_accuracy: 0.7459\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1753 - accuracy: 0.9374 - val_loss: 0.5138 - val_accuracy: 0.7634\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1473 - accuracy: 0.9422 - val_loss: 0.4763 - val_accuracy: 0.7551\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1362 - accuracy: 0.9392 - val_loss: 0.4919 - val_accuracy: 0.7757\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1614 - accuracy: 0.9405 - val_loss: 0.4816 - val_accuracy: 0.7582\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1440 - accuracy: 0.9409 - val_loss: 0.4978 - val_accuracy: 0.7562\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1572 - accuracy: 0.9396 - val_loss: 0.4755 - val_accuracy: 0.7737\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1540 - accuracy: 0.9418 - val_loss: 0.4526 - val_accuracy: 0.7953\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1527 - accuracy: 0.9378 - val_loss: 0.4915 - val_accuracy: 0.7695\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1568 - accuracy: 0.9352 - val_loss: 0.5120 - val_accuracy: 0.7541\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1865 - accuracy: 0.9383 - val_loss: 0.4629 - val_accuracy: 0.7809\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2360 - accuracy: 0.9422 - val_loss: 0.4712 - val_accuracy: 0.7881\n","Epoch 47/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1936 - accuracy: 0.9317 - val_loss: 0.4875 - val_accuracy: 0.7881\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1502 - accuracy: 0.9449 - val_loss: 0.4370 - val_accuracy: 0.8004\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.9458 - val_loss: 0.4758 - val_accuracy: 0.7850\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1506 - accuracy: 0.9506 - val_loss: 0.4960 - val_accuracy: 0.7798\n","Score: 0.7798354029655457 \n","Parameters:  {'learning_rate': 0.0016086310480853045, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6130 - accuracy: 0.9109 - val_loss: 0.7275 - val_accuracy: 0.5185\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2335 - accuracy: 0.9202 - val_loss: 0.7321 - val_accuracy: 0.5031\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2524 - accuracy: 0.9250 - val_loss: 1.1283 - val_accuracy: 0.6759\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1945 - accuracy: 0.9383 - val_loss: 0.6621 - val_accuracy: 0.6872\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2246 - accuracy: 0.9277 - val_loss: 0.5932 - val_accuracy: 0.7037\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2136 - accuracy: 0.9317 - val_loss: 0.5776 - val_accuracy: 0.7325\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1743 - accuracy: 0.9365 - val_loss: 0.5746 - val_accuracy: 0.7140\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1737 - accuracy: 0.9347 - val_loss: 0.5632 - val_accuracy: 0.7305\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2427 - accuracy: 0.9101 - val_loss: 0.7009 - val_accuracy: 0.5442\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2343 - accuracy: 0.9325 - val_loss: 0.5929 - val_accuracy: 0.7130\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1868 - accuracy: 0.9180 - val_loss: 0.6345 - val_accuracy: 0.6811\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1964 - accuracy: 0.9272 - val_loss: 0.5645 - val_accuracy: 0.7377\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1802 - accuracy: 0.9255 - val_loss: 0.5891 - val_accuracy: 0.7150\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2185 - accuracy: 0.9224 - val_loss: 0.5598 - val_accuracy: 0.7243\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1597 - accuracy: 0.9387 - val_loss: 0.5591 - val_accuracy: 0.7325\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1746 - accuracy: 0.9378 - val_loss: 0.5319 - val_accuracy: 0.7541\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1668 - accuracy: 0.9321 - val_loss: 0.5315 - val_accuracy: 0.7130\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1679 - accuracy: 0.9369 - val_loss: 0.6118 - val_accuracy: 0.7644\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2613 - accuracy: 0.9378 - val_loss: 0.5298 - val_accuracy: 0.7325\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1480 - accuracy: 0.9356 - val_loss: 0.5156 - val_accuracy: 0.7428\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1610 - accuracy: 0.9431 - val_loss: 0.4566 - val_accuracy: 0.7737\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1439 - accuracy: 0.9436 - val_loss: 0.4664 - val_accuracy: 0.7675\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1343 - accuracy: 0.9511 - val_loss: 0.4530 - val_accuracy: 0.7953\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1473 - accuracy: 0.9400 - val_loss: 0.4549 - val_accuracy: 0.7695\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1435 - accuracy: 0.9462 - val_loss: 0.4469 - val_accuracy: 0.7891\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1487 - accuracy: 0.9453 - val_loss: 0.4870 - val_accuracy: 0.7644\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1896 - accuracy: 0.9427 - val_loss: 0.5270 - val_accuracy: 0.7562\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2239 - accuracy: 0.9466 - val_loss: 0.4721 - val_accuracy: 0.7932\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2167 - accuracy: 0.9466 - val_loss: 0.4692 - val_accuracy: 0.7706\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9489 - val_loss: 0.4579 - val_accuracy: 0.7840\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1468 - accuracy: 0.9502 - val_loss: 0.4292 - val_accuracy: 0.8107\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1310 - accuracy: 0.9550 - val_loss: 0.3921 - val_accuracy: 0.8292\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1177 - accuracy: 0.9541 - val_loss: 0.4082 - val_accuracy: 0.8107\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.9528 - val_loss: 0.3850 - val_accuracy: 0.8241\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9537 - val_loss: 0.4130 - val_accuracy: 0.7942\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1495 - accuracy: 0.9519 - val_loss: 0.4229 - val_accuracy: 0.8128\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1004 - accuracy: 0.9568 - val_loss: 0.3824 - val_accuracy: 0.8447\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2719 - accuracy: 0.9555 - val_loss: 0.3646 - val_accuracy: 0.8251\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1470 - accuracy: 0.9581 - val_loss: 0.3546 - val_accuracy: 0.8333\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1214 - accuracy: 0.9572 - val_loss: 0.3674 - val_accuracy: 0.8292\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1336 - accuracy: 0.9541 - val_loss: 0.3159 - val_accuracy: 0.8549\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.9497 - val_loss: 0.3869 - val_accuracy: 0.8241\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0990 - accuracy: 0.9616 - val_loss: 0.3763 - val_accuracy: 0.8416\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.9612 - val_loss: 0.3260 - val_accuracy: 0.8405\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9638 - val_loss: 0.3080 - val_accuracy: 0.8467\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1374 - accuracy: 0.9497 - val_loss: 0.3244 - val_accuracy: 0.8539\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1447 - accuracy: 0.9559 - val_loss: 0.4044 - val_accuracy: 0.8158\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1129 - accuracy: 0.9630 - val_loss: 0.3056 - val_accuracy: 0.8539\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0902 - accuracy: 0.9722 - val_loss: 0.3136 - val_accuracy: 0.8724\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1165 - accuracy: 0.9563 - val_loss: 0.2894 - val_accuracy: 0.8601\n","Score: 0.8600823283195496 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.8339 - accuracy: 0.9281 - val_loss: 0.6550 - val_accuracy: 0.6430\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2743 - accuracy: 0.9242 - val_loss: 0.5430 - val_accuracy: 0.7428\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1888 - accuracy: 0.9281 - val_loss: 0.5398 - val_accuracy: 0.7459\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2217 - accuracy: 0.9242 - val_loss: 0.5407 - val_accuracy: 0.7058\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3920 - accuracy: 0.9233 - val_loss: 0.5261 - val_accuracy: 0.7397\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2619 - accuracy: 0.9352 - val_loss: 0.5406 - val_accuracy: 0.7212\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.5954 - accuracy: 0.9180 - val_loss: 0.5571 - val_accuracy: 0.6533\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1646 - accuracy: 0.9369 - val_loss: 0.5028 - val_accuracy: 0.7428\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1482 - accuracy: 0.9356 - val_loss: 0.4707 - val_accuracy: 0.7500\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9414 - val_loss: 0.5143 - val_accuracy: 0.7562\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9444 - val_loss: 0.4631 - val_accuracy: 0.7603\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.9409 - val_loss: 0.4250 - val_accuracy: 0.8025\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.9528 - val_loss: 0.8885 - val_accuracy: 0.8025\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1498 - accuracy: 0.9436 - val_loss: 0.4093 - val_accuracy: 0.8107\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1623 - accuracy: 0.9387 - val_loss: 0.4755 - val_accuracy: 0.7449\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1282 - accuracy: 0.9436 - val_loss: 0.5056 - val_accuracy: 0.7716\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1577 - accuracy: 0.9418 - val_loss: 0.3610 - val_accuracy: 0.8158\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1046 - accuracy: 0.9550 - val_loss: 0.4475 - val_accuracy: 0.7747\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1244 - accuracy: 0.9555 - val_loss: 0.3909 - val_accuracy: 0.8056\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1361 - accuracy: 0.9550 - val_loss: 0.3578 - val_accuracy: 0.8179\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1450 - accuracy: 0.9502 - val_loss: 0.3230 - val_accuracy: 0.8570\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1287 - accuracy: 0.9568 - val_loss: 0.3016 - val_accuracy: 0.8488\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1107 - accuracy: 0.9625 - val_loss: 0.3545 - val_accuracy: 0.8282\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1149 - accuracy: 0.9533 - val_loss: 0.3399 - val_accuracy: 0.8436\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1112 - accuracy: 0.9590 - val_loss: 0.3205 - val_accuracy: 0.8354\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1123 - accuracy: 0.9577 - val_loss: 0.3107 - val_accuracy: 0.8683\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0961 - accuracy: 0.9656 - val_loss: 0.3882 - val_accuracy: 0.8436\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0975 - accuracy: 0.9647 - val_loss: 0.2535 - val_accuracy: 0.8858\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1153 - accuracy: 0.9616 - val_loss: 0.2798 - val_accuracy: 0.8868\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0969 - accuracy: 0.9674 - val_loss: 0.2916 - val_accuracy: 0.8786\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1062 - accuracy: 0.9612 - val_loss: 0.2864 - val_accuracy: 0.8776\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0892 - accuracy: 0.9678 - val_loss: 0.2421 - val_accuracy: 0.8899\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0809 - accuracy: 0.9718 - val_loss: 0.2600 - val_accuracy: 0.8920\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1748 - accuracy: 0.9683 - val_loss: 0.2486 - val_accuracy: 0.8837\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0781 - accuracy: 0.9687 - val_loss: 0.2550 - val_accuracy: 0.8868\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0955 - accuracy: 0.9691 - val_loss: 0.2904 - val_accuracy: 0.8765\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0815 - accuracy: 0.9713 - val_loss: 0.2226 - val_accuracy: 0.9084\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0856 - accuracy: 0.9687 - val_loss: 0.2587 - val_accuracy: 0.8899\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0754 - accuracy: 0.9722 - val_loss: 0.3143 - val_accuracy: 0.8704\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0774 - accuracy: 0.9757 - val_loss: 0.2119 - val_accuracy: 0.9115\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9713 - val_loss: 0.2492 - val_accuracy: 0.9033\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0634 - accuracy: 0.9771 - val_loss: 0.2345 - val_accuracy: 0.9002\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0519 - accuracy: 0.9837 - val_loss: 0.2622 - val_accuracy: 0.9053\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0589 - accuracy: 0.9828 - val_loss: 0.1638 - val_accuracy: 0.9362\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0402 - accuracy: 0.9854 - val_loss: 0.1780 - val_accuracy: 0.9311\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.1860 - val_accuracy: 0.9259\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.2495 - val_accuracy: 0.8951\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.1536 - val_accuracy: 0.9527\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0299 - accuracy: 0.9885 - val_loss: 0.2386 - val_accuracy: 0.9259\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.0903 - accuracy: 0.9771 - val_loss: 0.1713 - val_accuracy: 0.9228\n","Score: 0.9228395223617554 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 50.5217 - accuracy: 0.9109 - val_loss: 0.6953 - val_accuracy: 0.5175\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2379 - accuracy: 0.9211 - val_loss: 0.6944 - val_accuracy: 0.5226\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2640 - accuracy: 0.9136 - val_loss: 0.7159 - val_accuracy: 0.5093\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2491 - accuracy: 0.9109 - val_loss: 0.6977 - val_accuracy: 0.4856\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2474 - accuracy: 0.9030 - val_loss: 0.6934 - val_accuracy: 0.4856\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2499 - accuracy: 0.9078 - val_loss: 0.6956 - val_accuracy: 0.4691\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2444 - accuracy: 0.9030 - val_loss: 0.6927 - val_accuracy: 0.5082\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2420 - accuracy: 0.9145 - val_loss: 0.7124 - val_accuracy: 0.5103\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2328 - accuracy: 0.9052 - val_loss: 0.6929 - val_accuracy: 0.4938\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2285 - accuracy: 0.9171 - val_loss: 0.6920 - val_accuracy: 0.5216\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 0.7002 - val_accuracy: 0.5185\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2408 - accuracy: 0.9127 - val_loss: 0.6976 - val_accuracy: 0.5185\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2275 - accuracy: 0.9215 - val_loss: 0.7447 - val_accuracy: 0.5216\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2021 - accuracy: 0.9083 - val_loss: 0.6932 - val_accuracy: 0.4794\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9198 - val_loss: 0.6979 - val_accuracy: 0.5010\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2105 - accuracy: 0.9136 - val_loss: 0.7182 - val_accuracy: 0.5144\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2016 - accuracy: 0.9127 - val_loss: 0.6946 - val_accuracy: 0.5113\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9061 - val_loss: 0.6932 - val_accuracy: 0.4990\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1957 - accuracy: 0.9127 - val_loss: 0.6941 - val_accuracy: 0.5021\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2007 - accuracy: 0.9109 - val_loss: 0.7105 - val_accuracy: 0.4866\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2142 - accuracy: 0.8995 - val_loss: 0.6924 - val_accuracy: 0.5082\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1868 - accuracy: 0.9118 - val_loss: 0.6950 - val_accuracy: 0.4969\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2000 - accuracy: 0.9114 - val_loss: 0.6932 - val_accuracy: 0.5278\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2124 - accuracy: 0.9162 - val_loss: 0.6985 - val_accuracy: 0.5103\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2273 - accuracy: 0.9101 - val_loss: 0.6957 - val_accuracy: 0.5021\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2401 - accuracy: 0.9153 - val_loss: 0.6993 - val_accuracy: 0.5165\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2734 - accuracy: 0.9092 - val_loss: 0.7201 - val_accuracy: 0.4949\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2810 - accuracy: 0.9175 - val_loss: 0.8139 - val_accuracy: 0.5134\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2803 - accuracy: 0.9193 - val_loss: 0.8725 - val_accuracy: 0.5175\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2942 - accuracy: 0.9149 - val_loss: 0.9311 - val_accuracy: 0.5226\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2824 - accuracy: 0.9198 - val_loss: 0.9648 - val_accuracy: 0.5206\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2910 - accuracy: 0.9131 - val_loss: 0.9404 - val_accuracy: 0.5154\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2925 - accuracy: 0.9149 - val_loss: 0.9543 - val_accuracy: 0.5134\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2875 - accuracy: 0.9171 - val_loss: 0.9371 - val_accuracy: 0.5257\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2939 - accuracy: 0.9127 - val_loss: 0.9566 - val_accuracy: 0.5031\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2887 - accuracy: 0.9171 - val_loss: 0.9547 - val_accuracy: 0.5216\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2941 - accuracy: 0.9131 - val_loss: 0.9416 - val_accuracy: 0.5134\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3006 - accuracy: 0.9105 - val_loss: 0.9318 - val_accuracy: 0.5154\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2906 - accuracy: 0.9162 - val_loss: 0.9700 - val_accuracy: 0.5082\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2877 - accuracy: 0.9162 - val_loss: 0.9553 - val_accuracy: 0.5185\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2927 - accuracy: 0.9140 - val_loss: 0.9384 - val_accuracy: 0.5226\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2792 - accuracy: 0.9215 - val_loss: 0.9835 - val_accuracy: 0.5165\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2933 - accuracy: 0.9114 - val_loss: 0.9255 - val_accuracy: 0.5206\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2913 - accuracy: 0.9162 - val_loss: 0.9788 - val_accuracy: 0.5072\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2977 - accuracy: 0.9105 - val_loss: 0.9319 - val_accuracy: 0.5144\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2846 - accuracy: 0.9198 - val_loss: 1.0002 - val_accuracy: 0.4990\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2726 - accuracy: 0.9242 - val_loss: 0.9782 - val_accuracy: 0.5278\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2933 - accuracy: 0.9109 - val_loss: 0.9293 - val_accuracy: 0.5216\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2903 - accuracy: 0.9167 - val_loss: 0.9489 - val_accuracy: 0.5195\n","Epoch 50/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2813 - accuracy: 0.9198 - val_loss: 0.9722 - val_accuracy: 0.5216\n","Score: 0.5216049551963806 \n","Parameters:  {'learning_rate': 0.008883763203436893, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.6038 - accuracy: 0.9162 - val_loss: 0.5981 - val_accuracy: 0.7160\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1921 - accuracy: 0.9312 - val_loss: 0.5680 - val_accuracy: 0.7058\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1700 - accuracy: 0.9325 - val_loss: 0.5402 - val_accuracy: 0.7459\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1618 - accuracy: 0.9347 - val_loss: 0.4916 - val_accuracy: 0.7675\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1483 - accuracy: 0.9440 - val_loss: 0.5187 - val_accuracy: 0.7634\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.3321 - accuracy: 0.9422 - val_loss: 0.5519 - val_accuracy: 0.7377\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1565 - accuracy: 0.9356 - val_loss: 0.4826 - val_accuracy: 0.7593\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1429 - accuracy: 0.9440 - val_loss: 0.4563 - val_accuracy: 0.7716\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1524 - accuracy: 0.9449 - val_loss: 0.4385 - val_accuracy: 0.8045\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1494 - accuracy: 0.9409 - val_loss: 0.5264 - val_accuracy: 0.7284\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1994 - accuracy: 0.9343 - val_loss: 0.4190 - val_accuracy: 0.8066\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1346 - accuracy: 0.9475 - val_loss: 0.4476 - val_accuracy: 0.7767\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1540 - accuracy: 0.9427 - val_loss: 0.4481 - val_accuracy: 0.7850\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1384 - accuracy: 0.9458 - val_loss: 0.4550 - val_accuracy: 0.7798\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9511 - val_loss: 0.4351 - val_accuracy: 0.7932\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1438 - accuracy: 0.9484 - val_loss: 0.3930 - val_accuracy: 0.8158\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9493 - val_loss: 0.4311 - val_accuracy: 0.7963\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9431 - val_loss: 0.4389 - val_accuracy: 0.7881\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1451 - accuracy: 0.9365 - val_loss: 0.4064 - val_accuracy: 0.7994\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1235 - accuracy: 0.9506 - val_loss: 0.3836 - val_accuracy: 0.8158\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1437 - accuracy: 0.9497 - val_loss: 0.3795 - val_accuracy: 0.8169\n","Epoch 22/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.9528 - val_loss: 0.3876 - val_accuracy: 0.8220\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1270 - accuracy: 0.9471 - val_loss: 0.3786 - val_accuracy: 0.8138\n","Epoch 24/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9471 - val_loss: 0.4059 - val_accuracy: 0.7901\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1570 - accuracy: 0.9471 - val_loss: 0.4304 - val_accuracy: 0.8117\n","Epoch 26/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1282 - accuracy: 0.9480 - val_loss: 0.4015 - val_accuracy: 0.8004\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2239 - accuracy: 0.9449 - val_loss: 0.3801 - val_accuracy: 0.8117\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.9537 - val_loss: 0.3828 - val_accuracy: 0.8313\n","Epoch 29/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1376 - accuracy: 0.9484 - val_loss: 0.3753 - val_accuracy: 0.8292\n","Epoch 30/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.9489 - val_loss: 0.3737 - val_accuracy: 0.8210\n","Epoch 31/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.9515 - val_loss: 0.3835 - val_accuracy: 0.8097\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1312 - accuracy: 0.9533 - val_loss: 0.3965 - val_accuracy: 0.8333\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.9528 - val_loss: 0.3685 - val_accuracy: 0.8210\n","Epoch 34/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.9537 - val_loss: 0.3719 - val_accuracy: 0.8261\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1314 - accuracy: 0.9506 - val_loss: 0.3692 - val_accuracy: 0.8179\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1309 - accuracy: 0.9515 - val_loss: 0.4014 - val_accuracy: 0.8128\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1689 - accuracy: 0.9436 - val_loss: 0.4326 - val_accuracy: 0.7870\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.9466 - val_loss: 0.3801 - val_accuracy: 0.8251\n","Epoch 39/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2540 - accuracy: 0.9497 - val_loss: 0.3880 - val_accuracy: 0.8148\n","Epoch 40/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1107 - accuracy: 0.9572 - val_loss: 0.3822 - val_accuracy: 0.8292\n","Epoch 41/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1035 - accuracy: 0.9612 - val_loss: 0.3771 - val_accuracy: 0.8241\n","Epoch 42/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9581 - val_loss: 0.3823 - val_accuracy: 0.8272\n","Epoch 43/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1508 - accuracy: 0.9409 - val_loss: 0.3800 - val_accuracy: 0.8241\n","Epoch 44/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1098 - accuracy: 0.9541 - val_loss: 0.3837 - val_accuracy: 0.8128\n","Epoch 45/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1013 - accuracy: 0.9599 - val_loss: 0.3359 - val_accuracy: 0.8395\n","Epoch 46/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1227 - accuracy: 0.9555 - val_loss: 0.3612 - val_accuracy: 0.8282\n","Epoch 47/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1166 - accuracy: 0.9568 - val_loss: 0.4258 - val_accuracy: 0.8107\n","Epoch 48/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1523 - accuracy: 0.9541 - val_loss: 0.3552 - val_accuracy: 0.8436\n","Epoch 49/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.9634 - val_loss: 0.3425 - val_accuracy: 0.8395\n","Epoch 50/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.1023 - accuracy: 0.9563 - val_loss: 0.3382 - val_accuracy: 0.8539\n","Score: 0.8539094924926758 \n","Parameters:  {'learning_rate': 0.001, 'num_filters': [32, 32], 'stride': [3, 3], 'epochs': 50, 'dense_layer': 256, 'batch_size': 32}\n","Epoch 1/50\n","567/567 [==============================] - 3s 6ms/step - loss: 2330.2334 - accuracy: 0.9136 - val_loss: 0.6988 - val_accuracy: 0.5113\n","Epoch 2/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.9180 - val_loss: 0.6928 - val_accuracy: 0.5185\n","Epoch 3/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2612 - accuracy: 0.9123 - val_loss: 0.6920 - val_accuracy: 0.5288\n","Epoch 4/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2547 - accuracy: 0.9193 - val_loss: 0.7109 - val_accuracy: 0.5216\n","Epoch 5/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2635 - accuracy: 0.9061 - val_loss: 0.6938 - val_accuracy: 0.5021\n","Epoch 6/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2629 - accuracy: 0.9167 - val_loss: 0.6974 - val_accuracy: 0.5206\n","Epoch 7/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2547 - accuracy: 0.9171 - val_loss: 0.6992 - val_accuracy: 0.5134\n","Epoch 8/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2595 - accuracy: 0.9184 - val_loss: 0.7269 - val_accuracy: 0.4959\n","Epoch 9/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2618 - accuracy: 0.9127 - val_loss: 0.6963 - val_accuracy: 0.5154\n","Epoch 10/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2536 - accuracy: 0.9206 - val_loss: 0.7130 - val_accuracy: 0.5134\n","Epoch 11/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2622 - accuracy: 0.9136 - val_loss: 0.7100 - val_accuracy: 0.4979\n","Epoch 12/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2589 - accuracy: 0.9171 - val_loss: 0.7049 - val_accuracy: 0.5123\n","Epoch 13/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2543 - accuracy: 0.9189 - val_loss: 0.7077 - val_accuracy: 0.5154\n","Epoch 14/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2580 - accuracy: 0.9145 - val_loss: 0.6981 - val_accuracy: 0.5247\n","Epoch 15/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2653 - accuracy: 0.9136 - val_loss: 0.7119 - val_accuracy: 0.5051\n","Epoch 16/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2513 - accuracy: 0.9215 - val_loss: 0.7294 - val_accuracy: 0.5072\n","Epoch 17/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2561 - accuracy: 0.9140 - val_loss: 0.6989 - val_accuracy: 0.5226\n","Epoch 18/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2627 - accuracy: 0.9127 - val_loss: 0.6951 - val_accuracy: 0.5093\n","Epoch 19/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2701 - accuracy: 0.9127 - val_loss: 0.7003 - val_accuracy: 0.5226\n","Epoch 20/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2679 - accuracy: 0.9087 - val_loss: 0.6947 - val_accuracy: 0.5195\n","Epoch 21/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2588 - accuracy: 0.9193 - val_loss: 0.7150 - val_accuracy: 0.5175\n","Epoch 22/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2551 - accuracy: 0.9184 - val_loss: 0.7178 - val_accuracy: 0.5154\n","Epoch 23/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2653 - accuracy: 0.9092 - val_loss: 0.6954 - val_accuracy: 0.5185\n","Epoch 24/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2635 - accuracy: 0.9153 - val_loss: 0.7077 - val_accuracy: 0.5123\n","Epoch 25/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2592 - accuracy: 0.9153 - val_loss: 0.7050 - val_accuracy: 0.5093\n","Epoch 26/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2620 - accuracy: 0.9167 - val_loss: 0.7212 - val_accuracy: 0.5093\n","Epoch 27/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9167 - val_loss: 0.7016 - val_accuracy: 0.5165\n","Epoch 28/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2610 - accuracy: 0.9136 - val_loss: 0.7002 - val_accuracy: 0.4949\n","Epoch 29/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2624 - accuracy: 0.9184 - val_loss: 0.7170 - val_accuracy: 0.4938\n","Epoch 30/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2554 - accuracy: 0.9136 - val_loss: 0.6988 - val_accuracy: 0.5072\n","Epoch 31/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2608 - accuracy: 0.9167 - val_loss: 0.7028 - val_accuracy: 0.5072\n","Epoch 32/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2670 - accuracy: 0.9149 - val_loss: 0.7170 - val_accuracy: 0.4928\n","Epoch 33/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2612 - accuracy: 0.9149 - val_loss: 0.7144 - val_accuracy: 0.5021\n","Epoch 34/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2623 - accuracy: 0.9140 - val_loss: 0.7054 - val_accuracy: 0.5134\n","Epoch 35/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2684 - accuracy: 0.9118 - val_loss: 0.7015 - val_accuracy: 0.5113\n","Epoch 36/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2655 - accuracy: 0.9136 - val_loss: 0.7093 - val_accuracy: 0.5072\n","Epoch 37/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2663 - accuracy: 0.9101 - val_loss: 0.6973 - val_accuracy: 0.5103\n","Epoch 38/50\n","567/567 [==============================] - 3s 5ms/step - loss: 0.2610 - accuracy: 0.9114 - val_loss: 0.6929 - val_accuracy: 0.5113\n","Epoch 39/50\n","567/567 [==============================] - 3s 6ms/step - loss: 0.2647 - accuracy: 0.9167 - val_loss: 0.7059 - val_accuracy: 0.5093\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","import numpy as np\n","\n","\n","# Define Objective Function\n","def objective_function(learning_rate, stride, dense_layer, num_filters, batch_size, epochs):\n","    model = build_model(learning_rate, stride, num_filters, dense_layer)\n","    \n","    # Train model\n","    history = model.fit(train, \n","                    batch_size=batch_size, \n","                    epochs=epochs,\n","                    validation_data=test,\n","                    verbose=1,\n","                    )\n","    \n","    # Return validation accuracy as score\n","    return history.history['val_accuracy'][-1]\n","\n","# Define Model Builder\n","def build_model(learning_rate, stride, num_filters, dense_layer):\n","    model = tf.keras.Sequential([\n","        layers.Conv2D(num_filters[0], (stride[0],stride[0]), activation='relu', input_shape=(7, 528, 1)),\n","        layers.Conv2D(num_filters[1], (stride[1],stride[1]), activation='relu'),\n","        layers.Flatten(),\n","        layers.Dense(dense_layer, activation='relu'),\n","        layers.Dense(1, activation='sigmoid')\n","    ])\n","    \n","    # Compile model\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    model.compile(optimizer=optimizer,\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    \n","    return model\n","\n","# Butterfly Optimization Function\n","def butterfly_optimization(objective_function, initial_hyperparameters, num_butterflies=10, max_iterations=50):\n","    global_best_hyperparameters = initial_hyperparameters.copy()\n","    global_best_score = objective_function(**initial_hyperparameters)\n","\n","    for iteration in range(max_iterations):\n","        for butterfly in range(num_butterflies):\n","            updated_hyperparameters = {}\n","            for param, value in initial_hyperparameters.items():\n","                if isinstance(value, float):\n","                    updated_value = value + np.random.normal(0, 0.1)\n","                    updated_hyperparameters[param] = np.clip(updated_value, 0.001, None)  # Ensure non-negative values\n","                elif isinstance(value, list):\n","                    updated_value = [int(np.round(v + np.random.normal(0, 0.1))) for v in value]\n","                    updated_hyperparameters[param] = [np.clip(v, 1, None) for v in updated_value]  # Ensure positive integers\n","                else:\n","                    updated_hyperparameters[param] = value\n","                \n","            score = objective_function(**updated_hyperparameters)\n","            print('Score:', score, '\\nParameters: ', updated_hyperparameters)\n","            if score > global_best_score:\n","                print('Global: ', updated_hyperparameters)\n","                global_best_score = score\n","                global_best_hyperparameters = updated_hyperparameters.copy()\n","        \n","        # Implement exploration and exploitation adjustments if needed\n","        \n","    return global_best_hyperparameters\n","\n","\n","# Define initial hyperparameters\n","initial_hyperparameters = {\n","    'learning_rate': 1e-5,\n","    'num_filters': [32, 32],\n","    'stride': [3, 3],\n","    'epochs': 50,\n","    'dense_layer':256,\n","    'batch_size': 32\n","}\n","\n","# Run Butterfly Optimization\n","best_hyperparameters = butterfly_optimization(objective_function, initial_hyperparameters)\n","\n","print(\"Best Hyperparameters:\", best_hyperparameters)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 114ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 26ms/step\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.94      0.91       468\n","         1.0       0.94      0.89      0.91       504\n","\n","    accuracy                           0.91       972\n","   macro avg       0.91      0.91      0.91       972\n","weighted avg       0.91      0.91      0.91       972\n","\n","[[440  28]\n"," [ 57 447]]\n"]}],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Step 4: Make predictions and evaluate on the test set\n","true_labels = []\n","predicted_labels = []\n","\n","for samples, labels in test.as_numpy_iterator():\n","    predictions = model0.predict(samples)\n","    predicted_classes = (predictions > 0.5).astype(int)  # Adjust threshold as needed for binary classification\n","    true_labels.extend(labels)\n","    predicted_labels.extend(predicted_classes)\n","\n","true_labels = np.array(true_labels)\n","predicted_labels = np.array(predicted_labels)\n","\n","# Step 5: Classification report and confusion matrix\n","print(classification_report(true_labels, predicted_labels))\n","print(confusion_matrix(true_labels, predicted_labels))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":768212,"sourceId":1324391,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":4}
